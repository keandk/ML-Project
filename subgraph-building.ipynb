{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import pydot # Import pydot\n",
    "import re # Import regex for label parsing\n",
    "# Make sure pydot.Error is accessible if needed for exception handling\n",
    "from pydot import Error as PydotError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define paths\n",
    "base_cpg_path = \"data_java/cpg-output\"\n",
    "json_path = \"data_java/center_nodes_result_specific.json\"\n",
    "output_base_path = \"data_java/subgraph_contexts\"\n",
    "\n",
    "# --- New: Define allowed neighbor labels ---\n",
    "allowed_neighbor_labels = {\n",
    "    'arrayInitializer', 'CatchClause', 'stonesoup_array', 'assignment',\n",
    "    'fieldAccess', 'addition', 'CONTROL_STRUCTURE', 'FIELD_IDENTIFIER',\n",
    "    'cast', 'IDENTIFIER', 'indexAccess', 'logicalAnd', 'CALL',\n",
    "    'logicalNot', 'alloc'\n",
    "}\n",
    "# Regex to extract the first word from the label attribute, assuming it's the type\n",
    "label_type_pattern = re.compile(r'^\"?([a-zA-Z_<>]+)')\n",
    "\n",
    "# Load the center nodes data from JSON\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        center_nodes_data = json.load(f)\n",
    "    logging.info(f\"Successfully loaded center nodes data from {json_path}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Error: JSON file not found at {json_path}\")\n",
    "    raise # Stop execution if JSON is missing\n",
    "except json.JSONDecodeError:\n",
    "    logging.error(f\"Error: Could not decode JSON from {json_path}\")\n",
    "    raise # Stop execution if JSON is invalid\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_base_path, exist_ok=True)\n",
    "logging.info(f\"Ensured output directory exists: {output_base_path}\")\n",
    "\n",
    "# Helper function to get node type from label attribute\n",
    "def get_node_type_from_attributes(attrs):\n",
    "    label_str = attrs.get('label')\n",
    "    if label_str:\n",
    "        match = label_type_pattern.match(label_str)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "# Process each entry in the JSON data\n",
    "for folder_name, center_node_ids_str in center_nodes_data.items():\n",
    "    logging.info(f\"Processing folder: {folder_name}\")\n",
    "    # Use the center node IDs from JSON directly (they are strings without quotes)\n",
    "    center_node_ids = set(center_node_ids_str)\n",
    "    folder_path = os.path.join(base_cpg_path, folder_name)\n",
    "\n",
    "    # Find the .dot file\n",
    "    dot_files = glob.glob(os.path.join(folder_path, '*.dot'))\n",
    "\n",
    "    if not dot_files:\n",
    "        logging.warning(f\"  No .dot file found in {folder_path}. Skipping.\")\n",
    "        continue\n",
    "    if len(dot_files) > 1:\n",
    "        logging.warning(f\"  Multiple .dot files found in {folder_path}. Using the first one: {dot_files[0]}.\")\n",
    "\n",
    "    dot_file_path = dot_files[0]\n",
    "    logging.info(f\"  Using .dot file: {dot_file_path}\")\n",
    "\n",
    "    relevant_lines = set()\n",
    "    # Nodes to include: Start with center nodes, add *filtered* neighbors later\n",
    "    nodes_to_include = set(center_node_ids)\n",
    "    nodes_definitions_added = set() # Track which node definitions we actually added (unquoted IDs)\n",
    "\n",
    "    try:\n",
    "        # Parse the dot file using pydot\n",
    "        logging.info(f\"  Parsing {dot_file_path} with pydot...\")\n",
    "        graphs = pydot.graph_from_dot_file(dot_file_path)\n",
    "\n",
    "        if not graphs:\n",
    "            logging.warning(f\"  pydot could not parse any graph from {dot_file_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if isinstance(graphs, list) and len(graphs) > 0 and isinstance(graphs[0], (pydot.Graph, pydot.Dot)):\n",
    "            graph = graphs[0] # Assign the first graph object\n",
    "            logging.info(f\"  Successfully parsed graph.\")\n",
    "        else:\n",
    "            logging.error(f\"  pydot.graph_from_dot_file did not return a valid graph object for {dot_file_path}. Found type: {type(graphs[0]) if graphs else 'None'}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- Build a map for quick node lookup by unquoted ID ---\n",
    "        logging.info(\"  Building node map...\")\n",
    "        node_map = {}\n",
    "        for node in graph.get_nodes():\n",
    "             # Use node.get_name() which might include quotes, strip them for the key\n",
    "             unquoted_id = node.get_name().strip('\"')\n",
    "             # Store the original node object\n",
    "             node_map[unquoted_id] = node\n",
    "        logging.info(f\"  Built map with {len(node_map)} nodes.\")\n",
    "\n",
    "\n",
    "        # Iterate through edges to find connections involving center nodes AND filter neighbors\n",
    "        logging.info(f\"  Finding relevant edges and filtering neighbors by label...\")\n",
    "        edges_processed = 0\n",
    "        edges_added = 0\n",
    "        neighbors_added = set()\n",
    "\n",
    "        for edge in graph.get_edges():\n",
    "            edges_processed += 1\n",
    "            source_id = edge.get_source().strip('\"')\n",
    "            dest_id = edge.get_destination().strip('\"')\n",
    "            is_relevant_edge = False\n",
    "            neighbor_to_add = None\n",
    "\n",
    "            # Check connection: Center -> Potential Neighbor\n",
    "            if source_id in center_node_ids:\n",
    "                potential_neighbor_node = node_map.get(dest_id)\n",
    "                if potential_neighbor_node:\n",
    "                    node_type = get_node_type_from_attributes(potential_neighbor_node.get_attributes())\n",
    "                    if node_type in allowed_neighbor_labels:\n",
    "                        neighbor_to_add = dest_id\n",
    "                        is_relevant_edge = True\n",
    "\n",
    "            # Check connection: Potential Neighbor -> Center\n",
    "            elif dest_id in center_node_ids: # Use elif to avoid adding edge twice if both are centers\n",
    "                potential_neighbor_node = node_map.get(source_id)\n",
    "                if potential_neighbor_node:\n",
    "                    node_type = get_node_type_from_attributes(potential_neighbor_node.get_attributes())\n",
    "                    if node_type in allowed_neighbor_labels:\n",
    "                        neighbor_to_add = source_id\n",
    "                        is_relevant_edge = True\n",
    "\n",
    "            if is_relevant_edge:\n",
    "                if neighbor_to_add:\n",
    "                    nodes_to_include.add(neighbor_to_add)\n",
    "                    neighbors_added.add(neighbor_to_add)\n",
    "                # Add the original edge string representation\n",
    "                relevant_lines.add(edge.to_string().strip())\n",
    "                edges_added += 1\n",
    "\n",
    "        logging.info(f\"  Processed {edges_processed} edges. Added {edges_added} relevant edges.\")\n",
    "        logging.info(f\"  Added {len(neighbors_added)} neighbors based on label criteria.\")\n",
    "        logging.info(f\"  Total nodes to include (centers + filtered neighbors): {len(nodes_to_include)}\")\n",
    "\n",
    "\n",
    "        # Iterate through nodes to get the definitions for all nodes_to_include\n",
    "        logging.info(f\"  Extracting node definitions for included nodes...\")\n",
    "        nodes_processed = 0\n",
    "        for unquoted_id, node_obj in node_map.items():\n",
    "            if unquoted_id in nodes_to_include:\n",
    "                relevant_lines.add(node_obj.to_string().strip())\n",
    "                nodes_definitions_added.add(unquoted_id) # Add the unquoted name\n",
    "                nodes_processed += 1\n",
    "        logging.info(f\"  Extracted definitions for {len(nodes_definitions_added)} included nodes.\")\n",
    "\n",
    "        # Sanity checks / Warnings (using unquoted IDs for comparison)\n",
    "        missing_center_defs = center_node_ids - nodes_definitions_added\n",
    "        if missing_center_defs:\n",
    "             # This might be expected if a center node itself doesn't have one of the allowed labels and has no allowed neighbors\n",
    "             logging.debug(f\"  Definitions for some center nodes might be missing if they have no allowed neighbors: {missing_center_defs}\")\n",
    "\n",
    "        # Calculate missing neighbor definitions (also using unquoted IDs)\n",
    "        neighbor_ids_in_final_set = nodes_to_include - center_node_ids\n",
    "        missing_neighbor_defs = neighbor_ids_in_final_set - nodes_definitions_added\n",
    "        if missing_neighbor_defs:\n",
    "             # This should ideally not happen if the node map was built correctly\n",
    "             logging.warning(f\"  Could not find definitions for all *filtered* neighbor nodes in {dot_file_path}. Missing: {missing_neighbor_defs}\")\n",
    "\n",
    "        # Write the collected lines to the output file\n",
    "        output_file_path = os.path.join(output_base_path, f\"{folder_name}_context.txt\")\n",
    "        sorted_lines = sorted(list(relevant_lines))\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f_out:\n",
    "            for line in sorted_lines:\n",
    "                f_out.write(f\"  {line}\\n\")\n",
    "\n",
    "        logging.info(f\"  Successfully wrote {len(sorted_lines)} lines to {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"  Error: .dot file not found at {dot_file_path}\")\n",
    "    except PydotError as e:\n",
    "         logging.error(f\"  A pydot library error occurred processing {dot_file_path}: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"  An unexpected {type(e).__name__} occurred while processing {dot_file_path}: {e}\", exc_info=True)\n",
    "\n",
    "logging.info(\"Subgraph extraction process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import pydot\n",
    "from IPython.display import Image, display\n",
    "from pydot import Error as PydotError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define paths\n",
    "context_base_path = \"data_java/subgraph_contexts\"\n",
    "visualization_output_path = \"data_java/subgraph_visualizations\"\n",
    "\n",
    "# Create the visualization output directory if it doesn't exist\n",
    "os.makedirs(visualization_output_path, exist_ok=True)\n",
    "logging.info(f\"Ensured output directory exists: {visualization_output_path}\")\n",
    "\n",
    "# Find all context files\n",
    "context_files = glob.glob(os.path.join(context_base_path, '*_context.txt'))\n",
    "\n",
    "if not context_files:\n",
    "    logging.warning(f\"No context files found in {context_base_path}. Nothing to visualize.\")\n",
    "else:\n",
    "    logging.info(f\"Found {len(context_files)} context files to visualize.\")\n",
    "\n",
    "# Process and visualize each context file\n",
    "for context_file_path in context_files:\n",
    "    base_name = os.path.basename(context_file_path).replace('_context.txt', '')\n",
    "    logging.info(f\"Processing visualization for: {base_name}\")\n",
    "    output_png_path = os.path.join(visualization_output_path, f\"{base_name}_subgraph.png\")\n",
    "\n",
    "    try:\n",
    "        # Read the subgraph content\n",
    "        logging.info(f\"  Reading context file: {context_file_path}\")\n",
    "        with open(context_file_path, 'r', encoding='utf-8') as f_in:\n",
    "            subgraph_content = f_in.read()\n",
    "        logging.info(f\"  Successfully read context file.\")\n",
    "\n",
    "        # Wrap the content in a valid DOT structure\n",
    "        dot_string = f\"digraph \\\"{base_name}_subgraph\\\" {{\\n graph [rankdir=LR];\\n node [shape=box, fontname=\\\"Courier New\\\"];\\n edge [arrowsize=0.5, fontsize=8];\\n{subgraph_content}\\n}}\"\n",
    "\n",
    "        # Parse the DOT string using pydot\n",
    "        logging.info(\"  Parsing DOT data...\")\n",
    "        graphs = pydot.graph_from_dot_data(dot_string)\n",
    "\n",
    "        if not graphs:\n",
    "            logging.warning(f\"  Could not parse DOT data from generated string for {base_name}. Skipping visualization.\")\n",
    "            continue\n",
    "\n",
    "        graph = graphs[0] # Assume the first graph is the one we want\n",
    "        logging.info(\"  Successfully parsed DOT data.\")\n",
    "\n",
    "        # --- NEW APPROACH: Use MUCH simpler label modification ---\n",
    "        logging.info(\"  Simplifying approach to modify node labels...\")\n",
    "        nodes_modified = 0\n",
    "        for node in graph.get_nodes():\n",
    "            try:\n",
    "                node_id = node.get_name()  # Keep the quotes, simpler\n",
    "                \n",
    "                # SIMPLIFICATION: Just set a basic label with the ID\n",
    "                # This avoids all the escaping issues by keeping things simple\n",
    "                node.set('label', f\"NODE {node_id}\")\n",
    "                nodes_modified += 1\n",
    "            except Exception as label_err:\n",
    "                logging.warning(f\"    Could not modify label for node {node.get_name()}: {label_err}\")\n",
    "        logging.info(f\"  Modified labels for {nodes_modified} nodes using simplified approach.\")\n",
    "        # --- End New Approach ---\n",
    "\n",
    "        # Generate the PNG image\n",
    "        try:\n",
    "            logging.info(f\"  Attempting to render PNG to {output_png_path}...\")\n",
    "            # Instead of write_png which relies on external dot command, try write with plain format\n",
    "            # first to test if the DOT data is valid\n",
    "            test_txt_path = f\"{output_png_path}.txt\"\n",
    "            graph.write(test_txt_path, format=\"plain\")\n",
    "            # graph.write(test_txt_path)\n",
    "            logging.info(f\"  Successfully wrote plain DOT text to {test_txt_path}.\")\n",
    "            \n",
    "            # Now try PNG\n",
    "            png_created = graph.write_png(output_png_path)\n",
    "            if png_created is False:\n",
    "                logging.error(f\"  graph.write_png returned False for {output_png_path}.\")\n",
    "                continue\n",
    "\n",
    "            logging.info(f\"  Successfully rendered PNG.\")\n",
    "            \n",
    "            # Display the image in the notebook\n",
    "            display(Image(filename=output_png_path))\n",
    "            print(\"-\" * 40)\n",
    "            logging.info(f\"  Successfully displayed image.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"  Error: Failed to find or create file. Check permissions.\")\n",
    "        except PydotError as pe:\n",
    "            logging.error(f\"  Pydot error during file operations: {pe}\")\n",
    "        except AssertionError as ae:\n",
    "            logging.error(f\"  AssertionError during rendering: {ae}\")\n",
    "            # Try to extract and print graphviz's stderr output from the error message\n",
    "            print(str(ae))\n",
    "            if \"returned code: 1\" in str(ae):\n",
    "                print(\"\\nstdout, stderr:\\n\", \" b''\")  # Placeholder pattern\n",
    "                # Try to work around by generating SVG instead of PNG\n",
    "                try:\n",
    "                    logging.info(f\"  Trying alternative SVG format...\")\n",
    "                    svg_path = f\"{output_png_path}.svg\"\n",
    "                    graph.write_svg(svg_path)\n",
    "                    logging.info(f\"  Successfully wrote SVG to {svg_path}\")\n",
    "                    display(Image(filename=svg_path))\n",
    "                except Exception as svg_err:\n",
    "                    logging.error(f\"  SVG fallback also failed: {svg_err}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"  Unexpected error: {e}\", exc_info=True)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"  Error: Context file not found at {context_file_path}\")\n",
    "    except PydotError as parse_err:\n",
    "        logging.error(f\"  Pydot error parsing DOT data: {parse_err}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"  Unexpected error processing {base_name}: {e}\", exc_info=True)\n",
    "\n",
    "logging.info(\"Subgraph visualization process finished.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
