# Tokenized code fragments for 156050-v1.0.0-bad
# Total center nodes processed: 58
# Total code fragments found: 234

CENTER_NODE: 30064771926
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerHost.ZZ_ROWMAP = zzUnpackRowMap()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerHost.ZZ_ROWMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackRowMap()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_ROWMAP
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771535
FRAGMENT_COUNT: 3
  ORIGINAL[0]: zzMarkedPos - zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1

CENTER_NODE: 30064771855
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerHost.YYINITIAL = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerHost.YYINITIAL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: YYINITIAL
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771959
FRAGMENT_COUNT: 3
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719477326
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.zzBuffer
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzStartRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: zzStartRead
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 30064771551
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number > yylength()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > FUN1 ( )
  ORIGINAL[1]: this.zzScanError(ZZ_PUSHBACK_2BIG)
  TYPE[1]: CALL
  TOKENIZED[1]: this . FUN1 ( VAR1 )
  ORIGINAL[2]: LexerHost.ZZ_PUSHBACK_2BIG
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this

CENTER_NODE: 30064771851
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerHost.YYEOF = -1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = -1
  ORIGINAL[1]: LexerHost.YYEOF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1

CENTER_NODE: 68719477293
FRAGMENT_COUNT: 7
  ORIGINAL[0]: numRead == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: int c = zzReader.read()
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2 . FUN1 ( )
  ORIGINAL[2]: c == -1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == -1
  ORIGINAL[3]: -1
  TYPE[3]: CALL
  TOKENIZED[3]: -1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: c
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477331
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ZZ_ERROR_MSG[errorCode]
  TYPE[0]: CALL
  TOKENIZED[0]: ZZ_ERROR_MSG[errorCode]
  ORIGINAL[1]: LexerHost.ZZ_ERROR_MSG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: errorCode
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477487
FRAGMENT_COUNT: 19
  ORIGINAL[0]: zzAction < 0 ? zzAction : ZZ_ACTION[zzAction]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0 ? VAR1 : ZZ_ACTION[zzAction]
  ORIGINAL[1]: error(ACE_PREFIX)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this
  ORIGINAL[3]: ACE_PREFIX
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ACE_PREFIX
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ACE_PREFIX
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ACE_PREFIX
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ACE_PREFIX
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ACE_PREFIX
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: ACE_PREFIX
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: ACE_PREFIX
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: ACE_PREFIX
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: ACE_PREFIX
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: ACE_PREFIX
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: ACE_PREFIX
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: ACE_PREFIX
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: ACE_PREFIX
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: ACE_PREFIX
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: ACE_PREFIX
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 47244640300
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771865
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] LexerHost.ZZ_CMAP = zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[0]: CALL
  TOKENIZED[0]: char[] VAR1 . VAR2 = FUN1 ( VAR3 )
  ORIGINAL[1]: LexerHost.ZZ_CMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: ZZ_CMAP
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771502
FRAGMENT_COUNT: 12
  ORIGINAL[0]: this.zzEOFDone = false
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = false
  ORIGINAL[1]: this.zzEOFDone
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: zzEOFDone
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this
  ORIGINAL[8]: this
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: this
  ORIGINAL[9]: this
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: this
  ORIGINAL[10]: this
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: this
  ORIGINAL[11]: this
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: this

CENTER_NODE: 68719477248
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < 72
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 72
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: packed
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771869
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerHost.ZZ_ACTION = zzUnpackAction()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerHost.ZZ_ACTION
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAction()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_ACTION
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476977
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int offset = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: offset = zzUnpackRowMap(ZZ_ROWMAP_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[2]: zzUnpackRowMap(ZZ_ROWMAP_PACKED_0, offset, result)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 10
  ORIGINAL[0]: int this.zzLexicalState = YYINITIAL
  TYPE[0]: CALL
  TOKENIZED[0]: int this . VAR1 = VAR2
  ORIGINAL[1]: this.zzLexicalState
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: LexerHost.YYINITIAL
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: zzLexicalState
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this
  ORIGINAL[8]: this
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: this
  ORIGINAL[9]: this
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: this

CENTER_NODE: 30064771119
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: result[j++]
  TYPE[1]: CALL
  TOKENIZED[1]: result[j++]
  ORIGINAL[2]: j++
  TYPE[2]: CALL
  TOKENIZED[2]: j++
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771389
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.parser.recordError(range, e)
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 . FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: this.parser
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.range
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: e
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771521
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState = newState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this.zzLexicalState
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: newState
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.zzEndRead = zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this.zzEndRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 30064771529
FRAGMENT_COUNT: 6
  ORIGINAL[0]: zzMarkedPos - zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzMarkedPos
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 6
  ORIGINAL[0]: int i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: int j = offset
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772898
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerHost.ZZ_PUSHBACK_2BIG = 2
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2
  ORIGINAL[1]: LexerHost.ZZ_PUSHBACK_2BIG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771080
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] result = new int[809]
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 = new int[809]
  ORIGINAL[1]: new int[809]
  TYPE[1]: CALL
  TOKENIZED[1]: new int[809]
  ORIGINAL[2]: result
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476997
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] result = new int[16000]
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 = new int[16000]
  ORIGINAL[1]: new int[16000]
  TYPE[1]: CALL
  TOKENIZED[1]: new int[16000]
  ORIGINAL[2]: result
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064772905
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerHost.ZZ_ATTRIBUTE = zzUnpackAttribute()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerHost.ZZ_ATTRIBUTE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAttribute()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 68719477206
FRAGMENT_COUNT: 7
  ORIGINAL[0]: this.useXhost
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzAtEOF
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: int length = finish - start
  TYPE[2]: CALL
  TOKENIZED[2]: int VAR1 = VAR2 - VAR3
  ORIGINAL[3]: this.zzEndRead
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: zzEndRead
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this

CENTER_NODE: 68719477111
FRAGMENT_COUNT: 7
  ORIGINAL[0]: stonesoup_mysql_host == null || stonesoup_mysql_user == null || stonesoup_mysql_pass == null || stonesoup_mysql_port == null || stonesoup_mysql_dbname == null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == null || VAR2 == null || VAR3 == null || VAR4 == null || VAR5 == null
  ORIGINAL[1]: new Random()
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( )
  ORIGINAL[2]: int random_int = random_generator.nextInt(1000) + 100
  TYPE[2]: CALL
  TOKENIZED[2]: int VAR1 = VAR2 . FUN1 ( 1000 ) + 100
  ORIGINAL[3]: random_generator.nextInt(1000) + 100
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . FUN1 ( 1000 ) + 100
  ORIGINAL[4]: random_int
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: random_generator
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: random_int
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771355
FRAGMENT_COUNT: 3
  ORIGINAL[0]: analyse(p, r, str, 0, str.length())
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , 0 , VAR3 . FUN2 ( ) )
  ORIGINAL[1]: str.length()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( )
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771848
FRAGMENT_COUNT: 4
  ORIGINAL[0]: LexerHost.arsenferratoseIconometric
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[2]: LexerHost.arsenferratoseIconometric
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: arsenferratoseIconometric
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771520
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new java.io.InputStreamReader(in)
  TYPE[0]: CALL
  TOKENIZED[0]: new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[1]: $obj6
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: $obj6
  ORIGINAL[2]: in
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: $obj6
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj6

CENTER_NODE: 68719477014
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: packed.charAt(i++)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( i++ )
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: packed
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: value
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: packed
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771394
FRAGMENT_COUNT: 6
  ORIGINAL[0]: this.parser.matchedRule(range, rule)
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 . FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: this.parser
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.range
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: range
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: rule
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771902
FRAGMENT_COUNT: 3
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719477176
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: packed
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771856
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerHost.ZZ_LEXSTATE = { 0, 0 }
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = { 0 , 0 }
  ORIGINAL[1]: LexerHost.ZZ_LEXSTATE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { 0, 0 }
  TYPE[2]: CALL
  TOKENIZED[2]: { 0 , 0 }

CENTER_NODE: 30064771545
FRAGMENT_COUNT: 1
  ORIGINAL[0]: throw new Error(message);
  TYPE[0]: CALL
  TOKENIZED[0]: throw new FUN1 ( VAR1 ) ;

CENTER_NODE: 30064772906
FRAGMENT_COUNT: 2
  ORIGINAL[0]: String LexerHost.ZZ_ATTRIBUTE_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerHost.ZZ_ATTRIBUTE_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064772033
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerHost.ZZ_TRANS = zzUnpackTrans()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerHost.ZZ_TRANS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackTrans()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064772484
FRAGMENT_COUNT: 3
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 47244640302
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 47244640270
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.yaff_scalare
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: yaff_scalare
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 47244640268
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 30064771852
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerHost.ZZ_BUFFERSIZE = 2048
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2048
  ORIGINAL[1]: LexerHost.ZZ_BUFFERSIZE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064772897
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerHost.ZZ_NO_MATCH = 1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 1
  ORIGINAL[1]: LexerHost.ZZ_NO_MATCH
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_NO_MATCH
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 47244640283
FRAGMENT_COUNT: 2
  ORIGINAL[0]: !p.has(r)
  TYPE[0]: CALL
  TOKENIZED[0]: !p . FUN1 ( VAR1 )
  ORIGINAL[1]: if (!p.has(r))
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: if ( !p . FUN1 ( VAR1 ) )

CENTER_NODE: 30064772900
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String[] LexerHost.ZZ_ERROR_MSG = { \
  TYPE[0]: CALL
  TOKENIZED[0]: String[] VAR1 . VAR2 = { \
  ORIGINAL[1]: LexerHost.ZZ_ERROR_MSG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { \
  TYPE[2]: CALL
  TOKENIZED[2]: { \

CENTER_NODE: 68719477220
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.useXhost
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.lexXHost
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: lexXHost
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.yaff_scalare
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: yaff_scalare
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064772894
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerHost.ZZ_UNKNOWN_ERROR = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerHost.ZZ_UNKNOWN_ERROR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771843
FRAGMENT_COUNT: 3
  ORIGINAL[0]: PrintStream LexerHost.ameliorablenessBarra = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LexerHost.ameliorablenessBarra
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ameliorablenessBarra
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

