# Tokenized code fragments for 155989-v1.0.0-bad
# Total center nodes processed: 25
# Total code fragments found: 105

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 68719476967
FRAGMENT_COUNT: 3
  ORIGINAL[0]: size * _block_size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 * VAR2
  ORIGINAL[1]: SmallDocumentBlock._block_size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476976
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this._data
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: _data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 68719476977
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this._data
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: _data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 5
  ORIGINAL[0]: offset >> BLOCK_SHIFT
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >> VAR2
  ORIGINAL[1]: SmallDocumentBlock.BLOCK_SHIFT
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: firstBlockIndex
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 30064771229
FRAGMENT_COUNT: 3
  ORIGINAL[0]: bigBlockSize.getBigBlockSize() / _block_size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ) / VAR2
  ORIGINAL[1]: getBigBlockSize()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: SmallDocumentBlock._block_size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2

CENTER_NODE: 30064771341
FRAGMENT_COUNT: 4
  ORIGINAL[0]: SmallDocumentBlock block = new SmallDocumentBlock(bigBlockSize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 = new FUN1 ( VAR3 )
  ORIGINAL[1]: new SmallDocumentBlock(bigBlockSize)
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( VAR1 )
  ORIGINAL[2]: block
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: block
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771368
FRAGMENT_COUNT: 4
  ORIGINAL[0]: byte SmallDocumentBlock._default_fill = (byte) 0xff
  TYPE[0]: CALL
  TOKENIZED[0]: byte VAR1 . VAR2 = ( byte ) 0xff
  ORIGINAL[1]: SmallDocumentBlock._default_fill
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: (byte) 0xff
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) 0xff
  ORIGINAL[3]: _default_fill
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771361
FRAGMENT_COUNT: 5
  ORIGINAL[0]: java.util.concurrent.atomic.AtomicBoolean SmallDocumentBlock.dorsicollarHypostome = new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 . VAR4 . VAR5 VAR6 . VAR7 = new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[1]: SmallDocumentBlock.dorsicollarHypostome
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[3]: SmallDocumentBlock.dorsicollarHypostome
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: dorsicollarHypostome
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771355
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this._bigBlockSize
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: _bigBlockSize
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 5
  ORIGINAL[0]: SmallDocumentBlock.dorsicollarHypostome.compareAndSet(false, true)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . FUN1 ( false , true )
  ORIGINAL[1]: File pushingnessPanocha = new File(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 VAR2 = new FUN1 ( \
  ORIGINAL[2]: new File(\
  TYPE[2]: CALL
  TOKENIZED[2]: new FUN1 ( \
  ORIGINAL[3]: pushingnessPanocha
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pushingnessPanocha
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771376
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int SmallDocumentBlock.BLOCK_MASK = _block_size - 1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = VAR3 - 1
  ORIGINAL[1]: SmallDocumentBlock.BLOCK_MASK
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: _block_size - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: SmallDocumentBlock._block_size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2

CENTER_NODE: 30064771349
FRAGMENT_COUNT: 4
  ORIGINAL[0]: size + _block_size - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 - 1
  ORIGINAL[1]: size + _block_size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: SmallDocumentBlock._block_size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771357
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int SmallDocumentBlock.mismate_oscheolith = 13
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 13
  ORIGINAL[1]: SmallDocumentBlock.mismate_oscheolith
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: mismate_oscheolith
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771322
FRAGMENT_COUNT: 19
  ORIGINAL[0]: j < blocks.length
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 . VAR3
  ORIGINAL[1]: k < _blocks_per_big_block
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: k++
  TYPE[2]: CALL
  TOKENIZED[2]: k++
  ORIGINAL[3]: sdbs.add(new SmallDocumentBlock(bigBlockSize, data, k))
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . FUN1 ( new FUN2 ( VAR2 , VAR3 , VAR4 ) )
  ORIGINAL[4]: $obj2 = new SmallDocumentBlock(bigBlockSize, data, k)
  TYPE[4]: CALL
  TOKENIZED[4]: $obj2 = new FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[5]: new SmallDocumentBlock(bigBlockSize, data, k)
  TYPE[5]: CALL
  TOKENIZED[5]: new FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[6]: new SmallDocumentBlock(bigBlockSize, data, k)
  TYPE[6]: CALL
  TOKENIZED[6]: new FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[7]: for (int k = 0; Some(k < _blocks_per_big_block); k++)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( int VAR1 = 0 ; FUN1 ( VAR1 < VAR2 ) ; k++ )
  ORIGINAL[8]: j
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: k
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: _blocks_per_big_block
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: k
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: sdbs
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: $obj2
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: $obj2
  ORIGINAL[14]: $obj2
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: $obj2
  ORIGINAL[15]: bigBlockSize
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: data
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: k
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: $obj2
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: $obj2

CENTER_NODE: 68719476920
FRAGMENT_COUNT: 4
  ORIGINAL[0]: SmallDocumentBlock[] rval = new SmallDocumentBlock[convertToBlockCount(size)]
  TYPE[0]: CALL
  TOKENIZED[0]: SmallDocumentBlock[] VAR1 = new SmallDocumentBlock[convertToBlockCount ( VAR2 ) ]
  ORIGINAL[1]: int index = 0
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = 0
  ORIGINAL[2]: index
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: index
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476902
FRAGMENT_COUNT: 5
  ORIGINAL[0]: count < full_count
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: count++
  TYPE[1]: CALL
  TOKENIZED[1]: count++
  ORIGINAL[2]: add(makeEmptySmallDocumentBlock(bigBlockSize))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( FUN2 ( VAR1 ) )
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640259
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 47244640279
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771358
FRAGMENT_COUNT: 2
  ORIGINAL[0]: PrintStream SmallDocumentBlock.naphthylamineIncidentalist = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: SmallDocumentBlock.naphthylamineIncidentalist
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 6
  ORIGINAL[0]: k < rval.length
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 . VAR3
  ORIGINAL[1]: array.length
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: length
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: array
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: array
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771221
FRAGMENT_COUNT: 7
  ORIGINAL[0]: this._bigBlockSize = bigBlockSize
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this._bigBlockSize
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: _bigBlockSize
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: bigBlockSize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this

