# Tokenized code fragments for 156140-v1.0.0-bad
# Total center nodes processed: 66
# Total code fragments found: 208

CENTER_NODE: 68719476943
FRAGMENT_COUNT: 3
  ORIGINAL[0]: value >>> 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >>> 0
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771558
FRAGMENT_COUNT: 2
  ORIGINAL[0]: antimoniteCriminalism(damewort_sulphuration)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: damewort_sulphuration
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476879
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (byte) value
  TYPE[0]: CALL
  TOKENIZED[0]: ( byte ) VAR1
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771555
FRAGMENT_COUNT: 2
  ORIGINAL[0]: bibPelletierine(profitmonger_unoperated)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: profitmonger_unoperated
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476917
FRAGMENT_COUNT: 3
  ORIGINAL[0]: value >>> 24
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >>> 24
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771559
FRAGMENT_COUNT: 2
  ORIGINAL[0]: virilelyLamin(nondictionary_proteinase)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: nondictionary_proteinase
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771214
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (short) (data[0] & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: ( short ) ( data[0] & 0xFF )
  ORIGINAL[1]: data[0] & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: data[0] & 0xFF
  ORIGINAL[2]: data[0]
  TYPE[2]: CALL
  TOKENIZED[2]: data[0]

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int b1 = data[offset + 1] & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = data[offset + 1] & 0xFF
  ORIGINAL[1]: data[offset + 1] & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset + 1] & 0xFF
  ORIGINAL[2]: data[offset + 1]
  TYPE[2]: CALL
  TOKENIZED[2]: data[offset + 1]
  ORIGINAL[3]: b1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771245
FRAGMENT_COUNT: 3
  ORIGINAL[0]: putInt(Float.floatToIntBits(value), outputStream)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 . FUN2 ( VAR2 ) , VAR3 )
  ORIGINAL[1]: Float.floatToIntBits(value)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[2]: outputStream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771089
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getFloat(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 5
  ORIGINAL[0]: new StrobilomycesSignpost<Object>(smuggle_strigose)
  TYPE[0]: CALL
  TOKENIZED[0]: new StrobilomycesSignpost<Object> ( VAR1 )
  ORIGINAL[1]: null != disinflame_pterocles
  TYPE[1]: CALL
  TOKENIZED[1]: null != VAR1
  ORIGINAL[2]: phytosaurOverfrail(ecthyma_elbowchair)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: ecthyma_elbowchair
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ecthyma_elbowchair
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476885
FRAGMENT_COUNT: 3
  ORIGINAL[0]: Double.doubleToLongBits(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[1]: Double
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477100
FRAGMENT_COUNT: 2
  ORIGINAL[0]: justiciarWaferwork(tungstosilicic_vare)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: tungstosilicic_vare
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771553
FRAGMENT_COUNT: 2
  ORIGINAL[0]: b & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 0xFF
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771382
FRAGMENT_COUNT: 3
  ORIGINAL[0]: putShort(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476868
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getUShort(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771189
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getShort(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771450
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data[i++] = (byte) ((value >>> 0) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: data[i++] = ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[1]: data[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: data[i++]
  ORIGINAL[2]: (byte) ((value >>> 0) & 0xFF)
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[3]: (value >>> 0) & 0xFF
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 >>> 0 ) & 0xFF

CENTER_NODE: 30064771195
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data[offset + 1] & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset + 1] & 0xFF
  ORIGINAL[1]: data[offset + 1]
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset + 1]
  ORIGINAL[2]: offset + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 5
  ORIGINAL[0]: $idx0 < value.length
  TYPE[0]: CALL
  TOKENIZED[0]: $idx0 < VAR1 . VAR2
  ORIGINAL[1]: <empty>
  TYPE[1]: CALL
  TOKENIZED[1]: <empty>
  ORIGINAL[2]: <empty>
  TYPE[2]: CALL
  TOKENIZED[2]: <empty>
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771429
FRAGMENT_COUNT: 3
  ORIGINAL[0]: putUInt(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476762
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getInt(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771653
FRAGMENT_COUNT: 4
  ORIGINAL[0]: LittleEndian.fragrancyWurzburger
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[2]: LittleEndian.fragrancyWurzburger
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: fragrancyWurzburger
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771561
FRAGMENT_COUNT: 2
  ORIGINAL[0]: methylpentosesPharisaic(sacrococcygeus_brannerite)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: sacrococcygeus_brannerite
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476757
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getLong(data, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476781
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getLong(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477110
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tracepointMessage(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: java.lang.ProcessBuilder stonesoup_proc_builder = new java.lang.ProcessBuilder(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 . VAR3 VAR4 = new VAR1 . VAR2 . FUN1 ( \
  ORIGINAL[2]: new java.lang.ProcessBuilder(\
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . VAR2 . FUN1 ( \
  ORIGINAL[3]: stonesoup_proc_builder
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_proc_builder
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int i = offset
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477045
FRAGMENT_COUNT: 4
  ORIGINAL[0]: long retNum = readInt(stream)
  TYPE[0]: CALL
  TOKENIZED[0]: long VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: retNum & 0x00FFFFFFFFl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & 0x00FFFFFFFFl
  ORIGINAL[2]: retNum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: retNum
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771080
FRAGMENT_COUNT: 2
  ORIGINAL[0]: long LittleEndian$BufferUnderrunException.serialVersionUID = 8736973884877006145L
  TYPE[0]: CALL
  TOKENIZED[0]: long LittleEndian$BufferUnderrunException . VAR1 = 8736973884877006145L
  ORIGINAL[1]: LittleEndian$BufferUnderrunException.serialVersionUID
  TYPE[1]: CALL
  TOKENIZED[1]: LittleEndian$BufferUnderrunException . VAR1

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 68719476997
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data[i++] = (byte) ((value >>> 8) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: data[i++] = ( byte ) ( ( VAR1 >>> 8 ) & 0xFF )
  ORIGINAL[1]: data[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: data[i++]
  ORIGINAL[2]: data[i++]
  TYPE[2]: CALL
  TOKENIZED[2]: data[i++]
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640276
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719476894
FRAGMENT_COUNT: 2
  ORIGINAL[0]: putInt(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476738
FRAGMENT_COUNT: 2
  ORIGINAL[0]: super(\
  TYPE[0]: CALL
  TOKENIZED[0]: super ( \
  ORIGINAL[1]: this
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: this

CENTER_NODE: 68719477080
FRAGMENT_COUNT: 2
  ORIGINAL[0]: readUShort(stream)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771444
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (byte) ((value >>> 24) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: ( byte ) ( ( VAR1 >>> 24 ) & 0xFF )
  ORIGINAL[1]: (value >>> 24) & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 >>> 24 ) & 0xFF
  ORIGINAL[2]: value >>> 24
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >>> 24

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new BufferUnderrunException()
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( )
  ORIGINAL[1]: (ch1 | ch2) < 0
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 | VAR2 ) < 0
  ORIGINAL[2]: $obj6
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj6
  ORIGINAL[3]: $obj6
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj6

CENTER_NODE: 30064771556
FRAGMENT_COUNT: 2
  ORIGINAL[0]: obligedPremium(exflagellation_pycnoconidium)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: exflagellation_pycnoconidium
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771463
FRAGMENT_COUNT: 3
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 8) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 8 ) & 0xFF ) )
  ORIGINAL[1]: (byte) ((value >>> 8) & 0xFF)
  TYPE[1]: CALL
  TOKENIZED[1]: ( byte ) ( ( VAR1 >>> 8 ) & 0xFF )
  ORIGINAL[2]: outputStream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476988
FRAGMENT_COUNT: 2
  ORIGINAL[0]: value & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 0xFF
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771216
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (short) (data[offset] & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: ( short ) ( data[offset] & 0xFF )
  ORIGINAL[1]: data[offset] & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset] & 0xFF

CENTER_NODE: 30064771557
FRAGMENT_COUNT: 2
  ORIGINAL[0]: indivertibleInterruptedness(miek_poseidonian)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: miek_poseidonian
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771554
FRAGMENT_COUNT: 2
  ORIGINAL[0]: uprighteouslyXanthometer(biocoenotic_toadless)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: biocoenotic_toadless
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477031
FRAGMENT_COUNT: 6
  ORIGINAL[0]: int ch3 = stream.read()
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2 . FUN1 ( )
  ORIGINAL[1]: int ch4 = stream.read()
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2 . FUN1 ( )
  ORIGINAL[2]: stream.read()
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . FUN1 ( )
  ORIGINAL[3]: ch4
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stream
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ch4
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476883
FRAGMENT_COUNT: 3
  ORIGINAL[0]: Double.doubleToLongBits(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[1]: Double
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771219
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getUInt(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476866
FRAGMENT_COUNT: 3
  ORIGINAL[0]: data[offset]
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset]
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771086
FRAGMENT_COUNT: 4
  ORIGINAL[0]: Double.longBitsToDouble(getLong(data, 0))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( FUN2 ( VAR2 , 0 ) )
  ORIGINAL[1]: getLong(data, 0)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 0 )
  ORIGINAL[2]: Double
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476920
FRAGMENT_COUNT: 3
  ORIGINAL[0]: value >>> 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >>> 0
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476749
FRAGMENT_COUNT: 6
  ORIGINAL[0]: System.arraycopy(data, offset, copy, 0, size)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 , VAR3 , VAR4 , 0 , VAR5 )
  ORIGINAL[1]: System
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: copy
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476902
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640259
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.tapu_ruffianly
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: tapu_ruffianly
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771508
FRAGMENT_COUNT: 10
  ORIGINAL[0]: new BufferUnderrunException()
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( )
  ORIGINAL[1]: (ch1 | ch2 | ch3 | ch4 | ch5 | ch6 | ch7 | ch8) < 0
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 | VAR2 | VAR3 | VAR4 | VAR5 | VAR6 | VAR7 | VAR8 ) < 0
  ORIGINAL[2]: ch1 | ch2 | ch3 | ch4 | ch5 | ch6 | ch7 | ch8
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 | VAR2 | VAR3 | VAR4 | VAR5 | VAR6 | VAR7 | VAR8
  ORIGINAL[3]: throw new BufferUnderrunException();
  TYPE[3]: CALL
  TOKENIZED[3]: throw new FUN1 ( ) ;
  ORIGINAL[4]: $obj5 = new BufferUnderrunException()
  TYPE[4]: CALL
  TOKENIZED[4]: $obj5 = new FUN1 ( )
  ORIGINAL[5]: new BufferUnderrunException()
  TYPE[5]: CALL
  TOKENIZED[5]: new FUN1 ( )
  ORIGINAL[6]: if ((ch1 | ch2 | ch3 | ch4 | ch5 | ch6 | ch7 | ch8) < 0)
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: if ( ( VAR1 | VAR2 | VAR3 | VAR4 | VAR5 | VAR6 | VAR7 | VAR8 ) < 0 )
  ORIGINAL[7]: $obj5
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: $obj5
  ORIGINAL[8]: $obj5
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: $obj5
  ORIGINAL[9]: $obj5
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: $obj5

CENTER_NODE: 30064771201
FRAGMENT_COUNT: 4
  ORIGINAL[0]: short[] result = new short[size / SHORT_SIZE]
  TYPE[0]: CALL
  TOKENIZED[0]: short[] VAR1 = new short[size / SHORT_SIZE]
  ORIGINAL[1]: new short[size / SHORT_SIZE]
  TYPE[1]: CALL
  TOKENIZED[1]: new short[size / SHORT_SIZE]
  ORIGINAL[2]: result
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771647
FRAGMENT_COUNT: 2
  ORIGINAL[0]: PrintStream LittleEndian.ocoteThysanuran = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LittleEndian.ocoteThysanuran
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719476889
FRAGMENT_COUNT: 4
  ORIGINAL[0]: Float.floatToIntBits(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: Float
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771384
FRAGMENT_COUNT: 4
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 0) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 0 ) & 0xFF ) )
  ORIGINAL[1]: (byte) ((value >>> 0) & 0xFF)
  TYPE[1]: CALL
  TOKENIZED[1]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[2]: (value >>> 0) & 0xFF
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 >>> 0 ) & 0xFF
  ORIGINAL[3]: outputStream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477098
FRAGMENT_COUNT: 2
  ORIGINAL[0]: urianSkyplast(portalled_nasolachrymal)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: portalled_nasolachrymal
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719476778
FRAGMENT_COUNT: 4
  ORIGINAL[0]: b3 << 24
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 << 24
  ORIGINAL[1]: b2 << 16
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 << 16
  ORIGINAL[2]: b2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.tapu_ruffianly
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: tapu_ruffianly
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 68719476862
FRAGMENT_COUNT: 5
  ORIGINAL[0]: long retNum = getInt(data, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: long VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: getInt(data, offset)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: retNum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: retNum
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476760
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getInt(data, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: Float
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

