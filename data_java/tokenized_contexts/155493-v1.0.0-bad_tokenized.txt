# Tokenized code fragments for 155493-v1.0.0-bad
# Total center nodes processed: 69
# Total code fragments found: 282

CENTER_NODE: 30064771820
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerQuery.ZZ_BUFFERSIZE = 2048
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2048
  ORIGINAL[1]: LexerQuery.ZZ_BUFFERSIZE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 47244640323
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 30064771818
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int LexerQuery.YYEOF = -1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = -1
  ORIGINAL[1]: LexerQuery.YYEOF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1
  ORIGINAL[3]: YYEOF
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 5
  ORIGINAL[0]: $obj9 = new java.io.InputStreamReader(in)
  TYPE[0]: CALL
  TOKENIZED[0]: $obj9 = new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[1]: new java.io.InputStreamReader(in)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this
  ORIGINAL[3]: $obj9
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj9
  ORIGINAL[4]: $obj9
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: $obj9

CENTER_NODE: 47244640284
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 30064771151
FRAGMENT_COUNT: 5
  ORIGINAL[0]: setStatus(NanoHTTPD.Response.Status.OK)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 . VAR2 . VAR3 . VAR4 )
  ORIGINAL[1]: NanoHTTPD.Response.Status.OK
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 . VAR3 . VAR4
  ORIGINAL[2]: NanoHTTPD.Response.Status
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2 . VAR3
  ORIGINAL[3]: OK
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: response
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771834
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] LexerQuery.ZZ_CMAP = zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[0]: CALL
  TOKENIZED[0]: char[] VAR1 . VAR2 = FUN1 ( VAR3 )
  ORIGINAL[1]: LexerQuery.ZZ_CMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: ZZ_CMAP
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771869
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String[] LexerQuery.ZZ_ERROR_MSG = { \
  TYPE[0]: CALL
  TOKENIZED[0]: String[] VAR1 . VAR2 = { \
  ORIGINAL[1]: LexerQuery.ZZ_ERROR_MSG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { \
  TYPE[2]: CALL
  TOKENIZED[2]: { \

CENTER_NODE: 30064771872
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_ATTRIBUTE = zzUnpackAttribute()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_ATTRIBUTE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAttribute()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771863
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerQuery.ZZ_UNKNOWN_ERROR = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerQuery.ZZ_UNKNOWN_ERROR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: int count = packed.charAt(i++)
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2 . FUN1 ( i++ )
  ORIGINAL[2]: packed.charAt(i++)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . FUN1 ( i++ )
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: value
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771389
FRAGMENT_COUNT: 6
  ORIGINAL[0]: offset = zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[1]: zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: LexerQuery.ZZ_TRANS_PACKED_0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: result
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476969
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.receivedBarrier.await()
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 . FUN1 ( )
  ORIGINAL[1]: new IOException(\
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( \
  ORIGINAL[2]: $obj1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj1

CENTER_NODE: 68719476944
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getMethod()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: response
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: session
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771598
FRAGMENT_COUNT: 3
  ORIGINAL[0]: $obj8 = new Error(message)
  TYPE[0]: CALL
  TOKENIZED[0]: $obj8 = new FUN1 ( VAR1 )
  ORIGINAL[1]: new Error(message)
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( VAR1 )
  ORIGINAL[2]: $obj8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj8

CENTER_NODE: 30064771132
FRAGMENT_COUNT: 5
  ORIGINAL[0]: this.responseWriter = writer
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this.responseWriter
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: responseWriter
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: writer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477367
FRAGMENT_COUNT: 5
  ORIGINAL[0]: proritualPyrolatry(disconvenience_poeticality, nonfraternityTransrhenane)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: nonfraternityTransrhenane
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: nonfraternityTransrhenane
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: disconvenience_poeticality
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: nonfraternityTransrhenane
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 7
  ORIGINAL[0]: String matchCheckHeader = session.getHeaders().get(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 = VAR3 . FUN1 ( ) . FUN2 ( \
  ORIGINAL[1]: getHeaders().get(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ) . FUN2 ( \
  ORIGINAL[2]: method
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: PUT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: matchCheckHeader
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: session
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: matchCheckHeader
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477110
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: packed.charAt(i++)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( i++ )
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: packed
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: value
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: packed
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771812
FRAGMENT_COUNT: 3
  ORIGINAL[0]: java.util.concurrent.atomic.AtomicBoolean LexerQuery.subpartUnhated = new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 . VAR4 . VAR5 VAR6 . VAR7 = new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[1]: LexerQuery.subpartUnhated
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )

CENTER_NODE: 68719477128
FRAGMENT_COUNT: 8
  ORIGINAL[0]: this.zzAtEOF
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.lastChar
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzEndRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: length > zzBuffer.length
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 > VAR2 . VAR1
  ORIGINAL[4]: this.zzBuffer
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: zzBuffer
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this

CENTER_NODE: 68719476997
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: j
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771169
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new NanoHTTPD.Response(NanoHTTPD.Response.Status.METHOD_NOT_ALLOWED, NanoHTTPD.MIME_PLAINTEXT, body)
  TYPE[0]: CALL
  TOKENIZED[0]: new VAR1 . FUN1 ( VAR1 . Response . VAR2 . VAR3 , VAR1 . VAR4 , VAR5 )
  ORIGINAL[1]: NanoHTTPD.Response.Status.METHOD_NOT_ALLOWED
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 . VAR3 . VAR4
  ORIGINAL[2]: NanoHTTPD.MIME_PLAINTEXT
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: MIME_PLAINTEXT
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: response
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: NanoHTTPD
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: body
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771410
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int offset = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771866
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerQuery.ZZ_NO_MATCH = 1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 1
  ORIGINAL[1]: LexerQuery.ZZ_NO_MATCH
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_NO_MATCH
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771824
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_LEXSTATE = { 0, 1 }
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = { 0 , 1 }
  ORIGINAL[1]: LexerQuery.ZZ_LEXSTATE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { 0, 1 }
  TYPE[2]: CALL
  TOKENIZED[2]: { 0 , 1 }

CENTER_NODE: 68719476894
FRAGMENT_COUNT: 4
  ORIGINAL[0]: NanoHTTPD.Response
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: Response
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: response
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NanoHTTPD
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640310
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 68719477206
FRAGMENT_COUNT: 12
  ORIGINAL[0]: this.zzReader
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzAtBOL
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzAtEOF
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: this.zzEOFDone
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: this.zzEndRead
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: this.zzStartRead
  TYPE[5]: CALL
  TOKENIZED[5]: this . VAR1
  ORIGINAL[6]: this.zzCurrentPos
  TYPE[6]: CALL
  TOKENIZED[6]: this . VAR1
  ORIGINAL[7]: this.zzMarkedPos
  TYPE[7]: CALL
  TOKENIZED[7]: this . VAR1
  ORIGINAL[8]: this.yychar
  TYPE[8]: CALL
  TOKENIZED[8]: this . VAR1
  ORIGINAL[9]: this.yycolumn
  TYPE[9]: CALL
  TOKENIZED[9]: this . VAR1
  ORIGINAL[10]: yycolumn
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: this
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: this

CENTER_NODE: 68719476767
FRAGMENT_COUNT: 6
  ORIGINAL[0]: this.yylength()
  TYPE[0]: CALL
  TOKENIZED[0]: this . FUN1 ( )
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: number
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this

CENTER_NODE: 30064771848
FRAGMENT_COUNT: 4
  ORIGINAL[0]: String LexerQuery.ZZ_ROWMAP_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerQuery.ZZ_ROWMAP_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \
  ORIGINAL[3]: ZZ_ROWMAP_PACKED_0
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771844
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_ROWMAP = zzUnpackRowMap()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_ROWMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackRowMap()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771839
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_ACTION = zzUnpackAction()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_ACTION
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAction()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771463
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] map = new char[0x10000]
  TYPE[0]: CALL
  TOKENIZED[0]: char[] VAR1 = new char[0x10000]
  ORIGINAL[1]: new char[0x10000]
  TYPE[1]: CALL
  TOKENIZED[1]: new char[0x10000]
  ORIGINAL[2]: map
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771284
FRAGMENT_COUNT: 6
  ORIGINAL[0]: offset = zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[1]: zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: LexerQuery.ZZ_ACTION_PACKED_0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: result
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477176
FRAGMENT_COUNT: 13
  ORIGINAL[0]: this.zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzBuffer
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzBuffer
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: this.zzEndRead
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: this.zzMarkedPos
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: this.zzStartRead
  TYPE[5]: CALL
  TOKENIZED[5]: this . VAR1
  ORIGINAL[6]: this.zzCurrentPos
  TYPE[6]: CALL
  TOKENIZED[6]: this . VAR1
  ORIGINAL[7]: this.zzCurrentPos
  TYPE[7]: CALL
  TOKENIZED[7]: this . VAR1
  ORIGINAL[8]: this.zzBuffer
  TYPE[8]: CALL
  TOKENIZED[8]: this . VAR1
  ORIGINAL[9]: this.zzReader
  TYPE[9]: CALL
  TOKENIZED[9]: this . VAR1
  ORIGINAL[10]: this.zzBuffer
  TYPE[10]: CALL
  TOKENIZED[10]: this . VAR1
  ORIGINAL[11]: zzBuffer
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: this
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: this

CENTER_NODE: 30064771856
FRAGMENT_COUNT: 4
  ORIGINAL[0]: String LexerQuery.ZZ_TRANS_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerQuery.ZZ_TRANS_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \
  ORIGINAL[3]: ZZ_TRANS_PACKED_0
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771596
FRAGMENT_COUNT: 1
  ORIGINAL[0]: throw new Error(message);
  TYPE[0]: CALL
  TOKENIZED[0]: throw new FUN1 ( VAR1 ) ;

CENTER_NODE: 30064771810
FRAGMENT_COUNT: 2
  ORIGINAL[0]: PrintStream LexerQuery.atomizerParanematic = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LexerQuery.atomizerParanematic
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771544
FRAGMENT_COUNT: 3
  ORIGINAL[0]: zzReader != null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != null
  ORIGINAL[1]: this.zzReader.close()
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1 . FUN1 ( )
  ORIGINAL[2]: this.zzReader
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1

CENTER_NODE: 30064771782
FRAGMENT_COUNT: 4
  ORIGINAL[0]: zzAction < 0 ? zzAction : ZZ_ACTION[zzAction]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0 ? VAR1 : ZZ_ACTION[zzAction]
  ORIGINAL[1]: rule(-160)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( -160 )
  ORIGINAL[2]: -160
  TYPE[2]: CALL
  TOKENIZED[2]: -160
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 68719477222
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.zzMarkedPos
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzStartRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: zzStartRead
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 30064771822
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerQuery.YYINITIAL = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerQuery.YYINITIAL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719477208
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771867
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerQuery.ZZ_PUSHBACK_2BIG = 2
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2
  ORIGINAL[1]: LexerQuery.ZZ_PUSHBACK_2BIG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 5
  ORIGINAL[0]: setResponseOptions(session, response)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: response
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: session
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: response
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: response
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771097
FRAGMENT_COUNT: 17
  ORIGINAL[0]: stonesoup_counter < nonfraternityTransrhenane[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < nonfraternityTransrhenane[5]
  ORIGINAL[1]: LexerQuery.stonesoup_sources.add(new FileOutputStream(String.format(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 . FUN1 ( new FUN2 ( VAR3 . FUN3 ( \
  ORIGINAL[2]: LexerQuery.stonesoup_sources
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: tracepointError(e.getClass().getName() + \
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 . FUN2 ( ) . FUN3 ( ) + \
  ORIGINAL[4]: e.getClass().getName() + \
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . FUN1 ( ) . FUN2 ( ) + \
  ORIGINAL[5]: e.getClass().getName() + \
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . FUN1 ( ) . FUN2 ( ) + \
  ORIGINAL[6]: e.getClass().getName()
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . FUN1 ( ) . FUN2 ( )
  ORIGINAL[7]: e.getClass()
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . FUN1 ( )
  ORIGINAL[8]: e.getMessage()
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 . FUN1 ( )
  ORIGINAL[9]: LexerQuery.atomizerParanematic.println(\
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 . VAR2 . FUN1 ( \
  ORIGINAL[10]: LexerQuery.atomizerParanematic
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 . VAR2
  ORIGINAL[11]: atomizerParanematic
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: Tracer
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: e
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: e
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: LexerQuery
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: LexerQuery
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 30064771078
FRAGMENT_COUNT: 3
  ORIGINAL[0]: quartersawed_penholder--
  TYPE[0]: CALL
  TOKENIZED[0]: quartersawed_penholder--
  ORIGINAL[1]: quartersawed_penholder
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: quartersawed_penholder
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640259
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771576
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new String(zzBuffer, zzStartRead, zzMarkedPos - zzStartRead)
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( VAR1 , VAR2 , VAR3 - VAR2 )
  ORIGINAL[1]: this.zzBuffer
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzMarkedPos - zzStartRead
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - VAR2
  ORIGINAL[4]: $obj7
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: $obj7
  ORIGINAL[5]: $obj7
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: $obj7

CENTER_NODE: 47244640268
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771225
FRAGMENT_COUNT: 10
  ORIGINAL[0]: new PipedInputStream(this.responseWriter)
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( this . VAR1 )
  ORIGINAL[1]: this.responseStream
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: new NanoHTTPD.Response(NanoHTTPD.Response.Status.CREATED, NanoHTTPD.MIME_PLAINTEXT, this.responseStream)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . FUN1 ( VAR1 . Response . VAR2 . VAR3 , VAR1 . VAR4 , this . VAR5 )
  ORIGINAL[3]: NanoHTTPD.Response.Status.CREATED
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2 . VAR3 . VAR4
  ORIGINAL[4]: NanoHTTPD.MIME_PLAINTEXT
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: this.responseStream
  TYPE[5]: CALL
  TOKENIZED[5]: this . VAR1
  ORIGINAL[6]: responseStream
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this
  ORIGINAL[8]: this
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: this
  ORIGINAL[9]: response
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771572
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState = newState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this.zzLexicalState
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: newState
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771852
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_TRANS = zzUnpackTrans()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_TRANS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackTrans()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 47244640283
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 30064771457
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] this.zzBuffer = new char[ZZ_BUFFERSIZE]
  TYPE[0]: CALL
  TOKENIZED[0]: char[] this . VAR1 = new char[ZZ_BUFFERSIZE]
  ORIGINAL[1]: this.zzBuffer
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: new char[ZZ_BUFFERSIZE]
  TYPE[2]: CALL
  TOKENIZED[2]: new char[ZZ_BUFFERSIZE]
  ORIGINAL[3]: LexerQuery.ZZ_BUFFERSIZE
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771877
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerQuery.ZZ_ATTRIBUTE_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerQuery.ZZ_ATTRIBUTE_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719477220
FRAGMENT_COUNT: 3
  ORIGINAL[0]: zzStartRead + pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2
  ORIGINAL[1]: this.zzStartRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: pos
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771879
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ArrayList LexerQuery.stonesoup_sources = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LexerQuery.stonesoup_sources
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: stonesoup_sources
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 5
  ORIGINAL[0]: setResponseOptions(session, response)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: this
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: this
  ORIGINAL[2]: session
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: session
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: response
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771307
FRAGMENT_COUNT: 4
  ORIGINAL[0]: zzUnpackRowMap(ZZ_ROWMAP_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: LexerQuery.ZZ_ROWMAP_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_ROWMAP_PACKED_0
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477056
FRAGMENT_COUNT: 4
  ORIGINAL[0]: packed.length()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( )
  ORIGINAL[1]: l
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: packed
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: packed
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771843
FRAGMENT_COUNT: 2
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \

