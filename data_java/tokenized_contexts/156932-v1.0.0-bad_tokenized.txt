# Tokenized code fragments for 156932-v1.0.0-bad
# Total center nodes processed: 66
# Total code fragments found: 210

CENTER_NODE: 30064771558
FRAGMENT_COUNT: 2
  ORIGINAL[0]: thornHalfpaced(petwood_gilling)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: petwood_gilling
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476879
FRAGMENT_COUNT: 4
  ORIGINAL[0]: putLong(data, offset, Double.doubleToLongBits(value))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 . FUN2 ( VAR4 ) )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: Double
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771555
FRAGMENT_COUNT: 2
  ORIGINAL[0]: relumineFruitfullness(inutilized_wholesomeness)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: inutilized_wholesomeness
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771559
FRAGMENT_COUNT: 2
  ORIGINAL[0]: tarandSulfurage(rissoa_teleostomous)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: rissoa_teleostomous
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771214
FRAGMENT_COUNT: 3
  ORIGINAL[0]: data[0] & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: data[0] & 0xFF
  ORIGINAL[1]: data[0]
  TYPE[1]: CALL
  TOKENIZED[1]: data[0]
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477019
FRAGMENT_COUNT: 4
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 0) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 0 ) & 0xFF ) )
  ORIGINAL[1]: (byte) ((value >>> 0) & 0xFF)
  TYPE[1]: CALL
  TOKENIZED[1]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[2]: outputStream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: outputStream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data[offset + 1] & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset + 1] & 0xFF
  ORIGINAL[1]: data[offset + 1]
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset + 1]
  ORIGINAL[2]: offset + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771089
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getFloat(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 10
  ORIGINAL[0]: LittleEndian.magadizeEnigmatography.compareAndSet(false, true)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . FUN1 ( false , true )
  ORIGINAL[1]: !inexpedienceVirile.getParentFile().exists() && !inexpedienceVirile.getParentFile().mkdirs()
  TYPE[1]: CALL
  TOKENIZED[1]: !inexpedienceVirile . FUN1 ( ) . FUN2 ( ) && !inexpedienceVirile . FUN1 ( ) . FUN3 ( )
  ORIGINAL[2]: throw new RuntimeException(\
  TYPE[2]: CALL
  TOKENIZED[2]: throw new FUN1 ( \
  ORIGINAL[3]: LittleEndian.interneeForgetter != null
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2 != null
  ORIGINAL[4]: LittleEndian.interneeForgetter.close()
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2 . FUN1 ( )
  ORIGINAL[5]: long result = 0xff & data[offset + 7]
  TYPE[5]: CALL
  TOKENIZED[5]: long VAR1 = 0xff & data[offset + 7]
  ORIGINAL[6]: 0xff & data[offset + 7]
  TYPE[6]: CALL
  TOKENIZED[6]: 0xff & data[offset + 7]
  ORIGINAL[7]: result
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: result
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: result
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640280
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719476884
FRAGMENT_COUNT: 3
  ORIGINAL[0]: putLong(Double.doubleToLongBits(value), outputStream)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 . FUN2 ( VAR2 ) , VAR3 )
  ORIGINAL[1]: Double.doubleToLongBits(value)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[2]: outputStream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640284
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771450
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (byte) ((value >>> 0) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[1]: (value >>> 0) & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 >>> 0 ) & 0xFF
  ORIGINAL[2]: value >>> 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >>> 0

CENTER_NODE: 30064771195
FRAGMENT_COUNT: 3
  ORIGINAL[0]: data[offset + 1]
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset + 1]
  ORIGINAL[1]: offset + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + 1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 7
  ORIGINAL[0]: $idx0 < value.length
  TYPE[0]: CALL
  TOKENIZED[0]: $idx0 < VAR1 . VAR2
  ORIGINAL[1]: <empty>
  TYPE[1]: CALL
  TOKENIZED[1]: <empty>
  ORIGINAL[2]: <empty>
  TYPE[2]: CALL
  TOKENIZED[2]: <empty>
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: value
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: $idx0
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: $idx0

CENTER_NODE: 68719476762
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getInt(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771538
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (short) readUShort(stream)
  TYPE[0]: CALL
  TOKENIZED[0]: ( short ) FUN1 ( VAR1 )
  ORIGINAL[1]: readUShort(stream)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )

CENTER_NODE: 30064771653
FRAGMENT_COUNT: 2
  ORIGINAL[0]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[0]: CALL
  TOKENIZED[0]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[1]: LittleEndian.magadizeEnigmatography
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771561
FRAGMENT_COUNT: 2
  ORIGINAL[0]: bevenomPolycarpon(archfriend_rundlet)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: archfriend_rundlet
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476757
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getLong(data, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476781
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getLong(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 4
  ORIGINAL[0]: long retNum = readInt(stream)
  TYPE[0]: CALL
  TOKENIZED[0]: long VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: readInt(stream)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: retNum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: retNum
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476964
FRAGMENT_COUNT: 2
  ORIGINAL[0]: putShort(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477110
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tracepointVariableString(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: valueString
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: Tracer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: valueString
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: valueString
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int i = offset
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2
  ORIGINAL[1]: data[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: data[i++]
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 30064771080
FRAGMENT_COUNT: 2
  ORIGINAL[0]: long LittleEndian$BufferUnderrunException.serialVersionUID = 8736973884877006145L
  TYPE[0]: CALL
  TOKENIZED[0]: long LittleEndian$BufferUnderrunException . VAR1 = 8736973884877006145L
  ORIGINAL[1]: LittleEndian$BufferUnderrunException.serialVersionUID
  TYPE[1]: CALL
  TOKENIZED[1]: LittleEndian$BufferUnderrunException . VAR1

CENTER_NODE: 68719476997
FRAGMENT_COUNT: 4
  ORIGINAL[0]: value >>> 16
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >>> 16
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477089
FRAGMENT_COUNT: 2
  ORIGINAL[0]: b & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 0xFF
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476738
FRAGMENT_COUNT: 2
  ORIGINAL[0]: super(\
  TYPE[0]: CALL
  TOKENIZED[0]: super ( \
  ORIGINAL[1]: this
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: this

CENTER_NODE: 30064771444
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (value >>> 24) & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 >>> 24 ) & 0xFF
  ORIGINAL[1]: value >>> 24
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >>> 24
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476984
FRAGMENT_COUNT: 3
  ORIGINAL[0]: data[offset]
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset]
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771560
FRAGMENT_COUNT: 2
  ORIGINAL[0]: daggerbushDemocracy(ameliorableness_parotoid)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: ameliorableness_parotoid
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477090
FRAGMENT_COUNT: 2
  ORIGINAL[0]: hypericumPlethorical(toher_bumbailiffship)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: toher_bumbailiffship
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771649
FRAGMENT_COUNT: 3
  ORIGINAL[0]: PrintStream LittleEndian.interneeForgetter = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LittleEndian.interneeForgetter
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: interneeForgetter
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new BufferUnderrunException()
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( )
  ORIGINAL[1]: (ch1 | ch2) < 0
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 | VAR2 ) < 0
  ORIGINAL[2]: $obj6
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj6
  ORIGINAL[3]: $obj6
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj6

CENTER_NODE: 30064771216
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (short) (data[offset] & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: ( short ) ( data[offset] & 0xFF )
  ORIGINAL[1]: data[offset] & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset] & 0xFF
  ORIGINAL[2]: data[offset]
  TYPE[2]: CALL
  TOKENIZED[2]: data[offset]

CENTER_NODE: 68719476864
FRAGMENT_COUNT: 3
  ORIGINAL[0]: data[offset]
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset]
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771246
FRAGMENT_COUNT: 3
  ORIGINAL[0]: putInt(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771218
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getUInt(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477093
FRAGMENT_COUNT: 2
  ORIGINAL[0]: flypePolysomatic(grouplet_undealable)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: grouplet_undealable
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771557
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ricracSolderer(noisette_jaculator)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: noisette_jaculator
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771554
FRAGMENT_COUNT: 2
  ORIGINAL[0]: bowleggedCoadjutant(asitia_splenemphraxis)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: asitia_splenemphraxis
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477031
FRAGMENT_COUNT: 6
  ORIGINAL[0]: int ch4 = stream.read()
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2 . FUN1 ( )
  ORIGINAL[1]: ch1 | ch2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 | VAR2
  ORIGINAL[2]: ch1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ch1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ch2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ch1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771086
FRAGMENT_COUNT: 4
  ORIGINAL[0]: Double.longBitsToDouble(getLong(data, 0))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( FUN2 ( VAR2 , 0 ) )
  ORIGINAL[1]: getLong(data, 0)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 0 )
  ORIGINAL[2]: Double
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476866
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getUShort(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476920
FRAGMENT_COUNT: 5
  ORIGINAL[0]: offset + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + 1
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 3
  ORIGINAL[0]: value >>> 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >>> 0
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771236
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data[offset] = (byte) value
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset] = ( byte ) VAR1
  ORIGINAL[1]: data[offset]
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset]
  ORIGINAL[2]: (byte) value
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476749
FRAGMENT_COUNT: 6
  ORIGINAL[0]: System.arraycopy(data, offset, copy, 0, size)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 , VAR3 , VAR4 , 0 , VAR5 )
  ORIGINAL[1]: System
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: copy
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476902
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data[i++] = (byte) ((value >>> 8) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: data[i++] = ( byte ) ( ( VAR1 >>> 8 ) & 0xFF )
  ORIGINAL[1]: data[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: data[i++]
  ORIGINAL[2]: data[i++]
  TYPE[2]: CALL
  TOKENIZED[2]: data[i++]
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640259
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.boatlip_coassession
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: boatlip_coassession
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 68719477001
FRAGMENT_COUNT: 2
  ORIGINAL[0]: putUInt(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771508
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (ch1 | ch2 | ch3 | ch4 | ch5 | ch6 | ch7 | ch8) < 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 | VAR2 | VAR3 | VAR4 | VAR5 | VAR6 | VAR7 | VAR8 ) < 0
  ORIGINAL[1]: ch1 | ch2 | ch3 | ch4 | ch5 | ch6 | ch7 | ch8
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 | VAR2 | VAR3 | VAR4 | VAR5 | VAR6 | VAR7 | VAR8
  ORIGINAL[2]: ch1 | ch2 | ch3 | ch4 | ch5 | ch6 | ch7
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 | VAR2 | VAR3 | VAR4 | VAR5 | VAR6 | VAR7
  ORIGINAL[3]: ch8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771201
FRAGMENT_COUNT: 4
  ORIGINAL[0]: short[] result = new short[size / SHORT_SIZE]
  TYPE[0]: CALL
  TOKENIZED[0]: short[] VAR1 = new short[size / SHORT_SIZE]
  ORIGINAL[1]: new short[size / SHORT_SIZE]
  TYPE[1]: CALL
  TOKENIZED[1]: new short[size / SHORT_SIZE]
  ORIGINAL[2]: size / SHORT_SIZE
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 / VAR2
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476889
FRAGMENT_COUNT: 3
  ORIGINAL[0]: Float.floatToIntBits(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[1]: Float
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771384
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (byte) ((value >>> 0) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[1]: (value >>> 0) & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 >>> 0 ) & 0xFF
  ORIGINAL[2]: value >>> 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >>> 0

CENTER_NODE: 68719476778
FRAGMENT_COUNT: 4
  ORIGINAL[0]: b3 << 24
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 << 24
  ORIGINAL[1]: b2 << 16
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 << 16
  ORIGINAL[2]: b2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476888
FRAGMENT_COUNT: 3
  ORIGINAL[0]: Float.floatToIntBits(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[1]: Float
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476913
FRAGMENT_COUNT: 4
  ORIGINAL[0]: value >>> 16
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >>> 16
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476832
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getShort(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.boatlip_coassession
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: boatlip_coassession
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 68719476862
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getInt(data, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476760
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getInt(data, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: Float
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

