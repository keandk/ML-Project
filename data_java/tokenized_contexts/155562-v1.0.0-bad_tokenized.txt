# Tokenized code fragments for 155562-v1.0.0-bad
# Total center nodes processed: 52
# Total code fragments found: 184

CENTER_NODE: 68719476871
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] result = new int[9]
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 = new int[9]
  ORIGINAL[1]: new int[9]
  TYPE[1]: CALL
  TOKENIZED[1]: new int[9]
  ORIGINAL[2]: result
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: packed
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476758
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this(new java.io.InputStreamReader(in));
  TYPE[0]: CALL
  TOKENIZED[0]: this ( new VAR1 . VAR2 . FUN1 ( VAR3 ) ) ;
  ORIGINAL[1]: this
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: this
  ORIGINAL[2]: $obj7
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj7

CENTER_NODE: 30064771151
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int j = offset
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2
  ORIGINAL[1]: j
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: l
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: j++
  TYPE[1]: CALL
  TOKENIZED[1]: j++
  ORIGINAL[2]: --count > 0
  TYPE[2]: CALL
  TOKENIZED[2]: --count > 0
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: result
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.zzEndRead = zzStartRead = 0
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2 = 0
  ORIGINAL[1]: this.zzEndRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead = 0
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1 = 0
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 68719476803
FRAGMENT_COUNT: 5
  ORIGINAL[0]: zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: LexerScheme.ZZ_ACTION_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: result
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771607
FRAGMENT_COUNT: 3
  ORIGINAL[0]: PrintStream LexerScheme.applauseEfflorescence = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LexerScheme.applauseEfflorescence
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: applauseEfflorescence
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771653
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String[] LexerScheme.ZZ_ERROR_MSG = { \
  TYPE[0]: CALL
  TOKENIZED[0]: String[] VAR1 . VAR2 = { \
  ORIGINAL[1]: LexerScheme.ZZ_ERROR_MSG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { \
  TYPE[2]: CALL
  TOKENIZED[2]: { \

CENTER_NODE: 30064771651
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.ZZ_PUSHBACK_2BIG = 2
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2
  ORIGINAL[1]: LexerScheme.ZZ_PUSHBACK_2BIG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719476757
FRAGMENT_COUNT: 7
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzBuffer
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: boolean this.zzAtBOL = true
  TYPE[2]: CALL
  TOKENIZED[2]: boolean this . VAR1 = true
  ORIGINAL[3]: this.zzAtBOL
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: this.zzReader
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: zzReader
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this

CENTER_NODE: 68719477053
FRAGMENT_COUNT: 7
  ORIGINAL[0]: number > yylength()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > FUN1 ( )
  ORIGINAL[1]: this.zzScanError(ZZ_PUSHBACK_2BIG)
  TYPE[1]: CALL
  TOKENIZED[1]: this . FUN1 ( VAR1 )
  ORIGINAL[2]: this.zzMarkedPos
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzMarkedPos
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this

CENTER_NODE: 30064771616
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.ZZ_BUFFERSIZE = 2048
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2048
  ORIGINAL[1]: LexerScheme.ZZ_BUFFERSIZE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] map = new char[0x10000]
  TYPE[0]: CALL
  TOKENIZED[0]: char[] VAR1 = new char[0x10000]
  ORIGINAL[1]: int i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477045
FRAGMENT_COUNT: 4
  ORIGINAL[0]: message = ZZ_ERROR_MSG[errorCode]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ZZ_ERROR_MSG[errorCode]
  ORIGINAL[1]: ZZ_ERROR_MSG[errorCode]
  TYPE[1]: CALL
  TOKENIZED[1]: ZZ_ERROR_MSG[errorCode]
  ORIGINAL[2]: message
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: message
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771167
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int offset = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640278
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 30064771636
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerScheme.ZZ_ROWMAP = zzUnpackRowMap()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ROWMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackRowMap()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_ROWMAP
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771649
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.ZZ_NO_MATCH = 1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 1
  ORIGINAL[1]: LexerScheme.ZZ_NO_MATCH
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 47244640288
FRAGMENT_COUNT: 2
  ORIGINAL[0]: numRead == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: if (numRead == 0)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: if ( VAR1 == 0 )

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 8
  ORIGINAL[0]: preroutine_coercively > 10
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 10
  ORIGINAL[1]: hobbianMawkish(preroutine_coercively++, unlimp_recirculate)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( preroutine_coercively++ , VAR1 )
  ORIGINAL[2]: preroutine_coercively++
  TYPE[2]: CALL
  TOKENIZED[2]: preroutine_coercively++
  ORIGINAL[3]: if (preroutine_coercively > 10)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: if ( VAR1 > 10 )
  ORIGINAL[4]: preroutine_coercively
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: preroutine_coercively
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: unlimp_recirculate
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: Tracer
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477030
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771622
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_LEXSTATE = { 0, 1 }
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = { 0 , 1 }
  ORIGINAL[1]: LexerScheme.ZZ_LEXSTATE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { 0, 1 }
  TYPE[2]: CALL
  TOKENIZED[2]: { 0 , 1 }

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 6
  ORIGINAL[0]: offset = zzUnpackRowMap(ZZ_ROWMAP_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[1]: zzUnpackRowMap(ZZ_ROWMAP_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: LexerScheme.ZZ_ROWMAP_PACKED_0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: result
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771632
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_ACTION = zzUnpackAction()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ACTION
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAction()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771656
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_ATTRIBUTE = zzUnpackAttribute()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ATTRIBUTE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAttribute()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771644
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_TRANS_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_TRANS_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719477176
FRAGMENT_COUNT: 5
  ORIGINAL[0]: hobbianMawkish(steadfastness_conicality, smearcaseUnrhetorically)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: smearcaseUnrhetorically
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: smearcaseUnrhetorically
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: steadfastness_conicality
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: smearcaseUnrhetorically
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719477031
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771642
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerScheme.ZZ_TRANS = zzUnpackTrans()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_TRANS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackTrans()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_TRANS
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771619
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.YYINITIAL = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerScheme.YYINITIAL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: YYINITIAL
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771608
FRAGMENT_COUNT: 3
  ORIGINAL[0]: java.util.concurrent.atomic.AtomicBoolean LexerScheme.protonemaPronounceable = new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 . VAR4 . VAR5 VAR6 . VAR7 = new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[1]: LexerScheme.protonemaPronounceable
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )

CENTER_NODE: 30064771638
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_ROWMAP_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ROWMAP_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 4
  ORIGINAL[0]: end(range)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: parser
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: range
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: range
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771615
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.YYEOF = -1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = -1
  ORIGINAL[1]: LexerScheme.YYEOF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1

CENTER_NODE: 47244640308
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640259
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771225
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new PrintStream(new FileOutputStream(tokologySpan, false), true, \
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( new FUN2 ( VAR1 , false ) , true , \
  ORIGINAL[1]: LexerScheme.applauseEfflorescence = null
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 = null
  ORIGINAL[2]: LexerScheme.applauseEfflorescence
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: $obj2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj2

CENTER_NODE: 30064771659
FRAGMENT_COUNT: 2
  ORIGINAL[0]: String LexerScheme.ZZ_ATTRIBUTE_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ATTRIBUTE_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771508
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.zzAtBOL
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: ZZ_LEXSTATE[zzLexicalState + 1]
  TYPE[1]: CALL
  TOKENIZED[1]: ZZ_LEXSTATE[zzLexicalState + 1]
  ORIGINAL[2]: zzLexicalState + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: this.zzLexicalState
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1

CENTER_NODE: 30064771647
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.ZZ_UNKNOWN_ERROR = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerScheme.ZZ_UNKNOWN_ERROR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771628
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] LexerScheme.ZZ_CMAP = zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[0]: CALL
  TOKENIZED[0]: char[] VAR1 . VAR2 = FUN1 ( VAR3 )
  ORIGINAL[1]: LexerScheme.ZZ_CMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: LexerScheme.ZZ_CMAP_PACKED
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2

CENTER_NODE: 30064771384
FRAGMENT_COUNT: 7
  ORIGINAL[0]: zzReader != null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != null
  ORIGINAL[1]: this.zzReader
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzReader.close()
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1 . FUN1 ( )
  ORIGINAL[3]: this.zzReader
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: if (zzReader != null)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: if ( VAR1 != null )
  ORIGINAL[5]: zzReader
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719477036
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.zzBuffer
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzStartRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: zzStartRead
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 30064771438
FRAGMENT_COUNT: 1
  ORIGINAL[0]: throw new Error(message);
  TYPE[0]: CALL
  TOKENIZED[0]: throw new FUN1 ( VAR1 ) ;

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 5
  ORIGINAL[0]: zzMarkedPos - zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzStartRead
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this

CENTER_NODE: 68719477040
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzBuffer
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzBuffer
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 30064771634
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_ACTION_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ACTION_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_ACTION_PACKED_0
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

