# Tokenized code fragments for 156561-v1.0.0-bad
# Total center nodes processed: 118
# Total code fragments found: 388

CENTER_NODE: 30064771212
FRAGMENT_COUNT: 4
  ORIGINAL[0]: setRequestMethod(session.getMethod())
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 . FUN2 ( ) )
  ORIGINAL[1]: getMethod()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: response
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: session
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477325
FRAGMENT_COUNT: 2
  ORIGINAL[0]: dizzilyDiapositive(talar_exostema)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: talar_exostema
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477326
FRAGMENT_COUNT: 2
  ORIGINAL[0]: resistivenessSuperlocal(bismarckian_cacophony)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: bismarckian_cacophony
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477289
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unclusteringDemibastion(unbethink_laryngoscleroma)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: unbethink_laryngoscleroma
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477300
FRAGMENT_COUNT: 2
  ORIGINAL[0]: parametritisTribalism(insectivora_malefactor)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: insectivora_malefactor
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640318
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 30064771740
FRAGMENT_COUNT: 2
  ORIGINAL[0]: shrinelessToponym(nanization_flusker)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: nanization_flusker
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771871
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_ROWMAP = zzUnpackRowMap()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ROWMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackRowMap()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771730
FRAGMENT_COUNT: 2
  ORIGINAL[0]: yestermornHeteromerous(onychoptosis_dauby)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: onychoptosis_dauby
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476977
FRAGMENT_COUNT: 6
  ORIGINAL[0]: int j = offset
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2
  ORIGINAL[1]: int l = packed.length()
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2 . FUN1 ( )
  ORIGINAL[2]: packed.length()
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . FUN1 ( )
  ORIGINAL[3]: l
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: packed
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: l
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477162
FRAGMENT_COUNT: 3
  ORIGINAL[0]: zzStartRead + pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2
  ORIGINAL[1]: this.zzStartRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: pos
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] result = new int[9]
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 = new int[9]
  ORIGINAL[1]: int offset = 0
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = 0
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771742
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unobstructNetherward(skunktop_azophen)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: skunktop_azophen
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771500
FRAGMENT_COUNT: 3
  ORIGINAL[0]: zzReader != null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != null
  ORIGINAL[1]: this.zzReader.close()
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1 . FUN1 ( )
  ORIGINAL[2]: this.zzReader
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1

CENTER_NODE: 68719477324
FRAGMENT_COUNT: 2
  ORIGINAL[0]: uncledomAries(fibroneuroma_culottes)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: fibroneuroma_culottes
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771510
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.zzEndRead = zzStartRead = 0
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2 = 0
  ORIGINAL[1]: this.zzEndRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead = 0
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1 = 0
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this

CENTER_NODE: 30064771782
FRAGMENT_COUNT: 22
  ORIGINAL[0]: valueString.startsWith(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( \
  ORIGINAL[1]: decodedSuccessfully = true
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = true
  ORIGINAL[2]: tracepointError(encoding_exc.getClass().getName() + \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 . FUN2 ( ) . FUN3 ( ) + \
  ORIGINAL[3]: encoding_exc.getClass().getName() + \
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . FUN1 ( ) . FUN2 ( ) + \
  ORIGINAL[4]: encoding_exc.getClass().getName() + \
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . FUN1 ( ) . FUN2 ( ) + \
  ORIGINAL[5]: encoding_exc.getClass().getName()
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . FUN1 ( ) . FUN2 ( )
  ORIGINAL[6]: encoding_exc.getClass()
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . FUN1 ( )
  ORIGINAL[7]: encoding_exc.getMessage()
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . FUN1 ( )
  ORIGINAL[8]: LexerScheme.leftnessOvermoisten.println(\
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 . VAR2 . FUN1 ( \
  ORIGINAL[9]: LexerScheme.leftnessOvermoisten
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 . VAR2
  ORIGINAL[10]: encoding_exc.printStackTrace(LexerScheme.leftnessOvermoisten)
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 . FUN1 ( VAR2 . VAR3 )
  ORIGINAL[11]: LexerScheme.leftnessOvermoisten
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 . VAR2
  ORIGINAL[12]: leftnessOvermoisten
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: leftnessOvermoisten
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: decodedSuccessfully
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: Tracer
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: encoding_exc
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: encoding_exc
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: LexerScheme
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: encoding_exc
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: LexerScheme
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: decodedSuccessfully
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1

CENTER_NODE: 68719477327
FRAGMENT_COUNT: 2
  ORIGINAL[0]: interfaultUnmirthful(apanthropia_upupa)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: apanthropia_upupa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476798
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.parcener_necrological = parcener_necrological
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR1
  ORIGINAL[1]: this.parcener_necrological
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: parcener_necrological
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771313
FRAGMENT_COUNT: 4
  ORIGINAL[0]: zzUnpackAttribute(ZZ_ATTRIBUTE_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: LexerScheme.ZZ_ATTRIBUTE_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_ATTRIBUTE_PACKED_0
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477303
FRAGMENT_COUNT: 2
  ORIGINAL[0]: snubbyMil(invertor_unsatire)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: invertor_unsatire
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: int value = packed.charAt(i++)
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2 . FUN1 ( i++ )
  ORIGINAL[2]: result[j++]
  TYPE[2]: CALL
  TOKENIZED[2]: result[j++]
  ORIGINAL[3]: --count > 0
  TYPE[3]: CALL
  TOKENIZED[3]: --count > 0
  ORIGINAL[4]: result
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771876
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_ROWMAP_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ROWMAP_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 30064771709
FRAGMENT_COUNT: 2
  ORIGINAL[0]: parasitizeDess(predentata_sternofacialis)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: predentata_sternofacialis
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477317
FRAGMENT_COUNT: 2
  ORIGINAL[0]: immensenessAutomobilist(enshrinement_cattishly)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: enshrinement_cattishly
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477330
FRAGMENT_COUNT: 2
  ORIGINAL[0]: halcyoninaeBraccia(kinship_hinau)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: kinship_hinau
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.parcener_necrological
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: parcener_necrological
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771745
FRAGMENT_COUNT: 2
  ORIGINAL[0]: wolfwardPatriotly(disimprisonment_mitriform)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: disimprisonment_mitriform
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 30064771852
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.ZZ_BUFFERSIZE = 2048
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2048
  ORIGINAL[1]: LexerScheme.ZZ_BUFFERSIZE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719477294
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cobalticyanicMillinormal(chilostomata_peptical)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: chilostomata_peptical
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771884
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.ZZ_UNKNOWN_ERROR = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerScheme.ZZ_UNKNOWN_ERROR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_UNKNOWN_ERROR
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771558
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number > yylength()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > FUN1 ( )
  ORIGINAL[1]: this.zzScanError(ZZ_PUSHBACK_2BIG)
  TYPE[1]: CALL
  TOKENIZED[1]: this . FUN1 ( VAR1 )
  ORIGINAL[2]: LexerScheme.ZZ_PUSHBACK_2BIG
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this

CENTER_NODE: 30064771733
FRAGMENT_COUNT: 2
  ORIGINAL[0]: oxideDelsartian(selachoidei_gallantness)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: selachoidei_gallantness
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771855
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.YYINITIAL = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerScheme.YYINITIAL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: YYINITIAL
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477074
FRAGMENT_COUNT: 5
  ORIGINAL[0]: int this.zzLexicalState = YYINITIAL
  TYPE[0]: CALL
  TOKENIZED[0]: int this . VAR1 = VAR2
  ORIGINAL[1]: this.zzLexicalState
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzBuffer
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzBuffer
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this

CENTER_NODE: 30064771851
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.YYEOF = -1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = -1
  ORIGINAL[1]: LexerScheme.YYEOF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1

CENTER_NODE: 30064771727
FRAGMENT_COUNT: 2
  ORIGINAL[0]: vandemonianismColletotrichum(lilywort_parallelize)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: lilywort_parallelize
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771865
FRAGMENT_COUNT: 4
  ORIGINAL[0]: LexerScheme.ZZ_CMAP_PACKED
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: LexerScheme.ZZ_CMAP_PACKED
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: ZZ_CMAP_PACKED
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640280
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640284
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640262
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719477291
FRAGMENT_COUNT: 2
  ORIGINAL[0]: decongestiveUnbrooded(okoniosis_continuedness)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: okoniosis_continuedness
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771712
FRAGMENT_COUNT: 2
  ORIGINAL[0]: glenSemitheological(scyphoi_unadvancedly)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: scyphoi_unadvancedly
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771731
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pauperateMachairodus(casebook_underpitch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: casebook_underpitch
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477110
FRAGMENT_COUNT: 9
  ORIGINAL[0]: zzCurrentPos >= zzBuffer.length
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 . VAR3
  ORIGINAL[1]: char[] newBuffer = new char[zzCurrentPos * 2]
  TYPE[1]: CALL
  TOKENIZED[1]: char[] VAR1 = new char[zzCurrentPos * 2]
  ORIGINAL[2]: System.arraycopy(zzBuffer, 0, newBuffer, 0, zzBuffer.length)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . FUN1 ( VAR2 , 0 , VAR3 , 0 , VAR2 . VAR4 )
  ORIGINAL[3]: this.zzBuffer
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: zzBuffer.length
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: System
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: System
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this
  ORIGINAL[8]: newBuffer
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 30064771755
FRAGMENT_COUNT: 2
  ORIGINAL[0]: dogsPisciculturist(scrolled_forhoo)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: scrolled_forhoo
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477295
FRAGMENT_COUNT: 2
  ORIGINAL[0]: conversanceFolliculose(besmother_kodak)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: besmother_kodak
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477297
FRAGMENT_COUNT: 2
  ORIGINAL[0]: erectorLuminism(tatsanottine_unrecked)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: tatsanottine_unrecked
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477311
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unejectedChurchly(micromil_slippered)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: micromil_slippered
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 4
  ORIGINAL[0]: $obj8 = new java.io.InputStreamReader(in)
  TYPE[0]: CALL
  TOKENIZED[0]: $obj8 = new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[1]: new java.io.InputStreamReader(in)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[2]: $obj8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj8
  ORIGINAL[3]: $obj8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj8

CENTER_NODE: 68719477312
FRAGMENT_COUNT: 2
  ORIGINAL[0]: begunkLactucol(scholasticate_drapery)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: scholasticate_drapery
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771736
FRAGMENT_COUNT: 2
  ORIGINAL[0]: qophProsyndicalist(euphonism_munjeet)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: euphonism_munjeet
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640269
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < 30
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 30
  ORIGINAL[1]: map[j++] = value
  TYPE[1]: CALL
  TOKENIZED[1]: map[j++] = VAR1
  ORIGINAL[2]: map[j++]
  TYPE[2]: CALL
  TOKENIZED[2]: map[j++]
  ORIGINAL[3]: --count > 0
  TYPE[3]: CALL
  TOKENIZED[3]: --count > 0
  ORIGINAL[4]: do {...} while (--count > 0)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: do { . . . } while ( --count > 0 )
  ORIGINAL[5]: value
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: count
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477302
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cochleareWobblingly(hemiplegy_uncriticism)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: hemiplegy_uncriticism
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640354
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719477284
FRAGMENT_COUNT: 2
  ORIGINAL[0]: nightedSublimable(forbidder_incidentalist)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: forbidder_incidentalist
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477331
FRAGMENT_COUNT: 2
  ORIGINAL[0]: expulserUnhang(oblational_tassel)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: oblational_tassel
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771718
FRAGMENT_COUNT: 2
  ORIGINAL[0]: spiriferidaeSuffiction(anise_narcoanesthesia)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: anise_narcoanesthesia
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477320
FRAGMENT_COUNT: 2
  ORIGINAL[0]: phenotypicBrugh(axis_rougeot)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: axis_rougeot
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771747
FRAGMENT_COUNT: 2
  ORIGINAL[0]: koelreuteriaSyrnium(indisputable_rheumatoidal)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: indisputable_rheumatoidal
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771719
FRAGMENT_COUNT: 2
  ORIGINAL[0]: heteroeciousWasango(freezing_unlasting)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: freezing_unlasting
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 20
  ORIGINAL[0]: length > zzBuffer.length
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 . VAR1
  ORIGINAL[1]: zzBuffer.length
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: this.zzBuffer
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: this.zzBuffer = new char[zzBuffer.length * 2]
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1 = new char[zzBuffer . VAR2 * 2]
  ORIGINAL[4]: this.zzBuffer
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: new char[zzBuffer.length * 2]
  TYPE[5]: CALL
  TOKENIZED[5]: new char[zzBuffer . VAR1 * 2]
  ORIGINAL[6]: zzBuffer.length * 2
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . VAR2 * 2
  ORIGINAL[7]: zzBuffer.length
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . VAR2
  ORIGINAL[8]: this.zzBuffer
  TYPE[8]: CALL
  TOKENIZED[8]: this . VAR1
  ORIGINAL[9]: while (length > zzBuffer.length)
  TYPE[9]: CONTROL_STRUCTURE
  TOKENIZED[9]: while ( VAR1 > VAR2 . VAR1 )
  ORIGINAL[10]: zzBuffer
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: length
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: zzBuffer
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: zzBuffer
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: length
  TYPE[14]: FIELD_IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: length
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: this
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: this
  ORIGINAL[17]: this
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: this
  ORIGINAL[18]: this
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: this
  ORIGINAL[19]: length
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 68719476803
FRAGMENT_COUNT: 7
  ORIGINAL[0]: this.data
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.receivedBarrier
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: PipedInputStream this.responseStream = null
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 this . VAR2 = null
  ORIGINAL[3]: this.responseStream
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: this.responseWriter
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: responseWriter
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this

CENTER_NODE: 30064771886
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.ZZ_NO_MATCH = 1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 1
  ORIGINAL[1]: LexerScheme.ZZ_NO_MATCH
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_NO_MATCH
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771714
FRAGMENT_COUNT: 2
  ORIGINAL[0]: isocracyStaphylinoidea(unthoughted_dwelled)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: unthoughted_dwelled
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: l
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: l
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771880
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_TRANS_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_TRANS_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719477206
FRAGMENT_COUNT: 8
  ORIGINAL[0]: this.zzAtEOF
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzEndRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: this.zzBuffer
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: zzBuffer
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: zzBufferL
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this

CENTER_NODE: 68719477296
FRAGMENT_COUNT: 2
  ORIGINAL[0]: mottramiteTummer(australian_rehumiliate)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: australian_rehumiliate
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771848
FRAGMENT_COUNT: 4
  ORIGINAL[0]: LexerScheme.abidingnessHeatheness
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[2]: LexerScheme.abidingnessHeatheness
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: abidingnessHeatheness
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477152
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState = newState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this.zzLexicalState
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: newState
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477323
FRAGMENT_COUNT: 2
  ORIGINAL[0]: feedmanSexagenary(tiptilt_bookman)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: tiptilt_bookman
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771894
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_ATTRIBUTE = zzUnpackAttribute()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ATTRIBUTE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAttribute()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771889
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String[] LexerScheme.ZZ_ERROR_MSG = { \
  TYPE[0]: CALL
  TOKENIZED[0]: String[] VAR1 . VAR2 = { \
  ORIGINAL[1]: LexerScheme.ZZ_ERROR_MSG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { \
  TYPE[2]: CALL
  TOKENIZED[2]: { \

CENTER_NODE: 68719476920
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.receivedBarrier.await()
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 . FUN1 ( )
  ORIGINAL[1]: new IOException(\
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( \
  ORIGINAL[2]: $obj1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj1
  ORIGINAL[3]: e
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int offset = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: offset = zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[2]: zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476902
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: this
  ORIGINAL[1]: method
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: OPTIONS
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477313
FRAGMENT_COUNT: 2
  ORIGINAL[0]: promythicProblemwise(lovelessly_carbuilder)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: lovelessly_carbuilder
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477328
FRAGMENT_COUNT: 2
  ORIGINAL[0]: apsisOverfertility(preinfect_campephagine)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: preinfect_campephagine
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477163
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzMarkedPos
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzMarkedPos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771527
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771735
FRAGMENT_COUNT: 2
  ORIGINAL[0]: paucityComplicant(ruach_uncledom)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: ruach_uncledom
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771895
FRAGMENT_COUNT: 2
  ORIGINAL[0]: String LexerScheme.ZZ_ATTRIBUTE_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ATTRIBUTE_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771535
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new String(zzBuffer, zzStartRead, zzMarkedPos - zzStartRead)
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( VAR1 , VAR2 , VAR3 - VAR2 )
  ORIGINAL[1]: this.zzBuffer
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzMarkedPos - zzStartRead
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - VAR2
  ORIGINAL[4]: this.zzMarkedPos
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: this.zzStartRead
  TYPE[5]: CALL
  TOKENIZED[5]: this . VAR1
  ORIGINAL[6]: $obj5
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: $obj5

CENTER_NODE: 30064771551
FRAGMENT_COUNT: 4
  ORIGINAL[0]: message = ZZ_ERROR_MSG[errorCode]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ZZ_ERROR_MSG[errorCode]
  ORIGINAL[1]: ZZ_ERROR_MSG[ZZ_UNKNOWN_ERROR]
  TYPE[1]: CALL
  TOKENIZED[1]: ZZ_ERROR_MSG[ZZ_UNKNOWN_ERROR]
  ORIGINAL[2]: LexerScheme.ZZ_UNKNOWN_ERROR
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: ZZ_UNKNOWN_ERROR
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477290
FRAGMENT_COUNT: 2
  ORIGINAL[0]: shoalwiseJanuary(petrea_filo)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: petrea_filo
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476844
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new NanoHTTPD.Response(NanoHTTPD.Response.Status.CREATED, NanoHTTPD.MIME_PLAINTEXT, body)
  TYPE[0]: CALL
  TOKENIZED[0]: new VAR1 . FUN1 ( VAR1 . Response . VAR2 . VAR3 , VAR1 . VAR4 , VAR5 )
  ORIGINAL[1]: NanoHTTPD.Response.Status.CREATED
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 . VAR3 . VAR4
  ORIGINAL[2]: NanoHTTPD.MIME_PLAINTEXT
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: body
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: response
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: body
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477299
FRAGMENT_COUNT: 2
  ORIGINAL[0]: indivisiblenessStaghorn(inadvisableness_haptics)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: inadvisableness_haptics
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 4
  ORIGINAL[0]: NanoHTTPD.Response response = new NanoHTTPD.Response(null)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 VAR3 = new VAR1 . FUN1 ( null )
  ORIGINAL[1]: new NanoHTTPD.Response(null)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . FUN1 ( null )
  ORIGINAL[2]: response
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: response
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771869
FRAGMENT_COUNT: 2
  ORIGINAL[0]: String LexerScheme.ZZ_ACTION_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ACTION_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719477322
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unthriftihoodLinearity(coreveller_slummocky)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: coreveller_slummocky
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771888
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.ZZ_PUSHBACK_2BIG = 2
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2
  ORIGINAL[1]: LexerScheme.ZZ_PUSHBACK_2BIG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_PUSHBACK_2BIG
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771132
FRAGMENT_COUNT: 5
  ORIGINAL[0]: setResponseOptions(session, response)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: this
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: this
  ORIGINAL[2]: session
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: response
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: response
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771711
FRAGMENT_COUNT: 2
  ORIGINAL[0]: rootwaltRearer(gillie_ununiform)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: gillie_ununiform
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771732
FRAGMENT_COUNT: 2
  ORIGINAL[0]: zizaniaKhila(yearling_nicenist)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: yearling_nicenist
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771734
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pseudoscholarlySobriety(pyrrhonist_shoddylike)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: pyrrhonist_shoddylike
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640257
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 30064771713
FRAGMENT_COUNT: 2
  ORIGINAL[0]: jeffersonianismSemelincident(peridiole_skirr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: peridiole_skirr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640288
FRAGMENT_COUNT: 2
  ORIGINAL[0]: recesser_tintinnabulate != null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != null
  ORIGINAL[1]: if (recesser_tintinnabulate != null)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: if ( VAR1 != null )

CENTER_NODE: 68719477315
FRAGMENT_COUNT: 2
  ORIGINAL[0]: troglodytismKotoko(oraculously_reappreciation)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: oraculously_reappreciation
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771856
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_LEXSTATE = { 0, 1 }
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = { 0 , 1 }
  ORIGINAL[1]: LexerScheme.ZZ_LEXSTATE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { 0, 1 }
  TYPE[2]: CALL
  TOKENIZED[2]: { 0 , 1 }

CENTER_NODE: 68719476890
FRAGMENT_COUNT: 3
  ORIGINAL[0]: setResponseOptions(session, response)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: response
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: response
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771867
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerScheme.ZZ_ACTION = zzUnpackAction()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ACTION
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAction()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_ACTION
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771097
FRAGMENT_COUNT: 7
  ORIGINAL[0]: body = String.format(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 . FUN1 ( \
  ORIGINAL[1]: format(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \
  ORIGINAL[3]: getUri()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: sendBody
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: body
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: String
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771744
FRAGMENT_COUNT: 2
  ORIGINAL[0]: hobbleArchwag(tricae_tuberculoderma)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: tricae_tuberculoderma
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771289
FRAGMENT_COUNT: 6
  ORIGINAL[0]: offset = zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[1]: zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: LexerScheme.ZZ_TRANS_PACKED_0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: result
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640282
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 30064771552
FRAGMENT_COUNT: 1
  ORIGINAL[0]: throw new Error(message);
  TYPE[0]: CALL
  TOKENIZED[0]: throw new FUN1 ( VAR1 ) ;

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771879
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_TRANS = zzUnpackTrans()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_TRANS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackTrans()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 10
  ORIGINAL[0]: new PipedInputStream(this.responseWriter)
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( this . VAR1 )
  ORIGINAL[1]: NanoHTTPD.Response response = new NanoHTTPD.Response(NanoHTTPD.Response.Status.CREATED, NanoHTTPD.MIME_PLAINTEXT, this.responseStream)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 VAR3 = new VAR1 . FUN1 ( VAR1 . VAR2 . VAR4 . VAR5 , VAR1 . VAR6 , this . VAR7 )
  ORIGINAL[2]: new NanoHTTPD.Response(NanoHTTPD.Response.Status.CREATED, NanoHTTPD.MIME_PLAINTEXT, this.responseStream)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . FUN1 ( VAR1 . Response . VAR2 . VAR3 , VAR1 . VAR4 , this . VAR5 )
  ORIGINAL[3]: NanoHTTPD.Response.Status.CREATED
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2 . VAR3 . VAR4
  ORIGINAL[4]: NanoHTTPD.MIME_PLAINTEXT
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: this.responseStream
  TYPE[5]: CALL
  TOKENIZED[5]: this . VAR1
  ORIGINAL[6]: response
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: response
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: NanoHTTPD
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: response
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477298
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ondographObdiplostemony(soliloquizer_prelanguage)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: soliloquizer_prelanguage
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771843
FRAGMENT_COUNT: 3
  ORIGINAL[0]: PrintStream LexerScheme.leftnessOvermoisten = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LexerScheme.leftnessOvermoisten
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: leftnessOvermoisten
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

