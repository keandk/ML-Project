# Tokenized code fragments for 155509-v1.0.0-bad
# Total center nodes processed: 57
# Total code fragments found: 199

CENTER_NODE: 30064771113
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getLong(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771427
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data[offset] = (byte) (value & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset] = ( byte ) ( VAR1 & 0xFF )
  ORIGINAL[1]: data[offset]
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset]
  ORIGINAL[2]: (byte) (value & 0xFF)
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) ( VAR1 & 0xFF )
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719476856
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getShort(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771084
FRAGMENT_COUNT: 5
  ORIGINAL[0]: Double.longBitsToDouble(getLong(data, offset))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( FUN2 ( VAR2 , VAR3 ) )
  ORIGINAL[1]: getLong(data, offset)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: Double
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771299
FRAGMENT_COUNT: 4
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 0) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 0 ) & 0xFF ) )
  ORIGINAL[1]: (byte) ((value >>> 0) & 0xFF)
  TYPE[1]: CALL
  TOKENIZED[1]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[2]: outputStream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: outputStream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477102
FRAGMENT_COUNT: 2
  ORIGINAL[0]: readUShort(stream)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476885
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getInt(data, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: retNum
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476906
FRAGMENT_COUNT: 3
  ORIGINAL[0]: Double.doubleToLongBits(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[1]: Double
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: value
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 5
  ORIGINAL[0]: discalced_atemporal.exists()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( )
  ORIGINAL[1]: discalced_atemporal.isDirectory()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( )
  ORIGINAL[2]: discalced_atemporal
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: discalced_atemporal
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: discalced_atemporal
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771627
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ArrayList LittleEndian.stonesoup_sources = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LittleEndian.stonesoup_sources
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: stonesoup_sources
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771450
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data[i++] = (byte) ((value >>> 24) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: data[i++] = ( byte ) ( ( VAR1 >>> 24 ) & 0xFF )
  ORIGINAL[1]: data[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: data[i++]
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: (byte) ((value >>> 24) & 0xFF)
  TYPE[3]: CALL
  TOKENIZED[3]: ( byte ) ( ( VAR1 >>> 24 ) & 0xFF )
  ORIGINAL[4]: data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476911
FRAGMENT_COUNT: 4
  ORIGINAL[0]: Float.floatToIntBits(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: Float
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771241
FRAGMENT_COUNT: 3
  ORIGINAL[0]: data[0] & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: data[0] & 0xFF
  ORIGINAL[1]: data[0]
  TYPE[1]: CALL
  TOKENIZED[1]: data[0]
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data[i++] = (byte) ((value >>> 0) & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: data[i++] = ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[1]: data[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: data[i++]
  ORIGINAL[2]: (byte) ((value >>> 0) & 0xFF)
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771263
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data[offset] = (byte) value
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset] = ( byte ) VAR1
  ORIGINAL[1]: data[offset]
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset]
  ORIGINAL[2]: (byte) value
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771085
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getFloat(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476757
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getInt(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477110
FRAGMENT_COUNT: 3
  ORIGINAL[0]: new BufferUnderrunException()
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( )
  ORIGINAL[1]: (ch1 | ch2) < 0
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 | VAR2 ) < 0
  ORIGINAL[2]: $obj9
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj9

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 10
  ORIGINAL[0]: data[offset + 0]
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset + 0]
  ORIGINAL[1]: data[offset + 1]
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset + 1]
  ORIGINAL[2]: data[offset + 2]
  TYPE[2]: CALL
  TOKENIZED[2]: data[offset + 2]
  ORIGINAL[3]: data[offset + 3]
  TYPE[3]: CALL
  TOKENIZED[3]: data[offset + 3]
  ORIGINAL[4]: data[offset + 4]
  TYPE[4]: CALL
  TOKENIZED[4]: data[offset + 4]
  ORIGINAL[5]: data[offset + 5] = (byte) ((value >>> 40) & 0xFF)
  TYPE[5]: CALL
  TOKENIZED[5]: data[offset + 5] = ( byte ) ( ( VAR1 >>> 40 ) & 0xFF )
  ORIGINAL[6]: data[offset + 5]
  TYPE[6]: CALL
  TOKENIZED[6]: data[offset + 5]
  ORIGINAL[7]: data[offset + 6]
  TYPE[7]: CALL
  TOKENIZED[7]: data[offset + 6]
  ORIGINAL[8]: data
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: offset
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477045
FRAGMENT_COUNT: 5
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 0) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 0 ) & 0xFF ) )
  ORIGINAL[1]: outputStream.write((byte) ((value >>> 8) & 0xFF))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 8 ) & 0xFF ) )
  ORIGINAL[2]: (byte) ((value >>> 8) & 0xFF)
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) ( ( VAR1 >>> 8 ) & 0xFF )
  ORIGINAL[3]: outputStream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: outputStream
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771080
FRAGMENT_COUNT: 7
  ORIGINAL[0]: System.arraycopy(data, offset, copy, 0, size)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( VAR2 , VAR3 , VAR4 , 0 , VAR5 )
  ORIGINAL[1]: System
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: copy
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: copy
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771409
FRAGMENT_COUNT: 4
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 0) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 0 ) & 0xFF ) )
  ORIGINAL[1]: (byte) ((value >>> 0) & 0xFF)
  TYPE[1]: CALL
  TOKENIZED[1]: ( byte ) ( ( VAR1 >>> 0 ) & 0xFF )
  ORIGINAL[2]: outputStream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: outputStream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477128
FRAGMENT_COUNT: 5
  ORIGINAL[0]: LittleEndian.stonesoup_sources.add(new FileOutputStream(String.format(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . FUN1 ( new FUN2 ( VAR3 . FUN3 ( \
  ORIGINAL[1]: e.getClass()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( )
  ORIGINAL[2]: Tracer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: e
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: e
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476997
FRAGMENT_COUNT: 8
  ORIGINAL[0]: int $idx0 = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int $idx0 = 0
  ORIGINAL[1]: $idx0 < value.length
  TYPE[1]: CALL
  TOKENIZED[1]: $idx0 < VAR1 . VAR2
  ORIGINAL[2]: value.length
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: $idx0++
  TYPE[3]: CALL
  TOKENIZED[3]: $idx0++
  ORIGINAL[4]: $idx0
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: $idx0
  ORIGINAL[5]: $idx0
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: $idx0
  ORIGINAL[6]: value
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: $idx0
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: $idx0

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 68719477069
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream.read()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( )
  ORIGINAL[1]: ch1
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476754
FRAGMENT_COUNT: 4
  ORIGINAL[0]: Float.intBitsToFloat(getInt(data, offset))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( FUN2 ( VAR2 , VAR3 ) )
  ORIGINAL[1]: getInt(data, offset)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: Float
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771621
FRAGMENT_COUNT: 3
  ORIGINAL[0]: java.util.concurrent.atomic.AtomicBoolean LittleEndian.doriUnthriftihood = new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 . VAR4 . VAR5 VAR6 . VAR7 = new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[1]: LittleEndian.doriUnthriftihood
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 2
  ORIGINAL[0]: long LittleEndian$BufferUnderrunException.serialVersionUID = 8736973884877006145L
  TYPE[0]: CALL
  TOKENIZED[0]: long LittleEndian$BufferUnderrunException . VAR1 = 8736973884877006145L
  ORIGINAL[1]: LittleEndian$BufferUnderrunException.serialVersionUID
  TYPE[1]: CALL
  TOKENIZED[1]: LittleEndian$BufferUnderrunException . VAR1

CENTER_NODE: 68719477113
FRAGMENT_COUNT: 2
  ORIGINAL[0]: b & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 0xFF
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476988
FRAGMENT_COUNT: 2
  ORIGINAL[0]: putShort(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771510
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (ch4 << 24) + (ch3 << 16) + (ch2 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 << 24 ) + ( VAR2 << 16 ) + ( VAR3 << 8 )
  ORIGINAL[1]: (ch4 << 24) + (ch3 << 16)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 << 24 ) + ( VAR2 << 16 )
  ORIGINAL[2]: ch4 << 24
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 << 24
  ORIGINAL[3]: ch3 << 16
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 << 16
  ORIGINAL[4]: ch2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477031
FRAGMENT_COUNT: 6
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 8) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 8 ) & 0xFF ) )
  ORIGINAL[1]: outputStream.write((byte) ((value >>> 16) & 0xFF))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 16 ) & 0xFF ) )
  ORIGINAL[2]: (byte) ((value >>> 16) & 0xFF)
  TYPE[2]: CALL
  TOKENIZED[2]: ( byte ) ( ( VAR1 >>> 16 ) & 0xFF )
  ORIGINAL[3]: outputStream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: outputStream
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: outputStream
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476890
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getUShort(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476883
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getUInt(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771619
FRAGMENT_COUNT: 2
  ORIGINAL[0]: PrintStream LittleEndian.arteriectasisPremaxilla = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LittleEndian.arteriectasisPremaxilla
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719476920
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int i = offset
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2
  ORIGINAL[1]: data[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: data[i++]
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476916
FRAGMENT_COUNT: 2
  ORIGINAL[0]: putInt(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476903
FRAGMENT_COUNT: 4
  ORIGINAL[0]: putLong(data, offset, Double.doubleToLongBits(value))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 . FUN2 ( VAR4 ) )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: Double
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476749
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getLong(data, 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 )
  ORIGINAL[1]: Double
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771272
FRAGMENT_COUNT: 5
  ORIGINAL[0]: putInt(Float.floatToIntBits(value), outputStream)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 . FUN2 ( VAR2 ) , VAR3 )
  ORIGINAL[1]: Float.floatToIntBits(value)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[2]: Float
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: outputStream
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771097
FRAGMENT_COUNT: 3
  ORIGINAL[0]: data[i++]
  TYPE[0]: CALL
  TOKENIZED[0]: data[i++]
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640259
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 2
  ORIGINAL[0]: super(\
  TYPE[0]: CALL
  TOKENIZED[0]: super ( \
  ORIGINAL[1]: this
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: this

CENTER_NODE: 30064771517
FRAGMENT_COUNT: 2
  ORIGINAL[0]: retNum & 0x00FFFFFFFFl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 0x00FFFFFFFFl
  ORIGINAL[1]: retNum
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771225
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (b1 << 8) + (b0 << 0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 << 8 ) + ( VAR2 << 0 )
  ORIGINAL[1]: b1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 << 8
  ORIGINAL[2]: b1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b0
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771249
FRAGMENT_COUNT: 2
  ORIGINAL[0]: data[offset] & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: data[offset] & 0xFF
  ORIGINAL[1]: data[offset]
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset]

CENTER_NODE: 30064771617
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unthoughtedlySinto((int) 0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( int ) 0 )
  ORIGINAL[1]: (int) 0
  TYPE[1]: CALL
  TOKENIZED[1]: ( int ) 0

CENTER_NODE: 30064771384
FRAGMENT_COUNT: 4
  ORIGINAL[0]: outputStream.write((byte) ((value >>> 40) & 0xFF))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( ( byte ) ( ( VAR2 >>> 40 ) & 0xFF ) )
  ORIGINAL[1]: (byte) ((value >>> 40) & 0xFF)
  TYPE[1]: CALL
  TOKENIZED[1]: ( byte ) ( ( VAR1 >>> 40 ) & 0xFF )
  ORIGINAL[2]: (value >>> 40) & 0xFF
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 >>> 40 ) & 0xFF
  ORIGINAL[3]: outputStream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771255
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int b1 = data[offset + 1] & 0xFF
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = data[offset + 1] & 0xFF
  ORIGINAL[1]: data[offset + 1] & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset + 1] & 0xFF
  ORIGINAL[2]: b1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477036
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int i = offset
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = VAR2
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640283
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 4
  ORIGINAL[0]: size / SHORT_SIZE
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / VAR2
  ORIGINAL[1]: size
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: SHORT_SIZE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: SHORT_SIZE
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771242
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (short) (data[offset] & 0xFF)
  TYPE[0]: CALL
  TOKENIZED[0]: ( short ) ( data[offset] & 0xFF )
  ORIGINAL[1]: data[offset] & 0xFF
  TYPE[1]: CALL
  TOKENIZED[1]: data[offset] & 0xFF

CENTER_NODE: 68719477026
FRAGMENT_COUNT: 2
  ORIGINAL[0]: putUInt(data, 0, value)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 )
  ORIGINAL[1]: value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

