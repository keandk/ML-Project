# Tokenized code fragments for 156983-v1.0.0-bad
# Total center nodes processed: 53
# Total code fragments found: 184

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: result[j++] = value
  TYPE[1]: CALL
  TOKENIZED[1]: result[j++] = VAR1
  ORIGINAL[2]: --count > 0
  TYPE[2]: CALL
  TOKENIZED[2]: --count > 0
  ORIGINAL[3]: --count
  TYPE[3]: CALL
  TOKENIZED[3]: --count
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771467
FRAGMENT_COUNT: 4
  ORIGINAL[0]: zzBuffer[zzStartRead + pos]
  TYPE[0]: CALL
  TOKENIZED[0]: zzBuffer[zzStartRead + pos]
  ORIGINAL[1]: zzStartRead + pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: pos
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771693
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerQuery.ZZ_BUFFERSIZE = 2048
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2048
  ORIGINAL[1]: LexerQuery.ZZ_BUFFERSIZE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_BUFFERSIZE
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771740
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerQuery.ZZ_PUSHBACK_2BIG = 2
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2
  ORIGINAL[1]: LexerQuery.ZZ_PUSHBACK_2BIG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_PUSHBACK_2BIG
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771450
FRAGMENT_COUNT: 5
  ORIGINAL[0]: this.yycolumn = 0
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = 0
  ORIGINAL[1]: this.yycolumn
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: yycolumn
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this

CENTER_NODE: 30064771682
FRAGMENT_COUNT: 2
  ORIGINAL[0]: PrintStream LexerQuery.purlicueDysoxidizable = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LexerQuery.purlicueDysoxidizable
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771456
FRAGMENT_COUNT: 5
  ORIGINAL[0]: this.zzLexicalState = newState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this.zzLexicalState
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: zzLexicalState
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: newState
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771718
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_ROWMAP = zzUnpackRowMap()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_ROWMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackRowMap()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771747
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerQuery.ZZ_ATTRIBUTE_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerQuery.ZZ_ATTRIBUTE_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 7
  ORIGINAL[0]: null != titmal_pneumotomy
  TYPE[0]: CALL
  TOKENIZED[0]: null != VAR1
  ORIGINAL[1]: Pattern stonesoup_rel_path_pattern = Pattern.compile(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 VAR2 = VAR1 . FUN1 ( \
  ORIGINAL[2]: Matcher rel_path_match = stonesoup_rel_path_pattern.matcher(valueString)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 VAR2 = VAR3 . FUN1 ( VAR4 )
  ORIGINAL[3]: stonesoup_rel_path_pattern.matcher(valueString)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . FUN1 ( VAR2 )
  ORIGINAL[4]: rel_path_match
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_rel_path_pattern
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: rel_path_match
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476977
FRAGMENT_COUNT: 4
  ORIGINAL[0]: packed.length()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( )
  ORIGINAL[1]: l
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: packed
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: packed
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771291
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] result = new int[26]
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 = new int[26]
  ORIGINAL[1]: new int[26]
  TYPE[1]: CALL
  TOKENIZED[1]: new int[26]
  ORIGINAL[2]: result
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 7
  ORIGINAL[0]: this.zzMarkedPos -= number
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 -= VAR2
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: zzMarkedPos
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: number
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771714
FRAGMENT_COUNT: 4
  ORIGINAL[0]: String LexerQuery.ZZ_ACTION_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerQuery.ZZ_ACTION_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \
  ORIGINAL[3]: \
  TYPE[3]: CALL
  TOKENIZED[3]: \

CENTER_NODE: 30064771742
FRAGMENT_COUNT: 4
  ORIGINAL[0]: String[] LexerQuery.ZZ_ERROR_MSG = { \
  TYPE[0]: CALL
  TOKENIZED[0]: String[] VAR1 . VAR2 = { \
  ORIGINAL[1]: LexerQuery.ZZ_ERROR_MSG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { \
  TYPE[2]: CALL
  TOKENIZED[2]: { \
  ORIGINAL[3]: ZZ_ERROR_MSG
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: int count = packed.charAt(i++)
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2 . FUN1 ( i++ )
  ORIGINAL[2]: int value = packed.charAt(i++)
  TYPE[2]: CALL
  TOKENIZED[2]: int VAR1 = VAR2 . FUN1 ( i++ )
  ORIGINAL[3]: packed.charAt(i++)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . FUN1 ( i++ )
  ORIGINAL[4]: value
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: packed
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: value
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771080
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] result = new int[26]
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 = new int[26]
  ORIGINAL[1]: new int[26]
  TYPE[1]: CALL
  TOKENIZED[1]: new int[26]
  ORIGINAL[2]: result
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771691
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerQuery.YYEOF = -1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = -1
  ORIGINAL[1]: LexerQuery.YYEOF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1

CENTER_NODE: 30064771685
FRAGMENT_COUNT: 5
  ORIGINAL[0]: java.util.concurrent.atomic.AtomicBoolean LexerQuery.autointoxicantFluorate = new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 . VAR4 . VAR5 VAR6 . VAR7 = new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[1]: LexerQuery.autointoxicantFluorate
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[3]: LexerQuery.autointoxicantFluorate
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: autointoxicantFluorate
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477101
FRAGMENT_COUNT: 5
  ORIGINAL[0]: $obj6 = new Error(message)
  TYPE[0]: CALL
  TOKENIZED[0]: $obj6 = new FUN1 ( VAR1 )
  ORIGINAL[1]: new Error(message)
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( VAR1 )
  ORIGINAL[2]: $obj6
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj6
  ORIGINAL[3]: $obj6
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj6
  ORIGINAL[4]: message
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771341
FRAGMENT_COUNT: 3
  ORIGINAL[0]: new char[ZZ_BUFFERSIZE]
  TYPE[0]: CALL
  TOKENIZED[0]: new char[ZZ_BUFFERSIZE]
  ORIGINAL[1]: LexerQuery.ZZ_BUFFERSIZE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_BUFFERSIZE
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771104
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int offset = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771706
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] LexerQuery.ZZ_CMAP = zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[0]: CALL
  TOKENIZED[0]: char[] VAR1 . VAR2 = FUN1 ( VAR3 )
  ORIGINAL[1]: LexerQuery.ZZ_CMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: ZZ_CMAP
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477206
FRAGMENT_COUNT: 5
  ORIGINAL[0]: zzAction < 0 ? zzAction : ZZ_ACTION[zzAction]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0 ? VAR1 : ZZ_ACTION[zzAction]
  ORIGINAL[1]: error(PERCENT)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this
  ORIGINAL[3]: PERCENT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: PERCENT
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771724
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_TRANS = zzUnpackTrans()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_TRANS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackTrans()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771723
FRAGMENT_COUNT: 2
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \

CENTER_NODE: 30064771479
FRAGMENT_COUNT: 1
  ORIGINAL[0]: throw new Error(message);
  TYPE[0]: CALL
  TOKENIZED[0]: throw new FUN1 ( VAR1 ) ;

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new java.io.InputStreamReader(in)
  TYPE[0]: CALL
  TOKENIZED[0]: new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[1]: $obj7
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: $obj7
  ORIGINAL[2]: in
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: $obj7
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj7

CENTER_NODE: 47244640288
FRAGMENT_COUNT: 3
  ORIGINAL[0]: map[j++] = value
  TYPE[0]: CALL
  TOKENIZED[0]: map[j++] = VAR1
  ORIGINAL[1]: --count > 0
  TYPE[1]: CALL
  TOKENIZED[1]: --count > 0
  ORIGINAL[2]: do {...} while (--count > 0)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: do { . . . } while ( --count > 0 )

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 68719477095
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzMarkedPos
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzMarkedPos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771728
FRAGMENT_COUNT: 4
  ORIGINAL[0]: String LexerQuery.ZZ_TRANS_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerQuery.ZZ_TRANS_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \
  ORIGINAL[3]: ZZ_TRANS_PACKED_0
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771694
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerQuery.YYINITIAL = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerQuery.YYINITIAL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771322
FRAGMENT_COUNT: 4
  ORIGINAL[0]: this.lastChar = length - 1
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2 - 1
  ORIGINAL[1]: this.lastChar
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: length - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: length
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771272
FRAGMENT_COUNT: 6
  ORIGINAL[0]: offset = zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[1]: zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: LexerQuery.ZZ_TRANS_PACKED_0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: result
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640270
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771709
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_ACTION = zzUnpackAction()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_ACTION
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAction()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.antipasch_irremeably
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: antipasch_irremeably
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771745
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerQuery.ZZ_ATTRIBUTE = zzUnpackAttribute()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerQuery.ZZ_ATTRIBUTE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAttribute()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_ATTRIBUTE
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 30064771696
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerQuery.ZZ_LEXSTATE = { 0, 1 }
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = { 0 , 1 }
  ORIGINAL[1]: LexerQuery.ZZ_LEXSTATE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { 0, 1 }
  TYPE[2]: CALL
  TOKENIZED[2]: { 0 , 1 }

CENTER_NODE: 47244640299
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 30064771738
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerQuery.ZZ_NO_MATCH = 1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 1
  ORIGINAL[1]: LexerQuery.ZZ_NO_MATCH
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_NO_MATCH
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477082
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771457
FRAGMENT_COUNT: 4
  ORIGINAL[0]: $obj5 = new String(zzBuffer, zzStartRead, zzMarkedPos - zzStartRead)
  TYPE[0]: CALL
  TOKENIZED[0]: $obj5 = new FUN1 ( VAR1 , VAR2 , VAR3 - VAR2 )
  ORIGINAL[1]: new String(zzBuffer, zzStartRead, zzMarkedPos - zzStartRead)
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( VAR1 , VAR2 , VAR3 - VAR2 )
  ORIGINAL[2]: $obj5
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj5
  ORIGINAL[3]: $obj5
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: $obj5

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.antipasch_irremeably
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: antipasch_irremeably
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 2
  ORIGINAL[0]: zzReader != null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != null
  ORIGINAL[1]: if (zzReader != null)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: if ( VAR1 != null )

CENTER_NODE: 30064771735
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerQuery.ZZ_UNKNOWN_ERROR = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerQuery.ZZ_UNKNOWN_ERROR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 68719477056
FRAGMENT_COUNT: 5
  ORIGINAL[0]: numRead > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: this.zzEndRead += numRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1 += VAR2
  ORIGINAL[2]: this.zzEndRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: numRead
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: numRead
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

