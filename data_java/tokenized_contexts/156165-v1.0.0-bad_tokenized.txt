# Tokenized code fragments for 156165-v1.0.0-bad
# Total center nodes processed: 115
# Total code fragments found: 356

CENTER_NODE: 68719477325
FRAGMENT_COUNT: 2
  ORIGINAL[0]: prancingActivin(mammiferous_rectigrade)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: mammiferous_rectigrade
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771920
FRAGMENT_COUNT: 4
  ORIGINAL[0]: String[] LexerScheme.ZZ_ERROR_MSG = { \
  TYPE[0]: CALL
  TOKENIZED[0]: String[] VAR1 . VAR2 = { \
  ORIGINAL[1]: LexerScheme.ZZ_ERROR_MSG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { \
  TYPE[2]: CALL
  TOKENIZED[2]: { \
  ORIGINAL[3]: ZZ_ERROR_MSG
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477326
FRAGMENT_COUNT: 2
  ORIGINAL[0]: agathosmaDisgulf(quadruplicity_clivus)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: quadruplicity_clivus
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477289
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unquestionateSanhedrin(enchytraeid_slopped)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: enchytraeid_slopped
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771749
FRAGMENT_COUNT: 2
  ORIGINAL[0]: undeservednessUnshadowed(hent_spaciously)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: hent_spaciously
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640318
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 30064771740
FRAGMENT_COUNT: 2
  ORIGINAL[0]: latiniformNautiloidean(serbdom_peroxidase)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: serbdom_peroxidase
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771872
FRAGMENT_COUNT: 2
  ORIGINAL[0]: PrintStream LexerScheme.speckyAchaeta = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = null
  ORIGINAL[1]: LexerScheme.speckyAchaeta
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771871
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.hyperaltruism_liaison = 2
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2
  ORIGINAL[1]: LexerScheme.hyperaltruism_liaison
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: hyperaltruism_liaison
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771730
FRAGMENT_COUNT: 2
  ORIGINAL[0]: spiderlikeMetamerous(spinstership_inturn)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: spinstership_inturn
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476977
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: packed.charAt(i++)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . FUN1 ( i++ )
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: packed
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: packed
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: packed
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477162
FRAGMENT_COUNT: 4
  ORIGINAL[0]: message = ZZ_ERROR_MSG[errorCode]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ZZ_ERROR_MSG[errorCode]
  ORIGINAL[1]: ZZ_ERROR_MSG[errorCode]
  TYPE[1]: CALL
  TOKENIZED[1]: ZZ_ERROR_MSG[errorCode]
  ORIGINAL[2]: message
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: message
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771742
FRAGMENT_COUNT: 2
  ORIGINAL[0]: aefaldyPituite(lairage_ciruela)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: lairage_ciruela
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477309
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sympodiallyCounterbend(unhindered_stichic)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: unhindered_stichic
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771500
FRAGMENT_COUNT: 6
  ORIGINAL[0]: zzReader != null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != null
  ORIGINAL[1]: this.zzReader
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzReader.close()
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1 . FUN1 ( )
  ORIGINAL[3]: this.zzReader
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: zzReader
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this

CENTER_NODE: 68719476887
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getMethod()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: response
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: session
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771916
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.ZZ_NO_MATCH = 1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 1
  ORIGINAL[1]: LexerScheme.ZZ_NO_MATCH
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_NO_MATCH
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477148
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771284
FRAGMENT_COUNT: 4
  ORIGINAL[0]: offset = zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[1]: zzUnpackTrans(ZZ_TRANS_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477324
FRAGMENT_COUNT: 2
  ORIGINAL[0]: trietericsPlasticizer(rapt_hungaria)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: rapt_hungaria
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771750
FRAGMENT_COUNT: 2
  ORIGINAL[0]: gastraeaHolosiderite(sphaerophorus_euplectella)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: sphaerophorus_euplectella
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477147
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzLexicalState
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzLexicalState
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 30064771782
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_psql_host == null || stonesoup_psql_user == null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == null || VAR2 == null
  ORIGINAL[1]: stonesoup_psql_host == null
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == null
  ORIGINAL[2]: stonesoup_psql_user == null
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == null
  ORIGINAL[3]: stonesoup_psql_user
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477327
FRAGMENT_COUNT: 2
  ORIGINAL[0]: longitudinallyTricolon(pulmobranchial_procatarctic)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: pulmobranchial_procatarctic
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771912
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_TRANS_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_TRANS_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 68719477303
FRAGMENT_COUNT: 2
  ORIGINAL[0]: paxillarIsovalerianate(pterodactylous_intuent)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: pterodactylous_intuent
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] result = new int[9]
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 = new int[9]
  ORIGINAL[1]: new int[9]
  TYPE[1]: CALL
  TOKENIZED[1]: new int[9]
  ORIGINAL[2]: result
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771709
FRAGMENT_COUNT: 2
  ORIGINAL[0]: antiaristocratPycnid(flareback_chiselmouth)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: flareback_chiselmouth
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771745
FRAGMENT_COUNT: 2
  ORIGINAL[0]: preconsignUncentered(emandibulate_angiomyosarcoma)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: emandibulate_angiomyosarcoma
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (true)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( true )

CENTER_NODE: 68719477316
FRAGMENT_COUNT: 2
  ORIGINAL[0]: oriasTrumpetwood(undistilled_prophyll)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: undistilled_prophyll
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477294
FRAGMENT_COUNT: 2
  ORIGINAL[0]: polyidrosisHemopod(microrhabdus_ripa)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: microrhabdus_ripa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771884
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.YYINITIAL = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerScheme.YYINITIAL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771904
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_ROWMAP_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ROWMAP_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: \
  TYPE[2]: CALL
  TOKENIZED[2]: \

CENTER_NODE: 30064771710
FRAGMENT_COUNT: 2
  ORIGINAL[0]: dispatchfulBendwise(scoliid_expurge)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: scoliid_expurge
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771558
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number > yylength()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > FUN1 ( )
  ORIGINAL[1]: this.zzScanError(ZZ_PUSHBACK_2BIG)
  TYPE[1]: CALL
  TOKENIZED[1]: this . FUN1 ( VAR1 )
  ORIGINAL[2]: LexerScheme.ZZ_PUSHBACK_2BIG
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: ZZ_PUSHBACK_2BIG
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771926
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_ATTRIBUTE_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ATTRIBUTE_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_ATTRIBUTE_PACKED_0
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771733
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sylvanlyNotchboard(dromiacea_remodeller)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dromiacea_remodeller
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477293
FRAGMENT_COUNT: 2
  ORIGINAL[0]: birnGib(bacteriform_taoism)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: bacteriform_taoism
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771727
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cortinariusAntineuritic(teck_frumpishness)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: teck_frumpishness
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640280
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640284
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640262
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719477291
FRAGMENT_COUNT: 2
  ORIGINAL[0]: climaticRearbitrate(unrevenging_hydroceramic)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: unrevenging_hydroceramic
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477110
FRAGMENT_COUNT: 11
  ORIGINAL[0]: this.zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzBuffer
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzBuffer
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: this.zzEndRead
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: this.zzMarkedPos
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: this.zzStartRead
  TYPE[5]: CALL
  TOKENIZED[5]: this . VAR1
  ORIGINAL[6]: zzCurrentPos >= zzBuffer.length
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 >= VAR2 . VAR3
  ORIGINAL[7]: this.zzCurrentPos
  TYPE[7]: CALL
  TOKENIZED[7]: this . VAR1
  ORIGINAL[8]: this.zzBuffer
  TYPE[8]: CALL
  TOKENIZED[8]: this . VAR1
  ORIGINAL[9]: zzBuffer
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: this
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: this

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 68719477157
FRAGMENT_COUNT: 3
  ORIGINAL[0]: this.zzBuffer
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: zzBuffer
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 68719477280
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pathophobiaElfishness(casavi_zincification)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: casavi_zincification
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771746
FRAGMENT_COUNT: 2
  ORIGINAL[0]: glaciologistAuthority(famously_workingly)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: famously_workingly
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771087
FRAGMENT_COUNT: 3
  ORIGINAL[0]: PipedOutputStream this.responseWriter = null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 this . VAR2 = null
  ORIGINAL[1]: this.responseWriter
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: this

CENTER_NODE: 68719477283
FRAGMENT_COUNT: 2
  ORIGINAL[0]: precompliantStove(corejoice_atropine)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: corejoice_atropine
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477297
FRAGMENT_COUNT: 2
  ORIGINAL[0]: reconnoitrerEnchytraeid(reprobative_sectary)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: reprobative_sectary
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771076
FRAGMENT_COUNT: 3
  ORIGINAL[0]: $obj7 = new java.io.InputStreamReader(in)
  TYPE[0]: CALL
  TOKENIZED[0]: $obj7 = new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[1]: new java.io.InputStreamReader(in)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . VAR2 . FUN1 ( VAR3 )
  ORIGINAL[2]: $obj7
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj7

CENTER_NODE: 30064771897
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerScheme.ZZ_ACTION = zzUnpackAction()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ACTION
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAction()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_ACTION
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477311
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pleurotomarioidSuccor(narcomania_costive)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: narcomania_costive
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476919
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int offset = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: offset = zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[2]: zzUnpackAction(ZZ_ACTION_PACKED_0, offset, result)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771728
FRAGMENT_COUNT: 2
  ORIGINAL[0]: opsonistPewee(catpipe_chloropalladic)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: catpipe_chloropalladic
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771736
FRAGMENT_COUNT: 2
  ORIGINAL[0]: daribahTrusion(mellsman_scoundrelly)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: mellsman_scoundrelly
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640269
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 68719477075
FRAGMENT_COUNT: 4
  ORIGINAL[0]: char[] map = new char[0x10000]
  TYPE[0]: CALL
  TOKENIZED[0]: char[] VAR1 = new char[0x10000]
  ORIGINAL[1]: int i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771900
FRAGMENT_COUNT: 3
  ORIGINAL[0]: String LexerScheme.ZZ_ACTION_PACKED_0 = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 VAR2 . VAR3 = \
  ORIGINAL[1]: LexerScheme.ZZ_ACTION_PACKED_0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_ACTION_PACKED_0
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771913
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.ZZ_UNKNOWN_ERROR = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 0
  ORIGINAL[1]: LexerScheme.ZZ_UNKNOWN_ERROR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771720
FRAGMENT_COUNT: 2
  ORIGINAL[0]: reboundSuspectable(spireme_overroll)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: spireme_overroll
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771307
FRAGMENT_COUNT: 4
  ORIGINAL[0]: offset = zzUnpackAttribute(ZZ_ATTRIBUTE_PACKED_0, offset, result)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR1 , VAR3 )
  ORIGINAL[1]: zzUnpackAttribute(ZZ_ATTRIBUTE_PACKED_0, offset, result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477284
FRAGMENT_COUNT: 2
  ORIGINAL[0]: antediluviallyRedactional(prodromus_scabriusculous)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: prodromus_scabriusculous
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771232
FRAGMENT_COUNT: 5
  ORIGINAL[0]: this.receivedBarrier.await()
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 . FUN1 ( )
  ORIGINAL[1]: new IOException(\
  TYPE[1]: CALL
  TOKENIZED[1]: new FUN1 ( \
  ORIGINAL[2]: $obj0
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: $obj0
  ORIGINAL[3]: e
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: $obj0
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: $obj0

CENTER_NODE: 30064771718
FRAGMENT_COUNT: 2
  ORIGINAL[0]: aurallyTransversus(mealer_centricality)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: mealer_centricality
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771747
FRAGMENT_COUNT: 2
  ORIGINAL[0]: plannerAnalgetic(tintinnabulate_veps)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: tintinnabulate_veps
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771541
FRAGMENT_COUNT: 3
  ORIGINAL[0]: zzMarkedPos - zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 8
  ORIGINAL[0]: length > zzBuffer.length
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 . VAR1
  ORIGINAL[1]: zzBuffer.length
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: this.zzBuffer
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzBuffer.length
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: this.zzBuffer
  TYPE[4]: CALL
  TOKENIZED[4]: this . VAR1
  ORIGINAL[5]: this.zzBuffer
  TYPE[5]: CALL
  TOKENIZED[5]: this . VAR1
  ORIGINAL[6]: length
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: length
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771119
FRAGMENT_COUNT: 2
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \

CENTER_NODE: 30064771886
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_LEXSTATE = { 0, 1 }
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = { 0 , 1 }
  ORIGINAL[1]: LexerScheme.ZZ_LEXSTATE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: { 0, 1 }
  TYPE[2]: CALL
  TOKENIZED[2]: { 0 , 1 }

CENTER_NODE: 30064771917
FRAGMENT_COUNT: 2
  ORIGINAL[0]: int LexerScheme.ZZ_PUSHBACK_2BIG = 2
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2
  ORIGINAL[1]: LexerScheme.ZZ_PUSHBACK_2BIG
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2

CENTER_NODE: 30064771714
FRAGMENT_COUNT: 2
  ORIGINAL[0]: spaningManway(theologism_axophyte)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: theologism_axophyte
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476958
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < l
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: j++
  TYPE[1]: CALL
  TOKENIZED[1]: j++
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771748
FRAGMENT_COUNT: 2
  ORIGINAL[0]: gelatinotypeRecasting(diprotodontia_framableness)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: diprotodontia_framableness
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771880
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int LexerScheme.YYEOF = -1
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = -1
  ORIGINAL[1]: LexerScheme.YYEOF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1
  ORIGINAL[3]: YYEOF
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477206
FRAGMENT_COUNT: 8
  ORIGINAL[0]: this.zzMarkedPos
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1
  ORIGINAL[1]: this.zzEndRead
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzBuffer
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: this.zzAtBOL
  TYPE[3]: CALL
  TOKENIZED[3]: this . VAR1
  ORIGINAL[4]: zzAtBOL
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: eof
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this

CENTER_NODE: 30064771883
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int LexerScheme.ZZ_BUFFERSIZE = 2048
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 . VAR2 = 2048
  ORIGINAL[1]: LexerScheme.ZZ_BUFFERSIZE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: ZZ_BUFFERSIZE
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771723
FRAGMENT_COUNT: 2
  ORIGINAL[0]: porencephalonAsiaticism(deregulationize_panamaian)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: deregulationize_panamaian
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771729
FRAGMENT_COUNT: 2
  ORIGINAL[0]: rebrandishForefield(norelin_pyothorax)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: norelin_pyothorax
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477296
FRAGMENT_COUNT: 2
  ORIGINAL[0]: boteinEtui(parachromatism_bantling)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: parachromatism_bantling
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771902
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int[] LexerScheme.ZZ_ROWMAP = zzUnpackRowMap()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ROWMAP
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackRowMap()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: ZZ_ROWMAP
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477323
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unfiberUnstimulating(frontalis_unberouged)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: frontalis_unberouged
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 6
  ORIGINAL[0]: int i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: int VAR1 = 0
  ORIGINAL[1]: int j = offset
  TYPE[1]: CALL
  TOKENIZED[1]: int VAR1 = VAR2
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476902
FRAGMENT_COUNT: 7
  ORIGINAL[0]: getHeaders()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: session
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: method
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: matchCheckHeader
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: session
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: session
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: session
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477313
FRAGMENT_COUNT: 2
  ORIGINAL[0]: balaniferousAffrontedness(hanksite_countervaunt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: hanksite_countervaunt
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477328
FRAGMENT_COUNT: 2
  ORIGINAL[0]: stegocephaliaOversourly(fountful_serif)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: fountful_serif
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771875
FRAGMENT_COUNT: 5
  ORIGINAL[0]: java.util.concurrent.atomic.AtomicBoolean LexerScheme.seminiferalUnarrived = new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 . VAR4 . VAR5 VAR6 . VAR7 = new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[1]: LexerScheme.seminiferalUnarrived
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: new java.util.concurrent.atomic.AtomicBoolean(false)
  TYPE[2]: CALL
  TOKENIZED[2]: new VAR1 . VAR2 . VAR3 . VAR4 . FUN1 ( false )
  ORIGINAL[3]: LexerScheme.seminiferalUnarrived
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: seminiferalUnarrived
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477288
FRAGMENT_COUNT: 2
  ORIGINAL[0]: derustPhyllopoda(nephewship_pretest)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: nephewship_pretest
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771735
FRAGMENT_COUNT: 2
  ORIGINAL[0]: quidderGunnage(neurectopia_ventrocaudal)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: neurectopia_ventrocaudal
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771895
FRAGMENT_COUNT: 4
  ORIGINAL[0]: LexerScheme.ZZ_CMAP_PACKED
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: zzUnpackCMap(ZZ_CMAP_PACKED)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: LexerScheme.ZZ_CMAP_PACKED
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: ZZ_CMAP_PACKED
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771535
FRAGMENT_COUNT: 6
  ORIGINAL[0]: zzMarkedPos - zzStartRead
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2
  ORIGINAL[1]: this.zzMarkedPos
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: this.zzStartRead
  TYPE[2]: CALL
  TOKENIZED[2]: this . VAR1
  ORIGINAL[3]: zzMarkedPos
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: this
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this

CENTER_NODE: 30064771551
FRAGMENT_COUNT: 1
  ORIGINAL[0]: throw new Error(message);
  TYPE[0]: CALL
  TOKENIZED[0]: throw new FUN1 ( VAR1 ) ;

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 4
  ORIGINAL[0]: NanoHTTPD.MIME_PLAINTEXT
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: MIME_PLAINTEXT
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: response
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NanoHTTPD
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771502
FRAGMENT_COUNT: 16
  ORIGINAL[0]: this.zzReader = reader
  TYPE[0]: CALL
  TOKENIZED[0]: this . VAR1 = VAR2
  ORIGINAL[1]: this.zzReader
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: zzReader
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: this
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: this
  ORIGINAL[4]: reader
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: this
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: this
  ORIGINAL[6]: this
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: this
  ORIGINAL[7]: this
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: this
  ORIGINAL[8]: this
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: this
  ORIGINAL[9]: this
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: this
  ORIGINAL[10]: this
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: this
  ORIGINAL[11]: this
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: this
  ORIGINAL[12]: this
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: this
  ORIGINAL[13]: this
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: this
  ORIGINAL[14]: this
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: this
  ORIGINAL[15]: this
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: this

CENTER_NODE: 30064771924
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_ATTRIBUTE = zzUnpackAttribute()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_ATTRIBUTE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackAttribute()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 68719477310
FRAGMENT_COUNT: 2
  ORIGINAL[0]: truncalExile(semivalvate_surpassingness)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: semivalvate_surpassingness
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771132
FRAGMENT_COUNT: 4
  ORIGINAL[0]: String.format(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \
  ORIGINAL[2]: <operator>.arrayInitializer
  TYPE[2]: CALL
  TOKENIZED[2]: <operator> . VAR1
  ORIGINAL[3]: String
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771409
FRAGMENT_COUNT: 4
  ORIGINAL[0]: int this.zzLexicalState = YYINITIAL
  TYPE[0]: CALL
  TOKENIZED[0]: int this . VAR1 = VAR2
  ORIGINAL[1]: this.zzLexicalState
  TYPE[1]: CALL
  TOKENIZED[1]: this . VAR1
  ORIGINAL[2]: LexerScheme.YYINITIAL
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: YYINITIAL
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771732
FRAGMENT_COUNT: 2
  ORIGINAL[0]: onychatrophiaActinography(stifledly_peaceful)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: stifledly_peaceful
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771734
FRAGMENT_COUNT: 2
  ORIGINAL[0]: nonpaidVotively(snarleyyow_semielliptic)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: snarleyyow_semielliptic
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640257
FRAGMENT_COUNT: 3
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch
  ORIGINAL[2]: catch
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: catch

CENTER_NODE: 30064771713
FRAGMENT_COUNT: 2
  ORIGINAL[0]: reuseRimmer(disasinize_slumpproof)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: disasinize_slumpproof
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640288
FRAGMENT_COUNT: 2
  ORIGINAL[0]: dauncy_athermic != null
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != null
  ORIGINAL[1]: if (dauncy_athermic != null)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: if ( VAR1 != null )

CENTER_NODE: 68719477315
FRAGMENT_COUNT: 2
  ORIGINAL[0]: swayingBepile(grapestalk_kayvan)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: grapestalk_kayvan
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771097
FRAGMENT_COUNT: 4
  ORIGINAL[0]: NanoHTTPD.Response response = new NanoHTTPD.Response(NanoHTTPD.Response.Status.OK, NanoHTTPD.MIME_PLAINTEXT, body)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 VAR3 = new VAR1 . FUN1 ( VAR1 . VAR2 . VAR4 . VAR5 , VAR1 . VAR6 , VAR7 )
  ORIGINAL[1]: new NanoHTTPD.Response(NanoHTTPD.Response.Status.OK, NanoHTTPD.MIME_PLAINTEXT, body)
  TYPE[1]: CALL
  TOKENIZED[1]: new VAR1 . FUN1 ( VAR1 . Response . VAR2 . VAR3 , VAR1 . VAR4 , VAR5 )
  ORIGINAL[2]: response
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: response
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771909
FRAGMENT_COUNT: 3
  ORIGINAL[0]: int[] LexerScheme.ZZ_TRANS = zzUnpackTrans()
  TYPE[0]: CALL
  TOKENIZED[0]: int[] VAR1 . VAR2 = FUN1 ( )
  ORIGINAL[1]: LexerScheme.ZZ_TRANS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: zzUnpackTrans()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 68719477287
FRAGMENT_COUNT: 2
  ORIGINAL[0]: thoneHomoeochronous(undercrypt_hurty)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: undercrypt_hurty
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 47244640282
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: finally
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: finally

CENTER_NODE: 30064771201
FRAGMENT_COUNT: 5
  ORIGINAL[0]: String.format(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . FUN1 ( \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \
  ORIGINAL[2]: <operator>.arrayInitializer
  TYPE[2]: CALL
  TOKENIZED[2]: <operator> . VAR1
  ORIGINAL[3]: String
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: message
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 2
  ORIGINAL[0]: try
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: try
  ORIGINAL[1]: catch
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: catch

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new PipedInputStream(this.responseWriter)
  TYPE[0]: CALL
  TOKENIZED[0]: new FUN1 ( this . VAR1 )
  ORIGINAL[1]: setResponseOptions(session, response)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: setChunkedTransfer(true)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( true )
  ORIGINAL[3]: response
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: response
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: response
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477298
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xincaJural(indicant_milanion)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: indicant_milanion
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

