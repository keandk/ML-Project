# Tokenized code fragments for 501258-v1.0.1-good
# Total center nodes processed: 105
# Total code fragments found: 530

CENTER_NODE: 68719480766
FRAGMENT_COUNT: 6
  ORIGINAL[0]: cur_offset
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: is_quoted
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: cur_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: cur_offset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064773989
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !compute_offset_length(tvb, offset, length, offset_ptr, length_ptr, exception)
  TYPE[0]: CALL
  TOKENIZED[0]: !compute_offset_length ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[1]: *offset_ptr + *length_ptr
  TYPE[1]: CALL
  TOKENIZED[1]: *offset_ptr + *length_ptr
  ORIGINAL[2]: *length_ptr
  TYPE[2]: CALL
  TOKENIZED[2]: *length_ptr
  ORIGINAL[3]: length_ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775029
FRAGMENT_COUNT: 6
  ORIGINAL[0]: eol_offset + 1 >= eob_offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + 1 >= VAR2
  ORIGINAL[1]: tvb_get_guint8(tvb, eol_offset + 1) == '\\n'
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 + 1 ) == '\\n'
  ORIGINAL[2]: tvb_get_guint8(tvb, eol_offset + 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 + 1 )
  ORIGINAL[3]: eol_offset++
  TYPE[3]: CALL
  TOKENIZED[3]: eol_offset++
  ORIGINAL[4]: eol_offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: next_offset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774292
FRAGMENT_COUNT: 2
  ORIGINAL[0]: DISSECTOR_ASSERT_NOT_REACHED()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: NULL
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064774463
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ptr = fast_ensure_contiguous(tvb, offset, sizeof(guint64))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , sizeof ( VAR4 ) )
  ORIGINAL[1]: fast_ensure_contiguous(tvb, offset, sizeof(guint64))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(guint64)
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: offset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719480054
FRAGMENT_COUNT: 5
  ORIGINAL[0]: &abs_length
  TYPE[0]: CALL
  TOKENIZED[0]: &abs_length
  ORIGINAL[1]: tvb_memcpy(tvb, duped, abs_offset, abs_length)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: abs_length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: abs_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: abs_length
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479612
FRAGMENT_COUNT: 4
  ORIGINAL[0]: exception = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: exception
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: exception
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: exception
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774188
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !compute_offset_length(tvb, offset, length, &abs_offset, &abs_length, NULL)
  TYPE[0]: CALL
  TOKENIZED[0]: !compute_offset_length ( VAR1 , VAR2 , VAR3 , &abs_offset , &abs_length , VAR4 )
  ORIGINAL[1]: abs_offset + abs_length <= tvb->length
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2 <= tvb->length
  ORIGINAL[2]: abs_offset + abs_length
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: tvb->length
  TYPE[3]: CALL
  TOKENIZED[3]: tvb->length
  ORIGINAL[4]: length
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tvb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tvb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479382
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dnp3_desegment = TRUE
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: dnp3_desegment
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRUE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480480
FRAGMENT_COUNT: 4
  ORIGINAL[0]: character < 256 ? character : '.'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 256 ? VAR1 : ' . '
  ORIGINAL[1]: character < 256
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 256
  ORIGINAL[2]: character
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: character
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771291
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (guint64)hi * 0x10000 + lo
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 ) VAR2 * 0x10000 + VAR3
  ORIGINAL[1]: (guint64)hi * 0x10000
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2 * 0x10000
  ORIGINAL[2]: (guint64)hi
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: lo
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479685
FRAGMENT_COUNT: 7
  ORIGINAL[0]: tvb->initialized
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->initialized
  ORIGINAL[1]: tvb->type
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->type
  ORIGINAL[2]: tvb->tvbuffs
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->tvbuffs
  ORIGINAL[3]: tvbuffs
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: composite
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tvb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064774779
FRAGMENT_COUNT: 4
  ORIGINAL[0]: result_offset == -1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == -1
  ORIGINAL[1]: result_offset - abs_offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - VAR2
  ORIGINAL[2]: result_offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: abs_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480250
FRAGMENT_COUNT: 5
  ORIGINAL[0]: bit_offset+no_of_bits
  TYPE[0]: CALL
  TOKENIZED[0]: bit_offset+no_of_bits
  ORIGINAL[1]: no_of_bits
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: no_of_bits
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: bit_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: no_of_bits
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476923
FRAGMENT_COUNT: 3
  ORIGINAL[0]: proto_item_append_text(item1, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , \
  ORIGINAL[1]: item1
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: text
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480569
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb_ensure_bytes_exist(tvb, offset, length)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: length
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774257
FRAGMENT_COUNT: 4
  ORIGINAL[0]: composite = &tvb->tvbuffs.composite
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = &tvb->tvbuffs . VAR1
  ORIGINAL[1]: &tvb->tvbuffs.composite
  TYPE[1]: CALL
  TOKENIZED[1]: &tvb->tvbuffs . VAR1
  ORIGINAL[2]: composite
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: num_members
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774001
FRAGMENT_COUNT: 1
  ORIGINAL[0]: DISSECTOR_ASSERT_NOT_REACHED()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )

CENTER_NODE: 68719480166
FRAGMENT_COUNT: 5
  ORIGINAL[0]: guid->data3 = tvb_get_letohs(tvb, offset + 6)
  TYPE[0]: CALL
  TOKENIZED[0]: guid->data3 = FUN1 ( VAR1 , VAR2 + 6 )
  ORIGINAL[1]: tvb_memcpy(tvb, guid->data4, offset + 8, sizeof guid->data4)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , guid->data4 , VAR2 + 8 , sizeof guid->data4 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: guid
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480114
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tvb_get_letohl(tvb, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: tvb
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064774207
FRAGMENT_COUNT: 3
  ORIGINAL[0]: DISSECTOR_ASSERT(tvb && tvb->initialized)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 && tvb->initialized )
  ORIGINAL[1]: tvb && tvb->initialized
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 && tvb->initialized
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771315
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *al_objtype
  TYPE[0]: CALL
  TOKENIZED[0]: *al_objtype
  ORIGINAL[1]: al_obj = tvb_get_ntohs(tvb, offset)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[2]: al_obj
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479929
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *b == needle
  TYPE[0]: CALL
  TOKENIZED[0]: *b == VAR1
  ORIGINAL[1]: *b
  TYPE[1]: CALL
  TOKENIZED[1]: *b
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774866
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ptr = ensure_contiguous(tvb, offset, size)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: ensure_contiguous(tvb, offset, size)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: ptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064773921
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb->length		= length
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->length = VAR1
  ORIGINAL[1]: tvb->length
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->length
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480101
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ptr = fast_ensure_contiguous(tvb, offset, 3)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , 3 )
  ORIGINAL[1]: pletoh24(ptr)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: ptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479744
FRAGMENT_COUNT: 4
  ORIGINAL[0]: -1
  TYPE[0]: CALL
  TOKENIZED[0]: -1
  ORIGINAL[1]: &abs_offset
  TYPE[1]: CALL
  TOKENIZED[1]: &abs_offset
  ORIGINAL[2]: abs_offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: abs_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479796
FRAGMENT_COUNT: 4
  ORIGINAL[0]: -1
  TYPE[0]: CALL
  TOKENIZED[0]: -1
  ORIGINAL[1]: &abs_offset
  TYPE[1]: CALL
  TOKENIZED[1]: &abs_offset
  ORIGINAL[2]: abs_offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: abs_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774737
FRAGMENT_COUNT: 9
  ORIGINAL[0]: tvb->real_data
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->real_data
  ORIGINAL[1]: tvb->real_data + abs_offset
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->real_data + VAR1
  ORIGINAL[2]: tvb->real_data
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->real_data
  ORIGINAL[3]: tvb->real_data
  TYPE[3]: CALL
  TOKENIZED[3]: tvb->real_data
  ORIGINAL[4]: real_data
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tvb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tvb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: abs_offset
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: tvb
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064774325
FRAGMENT_COUNT: 4
  ORIGINAL[0]: end_offset <= tvb->length
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= tvb->length
  ORIGINAL[1]: tvb->real_data + u_offset
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->real_data + VAR1
  ORIGINAL[2]: tvb->real_data
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->real_data
  ORIGINAL[3]: u_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480069
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fast_ensure_contiguous(tvb, offset, 3)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 3 )
  ORIGINAL[1]: ptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773889
FRAGMENT_COUNT: 3
  ORIGINAL[0]: DISSECTOR_ASSERT(tvb->type == TVBUFF_REAL_DATA)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( tvb->type == VAR1 )
  ORIGINAL[1]: tvb->type == TVBUFF_REAL_DATA
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->type == VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480057
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ensure_contiguous(tvb, offset, length)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064774786
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cmp == 0 ? 0 : -1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 ? 0 : -1
  ORIGINAL[1]: cmp == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1
  ORIGINAL[3]: ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cmp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480872
FRAGMENT_COUNT: 7
  ORIGINAL[0]: haystack_tvb->length < 1 || needle_tvb->length < 1
  TYPE[0]: CALL
  TOKENIZED[0]: haystack_tvb->length < 1 || needle_tvb->length < 1
  ORIGINAL[1]: haystack_data + haystack_abs_offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: haystack_data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: location
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: haystack_data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: haystack_abs_offset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: haystack_data
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775121
FRAGMENT_COUNT: 6
  ORIGINAL[0]: bytes_to_str(tvb_get_ptr(tvb, offset, len), len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( FUN2 ( VAR1 , VAR2 , VAR3 ) , VAR3 )
  ORIGINAL[1]: tvb_get_ptr(tvb, offset, len)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774461
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pntohl(ptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: ptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719480105
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(guint32)
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: guint32
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480845
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tempchar == '\\n'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == '\\n'
  ORIGINAL[1]: tempchar
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tempchar
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tempchar
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tempchar
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774192
FRAGMENT_COUNT: 5
  ORIGINAL[0]: length < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: THROW(ReportedBoundsError)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ReportedBoundsError
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480023
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb->type
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->type
  ORIGINAL[1]: tvb->tvbuffs.subset.tvb
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->tvbuffs . VAR1 . VAR2
  ORIGINAL[2]: target
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: abs_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774934
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tvb_memcpy(tvb, strptr, offset, size)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: tvb
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: strptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: lengthp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719480809
FRAGMENT_COUNT: 4
  ORIGINAL[0]: counter = offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: counter
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479734
FRAGMENT_COUNT: 6
  ORIGINAL[0]: DISSECTOR_ASSERT(tvb && tvb->initialized)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 && tvb->initialized )
  ORIGINAL[1]: tvb->initialized
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->initialized
  ORIGINAL[2]: compute_offset_length(tvb, offset, -1, &abs_offset, &abs_length, NULL)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , -1 , &abs_offset , &abs_length , VAR3 )
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: offset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775146
FRAGMENT_COUNT: 1
  ORIGINAL[0]: -1
  TYPE[0]: CALL
  TOKENIZED[0]: -1

CENTER_NODE: 68719479406
FRAGMENT_COUNT: 13
  ORIGINAL[0]: tvb->type
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->type
  ORIGINAL[1]: tvb->initialized
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->initialized
  ORIGINAL[2]: tvb->usage_count
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->usage_count
  ORIGINAL[3]: tvb->length
  TYPE[3]: CALL
  TOKENIZED[3]: tvb->length
  ORIGINAL[4]: tvb->reported_length
  TYPE[4]: CALL
  TOKENIZED[4]: tvb->reported_length
  ORIGINAL[5]: tvb->free_cb
  TYPE[5]: CALL
  TOKENIZED[5]: tvb->free_cb
  ORIGINAL[6]: tvb->real_data
  TYPE[6]: CALL
  TOKENIZED[6]: tvb->real_data
  ORIGINAL[7]: tvb->raw_offset
  TYPE[7]: CALL
  TOKENIZED[7]: tvb->raw_offset
  ORIGINAL[8]: tvb->used_in		= NULL
  TYPE[8]: CALL
  TOKENIZED[8]: tvb->used_in = VAR1
  ORIGINAL[9]: tvb->used_in
  TYPE[9]: CALL
  TOKENIZED[9]: tvb->used_in
  ORIGINAL[10]: tvb->ds_tvb
  TYPE[10]: CALL
  TOKENIZED[10]: tvb->ds_tvb
  ORIGINAL[11]: ds_tvb
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: tvb
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 30064774310
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tvb->type
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->type
  ORIGINAL[1]: composite_ensure_contiguous_no_exception(tvb, abs_offset, abs_length)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: abs_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: abs_length
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480040
FRAGMENT_COUNT: 5
  ORIGINAL[0]: duped = g_malloc(abs_length)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: tvb_memcpy(tvb, duped, abs_offset, abs_length)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: duped
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773873
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb->usage_count <= count
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->usage_count <= VAR1
  ORIGINAL[1]: tvb->usage_count = 1
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->usage_count = 1
  ORIGINAL[2]: tvb->usage_count
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->usage_count
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774021
FRAGMENT_COUNT: 9
  ORIGINAL[0]: &tvb->tvbuffs.subset.offset
  TYPE[0]: CALL
  TOKENIZED[0]: &tvb->tvbuffs . VAR1 . VAR2
  ORIGINAL[1]: tvb->tvbuffs.subset.offset
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->tvbuffs . VAR1 . VAR2
  ORIGINAL[2]: tvb->tvbuffs.subset
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->tvbuffs . VAR1
  ORIGINAL[3]: tvb->tvbuffs.subset
  TYPE[3]: CALL
  TOKENIZED[3]: tvb->tvbuffs . VAR1
  ORIGINAL[4]: tvb->tvbuffs.subset
  TYPE[4]: CALL
  TOKENIZED[4]: tvb->tvbuffs . VAR1
  ORIGINAL[5]: tvb->tvbuffs.subset
  TYPE[5]: CALL
  TOKENIZED[5]: tvb->tvbuffs . VAR1
  ORIGINAL[6]: tvb->tvbuffs.subset.offset
  TYPE[6]: CALL
  TOKENIZED[6]: tvb->tvbuffs . VAR1 . VAR2
  ORIGINAL[7]: tvb->tvbuffs.subset
  TYPE[7]: CALL
  TOKENIZED[7]: tvb->tvbuffs . VAR1
  ORIGINAL[8]: offset
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719480090
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ieee_fp_union.w[1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 [ 1 ]
  ORIGINAL[1]: tvb_get_ntohl(tvb, offset)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771087
FRAGMENT_COUNT: 4
  ORIGINAL[0]: proto_item_append_text(item, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , \
  ORIGINAL[1]: item
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: text
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: TRUE
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480503
FRAGMENT_COUNT: 6
  ORIGINAL[0]: len = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: ptr = ensure_contiguous(tvb, offset, size)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: ensure_contiguous(tvb, offset, size)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719480225
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tot_no_bits < 16
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 16
  ORIGINAL[1]: tot_no_bits > 16
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 > 16
  ORIGINAL[2]: tot_no_bits
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tot_no_bits
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tot_no_bits
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773882
FRAGMENT_COUNT: 6
  ORIGINAL[0]: slist != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: slist = slist->next
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = slist->next
  ORIGINAL[2]: slist->next
  TYPE[2]: CALL
  TOKENIZED[2]: slist->next
  ORIGINAL[3]: for (slist = tvb->used_in;slist != NULL;slist = slist->next)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = tvb->used_in ; VAR1 != VAR2 ; VAR1 = slist->next )
  ORIGINAL[4]: slist
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: slist
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479659
FRAGMENT_COUNT: 7
  ORIGINAL[0]: last_tvb=tvb
  TYPE[0]: CALL
  TOKENIZED[0]: last_tvb=tvb
  ORIGINAL[1]: tvb_set_subset(tvb, backing, backing_offset, backing_length, reported_length)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: backing
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tvb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tvb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719480174
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb_get_ntohguid(tvb, offset, guid)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: little_endian
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479952
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tvb->type == TVBUFF_COMPOSITE
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->type == VAR1
  ORIGINAL[1]: tvb->type
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->type
  ORIGINAL[2]: TVBUFF_COMPOSITE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480446
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774072
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb && !tvb->initialized
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && !tvb->initialized
  ORIGINAL[1]: !tvb->initialized
  TYPE[1]: CALL
  TOKENIZED[1]: !tvb->initialized
  ORIGINAL[2]: tvb->initialized
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->initialized
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774884
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (ptr = ensure_contiguous(tvb, offset, size)) == NULL
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 ) ) == VAR5
  ORIGINAL[1]: len = tvb_length_remaining(tvb, offset)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[2]: tvb_length_remaining(tvb, offset)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479512
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *last_tvb=NULL
  TYPE[0]: CALL
  TOKENIZED[0]: *last_tvb=NULL
  ORIGINAL[1]: last_tvb
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: last_tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640564
FRAGMENT_COUNT: 1
  ORIGINAL[0]: little_endian
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064774149
FRAGMENT_COUNT: 4
  ORIGINAL[0]: slist != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: slist
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774469
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ieee_fp_union.f
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: f
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: ieee_fp_union
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480136
FRAGMENT_COUNT: 6
  ORIGINAL[0]: memcpy(addr, ptr, sizeof *addr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof *addr )
  ORIGINAL[1]: sizeof *addr
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof *addr
  ORIGINAL[2]: ptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: addr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: addr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479778
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb->initialized
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->initialized
  ORIGINAL[1]: initialized
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774801
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cmp = memcmp(ptr, str, size)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: memcmp(ptr, str, size)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: ptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: cmp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cmp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773897
FRAGMENT_COUNT: 5
  ORIGINAL[0]: g_slist_prepend(tvb->used_in, used_in)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( tvb->used_in , VAR1 )
  ORIGINAL[1]: tvb->used_in
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->used_in
  ORIGINAL[2]: used_in
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: used_in
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479098
FRAGMENT_COUNT: 65
  ORIGINAL[0]: &tfs_set_notset
  TYPE[0]: CALL
  TOKENIZED[0]: &tfs_set_notset
  ORIGINAL[1]: &tfs_set_notset
  TYPE[1]: CALL
  TOKENIZED[1]: &tfs_set_notset
  ORIGINAL[2]: tfs_set_notset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tfs_set_notset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tfs_set_notset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tfs_set_notset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tfs_set_notset
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: tfs_set_notset
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: tfs_set_notset
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: tfs_set_notset
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: tfs_set_notset
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: tfs_set_notset
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: tfs_set_notset
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: tfs_set_notset
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: tfs_set_notset
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: tfs_set_notset
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: tfs_set_notset
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: tfs_set_notset
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: tfs_set_notset
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: tfs_set_notset
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: tfs_set_notset
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: tfs_set_notset
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: tfs_set_notset
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: tfs_set_notset
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: tfs_set_notset
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: tfs_set_notset
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: tfs_set_notset
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: tfs_set_notset
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: tfs_set_notset
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: tfs_set_notset
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: tfs_set_notset
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: tfs_set_notset
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: tfs_set_notset
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: tfs_set_notset
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: tfs_set_notset
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: tfs_set_notset
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: tfs_set_notset
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: tfs_set_notset
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: tfs_set_notset
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1
  ORIGINAL[39]: tfs_set_notset
  TYPE[39]: IDENTIFIER
  TOKENIZED[39]: VAR1
  ORIGINAL[40]: tfs_set_notset
  TYPE[40]: IDENTIFIER
  TOKENIZED[40]: VAR1
  ORIGINAL[41]: tfs_set_notset
  TYPE[41]: IDENTIFIER
  TOKENIZED[41]: VAR1
  ORIGINAL[42]: tfs_set_notset
  TYPE[42]: IDENTIFIER
  TOKENIZED[42]: VAR1
  ORIGINAL[43]: tfs_set_notset
  TYPE[43]: IDENTIFIER
  TOKENIZED[43]: VAR1
  ORIGINAL[44]: tfs_set_notset
  TYPE[44]: IDENTIFIER
  TOKENIZED[44]: VAR1
  ORIGINAL[45]: tfs_set_notset
  TYPE[45]: IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: tfs_set_notset
  TYPE[46]: IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: tfs_set_notset
  TYPE[47]: IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: tfs_set_notset
  TYPE[48]: IDENTIFIER
  TOKENIZED[48]: VAR1
  ORIGINAL[49]: tfs_set_notset
  TYPE[49]: IDENTIFIER
  TOKENIZED[49]: VAR1
  ORIGINAL[50]: tfs_set_notset
  TYPE[50]: IDENTIFIER
  TOKENIZED[50]: VAR1
  ORIGINAL[51]: tfs_set_notset
  TYPE[51]: IDENTIFIER
  TOKENIZED[51]: VAR1
  ORIGINAL[52]: tfs_set_notset
  TYPE[52]: IDENTIFIER
  TOKENIZED[52]: VAR1
  ORIGINAL[53]: tfs_set_notset
  TYPE[53]: IDENTIFIER
  TOKENIZED[53]: VAR1
  ORIGINAL[54]: tfs_set_notset
  TYPE[54]: IDENTIFIER
  TOKENIZED[54]: VAR1
  ORIGINAL[55]: tfs_set_notset
  TYPE[55]: IDENTIFIER
  TOKENIZED[55]: VAR1
  ORIGINAL[56]: tfs_set_notset
  TYPE[56]: IDENTIFIER
  TOKENIZED[56]: VAR1
  ORIGINAL[57]: tfs_set_notset
  TYPE[57]: IDENTIFIER
  TOKENIZED[57]: VAR1
  ORIGINAL[58]: tfs_set_notset
  TYPE[58]: IDENTIFIER
  TOKENIZED[58]: VAR1
  ORIGINAL[59]: tfs_set_notset
  TYPE[59]: IDENTIFIER
  TOKENIZED[59]: VAR1
  ORIGINAL[60]: tfs_set_notset
  TYPE[60]: IDENTIFIER
  TOKENIZED[60]: VAR1
  ORIGINAL[61]: tfs_set_notset
  TYPE[61]: IDENTIFIER
  TOKENIZED[61]: VAR1
  ORIGINAL[62]: tfs_set_notset
  TYPE[62]: IDENTIFIER
  TOKENIZED[62]: VAR1
  ORIGINAL[63]: tfs_set_notset
  TYPE[63]: IDENTIFIER
  TOKENIZED[63]: VAR1
  ORIGINAL[64]: tfs_set_notset
  TYPE[64]: IDENTIFIER
  TOKENIZED[64]: VAR1

CENTER_NODE: 68719479814
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tvb->type
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->type
  ORIGINAL[1]: type
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640591
FRAGMENT_COUNT: 2
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else
  ORIGINAL[1]: ptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640626
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064773940
FRAGMENT_COUNT: 3
  ORIGINAL[0]: DISSECTOR_ASSERT(length_ptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: length_ptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480097
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ptr = fast_ensure_contiguous(tvb, offset, sizeof(guint16))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , sizeof ( VAR4 ) )
  ORIGINAL[1]: pletohs(ptr)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: ptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479384
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !tvbuff_mem_chunk
  TYPE[0]: CALL
  TOKENIZED[0]: !tvbuff_mem_chunk
  ORIGINAL[1]: <global> tvbuff_mem_chunk
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: tvbuff_mem_chunk
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480706
FRAGMENT_COUNT: 4
  ORIGINAL[0]: _tvb_get_nstringz(tvb, offset, bufsize, buffer, &bytes_copied)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , &bytes_copied )
  ORIGINAL[1]: offset
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: bufsize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480606
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tvb_ensure_bytes_exist(tvb, offset, length)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: ptr = ensure_contiguous(tvb, offset, length)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: ensure_contiguous(tvb, offset, length)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774494
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pletoh64(ptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: ptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064774944
FRAGMENT_COUNT: 4
  ORIGINAL[0]: size = tvb_strsize(tvb, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: tvb_strsize(tvb, offset)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774449
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fast_ensure_contiguous(tvb, offset, sizeof(guint8))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(guint8)
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: guint8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480636
FRAGMENT_COUNT: 5
  ORIGINAL[0]: strptr = ep_alloc(size)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: tvb_memcpy(tvb, strptr, offset, size)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: strptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480145
FRAGMENT_COUNT: 6
  ORIGINAL[0]: guid->data2
  TYPE[0]: CALL
  TOKENIZED[0]: guid->data2
  ORIGINAL[1]: tvb_get_ntohs(tvb, offset + 4)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 + 4 )
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tvb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719480851
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb_get_ptr(tvb, offset, len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: tvb
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479730
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb->initialized
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->initialized
  ORIGINAL[1]: initialized
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774767
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb_length(tvb) < tvb_reported_length(tvb)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) < FUN2 ( VAR1 )
  ORIGINAL[1]: THROW(BoundsError)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: BoundsError
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: nul_offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771073
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *p = (const guint8 *)buf
  TYPE[0]: CALL
  TOKENIZED[0]: *p = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const guint8 *)buf
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: p
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480321
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tvbufflen < (guint) maxlength
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( VAR2 ) VAR3
  ORIGINAL[1]: limit = tvbufflen
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: limit
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvbufflen
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: limit
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: limit
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719480007
FRAGMENT_COUNT: 2
  ORIGINAL[0]: DISSECTOR_ASSERT_NOT_REACHED()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: NULL
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064773901
FRAGMENT_COUNT: 3
  ORIGINAL[0]: DISSECTOR_ASSERT(parent->initialized)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( parent->initialized )
  ORIGINAL[1]: parent->initialized
  TYPE[1]: CALL
  TOKENIZED[1]: parent->initialized
  ORIGINAL[2]: child
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479465
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tvb->usage_count += count
  TYPE[0]: CALL
  TOKENIZED[0]: tvb->usage_count += VAR1
  ORIGINAL[1]: tvb->usage_count
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->usage_count
  ORIGINAL[2]: tvb->usage_count
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->usage_count
  ORIGINAL[3]: usage_count
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479531
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb_new_real_data(data, length, reported_length)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: reported_length
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719478628
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tvb_length(tvb)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: length
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774509
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ptr = fast_ensure_contiguous(tvb, offset, sizeof(guint32))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , sizeof ( VAR4 ) )
  ORIGINAL[1]: fast_ensure_contiguous(tvb, offset, sizeof(guint32))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: ptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: addr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479932
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b = haystack
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: haystack
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480498
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (ptr = ensure_contiguous(tvb, offset, size)) == NULL
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 ) ) == VAR5
  ORIGINAL[1]: ensure_contiguous(tvb, offset, len)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774452
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ptr = fast_ensure_contiguous(tvb, offset, sizeof(guint16))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , sizeof ( VAR4 ) )
  ORIGINAL[1]: fast_ensure_contiguous(tvb, offset, sizeof(guint16))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(guint16)
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: offset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719480597
FRAGMENT_COUNT: 7
  ORIGINAL[0]: length != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: memcpy(strbuf, ptr, length)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strbuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: length
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: length
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775003
FRAGMENT_COUNT: 5
  ORIGINAL[0]: len == -1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == -1
  ORIGINAL[1]: buffer[bufsize - 1] = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 - 1 ] = 0
  ORIGINAL[2]: buffer[bufsize - 1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 - 1 ]
  ORIGINAL[3]: bufsize - 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 1
  ORIGINAL[4]: buffer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478623
FRAGMENT_COUNT: 7
  ORIGINAL[0]: length < DNP_HDR_LEN || tvb_get_ntohs(tvb, 0) != 0x0564
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 || FUN1 ( VAR3 , 0 ) != 0x0564
  ORIGINAL[1]: DNP_HDR_LEN
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: tvb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pinfo
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tree
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: TRUE
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: get_dnp3_message_len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064774337
FRAGMENT_COUNT: 4
  ORIGINAL[0]: p == NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: THROW(exception)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: exception
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479691
FRAGMENT_COUNT: 2
  ORIGINAL[0]: tvb_new(TVBUFF_COMPOSITE)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: TVBUFF_COMPOSITE
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064774235
FRAGMENT_COUNT: 6
  ORIGINAL[0]: reported_length < tvb->length
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < tvb->length
  ORIGINAL[1]: tvb->length = reported_length
  TYPE[1]: CALL
  TOKENIZED[1]: tvb->length = VAR1
  ORIGINAL[2]: tvb->length
  TYPE[2]: CALL
  TOKENIZED[2]: tvb->length
  ORIGINAL[3]: length
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: reported_length
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774986
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *bytes_copied = limit + 1
  TYPE[0]: CALL
  TOKENIZED[0]: *bytes_copied = VAR1 + 1
  ORIGINAL[1]: *bytes_copied
  TYPE[1]: CALL
  TOKENIZED[1]: *bytes_copied
  ORIGINAL[2]: limit + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: decreased_max
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: limit
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774503
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ieee_fp_union.w[1] = tvb_get_letohl(tvb, offset+4)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 [ 1 ] = FUN1 ( VAR3 , offset+4 )
  ORIGINAL[1]: ieee_fp_union.w[1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 [ 1 ]
  ORIGINAL[2]: tvb_get_letohl(tvb, offset+4)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , offset+4 )
  ORIGINAL[3]: ieee_fp_union
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

