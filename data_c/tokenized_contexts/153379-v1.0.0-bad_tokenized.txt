# Tokenized code fragments for 153379-v1.0.0-bad
# Total center nodes processed: 27
# Total code fragments found: 160

CENTER_NODE: 30064771199
FRAGMENT_COUNT: 7
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: inl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: inl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771787
FRAGMENT_COUNT: 10
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: Camellia_cfb8_encrypt(in,out,((long )(8 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num,ctx -> encrypt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( 8 == 1 && ! ( VAR3 -> VAR4 & 0x2000 ) ?inl * 8 : VAR5 ) ) , ( & ( ( VAR6 * ) ( VAR3 -> VAR7 ) ) -> VAR8 ) , VAR3 -> VAR9 , &ctx -> VAR10 , VAR3 -> VAR11 )
  ORIGINAL[2]: (long )(8 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( 8 == 1 && ! ( VAR1 -> VAR2 & 0x2000 ) ?inl * 8 : VAR3 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ctx -> iv
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: &ctx -> VAR1
  ORIGINAL[6]: ctx -> encrypt
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: in
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: out
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: inl
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771814
FRAGMENT_COUNT: 6
  ORIGINAL[0]: Camellia_set_key(key,ctx -> key_len * 8,(ctx -> cipher_data))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 -> VAR3 * 8 , ( VAR2 -> VAR4 ) )
  ORIGINAL[1]: ctx -> key_len * 8
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 * 8
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: cipher_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ctx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477080
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ctx -> cipher_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: cipher_data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ctx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: long
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: long

CENTER_NODE: 68719477315
FRAGMENT_COUNT: 5
  ORIGINAL[0]: * stonesoup_printf_context = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: * VAR1 = VAR2
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: <global> stonesoup_printf_context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: NULL
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771246
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8
  ORIGINAL[2]: sizeof(long )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long )
  ORIGINAL[3]: long
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: long

CENTER_NODE: 30064771831
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_input_len < 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 2
  ORIGINAL[1]: stonesoup_function_ptr = malloc(sizeof(void *))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( sizeof ( void * ) )
  ORIGINAL[2]: malloc(sizeof(void *))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( sizeof ( void * ) )
  ORIGINAL[3]: stonesoup_function_ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_function_ptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771129
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: stonesoup_trace
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_location
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: modulus_param_str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476796
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: stonesoup_trace
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_location
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477243
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: in += chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: out += chunk
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += VAR2
  ORIGINAL[3]: out
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: out
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771731
FRAGMENT_COUNT: 11
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: Camellia_cfb8_encrypt(in,out,((long )(8 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num,ctx -> encrypt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( 8 == 1 && ! ( VAR3 -> VAR4 & 0x2000 ) ?inl * 8 : VAR5 ) ) , ( & ( ( VAR6 * ) ( VAR3 -> VAR7 ) ) -> VAR8 ) , VAR3 -> VAR9 , &ctx -> VAR10 , VAR3 -> VAR11 )
  ORIGINAL[2]: (long )(8 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( 8 == 1 && ! ( VAR1 -> VAR2 & 0x2000 ) ?inl * 8 : VAR3 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ctx -> iv
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: &ctx -> VAR1
  ORIGINAL[6]: ctx -> num
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: ctx -> encrypt
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: in
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: out
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: ctx
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i <= inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= VAR2
  ORIGINAL[2]: i += bl
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += VAR2
  ORIGINAL[3]: Camellia_ecb_encrypt(in + i,out + i,(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> encrypt)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 + VAR2 , VAR3 + VAR2 , ( & ( ( VAR4 * ) ( VAR5 -> VAR6 ) ) -> VAR7 ) , VAR5 -> VAR8 )
  ORIGINAL[4]: for (i = 0;i <= inl;i += bl)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = 0 ; VAR1 <= VAR2 ; VAR1 += VAR3 )

CENTER_NODE: 30064771511
FRAGMENT_COUNT: 10
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: Camellia_cfb128_encrypt(in,out,((long )(128 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num,ctx -> encrypt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( 128 == 1 && ! ( VAR3 -> VAR4 & 0x2000 ) ?inl * 8 : VAR5 ) ) , ( & ( ( VAR6 * ) ( VAR3 -> VAR7 ) ) -> VAR8 ) , VAR3 -> VAR9 , &ctx -> VAR10 , VAR3 -> VAR11 )
  ORIGINAL[2]: (long )(128 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( 128 == 1 && ! ( VAR1 -> VAR2 & 0x2000 ) ?inl * 8 : VAR3 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ctx -> iv
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: &ctx -> VAR1
  ORIGINAL[6]: ctx -> encrypt
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: in
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: out
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: inl
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477371
FRAGMENT_COUNT: 6
  ORIGINAL[0]: {(761), (1), (192 / 8), (16), ((0 | 0x3)), (camellia_init_key), (camellia_192_cfb1_cipher), (((void *)0)), ((sizeof(EVP_CAMELLIA_KEY ))), (EVP_CIPHER_set_asn1_iv), (EVP_CIPHER_get_asn1_iv), (((void *)0)), ((void *)0)}
  TYPE[0]: CALL
  TOKENIZED[0]: { ( 761 ) , ( 1 ) , ( 192 / 8 ) , ( 16 ) , ( ( 0 | 0x3 ) ) , ( VAR1 ) , ( VAR2 ) , ( ( ( void * ) 0 ) ) , ( ( sizeof ( VAR3 ) ) ) , ( VAR4 ) , ( VAR5 ) , ( ( ( void * ) 0 ) ) , ( ( void * ) 0 ) }
  ORIGINAL[1]: sizeof(EVP_CAMELLIA_KEY )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: EVP_CIPHER_set_asn1_iv
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: EVP_CIPHER_set_asn1_iv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: EVP_CIPHER_get_asn1_iv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: EVP_CIPHER_set_asn1_iv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771630
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: in += chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: in
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: out
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477166
FRAGMENT_COUNT: 7
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: inl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: inl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: inl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476914
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: (size_t )1
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) 1
  ORIGINAL[2]: sizeof(long )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long )
  ORIGINAL[3]: long
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: long

CENTER_NODE: 30064771447
FRAGMENT_COUNT: 5
  ORIGINAL[0]: bordered_divisorial != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: dermatogen_forestalled = &plaistering_multeity
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = &plaistering_multeity
  ORIGINAL[2]: &plaistering_multeity
  TYPE[2]: CALL
  TOKENIZED[2]: &plaistering_multeity
  ORIGINAL[3]: dermatogen_forestalled
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dermatogen_forestalled
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476864
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ctx -> cipher
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: cipher
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: bl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ctx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476809
FRAGMENT_COUNT: 8
  ORIGINAL[0]: len < 10
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 10
  ORIGINAL[1]: *modulus_function = stonesoup_modulus_function2
  TYPE[1]: CALL
  TOKENIZED[1]: *modulus_function = VAR1
  ORIGINAL[2]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[3]: stonesoup_trace
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_trace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_trace
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: trace_point
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_trace
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771096
FRAGMENT_COUNT: 9
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stat(dirpath, &st) == -1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[2]: stat(dirpath, &st)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , &st )
  ORIGINAL[3]: -1
  TYPE[3]: CALL
  TOKENIZED[3]: -1
  ORIGINAL[4]: retval = mkdir(dirpath, 0700)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[5]: mkdir(dirpath, 0700)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[6]: retval
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dirpath
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: retval
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: sizeof(long ) * 8
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( long ) * 8

CENTER_NODE: 68719477152
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: in += chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: chunk
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: in
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771385
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i <= inl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= VAR2
  ORIGINAL[1]: (EVP_CAMELLIA_KEY *)(ctx -> cipher_data)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: cipher_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ctx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: inl -= chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -= VAR2
  ORIGINAL[2]: in += chunk
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += VAR2
  ORIGINAL[3]: in
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: in
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771411
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8 - 2
  ORIGINAL[2]: sizeof(long ) * 8
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) * 8
  ORIGINAL[3]: sizeof(long )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long )

