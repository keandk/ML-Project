# Tokenized code fragments for 152532-v1.0.0-bad
# Total center nodes processed: 35
# Total code fragments found: 150

CENTER_NODE: 47244640270
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476849
FRAGMENT_COUNT: 10
  ORIGINAL[0]: val = (se_alloc(sizeof(stream_t )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( FUN1 ( sizeof ( VAR2 ) ) )
  ORIGINAL[1]: se_alloc(sizeof(stream_t ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[2]: val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: val
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: val
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: val
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ((guint )((unsigned long )key -> circ . circuit)) ^ (key -> p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( VAR1 ) ( ( unsigned long ) VAR2 -> VAR3 . VAR4 ) ) ^ ( VAR2 -> VAR5 )
  ORIGINAL[1]: (guint )((unsigned long )key -> circ . circuit)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) ( ( unsigned long ) VAR2 -> VAR3 . VAR4 )
  ORIGINAL[2]: key -> p2p_dir
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 68719476865
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key -> circ . circuit = circuit
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 . VAR3 = VAR3
  ORIGINAL[1]: key -> circ . circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 . VAR3
  ORIGINAL[2]: circuit
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 6
  ORIGINAL[0]: key -> stream = stream
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: key -> stream
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key -> framenum
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: framenum
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476785
FRAGMENT_COUNT: 6
  ORIGINAL[0]: vfprintf(stonesoup_printf_context, format, argptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> stonesoup_printf_context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: argptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: argptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771371
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: circuit
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: g_hash_table_destroy(fragment_hash)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> fragment_hash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719476895
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (const fragment_key_t *)a
  TYPE[0]: CALL
  TOKENIZED[0]: ( const VAR1 * ) VAR2
  ORIGINAL[1]: a
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476882
FRAGMENT_COUNT: 4
  ORIGINAL[0]: pdu -> pdu_number
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: stream -> pdu_counter
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu_counter
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640274
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771218
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (stream_t *)(g_hash_table_lookup(stream_hash,(&key)))
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 * ) ( FUN1 ( VAR2 , ( &key ) ) )
  ORIGINAL[1]: g_hash_table_lookup(stream_hash,(&key))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( &key ) )
  ORIGINAL[2]: &key
  TYPE[2]: CALL
  TOKENIZED[2]: &key
  ORIGINAL[3]: <global> stream_hash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719476957
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: conv
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771310
FRAGMENT_COUNT: 4
  ORIGINAL[0]: key . stream = stream
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: key . stream
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771484
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (void )(frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: ( void ) ( frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: frag?((void )0) : ((getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[2]: (void )0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void ) 0
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: frag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771365
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 68719476961
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash_lookup(stream,framenum,offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: framenum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771197
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash = g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719476886
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *key = (const fragment_key_t *)k
  TYPE[0]: CALL
  TOKENIZED[0]: *key = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const fragment_key_t *)k
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key -> stream
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key -> framenum
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: key -> offset
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771481
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: except_throw(1,4,(ep_strdup_printf(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( 1 , 4 , ( FUN2 ( \
  ORIGINAL[2]: ep_strdup_printf(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \

CENTER_NODE: 30064771187
FRAGMENT_COUNT: 6
  ORIGINAL[0]: bilharziasis_voltaire != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: ((unsigned long )unprofessed_stileman) * exarchs_calelectrical * exarchs_calelectrical
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) VAR1 ) * VAR2 * VAR2
  ORIGINAL[2]: ((unsigned long )unprofessed_stileman) * exarchs_calelectrical
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) VAR1 ) * VAR2
  ORIGINAL[3]: (unsigned long )unprofessed_stileman
  TYPE[3]: CALL
  TOKENIZED[3]: ( unsigned long ) VAR1
  ORIGINAL[4]: exarchs_calelectrical
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: exarchs_calelectrical
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771535
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_i == 0 || trumpetfishes_intransitive[stonesoup_i - 1] != '\\\\'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 [ VAR1 - 1 ] != '\\\\'
  ORIGINAL[1]: stonesoup_i == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0
  ORIGINAL[2]: trumpetfishes_intransitive[stonesoup_i - 1] != '\\\\'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 - 1 ] != '\\\\'
  ORIGINAL[3]: trumpetfishes_intransitive[stonesoup_i - 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 - 1 ]

CENTER_NODE: 68719476945
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream = stream_hash_insert_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771498
FRAGMENT_COUNT: 6
  ORIGINAL[0]: frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: abort()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: except_throw(1,4,(ep_strdup_printf(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( 1 , 4 , ( FUN2 ( \
  ORIGINAL[5]: frag
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771253
FRAGMENT_COUNT: 5
  ORIGINAL[0]: key -> circ . conv = conv
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 . VAR3 = VAR3
  ORIGINAL[1]: key -> circ . conv
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 . VAR3
  ORIGINAL[2]: key -> circ
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: conv
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: conv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771309
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash = g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771373
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cleanup_stream_hash()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: cleanup_fragment_hash()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )

CENTER_NODE: 68719476908
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (const char *)__func__
  TYPE[1]: CALL
  TOKENIZED[1]: ( const char * ) VAR1
  ORIGINAL[2]: <global> __func__
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719476836
FRAGMENT_COUNT: 5
  ORIGINAL[0]: key . is_circuit = !0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = !0
  ORIGINAL[1]: key . is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: key . circ
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: circ
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771109
FRAGMENT_COUNT: 5
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[2]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 1
  ORIGINAL[0]: stream_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )

CENTER_NODE: 30064771258
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pdu_counter = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> pdu_counter
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 68719476964
FRAGMENT_COUNT: 6
  ORIGINAL[0]: framenum > stream -> lastfrag_framenum
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: stream -> lastfrag_framenum
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: framenum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: framenum
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: framenum
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476798
FRAGMENT_COUNT: 12
  ORIGINAL[0]: *key1 = (const stream_key_t *)a
  TYPE[0]: CALL
  TOKENIZED[0]: *key1 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const stream_key_t *)a
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key1 -> p2p_dir
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key1 -> is_circuit
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: key1 -> circ
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: key1 -> circ
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: key1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: key1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: key1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: key1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719477007
FRAGMENT_COUNT: 7
  ORIGINAL[0]: pdu -> fd_head != ((void *)0) && fit -> hf_reassembled_in != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != ( ( void * ) 0 ) && VAR3 -> VAR4 != ( ( void * ) 0 )
  ORIGINAL[1]: proto_tree_add_uint(tree, *fit -> hf_reassembled_in,tvb,0,0,pdu -> fd_head -> reassembled_in)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , *fit -> VAR2 , VAR3 , 0 , 0 , VAR4 -> VAR5 -> VAR6 )
  ORIGINAL[2]: *fit -> hf_reassembled_in
  TYPE[2]: CALL
  TOKENIZED[2]: *fit -> VAR1
  ORIGINAL[3]: pdu -> fd_head -> reassembled_in
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[4]: tree
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: fit
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tvb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

