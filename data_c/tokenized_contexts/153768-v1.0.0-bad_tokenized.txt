# Tokenized code fragments for 153768-v1.0.0-bad
# Total center nodes processed: 36
# Total code fragments found: 110

CENTER_NODE: 68719476961
FRAGMENT_COUNT: 8
  ORIGINAL[0]: pkt -> destruct == ((void *)0) && pkt -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 ) && VAR1 -> VAR3
  ORIGINAL[1]: pkt -> destruct
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tmp_pkt =  *pkt
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = *pkt
  ORIGINAL[4]: *pkt
  TYPE[4]: CALL
  TOKENIZED[4]: *pkt
  ORIGINAL[5]: copy_packet_data(pkt,&tmp_pkt)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , &tmp_pkt )
  ORIGINAL[6]: pkt
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: tmp_pkt
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771188
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pkt -> size = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: pkt -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 30064771101
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stat(dirpath, &st) == -1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[1]: retval = mkdir(dirpath, 0700)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[2]: mkdir(dirpath, 0700)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[3]: retval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pkt -> size <= size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR2
  ORIGINAL[1]: pkt -> size = size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: pkt -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771511
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < pkt -> side_data_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: pkt -> side_data[i] . type
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: pkt -> side_data[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: pkt -> side_data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: type
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pkt -> side_data_elems = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: pkt -> side_data_elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 30064771565
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: bytestream_put_buffer(&p,old . side_data[i] . data,old . side_data[i] . size)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &p , VAR1 . VAR2 [ VAR3 ] . VAR4 , VAR1 . VAR2 [ VAR3 ] . VAR5 )
  ORIGINAL[2]: &p
  TYPE[2]: CALL
  TOKENIZED[2]: &p
  ORIGINAL[3]: old . side_data[i] . data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: old . side_data[i] . size
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: old . side_data[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2 [ VAR3 ]
  ORIGINAL[6]: old . side_data[i] . size
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . VAR2 [ VAR3 ] . VAR4
  ORIGINAL[7]: old . side_data[i]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . VAR2 [ VAR3 ]
  ORIGINAL[8]: size
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771124
FRAGMENT_COUNT: 2
  ORIGINAL[0]: fflush(stonesoup_printf_context)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 30064771439
FRAGMENT_COUNT: 4
  ORIGINAL[0]: pkt -> data = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[1]: pkt -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477164
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sunland_statesmanlike > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: sizeof (struct stonesoup_struct)
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct stonesoup_struct
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 30064771169
FRAGMENT_COUNT: 1
  ORIGINAL[0]: after[200]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 200 ]

CENTER_NODE: 47244640274
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477146
FRAGMENT_COUNT: 3
  ORIGINAL[0]: gleefully_subaggregation = 7
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 7
  ORIGINAL[1]: ++stonesoup_global_variable
  TYPE[1]: CALL
  TOKENIZED[1]: ++stonesoup_global_variable
  ORIGINAL[2]: <global> stonesoup_global_variable
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719477214
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ++stonesoup_global_variable
  TYPE[0]: CALL
  TOKENIZED[0]: ++stonesoup_global_variable
  ORIGINAL[1]: latitudinarians_chatted(granulet_philogynaecic,epaphus_pardieu)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: granulet_philogynaecic
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: epaphus_pardieu
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640304
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771730
FRAGMENT_COUNT: 2
  ORIGINAL[0]: size > pkt -> side_data[i] . size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3 [ VAR4 ] . VAR1
  ORIGINAL[1]: - 12
  TYPE[1]: CALL
  TOKENIZED[1]: - 12

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640288
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640283
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771314
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dst -> side_data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *dst -> side_data
  TYPE[1]: CALL
  TOKENIZED[1]: *dst -> VAR1
  ORIGINAL[2]: dst -> side_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *dst -> side_data
  TYPE[3]: CALL
  TOKENIZED[3]: *dst -> VAR1
  ORIGINAL[4]: *dst -> side_data
  TYPE[4]: CALL
  TOKENIZED[4]: *dst -> VAR1
  ORIGINAL[5]: dst -> side_data
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: side_data
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dst
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771463
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *pkt -> side_data
  TYPE[0]: CALL
  TOKENIZED[0]: *pkt -> VAR1
  ORIGINAL[1]: pkt -> side_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: side_data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476845
FRAGMENT_COUNT: 7
  ORIGINAL[0]: ((unsigned int )size) < ((unsigned int )size) + 16
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned int ) VAR1 ) < ( ( unsigned int ) VAR1 ) + 16
  ORIGINAL[1]: data = (av_malloc((size + 16)))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( ( VAR2 + 16 ) ) )
  ORIGINAL[2]: av_malloc((size + 16))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 + 16 ) )
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: data
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: data
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640279
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[128]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 128 ]

CENTER_NODE: 30064771167
FRAGMENT_COUNT: 1
  ORIGINAL[0]: before[200]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 200 ]

CENTER_NODE: 30064771270
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !new_ptr
  TYPE[0]: CALL
  TOKENIZED[0]: !new_ptr
  ORIGINAL[1]: pkt -> size += grow_by
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 += VAR3
  ORIGINAL[2]: pkt -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: grow_by
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_tainted_file != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: *stonesoup_tainted_buff = ((char *)(malloc(sizeof(char ) * (stonesoup_lsize + 1))))
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff = ( ( char * ) ( FUN1 ( sizeof ( char ) * ( VAR1 + 1 ) ) ) )
  ORIGINAL[2]: *stonesoup_tainted_buff
  TYPE[2]: CALL
  TOKENIZED[2]: *stonesoup_tainted_buff
  ORIGINAL[3]: (char *)(malloc(sizeof(char ) * (stonesoup_lsize + 1)))
  TYPE[3]: CALL
  TOKENIZED[3]: ( char * ) ( FUN1 ( sizeof ( char ) * ( VAR1 + 1 ) ) )
  ORIGINAL[4]: stonesoup_tainted_buff
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477097
FRAGMENT_COUNT: 6
  ORIGINAL[0]: !pkt -> side_data
  TYPE[0]: CALL
  TOKENIZED[0]: !pkt -> VAR1
  ORIGINAL[1]: p = pkt -> data + pkt -> size - 8 - 5
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 + VAR2 -> VAR4 - 8 - 5
  ORIGINAL[2]: pkt -> data + pkt -> size - 8 - 5
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + VAR1 -> VAR3 - 8 - 5
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771433
FRAGMENT_COUNT: 3
  ORIGINAL[0]: copy_packet_data(dst,src)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: dst
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: src
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771200
FRAGMENT_COUNT: 10
  ORIGINAL[0]: pkt -> duration = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: pkt -> duration
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: duration
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pkt
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pkt
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pkt
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: pkt
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: pkt
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640301
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

