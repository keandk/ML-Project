# Tokenized code fragments for 153247-v1.0.0-bad
# Total center nodes processed: 27
# Total code fragments found: 187

CENTER_NODE: 30064771109
FRAGMENT_COUNT: 5
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[2]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771596
FRAGMENT_COUNT: 13
  ORIGINAL[0]: v1 -> port1 == v2 -> port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[1]: (&v1 -> addr1) -> type
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[2]: &v1 -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: &v1 -> VAR1
  ORIGINAL[3]: v1 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: &v1 -> VAR1
  ORIGINAL[5]: v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: &v1 -> addr1
  TYPE[8]: CALL
  TOKENIZED[8]: &v1 -> VAR1
  ORIGINAL[9]: v1 -> addr1
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: &v1 -> addr1
  TYPE[10]: CALL
  TOKENIZED[10]: &v1 -> VAR1
  ORIGINAL[11]: v1 -> addr1
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: type
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 68719476849
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_index++
  TYPE[1]: CALL
  TOKENIZED[1]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[2]: hash_val += ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += VAR2 [ VAR3 ]
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_index
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772167
FRAGMENT_COUNT: 8
  ORIGINAL[0]: conv -> data_list = g_slist_remove(conv -> data_list,(item -> data))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR4 ) )
  ORIGINAL[1]: conv -> data_list
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: g_slist_remove(conv -> data_list,(item -> data))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR4 ) )
  ORIGINAL[3]: conv -> data_list
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: data_list
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: item
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: conv
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: conv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771663
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation_hashtable_exact = g_hash_table_new(conversation_hash_exact,conversation_match_exact)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(conversation_hash_exact,conversation_match_exact)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> conversation_hashtable_exact
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771137
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c - 32
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 32
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771405
FRAGMENT_COUNT: 14
  ORIGINAL[0]: (v1 -> ptype) != (v2 -> ptype)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) != ( VAR3 -> VAR2 )
  ORIGINAL[1]: v1 -> ptype
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: v2 -> ptype
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ptype
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: v1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: v1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: v2
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: v1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: v1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: v1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: v1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: v1
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: v1
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 68719477323
FRAGMENT_COUNT: 8
  ORIGINAL[0]: conversation == ((void *)0) && (addr_a -> type) == AT_FC
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) && ( VAR2 -> VAR3 ) == VAR4
  ORIGINAL[1]: conversation_lookup_hashtable(conversation_hashtable_exact,frame_num,addr_b,addr_a,ptype,port_a,port_b)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 , VAR6 , VAR7 )
  ORIGINAL[2]: port_b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: port_a
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: port_b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: port_b
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: port_b
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: port_b
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477300
FRAGMENT_COUNT: 10
  ORIGINAL[0]: chain_head && chain_head -> setup_frame <= frame_num
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 -> VAR2 <= VAR3
  ORIGINAL[1]: chain_head -> last && chain_head -> last -> setup_frame <= frame_num
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && VAR1 -> VAR2 -> VAR3 <= VAR4
  ORIGINAL[2]: convo && convo -> setup_frame <= frame_num
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 && VAR1 -> VAR2 <= VAR3
  ORIGINAL[3]: chain_head -> latest_found = match
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 = VAR3
  ORIGINAL[4]: chain_head -> latest_found
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: latest_found
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: match
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: chain_head
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: match
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: match
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477487
FRAGMENT_COUNT: 7
  ORIGINAL[0]: ap -> proto > bp -> proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 -> VAR2
  ORIGINAL[1]: bp -> proto
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ap -> proto
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: bp -> proto
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: proto
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: bp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: bp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771164
FRAGMENT_COUNT: 8
  ORIGINAL[0]: conversation -> key_ptr -> ptype
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: conversation -> options & 0x01 && conversation -> options & 0x02
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 & 0x01 && VAR1 -> VAR2 & 0x02
  ORIGINAL[2]: conversation -> key_ptr -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: conversation -> key_ptr -> port1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[4]: conversation -> key_ptr
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: key_ptr
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: port1
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: conversation
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771535
FRAGMENT_COUNT: 10
  ORIGINAL[0]: ((&v1 -> addr2) -> type) == AT_NONE
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( &v1 -> VAR1 ) -> VAR2 ) == VAR3
  ORIGINAL[1]: (&v1 -> addr2) -> len == (&v2 -> addr2) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[2]: (&v1 -> addr2) -> len
  TYPE[2]: CALL
  TOKENIZED[2]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[3]: &v1 -> addr2
  TYPE[3]: CALL
  TOKENIZED[3]: &v1 -> VAR1
  ORIGINAL[4]: (&v2 -> addr2) -> len
  TYPE[4]: CALL
  TOKENIZED[4]: ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[5]: &v1 -> addr2
  TYPE[5]: CALL
  TOKENIZED[5]: &v1 -> VAR1
  ORIGINAL[6]: (&v1 -> addr2) -> len
  TYPE[6]: CALL
  TOKENIZED[6]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[7]: &v1 -> addr2
  TYPE[7]: CALL
  TOKENIZED[7]: &v1 -> VAR1
  ORIGINAL[8]: len
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v2
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064772129
FRAGMENT_COUNT: 3
  ORIGINAL[0]: se_alloc(sizeof(conv_proto_data ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[1]: sizeof(conv_proto_data )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: conv_proto_data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772175
FRAGMENT_COUNT: 4
  ORIGINAL[0]: conversation = find_conversation(pinfo -> fd -> num,addr_a,addr_b,ptype,port_a,port_b,0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 -> VAR3 -> VAR4 , VAR5 , VAR6 , VAR7 , VAR8 , VAR9 , 0 )
  ORIGINAL[1]: find_conversation(pinfo -> fd -> num,addr_a,addr_b,ptype,port_a,port_b,0)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 -> VAR3 , VAR4 , VAR5 , VAR6 , VAR7 , VAR8 , 0 )
  ORIGINAL[2]: conversation
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conversation
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771626
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *conv = (conversation_t *)value
  TYPE[0]: CALL
  TOKENIZED[0]: *conv = ( VAR1 * ) VAR2
  ORIGINAL[1]: (conversation_t *)value
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 * ) VAR2
  ORIGINAL[2]: conv
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476785
FRAGMENT_COUNT: 6
  ORIGINAL[0]: vfprintf(stonesoup_printf_context, format, argptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> stonesoup_printf_context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: argptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: argptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 1
  ORIGINAL[0]: item != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 4
  ORIGINAL[0]: first_char = buffer_param[0] - 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 [ 0 ] - 97
  ORIGINAL[1]: buffer_param[0] - 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ] - 97
  ORIGINAL[2]: buffer_param[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: first_char
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477070
FRAGMENT_COUNT: 6
  ORIGINAL[0]: g_hash_table_lookup(hashtable,(conv -> key_ptr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) )
  ORIGINAL[1]: conv -> key_ptr
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hashtable
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashtable
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashtable
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 7
  ORIGINAL[0]: key -> addr1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[2]: key -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: addr1
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ADD_ADDRESS_TO_HASH_index
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476964
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: ADD_ADDRESS_TO_HASH_index
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771768
FRAGMENT_COUNT: 9
  ORIGINAL[0]: cur != conv
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: conv -> next
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ((void *)0) == conv -> next
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( void * ) 0 ) == VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: conv -> next
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: next
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: conv
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: conv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: conv
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064772271
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_buffer_ptr != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_tainted_len = strlen( *stonesoup_buffer_ptr)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( *stonesoup_buffer_ptr )
  ORIGINAL[2]: strlen( *stonesoup_buffer_ptr)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( *stonesoup_buffer_ptr )
  ORIGINAL[3]: stonesoup_tainted_len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_trace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771581
FRAGMENT_COUNT: 6
  ORIGINAL[0]: hash_val += key -> port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 += VAR2 -> VAR3
  ORIGINAL[1]: key -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: port1
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hash_val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477519
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation -> dissector_handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dissector_handle
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: conversation
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772201
FRAGMENT_COUNT: 12
  ORIGINAL[0]: find_conversation(pinfo -> fd -> num,(&pinfo -> src),(&pinfo -> dst),pinfo -> ptype,pinfo -> srcport,pinfo -> destport,0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 -> VAR3 , ( &pinfo -> VAR4 ) , ( &pinfo -> VAR5 ) , VAR1 -> VAR6 , VAR1 -> VAR7 , VAR1 -> VAR8 , 0 )
  ORIGINAL[1]: pinfo -> srcport
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pinfo -> srcport
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: srcport
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pinfo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pinfo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pinfo
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pinfo
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: pinfo
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: pinfo
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: pinfo
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: pinfo
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719476895
FRAGMENT_COUNT: 18
  ORIGINAL[0]: v1 -> ptype
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: v1 -> port1 == v2 -> port1 && v1 -> port2 == v2 -> port2 && (((&v1 -> addr1) -> type) == ((&v2 -> addr1) -> type) && (((&v1 -> addr1) -> type) == AT_NONE || (&v1 -> addr1) -> len == (&v2 -> addr1) -> len && memcmp((&v1 -> addr1) -> data,(&v2 -> addr1) -> data,((&v1 -> addr1) -> len)) == 0)) && (((&v1 -> addr2) -> type) == ((&v2 -> addr2) -> type) && (((&v1 -> addr2) -> type) == AT_NONE || (&v1 -> addr2) -> len == (&v2 -> addr2) -> len && memcmp((&v1 -> addr2) -> data,(&v2 -> addr2) -> data,((&v1 -> addr2) -> len)) == 0))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == VAR3 -> VAR2 && VAR1 -> VAR4 == VAR3 -> VAR4 && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == ( ( &v2 -> VAR5 ) -> VAR6 ) && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == VAR7 || ( &v1 -> VAR5 ) -> VAR8 == ( &v2 -> VAR5 ) -> VAR8 && FUN1 ( ( &v1 -> VAR5 ) -> VAR9 , ( &v2 -> VAR5 ) -> VAR9 , ( ( &v1 -> VAR5 ) -> VAR8 ) ) == 0 ) ) && ( ( ( &v1 -> VAR10 ) -> VAR6 ) == ( ( &v2 -> VAR10 ) -> VAR6 ) && ( ( ( &v1 -> VAR10 ) -> VAR6 ) == VAR7 || ( &v1 -> VAR10 ) -> VAR8 == ( &v2 -> VAR10 ) -> VAR8 && FUN1 ( ( &v1 -> VAR10 ) -> VAR9 , ( &v2 -> VAR10 ) -> VAR9 , ( ( &v1 -> VAR10 ) -> VAR8 ) ) == 0 ) )
  ORIGINAL[2]: v1 -> port1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: v1 -> port2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: v1 -> addr1
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: v1 -> addr2
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: v1 -> addr2
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: v1 -> addr2
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: v1 -> addr2
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: v1 -> addr2
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: v1 -> port2
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: port2
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: v1
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: v1
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

