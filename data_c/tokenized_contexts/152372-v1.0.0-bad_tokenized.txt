# Tokenized code fragments for 152372-v1.0.0-bad
# Total center nodes processed: 24
# Total code fragments found: 146

CENTER_NODE: 30064771080
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ss_tc_root = getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: ss_tc_root
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ss_tc_root
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771303
FRAGMENT_COUNT: 20
  ORIGINAL[0]: v1 -> port1 == v2 -> port1 && v1 -> port2 == v2 -> port2 && (((&v1 -> addr1) -> type) == ((&v2 -> addr1) -> type) && (((&v1 -> addr1) -> type) == AT_NONE || (&v1 -> addr1) -> len == (&v2 -> addr1) -> len && memcmp((&v1 -> addr1) -> data,(&v2 -> addr1) -> data,((&v1 -> addr1) -> len)) == 0)) && (((&v1 -> addr2) -> type) == ((&v2 -> addr2) -> type) && (((&v1 -> addr2) -> type) == AT_NONE || (&v1 -> addr2) -> len == (&v2 -> addr2) -> len && memcmp((&v1 -> addr2) -> data,(&v2 -> addr2) -> data,((&v1 -> addr2) -> len)) == 0))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2 && VAR1 -> VAR4 == VAR3 -> VAR4 && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == ( ( &v2 -> VAR5 ) -> VAR6 ) && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == VAR7 || ( &v1 -> VAR5 ) -> VAR8 == ( &v2 -> VAR5 ) -> VAR8 && FUN1 ( ( &v1 -> VAR5 ) -> VAR9 , ( &v2 -> VAR5 ) -> VAR9 , ( ( &v1 -> VAR5 ) -> VAR8 ) ) == 0 ) ) && ( ( ( &v1 -> VAR10 ) -> VAR6 ) == ( ( &v2 -> VAR10 ) -> VAR6 ) && ( ( ( &v1 -> VAR10 ) -> VAR6 ) == VAR7 || ( &v1 -> VAR10 ) -> VAR8 == ( &v2 -> VAR10 ) -> VAR8 && FUN1 ( ( &v1 -> VAR10 ) -> VAR9 , ( &v2 -> VAR10 ) -> VAR9 , ( ( &v1 -> VAR10 ) -> VAR8 ) ) == 0 ) )
  ORIGINAL[1]: v1 -> port2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: v1 -> port2 == v2 -> port1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == VAR3 -> VAR4
  ORIGINAL[3]: v1 -> port2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: v2 -> port1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: port2
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: v1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: v1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: v2
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: v1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: v1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: v1
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: v1
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: v1
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: v1
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: v1
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: v1
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: v1
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: v1
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 68719477057
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *v2 = (const conversation_key *)w
  TYPE[0]: CALL
  TOKENIZED[0]: *v2 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: v1 -> ptype
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ptype
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: v1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: v1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476835
FRAGMENT_COUNT: 5
  ORIGINAL[0]: key -> addr1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: addr1
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476949
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[2]: (&key -> addr1) -> len
  TYPE[2]: CALL
  TOKENIZED[2]: ( &key -> VAR1 ) -> VAR2
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_index++
  TYPE[3]: CALL
  TOKENIZED[3]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ADD_ADDRESS_TO_HASH_index
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ADD_ADDRESS_TO_HASH_index
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ADD_ADDRESS_TO_HASH_index
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771747
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((void *)0) == prev
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( void * ) 0 ) == VAR1
  ORIGINAL[1]: conv -> last = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[2]: conv -> last
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 68719476795
FRAGMENT_COUNT: 4
  ORIGINAL[0]: conversation -> options & 0x08
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 & 0x08
  ORIGINAL[1]: (conversation -> key_ptr -> ptype) != PT_UDP
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 -> VAR3 ) != VAR4
  ORIGINAL[2]: conversation -> key_ptr -> ptype
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: PT_UDP
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771649
FRAGMENT_COUNT: 3
  ORIGINAL[0]: g_slist_free(conv -> data_list)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: conv -> data_list
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: conv
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772153
FRAGMENT_COUNT: 7
  ORIGINAL[0]: p1 -> proto = proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: p1 -> proto
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: proto
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: proto
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772173
FRAGMENT_COUNT: 5
  ORIGINAL[0]: item != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: p1 = ((conv_proto_data *)(item -> data))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( VAR2 * ) ( VAR3 -> VAR4 ) )
  ORIGINAL[2]: (conv_proto_data *)(item -> data)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[3]: p1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772196
FRAGMENT_COUNT: 5
  ORIGINAL[0]: conversation -> dissector_handle = handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: conversation -> dissector_handle
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dissector_handle
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conversation
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: handle
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477093
FRAGMENT_COUNT: 4
  ORIGINAL[0]: conversation_hashtable_no_addr2 = g_hash_table_new(conversation_hash_no_addr2,conversation_match_no_addr2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: conversation_hashtable_no_port2 = g_hash_table_new(conversation_hash_no_port2,conversation_match_no_port2)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[2]: g_hash_table_new(conversation_hash_no_port2,conversation_match_no_port2)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: <global> conversation_hashtable_no_port2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064772073
FRAGMENT_COUNT: 7
  ORIGINAL[0]: (addr_a -> type) == AT_FC
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) == VAR3
  ORIGINAL[1]: (addr_a -> type) == AT_FC
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 ) == VAR3
  ORIGINAL[2]: conversation == ((void *)0) && (addr_a -> type) == AT_FC
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 ) && ( VAR2 -> VAR3 ) == VAR4
  ORIGINAL[3]: conversation == ((void *)0)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[4]: (addr_a -> type) == AT_FC
  TYPE[4]: CALL
  TOKENIZED[4]: ( VAR1 -> VAR2 ) == VAR3
  ORIGINAL[5]: addr_a -> type
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: AT_FC
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772178
FRAGMENT_COUNT: 4
  ORIGINAL[0]: temp . proto = proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: temp . proto
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: proto
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771121
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064771571
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cherida_coenoblastic != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: strlen(hooflike_unpublic) < 1000 - strlen(stonesoup_command_str)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) < 1000 - FUN1 ( VAR2 )
  ORIGINAL[2]: strlen(hooflike_unpublic)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: 1000 - strlen(stonesoup_command_str)
  TYPE[3]: CALL
  TOKENIZED[3]: 1000 - FUN1 ( VAR1 )
  ORIGINAL[4]: strlen(stonesoup_command_str)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )

CENTER_NODE: 47244640276
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[2]: ADD_ADDRESS_TO_HASH_index++
  TYPE[2]: CALL
  TOKENIZED[2]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[3]: hash_val += ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 += VAR2 [ VAR3 ]
  ORIGINAL[4]: for (ADD_ADDRESS_TO_HASH_index = 0;ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len;ADD_ADDRESS_TO_HASH_index++)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = 0 ; VAR1 < ( &key -> VAR2 ) -> VAR3 ; ADD_ADDRESS_TO_HASH_index++ )

CENTER_NODE: 47244640375
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640331
FRAGMENT_COUNT: 1
  ORIGINAL[0]: chain_head && chain_head -> setup_frame <= frame_num
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 -> VAR2 <= VAR3

CENTER_NODE: 30064772217
FRAGMENT_COUNT: 5
  ORIGINAL[0]: pinfo -> fd -> num
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: pinfo -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fd
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: num
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pinfo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477148
FRAGMENT_COUNT: 11
  ORIGINAL[0]: ((void *)0) == conv -> next
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( void * ) 0 ) == VAR1 -> VAR2
  ORIGINAL[1]: chain_head = conv -> next
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3
  ORIGINAL[2]: conv -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: chain_head -> key_ptr
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: chain_head
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: conv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chain_head
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: chain_head
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: chain_head
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: chain_head
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: chain_head
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640380
FRAGMENT_COUNT: 1
  ORIGINAL[0]: conversation != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 14
  ORIGINAL[0]: (v1 -> ptype) != (v2 -> ptype)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) != ( VAR3 -> VAR2 )
  ORIGINAL[1]: v1 -> ptype
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: v2 -> ptype
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ptype
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: v1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: v1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: v2
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: v1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: v1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: v1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: v1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: v1
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: v1
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 30064771482
FRAGMENT_COUNT: 13
  ORIGINAL[0]: v1 -> port1 == v2 -> port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[1]: (&v1 -> addr1) -> type
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[2]: &v1 -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: &v1 -> VAR1
  ORIGINAL[3]: v1 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: &v1 -> VAR1
  ORIGINAL[5]: v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: &v1 -> addr1
  TYPE[8]: CALL
  TOKENIZED[8]: &v1 -> VAR1
  ORIGINAL[9]: v1 -> addr1
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: &v1 -> addr1
  TYPE[10]: CALL
  TOKENIZED[10]: &v1 -> VAR1
  ORIGINAL[11]: v1 -> addr1
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: type
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1

