# Tokenized code fragments for 153634-v1.0.0-bad
# Total center nodes processed: 147
# Total code fragments found: 420

CENTER_NODE: 30064771225
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: 1 && (( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum) || c == '_')
  TYPE[3]: CALL
  TOKENIZED[3]: 1 && ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) || VAR1 == '_' )

CENTER_NODE: 68719479029
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER=2
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064774834
FRAGMENT_COUNT: 14
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> newlines = (xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[2]: d -> newlines
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[4]: d -> newlines
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> newlines
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: newlines
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640624
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771183
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: (1 << 8) + 8 * sizeof(int ) - 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( 1 << 8 ) + 8 * sizeof ( int ) - 1
  ORIGINAL[3]: 8 * sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: 8 * sizeof ( int )
  ORIGINAL[4]: sizeof(int )
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( int )

CENTER_NODE: 30064774623
FRAGMENT_COUNT: 5
  ORIGINAL[0]: 1 & 2
  TYPE[0]: CALL
  TOKENIZED[0]: 1 & 2
  ORIGINAL[1]: ( *d) . states
  TYPE[1]: CALL
  TOKENIZED[1]: ( *d ) . VAR1
  ORIGINAL[2]: *d
  TYPE[2]: CALL
  TOKENIZED[2]: *d
  ORIGINAL[3]: states
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771149
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b % (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640313
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476870
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == '_'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == '_'
  ORIGINAL[1]: iswalnum(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775518
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: j = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: for (j = 0;j < p -> ncoll_elems;++j)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640974
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775072
FRAGMENT_COUNT: 7
  ORIGINAL[0]: work_mbc -> range_sts[i] <= wc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] <= VAR4
  ORIGINAL[1]: work_mbc -> range_ends[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: work_mbc -> range_ends
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: range_ends
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: work_mbc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: work_mbc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640812
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776269
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640355
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776327
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640888
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cp = lookin
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: ( *cp) != '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: ( *cp ) != '\\0'
  ORIGINAL[2]: ++cp
  TYPE[2]: CALL
  TOKENIZED[2]: ++cp
  ORIGINAL[3]: for (cp = lookin;( *cp) != '\\0';++cp)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = VAR2 ; ( *cp ) != '\\0' ; ++cp )

CENTER_NODE: 68719478018
FRAGMENT_COUNT: 6
  ORIGINAL[0]: m -> alloc <= s1 -> nelem + s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4 + VAR5 -> VAR4
  ORIGINAL[1]: m -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: &new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: &new_n_alloc
  ORIGINAL[3]: new_n_alloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_n_alloc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476817
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479669
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640633
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640710
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773754
FRAGMENT_COUNT: 11
  ORIGINAL[0]: &tmp
  TYPE[0]: CALL
  TOKENIZED[0]: &tmp
  ORIGINAL[1]: j < nlastpos[- 2]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 [ - 2 ]
  ORIGINAL[2]: merge((&tmp),(&d -> follows[pos[j] . index]),&merged)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( &tmp ) , ( &d -> VAR1 [ VAR2 [ VAR3 ] . VAR4 ] ) , &merged )
  ORIGINAL[3]: &tmp
  TYPE[3]: CALL
  TOKENIZED[3]: &tmp
  ORIGINAL[4]: tmp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tmp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tmp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: tmp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: tmp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: tmp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640400
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771160
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 8 * sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: 8 * sizeof ( int )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 30064772953
FRAGMENT_COUNT: 7
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: dfa -> multibyte_prop[dfa -> tindex - 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[2]: dfa -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> multibyte_prop[tindex + i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[4]: multibyte_prop
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1

CENTER_NODE: 47244640343
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640592
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772029
FRAGMENT_COUNT: 12
  ORIGINAL[0]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 || lexleft == 0 || ((syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr) == ')' : lexleft > 1 && lexptr[0] == '\\\\' && lexptr[1] == ')')) || ((syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr) == '|' : lexleft > 1 && lexptr[0] == '\\\\' && lexptr[1] == '|')) || syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 && lexleft > 0 && ( *lexptr) == 10
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 || VAR2 == 0 || ( ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr ) == ' ) ' : VAR2 > 1 && VAR3 [ 0 ] == '\\\\' && VAR3 [ 1 ] == ' ) ' ) ) || ( ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr ) == '|' : VAR2 > 1 && VAR3 [ 0 ] == '\\\\' && VAR3 [ 1 ] == '|' ) ) || VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 && VAR2 > 0 && ( *lexptr ) == 10
  ORIGINAL[1]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 || lexleft == 0 || ((syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr) == ')' : lexleft > 1 && lexptr[0] == '\\\\' && lexptr[1] == ')')) || ((syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr) == '|' : lexleft > 1 && lexptr[0] == '\\\\' && lexptr[1] == '|'))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 || VAR2 == 0 || ( ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr ) == ' ) ' : VAR2 > 1 && VAR3 [ 0 ] == '\\\\' && VAR3 [ 1 ] == ' ) ' ) ) || ( ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1?lexleft > 0 && ( *lexptr ) == '|' : VAR2 > 1 && VAR3 [ 0 ] == '\\\\' && VAR3 [ 1 ] == '|' ) )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 && lexleft > 0 && ( *lexptr) == 10
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 && VAR2 > 0 && ( *lexptr ) == 10
  ORIGINAL[3]: lasttok = ENDLINE
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2
  ORIGINAL[4]: laststart = 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = 0
  ORIGINAL[5]: __ctype_get_mb_cur_max() > 1
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( ) > 1
  ORIGINAL[6]: __ctype_get_mb_cur_max()
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( )
  ORIGINAL[7]: goto normal_char;
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: goto VAR1 ;
  ORIGINAL[8]: backslash
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: <global> lasttok
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: ENDLINE
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: <global> laststart
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1

CENTER_NODE: 47244640311
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640564
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773259
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640820
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064773432
FRAGMENT_COUNT: 12
  ORIGINAL[0]: d -> states[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: !d -> states[i] . first_end
  TYPE[1]: CALL
  TOKENIZED[1]: !d -> VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: d -> states[i] . first_end
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: d -> states[i] . first_end = d -> tokens[s -> elems[j] . index]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 = VAR1 -> VAR5 [ VAR6 -> VAR7 [ VAR8 ] . VAR9 ]
  ORIGINAL[5]: d -> states[i] . first_end
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[6]: d -> states[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[7]: d -> tokens[s -> elems[j] . index]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[8]: d -> states[i]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[9]: d -> states[i]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[10]: first_end
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719479206
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: d -> states[s]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> states
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479818
FRAGMENT_COUNT: 3
  ORIGINAL[0]: empty_string[] = \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ ] = \
  ORIGINAL[1]: empty_string
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: empty_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775634
FRAGMENT_COUNT: 20
  ORIGINAL[0]: i < (d -> sindex)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[1]: d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sindex
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: d
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 30064775616
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: abort()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: ANYCHAR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773061
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) )
  ORIGINAL[2]: dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: sizeof(( *dst -> elems))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *dst -> VAR1 ) )
  ORIGINAL[5]: *dst -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: *dst -> VAR1

CENTER_NODE: 68719479791
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *both
  TYPE[0]: CALL
  TOKENIZED[0]: *both
  ORIGINAL[1]: both == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: both[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: both
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: both
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640756
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771634
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c == '\\\\'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == '\\\\'
  ORIGINAL[1]: syntax_bits & ((unsigned long )1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & ( ( unsigned long ) 1 )
  ORIGINAL[2]: (unsigned long )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned long ) 1
  ORIGINAL[3]: <global> syntax_bits
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640431
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775799
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *lcp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *lcp ) != '\\0'
  ORIGINAL[1]: rcp = strchr(right,( *lcp))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , ( *lcp ) )
  ORIGINAL[2]: strchr(right,( *lcp))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( *lcp ) )
  ORIGINAL[3]: *lcp
  TYPE[3]: CALL
  TOKENIZED[3]: *lcp
  ORIGINAL[4]: rcp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: right
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771172
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sbit[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: setbit(i,newline)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> newline
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064771142
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640544
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640872
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640398
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640602
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719476833
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773010
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: addtok(CAT)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: CAT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479696
FRAGMENT_COUNT: 9
  ORIGINAL[0]: (new = icpyalloc(new)) == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR1 ) ) == ( ( void * ) 0 )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: ++i
  TYPE[3]: CALL
  TOKENIZED[3]: ++i
  ORIGINAL[4]: istrstr(cpp[i],new) != ((void *)0)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 [ VAR2 ] , VAR3 ) != ( ( void * ) 0 )
  ORIGINAL[5]: cpp[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775693
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new == ((void *)0)?0 : strlen(new)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[1]: new == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: strlen(new)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: new
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640883
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776325
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 68719477739
FRAGMENT_COUNT: 2
  ORIGINAL[0]: t
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: STAR
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064774178
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> tokens[pos . index] >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ] >= 0
  ORIGINAL[1]: d -> tokens[pos . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[2]: pos . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: pos . index
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: index
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064773031
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !syntax_bits_set
  TYPE[0]: CALL
  TOKENIZED[0]: !syntax_bits_set
  ORIGINAL[1]: dfaerror((gettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( FUN2 ( \
  ORIGINAL[2]: gettext(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \

CENTER_NODE: 30064771173
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771281
FRAGMENT_COUNT: 7
  ORIGINAL[0]: setbit_c((( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)),c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN2 ( VAR1 ) ) , VAR3 )
  ORIGINAL[1]: setbit(((*__ctype_b_loc())[(int)b] & ((short unsigned)_ISupper) ? tolower(b) : toupper(b)), c)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( short unsigned ) VAR2 ) ? FUN2 ( VAR1 ) : FUN3 ( VAR1 ) ) , VAR3 )
  ORIGINAL[2]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)
  TYPE[2]: CALL
  TOKENIZED[2]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN1 ( VAR1 )
  ORIGINAL[3]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)
  TYPE[3]: CALL
  TOKENIZED[3]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[4]: tolower(b)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: toupper(b)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 )
  ORIGINAL[6]: c
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479685
FRAGMENT_COUNT: 6
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775300
FRAGMENT_COUNT: 11
  ORIGINAL[0]: nelem == 0 || maxlen == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 == 0
  ORIGINAL[1]: free(follows . elems)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 . VAR2 )
  ORIGINAL[2]: follows . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: follows
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: follows
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: follows
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: follows
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: follows
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: follows
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: follows
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719480068
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(struct dfa )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( struct VAR1 )
  ORIGINAL[1]: struct dfa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: struct VAR1

CENTER_NODE: 30064772875
FRAGMENT_COUNT: 6
  ORIGINAL[0]: 1 && tok == WCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2
  ORIGINAL[1]: addtok_wc((case_fold?towlower(wctok) : wctok))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( case_fold?towlower ( VAR1 ) : VAR1 ) )
  ORIGINAL[2]: case_fold?towlower(wctok) : wctok
  TYPE[2]: CALL
  TOKENIZED[2]: case_fold?towlower ( VAR1 ) : VAR1
  ORIGINAL[3]: towlower(wctok)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: <global> case_fold
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> wctok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 68719478263
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ++j
  TYPE[1]: CALL
  TOKENIZED[1]: ++j
  ORIGINAL[2]: c[j] & ~(letters[j] | newline[j])
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] & ~ ( VAR3 [ VAR2 ] | VAR4 [ VAR2 ] )
  ORIGINAL[3]: context |= 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 |= 1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775890
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> right
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: right
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640420
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640380
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640901
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773082
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *s -> elems))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[1]: *s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: *s -> VAR1
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640353
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640836
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479606
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaparse(s,len,d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477876
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok == REPMN && (minrep || maxrep)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[1]: minrep == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0
  ORIGINAL[2]: addtok(QMARK)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: i = 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640390
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064772929
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: ntoks1 = nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 - 1 )
  ORIGINAL[2]: nsubtoks(tindex - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 - 1 )
  ORIGINAL[3]: ntoks1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476781
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476782
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479772
FRAGMENT_COUNT: 5
  ORIGINAL[0]: old == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: old
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: old
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640288
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: prednames[i] . name
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: for (i = 0;prednames[i] . name;++i)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR2 [ VAR1 ] . VAR3 ; ++i )

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640599
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640364
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771094
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data_size < buffer_size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: stonesoup_exit_flag = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: <global> stonesoup_exit_flag
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640408
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478220
FRAGMENT_COUNT: 8
  ORIGINAL[0]: s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET && d -> tokens[s -> elems[i] . index] < CSET
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < VAR10
  ORIGINAL[2]: p . constraint = old . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2 = VAR3 . VAR2
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064773606
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (s -> elems[j] . constraint >> 1 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[1]: separate_contexts |= 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 2
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: separate_contexts
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640441
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477905
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: OR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640423
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640714
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479063
FRAGMENT_COUNT: 5
  ORIGINAL[0]: wc = inputwcs[idx]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 [ VAR3 ]
  ORIGINAL[1]: inputwcs[idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> inputwcs
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775575
FRAGMENT_COUNT: 12
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: d -> nmultibyte_prop = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = 1
  ORIGINAL[2]: d -> nmultibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> nmultibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> nmultibyte_prop
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nmultibyte_prop
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640546
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640925
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640626
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480123
FRAGMENT_COUNT: 7
  ORIGINAL[0]: strlen(denuclearizes_gell) < 20
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) < 20
  ORIGINAL[1]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[3]: stonesoup_trace
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_trace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: trace_point
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_trace
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771115
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: mg_destroy_server(&stonesoup_server)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &stonesoup_server )
  ORIGINAL[2]: &stonesoup_server
  TYPE[2]: CALL
  TOKENIZED[2]: &stonesoup_server
  ORIGINAL[3]: stonesoup_server
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479524
FRAGMENT_COUNT: 10
  ORIGINAL[0]: s >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: build_state(s,d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064772869
FRAGMENT_COUNT: 7
  ORIGINAL[0]: work_mbc -> cset != (- 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[1]: work_mbc -> cset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: CSET + work_mbc -> cset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2 -> VAR3
  ORIGINAL[3]: work_mbc -> cset
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: cset
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: work_mbc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: work_mbc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064774858
FRAGMENT_COUNT: 18
  ORIGINAL[0]: rval == TRANSIT_STATE_IN_PROGRESS
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: (t = d -> trans[works]) != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 = VAR2 -> VAR3 [ VAR4 ] ) != ( ( void * ) 0 )
  ORIGINAL[2]: t = d -> trans[works]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: works = t[ *p]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2 [ *p ]
  ORIGINAL[5]: t[ *p]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ *p ]
  ORIGINAL[6]: *p
  TYPE[6]: CALL
  TOKENIZED[6]: *p
  ORIGINAL[7]: rval = TRANSIT_STATE_DONE
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = VAR2
  ORIGINAL[8]: works < 0
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 < 0
  ORIGINAL[9]: works < 0
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 < 0
  ORIGINAL[10]: rval
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: works
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: t
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: rval
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: TRANSIT_STATE_DONE
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: works
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: works
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 30064771120
FRAGMENT_COUNT: 4
  ORIGINAL[0]: END=-1
  TYPE[0]: CALL
  TOKENIZED[0]: END=-1
  ORIGINAL[1]: -1
  TYPE[1]: CALL
  TOKENIZED[1]: -1
  ORIGINAL[2]: END
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: EMPTY
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476912
FRAGMENT_COUNT: 6
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: utf8 == - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == - 1
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: utf8
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: utf8
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476852
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> calloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> cindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> charclasses
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &new_n_alloc
  TYPE[4]: CALL
  TOKENIZED[4]: &new_n_alloc
  ORIGINAL[5]: dfa -> charclasses
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: charclasses
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 47244640595
FRAGMENT_COUNT: 2
  ORIGINAL[0]: lo < hi
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: while (lo < hi)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: while ( VAR1 < VAR2 )

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774766
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> fails
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: sizeof(( *d -> fails)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: *d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1
  ORIGINAL[3]: *d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: d -> fails
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: fails
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

