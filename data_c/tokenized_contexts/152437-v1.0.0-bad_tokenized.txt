# Tokenized code fragments for 152437-v1.0.0-bad
# Total center nodes processed: 77
# Total code fragments found: 369

CENTER_NODE: 30064771375
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *mem = (void *)0
  TYPE[0]: CALL
  TOKENIZED[0]: *mem = ( void * ) 0
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: mem
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: minimum_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771279
FRAGMENT_COUNT: 5
  ORIGINAL[0]: find_char_backward(str -> data,str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ch
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 3
  ORIGINAL[0]: new_string -> len = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: new_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476916
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_string_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: cstring
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771634
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < list -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ((char **)(list -> elts))[i]
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[2]: (char **)(list -> elts)
  TYPE[2]: CALL
  TOKENIZED[2]: ( char ** ) ( VAR1 -> VAR2 )
  ORIGINAL[3]: list -> elts
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640301
FRAGMENT_COUNT: 1
  ORIGINAL[0]: old_count != new_count
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2

CENTER_NODE: 68719477036
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771233
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mem = apr_palloc(pool,sizeof(( *new_string)) + size + 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , sizeof ( ( *new_string ) ) + VAR3 + 1 )
  ORIGINAL[1]: apr_palloc(pool,sizeof(( *new_string)) + size + 1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , sizeof ( ( *new_string ) ) + VAR2 + 1 )
  ORIGINAL[2]: sizeof(( *new_string)) + size + 1
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *new_string ) ) + VAR1 + 1
  ORIGINAL[3]: mem
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477242
FRAGMENT_COUNT: 25
  ORIGINAL[0]: 0 != (svn_ctype_table[(unsigned char )( *p)] & 0x0002)
  TYPE[0]: CALL
  TOKENIZED[0]: 0 != ( VAR1 [ ( unsigned char ) ( *p ) ] & 0x0002 )
  ORIGINAL[1]: svn_ctype_table[(unsigned char )( *p)] & 0x0002
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ ( unsigned char ) ( *p ) ] & 0x0002
  ORIGINAL[2]: svn_ctype_table[(unsigned char )( *p)]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ ( unsigned char ) ( *p ) ]
  ORIGINAL[3]: (unsigned char )( *p)
  TYPE[3]: CALL
  TOKENIZED[3]: ( unsigned char ) ( *p )
  ORIGINAL[4]: *p
  TYPE[4]: CALL
  TOKENIZED[4]: *p
  ORIGINAL[5]: *e = p + (strlen(p) - 1)
  TYPE[5]: CALL
  TOKENIZED[5]: *e = VAR1 + ( FUN1 ( VAR1 ) - 1 )
  ORIGINAL[6]: p + (strlen(p) - 1)
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 + ( FUN1 ( VAR1 ) - 1 )
  ORIGINAL[7]: strlen(p) - 1
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( VAR1 ) - 1
  ORIGINAL[8]: strlen(p)
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 )
  ORIGINAL[9]: e >= p && 0 != (svn_ctype_table[(unsigned char )( *e)] & 0x0002)
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 >= VAR2 && 0 != ( VAR3 [ ( unsigned char ) ( *e ) ] & 0x0002 )
  ORIGINAL[10]: e >= p
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 >= VAR2
  ORIGINAL[11]: *(++e) = '\\0'
  TYPE[11]: CALL
  TOKENIZED[11]: * ( ++e ) = '\\0'
  ORIGINAL[12]: *(++e)
  TYPE[12]: CALL
  TOKENIZED[12]: * ( ++e )
  ORIGINAL[13]: ++e
  TYPE[13]: CALL
  TOKENIZED[13]: ++e
  ORIGINAL[14]: p
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: chop_whitespace
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: svn_ctype_table
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: p
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: e
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: p
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: p
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: e
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: p
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: e
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: p
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1

CENTER_NODE: 30064771261
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str = svn_string_createv(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: svn_string_createv(pool,fmt,ap)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772107
FRAGMENT_COUNT: 3
  ORIGINAL[0]: * stonesoup_printf_context = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: * VAR1 = VAR2
  ORIGINAL[1]: stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 8
  ORIGINAL[0]: memmove((str -> data + pos),(str -> data + pos + count),str -> len - pos - count + 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 + VAR3 ) , ( VAR1 -> VAR2 + VAR3 + VAR4 ) , VAR1 -> VAR5 - VAR3 - VAR4 + 1 )
  ORIGINAL[1]: str -> data + pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 + VAR3
  ORIGINAL[2]: str -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> data + pos + count
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 + VAR3 + VAR4
  ORIGINAL[4]: str -> data + pos
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 + VAR3
  ORIGINAL[5]: str -> len - pos - count + 1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 - VAR3 - VAR4 + 1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771115
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771221
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new_string -> data = data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: new_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_string
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771780
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *svn_err__temp = svn_cstring_strtoui64(&val,str,0,4294967295U,10)
  TYPE[0]: CALL
  TOKENIZED[0]: *svn_err__temp = FUN1 ( &val , VAR1 , 0 , 4294967295U , 10 )
  ORIGINAL[1]: svn_cstring_strtoui64(&val,str,0,4294967295U,10)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &val , VAR1 , 0 , 4294967295U , 10 )
  ORIGINAL[2]: &val
  TYPE[2]: CALL
  TOKENIZED[2]: &val
  ORIGINAL[3]: svn_err__temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477228
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771320
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476927
FRAGMENT_COUNT: 4
  ORIGINAL[0]: strlen(data)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476830
FRAGMENT_COUNT: 6
  ORIGINAL[0]: membuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: membuf -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: membuf -> pool
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pool
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: membuf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771828
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoi64(&val,str,(- 2147483647 - 1),2147483647,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &val , VAR1 , ( - 2147483647 - 1 ) , 2147483647 , 10 )
  ORIGINAL[1]: - 2147483647 - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 2147483647 - 1
  ORIGINAL[2]: - 2147483647
  TYPE[2]: CALL
  TOKENIZED[2]: - 2147483647

CENTER_NODE: 30064771357
FRAGMENT_COUNT: 6
  ORIGINAL[0]: str -> len > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771585
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare(str1 -> data,(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str1 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477008
FRAGMENT_COUNT: 6
  ORIGINAL[0]: __builtin_va_start(ap,fmt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: str = svn_stringbuf_createv(pool,fmt,ap)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: svn_stringbuf_createv(pool,fmt,ap)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771554
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_first_non_whitespace((str -> data),str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476802
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *size
  TYPE[0]: CALL
  TOKENIZED[0]: *size
  ORIGINAL[1]: minimum_size
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771699
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ( *p) == 10
  TYPE[0]: CALL
  TOKENIZED[0]: ( *p ) == 10
  ORIGINAL[1]: ( *(p + 1)) == 13
  TYPE[1]: CALL
  TOKENIZED[1]: ( * ( VAR1 + 1 ) ) == 13
  ORIGINAL[2]: *(p + 1)
  TYPE[2]: CALL
  TOKENIZED[2]: * ( VAR1 + 1 )
  ORIGINAL[3]: p + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: p + 1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 + 1

CENTER_NODE: 30064771363
FRAGMENT_COUNT: 13
  ORIGINAL[0]: nbytes > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = 0
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: str -> len -= nbytes
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 -= VAR3
  ORIGINAL[5]: str -> len
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: len
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: len
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: nbytes
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: str
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: str
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: nbytes
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: str
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 68719477527
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_string__similarity((&stringa),(&stringb),buffer,rlcs)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( &stringa ) , ( &stringb ) , VAR1 , VAR2 )
  ORIGINAL[1]: &stringb
  TYPE[1]: CALL
  TOKENIZED[1]: &stringb
  ORIGINAL[2]: buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rlcs
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477094
FRAGMENT_COUNT: 4
  ORIGINAL[0]: appendstr -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: targetstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: appendstr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640270
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477331
FRAGMENT_COUNT: 4
  ORIGINAL[0]: strlen(separator)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: sep_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: separator
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: separator
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476976
FRAGMENT_COUNT: 7
  ORIGINAL[0]: memcpy((strbuf -> data),bytes,size)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR4 )
  ORIGINAL[1]: strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: bytes
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: size
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477286
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < list -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: *this_str = ((char **)(list -> elts))[i]
  TYPE[1]: CALL
  TOKENIZED[1]: *this_str = ( ( char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[2]: strcmp(this_str,str)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: this_str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this_str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476939
FRAGMENT_COUNT: 4
  ORIGINAL[0]: original_string -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640325
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719477105
FRAGMENT_COUNT: 6
  ORIGINAL[0]: bytes + count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: *temp = (apr_pstrndup(str -> pool,bytes,count))
  TYPE[1]: CALL
  TOKENIZED[1]: *temp = ( FUN1 ( VAR1 -> VAR2 , VAR3 , VAR4 ) )
  ORIGINAL[2]: apr_pstrndup(str -> pool,bytes,count)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , VAR3 , VAR4 )
  ORIGINAL[3]: temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: temp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771914
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i > 3
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 3
  ORIGINAL[1]: i -= 3
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -= 3
  ORIGINAL[2]: for (i = length;i > 3;i -= 3)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = VAR2 ; VAR1 > 3 ; VAR1 -= 3 )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771336
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_string -> blocksize = size + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3 + 1
  ORIGINAL[1]: new_string -> blocksize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771185
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *const _m_b_f_ = membuf
  TYPE[0]: CALL
  TOKENIZED[0]: *const VAR1 = VAR2
  ORIGINAL[1]: _m_b_f_
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: membuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _m_b_f_
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476943
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str2 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str1 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476945
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476952
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ++blocksize
  TYPE[0]: CALL
  TOKENIZED[0]: ++blocksize
  ORIGINAL[1]: blocksize
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: blocksize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: blocksize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771253
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_string_ncreate((strbuf -> data),strbuf -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: strbuf -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771175
FRAGMENT_COUNT: 5
  ORIGINAL[0]: membuf -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: membuf_ensure(&membuf -> data,&membuf -> size,size,membuf -> pool)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 -> VAR4 )
  ORIGINAL[2]: &membuf -> size
  TYPE[2]: CALL
  TOKENIZED[2]: &membuf -> VAR1
  ORIGINAL[3]: membuf -> size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771547
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_stringbuf_ncreate((original_string -> data),original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771904
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: *dest = 45
  TYPE[1]: CALL
  TOKENIZED[1]: *dest = 45
  ORIGINAL[2]: *dest
  TYPE[2]: CALL
  TOKENIZED[2]: *dest
  ORIGINAL[3]: dest
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dest
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477219
FRAGMENT_COUNT: 7
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str -> len -= offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -= VAR3
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> blocksize
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: blocksize
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477582
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stra < enda && strb < endb
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 < VAR4
  ORIGINAL[1]: slots = resta > restb?restb : resta
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 > restb?restb : VAR2
  ORIGINAL[2]: resta < restb
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2
  ORIGINAL[3]: resta
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: resta
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: restb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477020
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_stringbuf_ensure(str,amt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: amt
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: amt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: amt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477499
FRAGMENT_COUNT: 4
  ORIGINAL[0]: buffer[2 * 21]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 2 * 21 ]
  ORIGINAL[1]: buffer[2 * 21]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 2 * 21 ]
  ORIGINAL[2]: buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477412
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoi64(n,str,- 9223372036854775807L - 1,9223372036854775807L,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , - 9223372036854775807L - 1 , 9223372036854775807L , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771676
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !( *token)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( *token )
  ORIGINAL[1]: next = (strchr(token,csep))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 , VAR3 ) )
  ORIGINAL[2]: strchr(token,csep)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: next
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: next
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771322
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_stringbuf_ncreate(str -> data,str -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771159
FRAGMENT_COUNT: 5
  ORIGINAL[0]: &membuf -> size
  TYPE[0]: CALL
  TOKENIZED[0]: &membuf -> VAR1
  ORIGINAL[1]: membuf -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: membuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: membuf
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477016
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771805
FRAGMENT_COUNT: 14
  ORIGINAL[0]: *__errno_location() == 22 || endptr == str || str[0] == '\\0' || ( *endptr) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 22 || VAR1 == VAR2 || VAR2 [ 0 ] == '\\0' || ( *endptr ) != '\\0'
  ORIGINAL[1]: *__errno_location() == 34 && (val == - 9223372036854775807L - 1 || val == 9223372036854775807L) || val < minval || val > maxval
  TYPE[1]: CALL
  TOKENIZED[1]: *__errno_location ( ) == 34 && ( VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L ) || VAR1 < VAR2 || VAR1 > VAR3
  ORIGINAL[2]: *__errno_location() == 34 && (val == - 9223372036854775807L - 1 || val == 9223372036854775807L) || val < minval
  TYPE[2]: CALL
  TOKENIZED[2]: *__errno_location ( ) == 34 && ( VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L ) || VAR1 < VAR2
  ORIGINAL[3]: val > maxval
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 > VAR2
  ORIGINAL[4]: svn_error_createf(SVN_ERR_INCORRECT_PARAMS,((void *)0),\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , ( ( void * ) 0 ) , \
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: *n = val
  TYPE[6]: CALL
  TOKENIZED[6]: *n = VAR1
  ORIGINAL[7]: *n
  TYPE[7]: CALL
  TOKENIZED[7]: *n
  ORIGINAL[8]: SVN_ERR_INCORRECT_PARAMS
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: str
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: minval
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: maxval
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: n
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: val
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 30064771764
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *__errno_location() == 34 && (val == - 9223372036854775807L - 1 || val == 9223372036854775807L)
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 34 && ( VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L )
  ORIGINAL[1]: *__errno_location() == 34
  TYPE[1]: CALL
  TOKENIZED[1]: *__errno_location ( ) == 34
  ORIGINAL[2]: val == - 9223372036854775807L - 1 || val == 9223372036854775807L
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L
  ORIGINAL[3]: val == - 9223372036854775807L - 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == - 9223372036854775807L - 1
  ORIGINAL[4]: val == 9223372036854775807L
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == 9223372036854775807L

CENTER_NODE: 30064771283
FRAGMENT_COUNT: 2
  ORIGINAL[0]: svn_stringbuf_create_ensure(0,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064772075
FRAGMENT_COUNT: 5
  ORIGINAL[0]: 1 == 1
  TYPE[0]: CALL
  TOKENIZED[0]: 1 == 1
  ORIGINAL[1]: bassetting_bepistoled = bassetting_bepistoled * 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR1 * 2
  ORIGINAL[2]: bassetting_bepistoled * 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 * 2
  ORIGINAL[3]: bassetting_bepistoled
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: bassetting_bepistoled
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771627
FRAGMENT_COUNT: 7
  ORIGINAL[0]: svn_cstring_split_append(a,input,sep_chars,chop_whitespace,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 )
  ORIGINAL[1]: a
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: input
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: sep_chars
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chop_whitespace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pool
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: a
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771728
FRAGMENT_COUNT: 5
  ORIGINAL[0]: b = ( *(str2++))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( * ( str2++ ) )
  ORIGINAL[1]: *(str2++)
  TYPE[1]: CALL
  TOKENIZED[1]: * ( str2++ )
  ORIGINAL[2]: cmp || !a || !b
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 || !a || !b
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cmp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771204
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: !(0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002))
  TYPE[1]: CALL
  TOKENIZED[1]: ! ( 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 ) )
  ORIGINAL[2]: for (i = 0;i < len;i++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 ; i++ )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771778
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoui64(n,str,0,18446744073709551615UL,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 , 18446744073709551615UL , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476799
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *data = (!minimum_size?((void *)0) : apr_palloc(pool,minimum_size))
  TYPE[0]: CALL
  TOKENIZED[0]: *data = ( !minimum_size? ( ( void * ) 0 ) : FUN1 ( VAR1 , VAR2 ) )
  ORIGINAL[1]: *size
  TYPE[1]: CALL
  TOKENIZED[1]: *size
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771442
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,cstr,strlen(cstr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[1]: strlen(cstr)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: targetstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: cstr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771401
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> blocksize > old_len + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 + 1
  ORIGINAL[1]: dest = str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3
  ORIGINAL[2]: str -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dest
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dest
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477513
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: ui64toa_sep(((apr_uint64_t )number),seperator,buffer)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( VAR1 ) VAR2 ) , VAR3 , VAR4 )
  ORIGINAL[2]: (apr_uint64_t )number
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: seperator
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: buffer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771265
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476877
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: str[--i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ --i ]
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640329
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771280
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (svn_string_t *)(&strbuf -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 * ) ( &strbuf -> VAR2 )
  ORIGINAL[1]: &strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: &strbuf -> VAR1

CENTER_NODE: 30064771868
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number >= 100000000
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 100000000
  ORIGINAL[1]: decimal_table[reduced % 100]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 % 100 ]
  ORIGINAL[2]: reduced % 100
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 % 100
  ORIGINAL[3]: reduced
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771198
FRAGMENT_COUNT: 8
  ORIGINAL[0]: len1 != len2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: memcmp(str1,str2,len1) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: memcmp(str1,str2,len1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: len1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str2
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: len1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771552
FRAGMENT_COUNT: 4
  ORIGINAL[0]: string_compare((str1 -> data),(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str2 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771195
FRAGMENT_COUNT: 8
  ORIGINAL[0]: _s_z_ > _m_b_f_ -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: _m_b_f_ -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: memset(_m_b_f_ -> data,0,_m_b_f_ -> size)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , 0 , VAR1 -> VAR3 )
  ORIGINAL[3]: _m_b_f_ -> data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: _m_b_f_ -> size
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: size
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: _m_b_f_
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: _m_b_f_
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

