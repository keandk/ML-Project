# Tokenized code fragments for 152867-v1.0.0-bad
# Total center nodes processed: 145
# Total code fragments found: 468

CENTER_NODE: 47244640444
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771306
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: (wchar_t )eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> eolbyte
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640602
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640904
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775162
FRAGMENT_COUNT: 6
  ORIGINAL[0]: sizeof(( *rarray)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *rarray ) ) == 1
  ORIGINAL[1]: d -> states[s] . mbps . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[2]: d -> states[s] . mbps
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[s]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: mbps
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: nelem
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064773147
FRAGMENT_COUNT: 12
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1?xmalloc(size) : xnmalloc(size,sizeof(( *s -> elems)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1?xmalloc ( VAR2 ) : FUN1 ( VAR2 , sizeof ( ( *s -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *s -> elems)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[2]: sizeof(( *s -> elems))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[3]: xmalloc(size)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: xnmalloc(size,sizeof(( *s -> elems)))
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , sizeof ( ( *s -> VAR2 ) ) )
  ORIGINAL[5]: sizeof(( *s -> elems))
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[6]: *s -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: *s -> VAR1
  ORIGINAL[7]: s -> elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: elems
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: size
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: size
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064775197
FRAGMENT_COUNT: 6
  ORIGINAL[0]: mblen_buf[ *pp - buf_begin] == 0?1 : mblen_buf[ *pp - buf_begin]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ *pp - VAR2 ] == 0?1 : VAR1 [ *pp - VAR2 ]
  ORIGINAL[1]: mblen_buf[ *pp - buf_begin] == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ *pp - VAR2 ] == 0
  ORIGINAL[2]: mblen_buf[ *pp - buf_begin]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ *pp - VAR2 ]
  ORIGINAL[3]: mblen_buf[ *pp - buf_begin]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ *pp - VAR2 ]
  ORIGINAL[4]: *pp - buf_begin
  TYPE[4]: CALL
  TOKENIZED[4]: *pp - VAR1
  ORIGINAL[5]: <global> mblen_buf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: stonesoup_trace
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_location
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640605
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774964
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1
  ORIGINAL[3]: ((unsigned long )1) << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) 1 ) << 1 << 1 << 1

CENTER_NODE: 30064775804
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (new = icpyalloc(new)) == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR1 ) ) == ( ( void * ) 0 )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: for (i = 0;cpp[i] != ((void *)0);++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR2 [ VAR1 ] != ( ( void * ) 0 ) ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640547
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773190
FRAGMENT_COUNT: 5
  ORIGINAL[0]: lo < count && p . index == s -> elems[lo] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 . VAR4 == VAR5 -> VAR6 [ VAR1 ] . VAR4
  ORIGINAL[1]: s -> alloc <= count + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 <= VAR3 + 1
  ORIGINAL[2]: s -> alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: count + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775908
FRAGMENT_COUNT: 8
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: new[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: new[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: strlen(new[i])
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 [ VAR2 ] )
  ORIGINAL[4]: new[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719479506
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inputwcs[p - buf_begin]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 - VAR3 ]
  ORIGINAL[1]: free(mblen_buf)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: free(inputwcs)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: <global> inputwcs
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: backref
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> inputwcs
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640325
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476969
FRAGMENT_COUNT: 5
  ORIGINAL[0]: setbit_c((( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)),c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN2 ( VAR1 ) ) , VAR3 )
  ORIGINAL[1]: setbit(((*__ctype_b_loc())[(int)b] & ((short unsigned)_ISupper) ? tolower(b) : toupper(b)), c)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( short unsigned ) VAR2 ) ? FUN2 ( VAR1 ) : FUN3 ( VAR1 ) ) , VAR3 )
  ORIGINAL[2]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)
  TYPE[2]: CALL
  TOKENIZED[2]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN1 ( VAR1 )
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771238
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775691
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfaanalyze(d,searchflag)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: searchflag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640306
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640755
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775790
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640713
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773082
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: branch()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476841
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 68719476871
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640840
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775339
FRAGMENT_COUNT: 7
  ORIGINAL[0]: match_lens[i] ==  *pp - p1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == *pp - VAR3
  ORIGINAL[1]: j < d -> follows[d -> states[s1] . mbps . elems[i] . index] . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[2]: d -> states[s1] . mbps . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[3]: d -> states[s1] . mbps
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: d -> states[s1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: mbps
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: elems
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476840
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: trace_point
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_point
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: trace_point
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_trace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: trace_point
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771258
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(charclass )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477906
FRAGMENT_COUNT: 7
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: tindex + i
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tindex
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640549
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640983
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640661
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640768
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640393
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640662
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640584
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: i < minrep
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: for (i = 1;i < minrep;++i)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 1 ; VAR1 < VAR2 ; ++i )

CENTER_NODE: 30064773070
FRAGMENT_COUNT: 2
  ORIGINAL[0]: closure()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 47244640346
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640375
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640383
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640445
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773331
FRAGMENT_COUNT: 21
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: i < s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ++i
  TYPE[3]: CALL
  TOKENIZED[3]: ++i
  ORIGINAL[4]: s -> elems[i] = s -> elems[i + 1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] = VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[5]: s -> elems[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: s -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: s -> elems[i + 1]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[8]: s -> elems
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: i + 1
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 + 1
  ORIGINAL[10]: for (--s -> nelem;i < s -> nelem;++i)
  TYPE[10]: CONTROL_STRUCTURE
  TOKENIZED[10]: for ( --s -> VAR1 ; VAR2 < VAR3 -> VAR1 ; ++i )
  ORIGINAL[11]: nelem
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: elems
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: elems
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: s
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: i
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: s
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: i
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: s
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: i
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640683
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774801
FRAGMENT_COUNT: 14
  ORIGINAL[0]: d -> realtrans = ((sizeof(( *d -> realtrans)) == 1?xzalloc((d -> tralloc + 1)) : xcalloc((d -> tralloc + 1),sizeof(( *d -> realtrans)))))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = ( ( sizeof ( ( *d -> VAR2 ) ) == 1?xzalloc ( ( VAR1 -> VAR3 + 1 ) ) : FUN1 ( ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) ) ) )
  ORIGINAL[1]: d -> realtrans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(( *d -> realtrans)) == 1?xzalloc((d -> tralloc + 1)) : xcalloc((d -> tralloc + 1),sizeof(( *d -> realtrans)))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *d -> VAR1 ) ) == 1?xzalloc ( ( VAR2 -> VAR3 + 1 ) ) : FUN1 ( ( VAR2 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[3]: d -> realtrans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> realtrans
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> realtrans
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: realtrans
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 30064772885
FRAGMENT_COUNT: 15
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: !work_mbc -> invert
  TYPE[1]: CALL
  TOKENIZED[1]: !work_mbc -> VAR1
  ORIGINAL[2]: work_mbc -> invert
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: i = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 0
  ORIGINAL[4]: i < work_mbc -> nchars
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < VAR2 -> VAR3
  ORIGINAL[5]: work_mbc -> nchars
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: work_mbc -> nchars = 0
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 = 0
  ORIGINAL[7]: work_mbc -> nchars
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: nchars
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: nchars
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: work_mbc
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: work_mbc
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: work_mbc
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064771261
FRAGMENT_COUNT: 31
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: equal(s,dfa -> charclasses[i])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[3]: dfa -> charclasses[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: dfa -> charclasses
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[6]: dfa -> calloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: dfa -> cindex + 1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 + 1
  ORIGINAL[8]: dfa -> cindex
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: ++dfa -> cindex
  TYPE[9]: CALL
  TOKENIZED[9]: ++dfa -> VAR1
  ORIGINAL[10]: dfa -> cindex
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: copyset(s,dfa -> charclasses[i])
  TYPE[11]: CALL
  TOKENIZED[11]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[12]: dfa -> charclasses[i]
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[13]: dfa -> charclasses
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: for (i = 0;i < dfa -> cindex;++i)
  TYPE[14]: CONTROL_STRUCTURE
  TOKENIZED[14]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[15]: charclasses
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: calloc
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: cindex
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: cindex
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: charclasses
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: i
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: s
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: <global> dfa
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: <global> VAR1
  ORIGINAL[23]: i
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: <global> dfa
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: <global> VAR1
  ORIGINAL[25]: <global> dfa
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: <global> VAR1
  ORIGINAL[26]: <global> dfa
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: <global> VAR1
  ORIGINAL[27]: s
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: <global> dfa
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: <global> VAR1
  ORIGINAL[29]: i
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: i
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1

CENTER_NODE: 30064775597
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> mbcsets = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[1]: d -> mbcsets
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: mbcsets
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775926
FRAGMENT_COUNT: 4
  ORIGINAL[0]: both == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: both[0] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ] = ( ( void * ) 0 )
  ORIGINAL[2]: both[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064776376
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640403
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640773
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775770
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640356
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773996
FRAGMENT_COUNT: 4
  ORIGINAL[0]: separate_contexts = state_separate_contexts((&merged))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( ( &merged ) )
  ORIGINAL[1]: state_separate_contexts((&merged))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( &merged ) )
  ORIGINAL[2]: separate_contexts
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477993
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dst -> alloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: src -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772582
FRAGMENT_COUNT: 4
  ORIGINAL[0]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1
  ORIGINAL[3]: ((unsigned long )1) << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) 1 ) << 1 << 1

CENTER_NODE: 47244640681
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640717
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480159
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640566
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064776363
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 68719476972
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: utf8
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640336
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771136
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: strcmp(getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( FUN2 ( \
  ORIGINAL[2]: strcmp(getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( FUN2 ( \
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \

CENTER_NODE: 30064773109
FRAGMENT_COUNT: 9
  ORIGINAL[0]: END - d -> nregexps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2 -> VAR3
  ORIGINAL[1]: d -> nregexps
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> nregexps
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nregexps
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: END
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640682
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640878
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640324
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640775
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640934
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640776
FRAGMENT_COUNT: 2
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: while (oldalloc < d -> tralloc)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: while ( VAR1 < VAR2 -> VAR3 )

CENTER_NODE: 47244640411
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478861
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < ngrps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: possible_contexts = charclass_context(labels[i])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 [ VAR3 ] )
  ORIGINAL[2]: separate_contexts = state_separate_contexts((&follows))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( ( &follows ) )
  ORIGINAL[3]: state_separate_contexts((&follows))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( &follows ) )
  ORIGINAL[4]: separate_contexts
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: follows
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: separate_contexts
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479171
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[1]: match = !work_mbc -> invert
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = !work_mbc -> VAR2
  ORIGINAL[2]: match_len = (mblen_buf[idx] == 0?1 : mblen_buf[idx])
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( VAR2 [ VAR3 ] == 0?1 : VAR2 [ VAR3 ] )
  ORIGINAL[3]: mblen_buf[idx] == 0?1 : mblen_buf[idx]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] == 0?1 : VAR1 [ VAR2 ]
  ORIGINAL[4]: match_len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> mblen_buf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: match_len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: match_len
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640762
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640660
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775715
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (i = 0;i < d -> tindex;++i)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773649
FRAGMENT_COUNT: 45
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ++j
  TYPE[2]: CALL
  TOKENIZED[2]: ++j
  ORIGINAL[3]: (s -> elems[j] . constraint >> 2 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[4]: s -> elems[j] . constraint >> 2 & 0x111
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111
  ORIGINAL[5]: s -> elems[j] . constraint >> 2
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2
  ORIGINAL[6]: s -> elems[j] . constraint
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[7]: s -> elems[j]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[8]: s -> elems
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: s -> elems[j] . constraint & 0x111
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111
  ORIGINAL[10]: s -> elems[j] . constraint
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[11]: s -> elems[j]
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[12]: s -> elems
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: (s -> elems[j] . constraint >> 1 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[13]: CALL
  TOKENIZED[13]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[14]: s -> elems[j] . constraint >> 1 & 0x111
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111
  ORIGINAL[15]: s -> elems[j] . constraint >> 1
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1
  ORIGINAL[16]: s -> elems[j] . constraint
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[17]: s -> elems[j]
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[18]: s -> elems
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2
  ORIGINAL[19]: s -> elems[j] . constraint & 0x111
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111
  ORIGINAL[20]: s -> elems[j] . constraint
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[21]: s -> elems[j]
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[22]: s -> elems
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 -> VAR2
  ORIGINAL[23]: for (j = 0;j < s -> nelem;++j)
  TYPE[23]: CONTROL_STRUCTURE
  TOKENIZED[23]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[24]: nelem
  TYPE[24]: FIELD_IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: elems
  TYPE[25]: FIELD_IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: constraint
  TYPE[26]: FIELD_IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: elems
  TYPE[27]: FIELD_IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: constraint
  TYPE[28]: FIELD_IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: elems
  TYPE[29]: FIELD_IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: constraint
  TYPE[30]: FIELD_IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: elems
  TYPE[31]: FIELD_IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: constraint
  TYPE[32]: FIELD_IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: j
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: s
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: j
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: s
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: j
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: s
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1
  ORIGINAL[39]: j
  TYPE[39]: IDENTIFIER
  TOKENIZED[39]: VAR1
  ORIGINAL[40]: s
  TYPE[40]: IDENTIFIER
  TOKENIZED[40]: VAR1
  ORIGINAL[41]: j
  TYPE[41]: IDENTIFIER
  TOKENIZED[41]: VAR1
  ORIGINAL[42]: s
  TYPE[42]: IDENTIFIER
  TOKENIZED[42]: VAR1
  ORIGINAL[43]: j
  TYPE[43]: IDENTIFIER
  TOKENIZED[43]: VAR1
  ORIGINAL[44]: separate_contexts
  TYPE[44]: IDENTIFIER
  TOKENIZED[44]: VAR1

CENTER_NODE: 47244640595
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640426
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476745
FRAGMENT_COUNT: 3
  ORIGINAL[0]: size_filepath = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: retval = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: retval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775655
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> multibyte_prop)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[1]: d -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(( *d -> multibyte_prop))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[3]: *d -> multibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: d -> multibyte_prop
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 6
  ORIGINAL[0]: sbit[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: setbit(i,newline)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> newline
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773367
FRAGMENT_COUNT: 7
  ORIGINAL[0]: hash != d -> states[i] . hash
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 -> VAR3 [ VAR4 ] . VAR1
  ORIGINAL[1]: d -> states[i] . hash
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: d -> states[i] . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476882
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640886
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479653
FRAGMENT_COUNT: 11
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i < d -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2 -> VAR3
  ORIGINAL[3]: d -> tindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ++i
  TYPE[4]: CALL
  TOKENIZED[4]: ++i
  ORIGINAL[5]: d -> tokens[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640815
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640774
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640841
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775953
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mp -> left[0] = mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = VAR1 -> VAR4 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> left[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> left
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = '\\0'
  ORIGINAL[4]: mp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771584
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c1 == ':'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ':'
  ORIGINAL[1]: !pred
  TYPE[1]: CALL
  TOKENIZED[1]: !pred
  ORIGINAL[2]: dfaerror((gettext(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( FUN2 ( \
  ORIGINAL[3]: __ctype_get_mb_cur_max() > 1
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ) > 1
  ORIGINAL[4]: __ctype_get_mb_cur_max()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )

CENTER_NODE: 47244640423
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771200
FRAGMENT_COUNT: 3
  ORIGINAL[0]: REPMN=267
  TYPE[0]: CALL
  TOKENIZED[0]: REPMN=267
  ORIGINAL[1]: REPMN
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: CAT
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775869
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ( *lcp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *lcp ) != '\\0'
  ORIGINAL[1]: rcp != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: rcp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640629
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775777
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: *cp
  TYPE[1]: CALL
  TOKENIZED[1]: *cp
  ORIGINAL[2]: ++cp
  TYPE[2]: CALL
  TOKENIZED[2]: ++cp
  ORIGINAL[3]: strncmp(cp,lookfor,len) == 0
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[4]: strncmp(cp,lookfor,len)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[5]: (char *)cp
  TYPE[5]: CALL
  TOKENIZED[5]: ( char * ) VAR1
  ORIGINAL[6]: cp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: cp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640879
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771209
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771249
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )
  ORIGINAL[3]: int
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: int

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 2
  ORIGINAL[0]: *__ctype_b_loc()
  TYPE[0]: CALL
  TOKENIZED[0]: *__ctype_b_loc ( )
  ORIGINAL[1]: __ctype_b_loc()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )

CENTER_NODE: 47244640597
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774718
FRAGMENT_COUNT: 14
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: trans[i] >= d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] >= VAR3 -> VAR4
  ORIGINAL[4]: trans[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: for (i = 0;i < (1 << 8);++i)
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )
  ORIGINAL[7]: tralloc
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: trans
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771367
FRAGMENT_COUNT: 6
  ORIGINAL[0]: prednames[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: strcmp(str,prednames[i] . name)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 [ VAR3 ] . VAR4 )
  ORIGINAL[2]: prednames[i] . name
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: prednames[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: prednames[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: name
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477889
FRAGMENT_COUNT: 2
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: PLUS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719479711
FRAGMENT_COUNT: 5
  ORIGINAL[0]: oldsize = old == ((void *)0)?0 : strlen(old)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR2 )
  ORIGINAL[1]: old == ((void *)0)?0 : strlen(old)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[2]: oldsize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: old
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: oldsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640434
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640314
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772973
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7
  ORIGINAL[2]: tok == MBCSET
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: MBCSET
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771229
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: b / (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[3]: ~(1 << b % (8 * sizeof(int )))
  TYPE[3]: CALL
  TOKENIZED[3]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640636
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479113
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> fails[works]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: d -> fails[works]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: works
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: works
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640353
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479086
FRAGMENT_COUNT: 2
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640401
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640639
FRAGMENT_COUNT: 1
  ORIGINAL[0]: visited[old . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 . VAR3 ]

CENTER_NODE: 30064776196
FRAGMENT_COUNT: 16
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: &musts[2]
  TYPE[1]: CALL
  TOKENIZED[1]: &musts [ 2 ]
  ORIGINAL[2]: musts[2]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 2 ]
  ORIGINAL[3]: &musts[2]
  TYPE[3]: CALL
  TOKENIZED[3]: &musts [ 2 ]
  ORIGINAL[4]: musts[2]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ 2 ]
  ORIGINAL[5]: musts
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: musts
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: musts
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: musts
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: musts
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: musts
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: musts
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: musts
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: musts
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: musts
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: musts
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640991
FRAGMENT_COUNT: 4
  ORIGINAL[0]: out_filename = optarg
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: break;
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: break ;
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771218
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 8 * sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: 8 * sizeof ( int )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 68719480153
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773292
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s1 -> elems[i] . index < s2 -> elems[j] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 < VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[1]: m -> elems[m -> nelem++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> nelem++ ]
  ORIGINAL[2]: m -> nelem++
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> nelem++
  ORIGINAL[3]: m -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640839
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477775
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dfa -> nmultibyte_prop <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: &new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: &new_n_alloc
  ORIGINAL[3]: new_n_alloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_n_alloc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640761
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478327
FRAGMENT_COUNT: 7
  ORIGINAL[0]: c[j] & letters[j]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] & VAR3 [ VAR2 ]
  ORIGINAL[1]: context |= 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 2
  ORIGINAL[2]: context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: context
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: context
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: context
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 0

