# Tokenized code fragments for 152395-v1.0.0-bad
# Total center nodes processed: 34
# Total code fragments found: 163

CENTER_NODE: 68719477018
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream -> pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: stream -> seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: seek
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476738
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (struct mg_connection*) stonesoup_printf_context
  TYPE[0]: CALL
  TOKENIZED[0]: ( struct mg_connection* ) VAR1
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 47244640326
FRAGMENT_COUNT: 1
  ORIGINAL[0]: gz_skip(file,file -> skip) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR1 -> VAR2 ) == - 1

CENTER_NODE: 30064771331
FRAGMENT_COUNT: 4
  ORIGINAL[0]: state == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: state -> fast_seek = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[2]: state -> fast_seek
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064771695
FRAGMENT_COUNT: 5
  ORIGINAL[0]: file -> pos + offset - off2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 + VAR3 - VAR4
  ORIGINAL[1]: file -> pos + offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 + VAR3
  ORIGINAL[2]: file -> pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: <global> offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: off2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 1
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1

CENTER_NODE: 68719477020
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> raw_pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: raw_pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771638
FRAGMENT_COUNT: 14
  ORIGINAL[0]: fh -> err != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != 0
  ORIGINAL[1]: fh -> err
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: *err_info = (fh -> err_info == ((void *)0)?((void *)0) : g_strdup(fh -> err_info))
  TYPE[2]: CALL
  TOKENIZED[2]: *err_info = ( VAR1 -> VAR2 == ( ( void * ) 0 ) ? ( ( void * ) 0 ) : FUN1 ( VAR1 -> VAR2 ) )
  ORIGINAL[3]: *err_info
  TYPE[3]: CALL
  TOKENIZED[3]: *err_info
  ORIGINAL[4]: fh -> err_info == ((void *)0)?((void *)0) : g_strdup(fh -> err_info)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 == ( ( void * ) 0 ) ? ( ( void * ) 0 ) : FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[5]: fh -> err_info == ((void *)0)
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[6]: fh -> err_info
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: (void *)0
  TYPE[7]: CALL
  TOKENIZED[7]: ( void * ) 0
  ORIGINAL[8]: fh -> err
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: err_info
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: err
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: err_info
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: fh
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: fh
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 30064771296
FRAGMENT_COUNT: 9
  ORIGINAL[0]: state -> compression = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: state -> compression
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: compression
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: state
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: state
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771389
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream -> fast_seek = seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: stream -> fast_seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fast_seek
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: seek
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ret < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: state -> err =  *__errno_location()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = *__errno_location ( )
  ORIGINAL[2]: state -> err
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *__errno_location()
  TYPE[3]: CALL
  TOKENIZED[3]: *__errno_location ( )
  ORIGINAL[4]: __errno_location()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )

CENTER_NODE: 68719477024
FRAGMENT_COUNT: 4
  ORIGINAL[0]: err != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: *err
  TYPE[1]: CALL
  TOKENIZED[1]: *err
  ORIGINAL[2]: err
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: err
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771510
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> is_compressed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: is_compressed
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477016
FRAGMENT_COUNT: 2
  ORIGINAL[0]: file_seek(file,delta,1,err)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 1 , VAR3 )
  ORIGINAL[1]: err
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771170
FRAGMENT_COUNT: 4
  ORIGINAL[0]: raw_read(state,state -> in,state -> size,((unsigned int *)(&state -> avail_in))) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , ( ( unsigned int * ) ( &state -> VAR4 ) ) ) == - 1
  ORIGINAL[1]: state -> next_in = state -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[2]: state -> next_in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: state -> in
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 68719476751
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(char)
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( char )
  ORIGINAL[1]: buffer_size
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: char
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: char

CENTER_NODE: 30064771173
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 47244640308
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477127
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream -> err = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: stream -> err
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: stream -> err_info
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: err_info
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stream
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771668
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1
  ORIGINAL[1]: file -> fd = fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: file -> fd
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: fd
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: file
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: fd
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771490
FRAGMENT_COUNT: 7
  ORIGINAL[0]: raw_read(state,state -> out,state -> size,&state -> have) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , &state -> VAR4 ) == - 1
  ORIGINAL[1]: state -> next = state -> out
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[2]: state -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: state -> out
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: next
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477145
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fd != - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != - 1
  ORIGINAL[1]: close(fd)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: fd
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: fd
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771657
FRAGMENT_COUNT: 3
  ORIGINAL[0]: close(file -> fd)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771609
FRAGMENT_COUNT: 15
  ORIGINAL[0]: file -> have == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: file -> have == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == 0
  ORIGINAL[2]: eol != ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: n = ((unsigned int )(eol - file -> next)) + 1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = ( ( unsigned int ) ( VAR2 - VAR3 -> VAR4 ) ) + 1
  ORIGINAL[5]: ((unsigned int )(eol - file -> next)) + 1
  TYPE[5]: CALL
  TOKENIZED[5]: ( ( unsigned int ) ( VAR1 - VAR2 -> VAR3 ) ) + 1
  ORIGINAL[6]: (unsigned int )(eol - file -> next)
  TYPE[6]: CALL
  TOKENIZED[6]: ( unsigned int ) ( VAR1 - VAR2 -> VAR3 )
  ORIGINAL[7]: eol - file -> next
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 - VAR2 -> VAR3
  ORIGINAL[8]: file -> next
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: next
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: eol
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: n
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: eol
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: file
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: buf
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719476864
FRAGMENT_COUNT: 8
  ORIGINAL[0]: state -> avail_in
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: state -> avail_in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> fast_seek
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: state -> raw_pos
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: state -> avail_in
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: avail_in
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771216
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !item || item -> out < out_pos
  TYPE[0]: CALL
  TOKENIZED[0]: !item || VAR1 -> VAR2 < VAR3
  ORIGINAL[1]: !item
  TYPE[1]: CALL
  TOKENIZED[1]: !item
  ORIGINAL[2]: item -> out < out_pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 < VAR3
  ORIGINAL[3]: item -> out
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: out_pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476997
FRAGMENT_COUNT: 16
  ORIGINAL[0]: file -> skip
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file -> next
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: file -> out
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: file -> pos
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: file -> pos
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: lseek(file -> fd,off,0) == (- 1)
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( VAR1 -> VAR2 , VAR3 , 0 ) == ( - 1 )
  ORIGINAL[8]: file -> fd
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: file -> raw_pos
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: file -> have = 0
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 = 0
  ORIGINAL[11]: file -> have
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: file -> eof
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: eof
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: file
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: file
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 30064771109
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: mg_set_option(stonesoup_server, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: stonesoup_server
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771192
FRAGMENT_COUNT: 8
  ORIGINAL[0]: file -> fast_seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> fast_seek -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: low < max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2
  ORIGINAL[3]: file -> fast_seek -> pdata
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[4]: file -> fast_seek
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: fast_seek
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pdata
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771557
FRAGMENT_COUNT: 7
  ORIGINAL[0]: file -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> have--
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> have--
  ORIGINAL[2]: file -> have
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: have
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: file
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: file
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 68719477118
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file -> eof
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: eof
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: file
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

