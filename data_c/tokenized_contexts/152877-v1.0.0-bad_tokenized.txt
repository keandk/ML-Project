# Tokenized code fragments for 152877-v1.0.0-bad
# Total center nodes processed: 142
# Total code fragments found: 476

CENTER_NODE: 47244640833
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640675
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771291
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISalpha)
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )b]
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[2]: (unsigned short )_ISalpha
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned short ) VAR1
  ORIGINAL[3]: <global> case_fold
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: _ISalpha
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640437
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( int )
  ORIGINAL[1]: int
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: int

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640754
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640290
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774866
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_DONE
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775731
FRAGMENT_COUNT: 10
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i] != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: cpp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: cpp[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: cpp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771244
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum)
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )c]
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[2]: *__ctype_b_loc()
  TYPE[2]: CALL
  TOKENIZED[2]: *__ctype_b_loc ( )
  ORIGINAL[3]: (int )c
  TYPE[3]: CALL
  TOKENIZED[3]: ( int ) VAR1
  ORIGINAL[4]: (unsigned short )_ISalnum
  TYPE[4]: CALL
  TOKENIZED[4]: ( unsigned short ) VAR1

CENTER_NODE: 47244640587
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773023
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: addtok(CAT)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: CAT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773374
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> states
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: *d -> states
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1
  ORIGINAL[3]: d -> states[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: states
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719479095
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: wc == ((wchar_t )'\\0')
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: context & 1?pos . constraint & 0xf : 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 & 1?pos . VAR2 & 0xf : 0
  ORIGINAL[4]: context & 2
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 & 2
  ORIGINAL[5]: context
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: context
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: context
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476804
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BEGWORD=260
  TYPE[0]: CALL
  TOKENIZED[0]: BEGWORD=260
  ORIGINAL[1]: ENDWORD=261
  TYPE[1]: CALL
  TOKENIZED[1]: ENDWORD=261
  ORIGINAL[2]: ENDWORD
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771304
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640609
FRAGMENT_COUNT: 1
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3

CENTER_NODE: 47244640306
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773048
FRAGMENT_COUNT: 9
  ORIGINAL[0]: depth = d -> depth
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR1
  ORIGINAL[1]: d -> depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: depth
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> depth
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064774864
FRAGMENT_COUNT: 4
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> fails[oldalloc++] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ oldalloc++ ] = ( ( void * ) 0 )
  ORIGINAL[2]: d -> fails[oldalloc++]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ oldalloc++ ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064772771
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa -> nmultibyte_prop <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> tindex + 1 + (!dfa -> multibyte_prop)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 + 1 + ( !dfa -> VAR3 )
  ORIGINAL[2]: !dfa -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: !dfa -> VAR1
  ORIGINAL[3]: dfa -> multibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 30064772904
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7
  ORIGINAL[2]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6
  ORIGINAL[3]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[4]: tok == BEGWORD
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: tok == ANYCHAR
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: ANYCHAR
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064775704
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new == ((void *)0)?0 : strlen(new)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[1]: new == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: strlen(new)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064776347
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640621
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773097
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1?xmalloc(size) : xnmalloc(size,sizeof(( *s -> elems)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1?xmalloc ( VAR2 ) : FUN1 ( VAR2 , sizeof ( ( *s -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *s -> elems)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[2]: xmalloc(size)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640559
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640328
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640267
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640393
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478060
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s1 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s1 -> elems[i] . index < s2 -> elems[j] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 < VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[2]: m -> elems[m -> nelem]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> VAR3 ]
  ORIGINAL[3]: s1 -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640287
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479074
FRAGMENT_COUNT: 10
  ORIGINAL[0]: d -> trans
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> fails[works]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: build_state(works,d)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: works
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064772837
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < work_mbc -> nchars
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: addtok_wc(work_mbc -> chars[i])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] )
  ORIGINAL[2]: work_mbc -> chars[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: need_or
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479645
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> charclasses
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: i < d -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 < VAR2 -> VAR3
  ORIGINAL[6]: d -> tindex
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> follows
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: follows
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640308
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640375
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476797
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064776333
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776361
FRAGMENT_COUNT: 3
  ORIGINAL[0]: {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: { { ( \
  ORIGINAL[1]: {(\
  TYPE[1]: CALL
  TOKENIZED[1]: { ( \
  ORIGINAL[2]: iscntrl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479207
FRAGMENT_COUNT: 7
  ORIGINAL[0]: rarray = ((sizeof(( *rarray)) == 1?xmalloc(d -> states[s] . mbps . nelem) : xnmalloc(d -> states[s] . mbps . nelem,sizeof(( *rarray)))))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( sizeof ( ( *rarray ) ) == 1?xmalloc ( VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 ) : FUN1 ( VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 , sizeof ( ( *rarray ) ) ) ) )
  ORIGINAL[1]: sizeof(( *rarray)) == 1?xmalloc(d -> states[s] . mbps . nelem) : xnmalloc(d -> states[s] . mbps . nelem,sizeof(( *rarray)))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *rarray ) ) == 1?xmalloc ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 ) : FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 , sizeof ( ( *rarray ) ) )
  ORIGINAL[2]: rarray
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rarray
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: rarray
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: rarray
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: rarray
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640256
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ss_tc_root != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2

CENTER_NODE: 30064771185
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640868
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476793
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c >= 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640403
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640747
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775716
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640338
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773511
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8
  ORIGINAL[1]: s -> elems[i] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: s -> elems[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: index
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064773571
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (j = 0;j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++j)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++j )
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775207
FRAGMENT_COUNT: 8
  ORIGINAL[0]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[1]: d -> states[s]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> states
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: states
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771255
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == '_' || iswalnum(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '_' || FUN1 ( VAR1 )
  ORIGINAL[2]: wc == '_'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == '_'
  ORIGINAL[3]: iswalnum(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774755
FRAGMENT_COUNT: 19
  ORIGINAL[0]: d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: sizeof(( *d -> realtrans)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: d -> tralloc + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> tralloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tralloc
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 47244640878
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640896
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772300
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((unsigned long )1) << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned long ) 1 ) << 1 << 1 << 1
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476998
FRAGMENT_COUNT: 11
  ORIGINAL[0]: cur_mb_len <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: --lexleft
  TYPE[1]: CALL
  TOKENIZED[1]: --lexleft
  ORIGINAL[2]: wc = (c = (to_uchar( *(lexptr++))))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( VAR2 = ( FUN1 ( * ( lexptr++ ) ) ) )
  ORIGINAL[3]: c = (to_uchar( *(lexptr++)))
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = ( FUN1 ( * ( lexptr++ ) ) )
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: wc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: wc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: wc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: wc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: wc
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719479817
FRAGMENT_COUNT: 6
  ORIGINAL[0]: right[rnum] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: left[lnum]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: lnum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: lnum
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: left
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: lnum
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640264
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: s[i] = ~s[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[4]: for (i = 0;i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++i)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++i )

CENTER_NODE: 47244640426
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479621
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaparse(s,len,d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640807
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775612
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *d -> mbcsets)) == 1?xmalloc(d -> mbcsets_alloc) : xnmalloc(d -> mbcsets_alloc,sizeof(( *d -> mbcsets)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *d -> mbcsets)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xmalloc(d -> mbcsets_alloc)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[3]: d -> mbcsets_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 30064774574
FRAGMENT_COUNT: 12
  ORIGINAL[0]: 4 & 4?( *d) . states[s] . constraint >> 8 & 0xf : 0
  TYPE[0]: CALL
  TOKENIZED[0]: 4 & 4? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf : 0
  ORIGINAL[1]: 4 & 4
  TYPE[1]: CALL
  TOKENIZED[1]: 4 & 4
  ORIGINAL[2]: ( *d) . states[s] . constraint >> 8 & 0xf
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf
  ORIGINAL[3]: ( *d) . states[s] . constraint >> 8
  TYPE[3]: CALL
  TOKENIZED[3]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8
  ORIGINAL[4]: ( *d) . states[s] . constraint
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[5]: ( *d) . states[s]
  TYPE[5]: CALL
  TOKENIZED[5]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[6]: ( *d) . states
  TYPE[6]: CALL
  TOKENIZED[6]: ( *d ) . VAR1
  ORIGINAL[7]: *d
  TYPE[7]: CALL
  TOKENIZED[7]: *d
  ORIGINAL[8]: states
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: constraint
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064775630
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: free_mbdata(d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640348
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479831
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> is
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: is
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640395
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640589
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640628
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640709
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775847
FRAGMENT_COUNT: 12
  ORIGINAL[0]: old == ((void *)0) || new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: new[i] != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[2]: new[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: new[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: new[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: old == ((void *)0)
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[7]: new
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: new
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: new
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: new
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064775507
FRAGMENT_COUNT: 55
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> nmbcsets
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: *p = &d -> mbcsets[i]
  TYPE[3]: CALL
  TOKENIZED[3]: *p = &d -> VAR1 [ VAR2 ]
  ORIGINAL[4]: &d -> mbcsets[i]
  TYPE[4]: CALL
  TOKENIZED[4]: &d -> VAR1 [ VAR2 ]
  ORIGINAL[5]: d -> mbcsets[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: d -> mbcsets
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: free((p -> chars))
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[8]: p -> chars
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: free((p -> ch_classes))
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[10]: p -> ch_classes
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: free((p -> range_sts))
  TYPE[11]: CALL
  TOKENIZED[11]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[12]: p -> range_sts
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: free((p -> range_ends))
  TYPE[13]: CALL
  TOKENIZED[13]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[14]: p -> range_ends
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: j = 0
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 = 0
  ORIGINAL[16]: j < p -> nequivs
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 < VAR2 -> VAR3
  ORIGINAL[17]: p -> nequivs
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: free((p -> equivs))
  TYPE[18]: CALL
  TOKENIZED[18]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[19]: p -> equivs
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2
  ORIGINAL[20]: j = 0
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 = 0
  ORIGINAL[21]: j < p -> ncoll_elems
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 < VAR2 -> VAR3
  ORIGINAL[22]: p -> ncoll_elems
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 -> VAR2
  ORIGINAL[23]: free((p -> coll_elems))
  TYPE[23]: CALL
  TOKENIZED[23]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[24]: p -> coll_elems
  TYPE[24]: CALL
  TOKENIZED[24]: VAR1 -> VAR2
  ORIGINAL[25]: for (i = 0;i < d -> nmbcsets;++i)
  TYPE[25]: CONTROL_STRUCTURE
  TOKENIZED[25]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[26]: nmbcsets
  TYPE[26]: FIELD_IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: mbcsets
  TYPE[27]: FIELD_IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: chars
  TYPE[28]: FIELD_IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: ch_classes
  TYPE[29]: FIELD_IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: range_sts
  TYPE[30]: FIELD_IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: range_ends
  TYPE[31]: FIELD_IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: nequivs
  TYPE[32]: FIELD_IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: equivs
  TYPE[33]: FIELD_IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: ncoll_elems
  TYPE[34]: FIELD_IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: coll_elems
  TYPE[35]: FIELD_IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: i
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: d
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: i
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1
  ORIGINAL[39]: p
  TYPE[39]: IDENTIFIER
  TOKENIZED[39]: VAR1
  ORIGINAL[40]: d
  TYPE[40]: IDENTIFIER
  TOKENIZED[40]: VAR1
  ORIGINAL[41]: i
  TYPE[41]: IDENTIFIER
  TOKENIZED[41]: VAR1
  ORIGINAL[42]: p
  TYPE[42]: IDENTIFIER
  TOKENIZED[42]: VAR1
  ORIGINAL[43]: p
  TYPE[43]: IDENTIFIER
  TOKENIZED[43]: VAR1
  ORIGINAL[44]: p
  TYPE[44]: IDENTIFIER
  TOKENIZED[44]: VAR1
  ORIGINAL[45]: p
  TYPE[45]: IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: j
  TYPE[46]: IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: j
  TYPE[47]: IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: p
  TYPE[48]: IDENTIFIER
  TOKENIZED[48]: VAR1
  ORIGINAL[49]: p
  TYPE[49]: IDENTIFIER
  TOKENIZED[49]: VAR1
  ORIGINAL[50]: j
  TYPE[50]: IDENTIFIER
  TOKENIZED[50]: VAR1
  ORIGINAL[51]: j
  TYPE[51]: IDENTIFIER
  TOKENIZED[51]: VAR1
  ORIGINAL[52]: p
  TYPE[52]: IDENTIFIER
  TOKENIZED[52]: VAR1
  ORIGINAL[53]: p
  TYPE[53]: IDENTIFIER
  TOKENIZED[53]: VAR1
  ORIGINAL[54]: d
  TYPE[54]: IDENTIFIER
  TOKENIZED[54]: VAR1

CENTER_NODE: 47244640317
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773792
FRAGMENT_COUNT: 39
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: nullable[- 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ - 1 ]
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: nlastpos[- 2] += nlastpos[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 2 ] += VAR1 [ - 1 ]
  ORIGINAL[4]: nlastpos[- 2]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ - 2 ]
  ORIGINAL[5]: - 2
  TYPE[5]: CALL
  TOKENIZED[5]: - 2
  ORIGINAL[6]: nlastpos[- 1]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ - 1 ]
  ORIGINAL[7]: - 1
  TYPE[7]: CALL
  TOKENIZED[7]: - 1
  ORIGINAL[8]: pos = lastpos + nlastpos[- 2]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 = VAR2 + VAR3 [ - 2 ]
  ORIGINAL[9]: lastpos + nlastpos[- 2]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 + VAR2 [ - 2 ]
  ORIGINAL[10]: nlastpos[- 2]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 [ - 2 ]
  ORIGINAL[11]: - 2
  TYPE[11]: CALL
  TOKENIZED[11]: - 2
  ORIGINAL[12]: j = nlastpos[- 1]
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 = VAR2 [ - 1 ]
  ORIGINAL[13]: nlastpos[- 1]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 [ - 1 ]
  ORIGINAL[14]: - 1
  TYPE[14]: CALL
  TOKENIZED[14]: - 1
  ORIGINAL[15]: j-- > 0
  TYPE[15]: CALL
  TOKENIZED[15]: j-- > 0
  ORIGINAL[16]: j--
  TYPE[16]: CALL
  TOKENIZED[16]: j--
  ORIGINAL[17]: lastpos += nlastpos[- 2]
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 += VAR2 [ - 2 ]
  ORIGINAL[18]: nlastpos[- 2]
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 [ - 2 ]
  ORIGINAL[19]: - 2
  TYPE[19]: CALL
  TOKENIZED[19]: - 2
  ORIGINAL[20]: nlastpos[- 2] = nlastpos[- 1]
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 [ - 2 ] = VAR1 [ - 1 ]
  ORIGINAL[21]: nlastpos[- 2]
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 [ - 2 ]
  ORIGINAL[22]: - 2
  TYPE[22]: CALL
  TOKENIZED[22]: - 2
  ORIGINAL[23]: nlastpos[- 1]
  TYPE[23]: CALL
  TOKENIZED[23]: VAR1 [ - 1 ]
  ORIGINAL[24]: - 1
  TYPE[24]: CALL
  TOKENIZED[24]: - 1
  ORIGINAL[25]: nullable
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: nlastpos
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: nlastpos
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: pos
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: lastpos
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: nlastpos
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: j
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: nlastpos
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: j
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: lastpos
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: nlastpos
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: nlastpos
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: nlastpos
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: nlastpos
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640701
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !intersectf
  TYPE[0]: CALL
  TOKENIZED[0]: !intersectf

CENTER_NODE: 30064775307
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *pp - p1 < maxlen
  TYPE[0]: CALL
  TOKENIZED[0]: *pp - VAR1 < VAR2
  ORIGINAL[1]: s1 = state_index(d,(&follows),wchar_context(wc))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , ( &follows ) , FUN2 ( VAR3 ) )
  ORIGINAL[2]: state_index(d,(&follows),wchar_context(wc))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( &follows ) , FUN2 ( VAR2 ) )
  ORIGINAL[3]: &follows
  TYPE[3]: CALL
  TOKENIZED[3]: &follows
  ORIGINAL[4]: wchar_context(wc)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: s1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640415
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480143
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dfa -> charclasses[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[2]: dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *dfa -> charclasses
  TYPE[3]: CALL
  TOKENIZED[3]: *dfa -> VAR1
  ORIGINAL[4]: dfa -> charclasses
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: charclasses
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1

CENTER_NODE: 30064771155
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064774949
FRAGMENT_COUNT: 4
  ORIGINAL[0]: buffer[128]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 128 ]
  ORIGINAL[1]: buffer[128]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 128 ]
  ORIGINAL[2]: buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771204
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(charclass )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640359
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640541
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640871
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772966
FRAGMENT_COUNT: 7
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: dfa -> multibyte_prop[dfa -> tindex - 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[2]: dfa -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> multibyte_prop[tindex + i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[4]: multibyte_prop
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1

CENTER_NODE: 47244640385
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640597
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775371
FRAGMENT_COUNT: 13
  ORIGINAL[0]: s == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: inputwcs[p - buf_begin] == 0 && mblen_buf[p - buf_begin] > 0 && ((const unsigned char *)p) < buf_end
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 - VAR3 ] == 0 && VAR4 [ VAR2 - VAR3 ] > 0 && ( ( const unsigned char * ) VAR2 ) < VAR5
  ORIGINAL[2]: inputwcs[p - buf_begin] == 0 && mblen_buf[p - buf_begin] > 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 - VAR3 ] == 0 && VAR4 [ VAR2 - VAR3 ] > 0
  ORIGINAL[3]: inputwcs[p - buf_begin] == 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 - VAR3 ] == 0
  ORIGINAL[4]: inputwcs[p - buf_begin]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 - VAR3 ]
  ORIGINAL[5]: p - buf_begin
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 - VAR2
  ORIGINAL[6]: ((const unsigned char *)p) < buf_end
  TYPE[6]: CALL
  TOKENIZED[6]: ( ( const unsigned char * ) VAR1 ) < VAR2
  ORIGINAL[7]: ++p
  TYPE[7]: CALL
  TOKENIZED[7]: ++p
  ORIGINAL[8]: while (inputwcs[p - buf_begin] == 0 && mblen_buf[p - buf_begin] > 0 && ((const unsigned char *)p) < buf_end)
  TYPE[8]: CONTROL_STRUCTURE
  TOKENIZED[8]: while ( VAR1 [ VAR2 - VAR3 ] == 0 && VAR4 [ VAR2 - VAR3 ] > 0 && ( ( const unsigned char * ) VAR2 ) < VAR5 )
  ORIGINAL[9]: <global> inputwcs
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: <global> buf_begin
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 30064775758
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: istrstr(cpp[i],new) != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 [ VAR2 ] , VAR3 ) != ( ( void * ) 0 )
  ORIGINAL[2]: istrstr(cpp[i],new)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 [ VAR2 ] , VAR3 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640418
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640973
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775827
FRAGMENT_COUNT: 6
  ORIGINAL[0]: rcp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: rcp = strchr((rcp + 1),( *lcp))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( ( VAR1 + 1 ) , ( *lcp ) )
  ORIGINAL[2]: strchr((rcp + 1),( *lcp))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 + 1 ) , ( *lcp ) )
  ORIGINAL[3]: rcp + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: *lcp
  TYPE[4]: CALL
  TOKENIZED[4]: *lcp
  ORIGINAL[5]: rcp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064773089
FRAGMENT_COUNT: 6
  ORIGINAL[0]: src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dst -> nelem = src -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3 -> VAR2
  ORIGINAL[2]: dst -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: src -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: nelem
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: src
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640705
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640619
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480137
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773141
FRAGMENT_COUNT: 12
  ORIGINAL[0]: s -> alloc <= count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 + 1
  ORIGINAL[1]: !s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: !s -> VAR1
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: s -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: *s -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: *s -> VAR1
  ORIGINAL[6]: s -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: elems
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719476826
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( int )
  ORIGINAL[1]: int
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: int

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sbit[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: setbit(i,letters)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640883
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cp = lookin
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: ( *cp) != '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: ( *cp ) != '\\0'
  ORIGINAL[2]: ++cp
  TYPE[2]: CALL
  TOKENIZED[2]: ++cp
  ORIGINAL[3]: for (cp = lookin;( *cp) != '\\0';++cp)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = VAR2 ; ( *cp ) != '\\0' ; ++cp )

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640345
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640539
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477841
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfa -> tokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: tokens
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719478302
FRAGMENT_COUNT: 7
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: (s -> elems[j] . constraint >> 2 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[3]: separate_contexts |= 4
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 |= 4
  ORIGINAL[4]: s -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771187
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: charclass
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640924
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772979
FRAGMENT_COUNT: 7
  ORIGINAL[0]: tok == QMARK || tok == STAR || tok == PLUS || tok == REPMN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[1]: tok == QMARK || tok == STAR || tok == PLUS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[2]: tok == REPMN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: tok == REPMN
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == VAR2
  ORIGINAL[4]: tok == REPMN
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: <global> tok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: REPMN
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479889
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sebastianite_paleoanthropus != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: tracepoint(stonesoup_trace, weakness_end)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: stonesoup_trace
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: weakness_end
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640761
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773028
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: branch()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

