# Tokenized code fragments for 152231-v1.0.0-bad
# Total center nodes processed: 31
# Total code fragments found: 131

CENTER_NODE: 68719476782
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771671
FRAGMENT_COUNT: 5
  ORIGINAL[0]: close(file -> fd)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fd
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: file
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640256
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ss_tc_root != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2

CENTER_NODE: 47244640311
FRAGMENT_COUNT: 1
  ORIGINAL[0]: state -> compression == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0

CENTER_NODE: 30064771505
FRAGMENT_COUNT: 4
  ORIGINAL[0]: file_seek(file,delta,1,err)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 1 , VAR3 )
  ORIGINAL[1]: file
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: delta
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: err
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771644
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file -> eof && file -> avail_in == 0 && file -> have == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0 && VAR1 -> VAR4 == 0
  ORIGINAL[1]: file -> eof && file -> avail_in == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0
  ORIGINAL[2]: file -> have == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 68719477038
FRAGMENT_COUNT: 5
  ORIGINAL[0]: fstat(stream -> fd,statb) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR3 ) == - 1
  ORIGINAL[1]: err != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: err
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: err
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477085
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ret < 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 1
  ORIGINAL[1]: buf[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ]
  ORIGINAL[2]: buf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771444
FRAGMENT_COUNT: 9
  ORIGINAL[0]: here = fast_seek_find(file,file -> pos + offset)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR2 -> VAR3 + VAR4 )
  ORIGINAL[1]: offset < 0 || offset > 1048576L || here -> compression == 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 0 || VAR1 > 1048576L || VAR2 -> VAR3 == 1
  ORIGINAL[2]: offset < 0 || offset > 1048576L
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < 0 || VAR1 > 1048576L
  ORIGINAL[3]: offset < 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 < 0
  ORIGINAL[4]: offset > 1048576L
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 > 1048576L
  ORIGINAL[5]: here -> compression == 1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 == 1
  ORIGINAL[6]: here -> compression
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: compression
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: here
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !item
  TYPE[0]: CALL
  TOKENIZED[0]: !item
  ORIGINAL[1]: item -> out < out_pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 < VAR3
  ORIGINAL[2]: item -> out
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: out
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: item
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: item
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: out_pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 1
  ORIGINAL[0]: fill_in_buffer(state) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) == - 1

CENTER_NODE: 68719477046
FRAGMENT_COUNT: 6
  ORIGINAL[0]: file -> seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: gz_skip(file,file -> skip) == - 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR1 -> VAR2 ) == - 1
  ORIGINAL[2]: got = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: got
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: got
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: got
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477143
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stream -> err
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: stream -> err_info = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[2]: stream -> err_info
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: stream -> eof
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: eof
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stream
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477033
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream -> pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: stream -> seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: seek
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771186
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 68719477157
FRAGMENT_COUNT: 9
  ORIGINAL[0]: file -> fd
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> out
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file -> in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file -> fast_seek_cur
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: file -> err = 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 = 0
  ORIGINAL[5]: file -> err
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: file -> err_info
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: err_info
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: file
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771135
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *extension != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: *extension != ( ( void * ) 0 )
  ORIGINAL[1]: *extension
  TYPE[1]: CALL
  TOKENIZED[1]: *extension
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: *extension
  TYPE[3]: CALL
  TOKENIZED[3]: *extension
  ORIGINAL[4]: extension
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: extension
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477169
FRAGMENT_COUNT: 4
  ORIGINAL[0]: n = (((gint64 )(file -> have)) > offset?((unsigned int )offset) : file -> have)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( ( VAR2 ) ( VAR3 -> VAR4 ) ) > offset? ( ( unsigned int ) VAR5 ) : VAR3 -> VAR4 )
  ORIGINAL[1]: ((gint64 )(file -> have)) > offset?((unsigned int )offset) : file -> have
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) ( VAR2 -> VAR3 ) ) > offset? ( ( unsigned int ) VAR4 ) : VAR2 -> VAR3
  ORIGINAL[2]: n
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: gint64
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477035
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> raw_pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: raw_pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771187
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 68719476963
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> fast_seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: fast_seek
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771523
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> is_compressed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: is_compressed
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771400
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ft == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 68719477132
FRAGMENT_COUNT: 7
  ORIGINAL[0]: buf == str
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: left && eol == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 && VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: buf[0] = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ] = 0
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: left
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477148
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fd
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771658
FRAGMENT_COUNT: 5
  ORIGINAL[0]: fh -> err != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != 0
  ORIGINAL[1]: fh -> err_info == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: fh -> err_info
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 12
  ORIGINAL[0]: state -> eof == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: raw_read(state,state -> in,state -> size,((unsigned int *)(&state -> avail_in))) == - 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , ( ( unsigned int * ) ( &state -> VAR4 ) ) ) == - 1
  ORIGINAL[2]: raw_read(state,state -> in,state -> size,((unsigned int *)(&state -> avail_in)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , ( ( unsigned int * ) ( &state -> VAR4 ) ) )
  ORIGINAL[3]: - 1
  TYPE[3]: CALL
  TOKENIZED[3]: - 1
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1
  ORIGINAL[5]: state -> next_in = state -> in
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[6]: state -> next_in
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: state -> in
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: next_in
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: in
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: state
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: state
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771317
FRAGMENT_COUNT: 3
  ORIGINAL[0]: state -> pos = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: state -> pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476804
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *have = 0
  TYPE[0]: CALL
  TOKENIZED[0]: *have = 0
  ORIGINAL[1]: ret = (read(state -> fd,(buf +  *have),(count -  *have)))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 -> VAR3 , ( VAR4 + *have ) , ( VAR5 - *have ) ) )
  ORIGINAL[2]: read(state -> fd,(buf +  *have),(count -  *have))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , ( VAR3 + *have ) , ( VAR4 - *have ) )
  ORIGINAL[3]: *have < count
  TYPE[3]: CALL
  TOKENIZED[3]: *have < VAR1
  ORIGINAL[4]: ret
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ret
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

