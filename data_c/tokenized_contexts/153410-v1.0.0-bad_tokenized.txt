# Tokenized code fragments for 153410-v1.0.0-bad
# Total center nodes processed: 141
# Total code fragments found: 383

CENTER_NODE: 68719479734
FRAGMENT_COUNT: 9
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: i + 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + 2
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: cpp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640588
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479164
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < work_mbc -> nequivs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478271
FRAGMENT_COUNT: 12
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[3]: ++j
  TYPE[3]: CALL
  TOKENIZED[3]: ++j
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: j
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: j
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: j
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: j
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: j
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064772151
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: backslash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773615
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (s -> elems[j] . constraint >> 1 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[1]: separate_contexts |= 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 2
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: separate_contexts
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479657
FRAGMENT_COUNT: 10
  ORIGINAL[0]: dm = ndm
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: dm -> next
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dm -> must
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: free(dm)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: dm
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dm
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ndm
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dm
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: dm
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: dm
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774861
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_DONE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640586
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640414
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640708
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479680
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771151
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640926
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771167
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b % (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640618
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640746
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640750
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775615
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: !1
  TYPE[1]: CALL
  TOKENIZED[1]: !1
  ORIGINAL[2]: !using_utf8()
  TYPE[2]: CALL
  TOKENIZED[2]: !using_utf8 ( )
  ORIGINAL[3]: i = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 0
  ORIGINAL[4]: i < d -> tindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < VAR2 -> VAR3
  ORIGINAL[5]: d -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: tindex
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064775857
FRAGMENT_COUNT: 4
  ORIGINAL[0]: left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: right == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: right
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775894
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> left[0] = mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = VAR1 -> VAR4 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> left[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = '\\0'
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640337
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774895
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mbclen = (mblen_buf[idx] == 0?1 : mblen_buf[idx])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( VAR2 [ VAR3 ] == 0?1 : VAR2 [ VAR3 ] )
  ORIGINAL[1]: mblen_buf[idx] == 0?1 : mblen_buf[idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] == 0?1 : VAR1 [ VAR2 ]
  ORIGINAL[2]: mbclen
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771173
FRAGMENT_COUNT: 4
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776348
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 68719479759
FRAGMENT_COUNT: 7
  ORIGINAL[0]: rcp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: lcp[i] != '\\0' && lcp[i] == rcp[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != '\\0' && VAR1 [ VAR2 ] == VAR3 [ VAR2 ]
  ORIGINAL[2]: lcp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lcp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640866
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773513
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9
  ORIGINAL[1]: s -> elems[i] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: s -> elems[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: index
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775497
FRAGMENT_COUNT: 3
  ORIGINAL[0]: free((d -> multibyte_prop))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[1]: d -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773069
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) )
  ORIGINAL[2]: dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: sizeof(( *dst -> elems))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *dst -> VAR1 ) )
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: dst
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new_n_alloc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771160
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 8 * sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: 8 * sizeof ( int )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479495
FRAGMENT_COUNT: 14
  ORIGINAL[0]: d -> success[s] & sbit[ *p]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] & VAR4 [ *p ]
  ORIGINAL[1]: *backref = d -> states[s] . backref != 0
  TYPE[1]: CALL
  TOKENIZED[1]: *backref = VAR1 -> VAR2 [ VAR3 ] . VAR4 != 0
  ORIGINAL[2]: *backref
  TYPE[2]: CALL
  TOKENIZED[2]: *backref
  ORIGINAL[3]: d -> states[s] . backref != 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 != 0
  ORIGINAL[4]: d -> states[s] . backref
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: d -> states[s]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: d -> states
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: states
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: backref
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: backref
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: backref
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: s
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 68719476793
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640596
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772865
FRAGMENT_COUNT: 4
  ORIGINAL[0]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0 || work_mbc -> ncoll_elems != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0 || VAR1 -> VAR8 != 0
  ORIGINAL[1]: (dfa -> nmbcsets - 1 << 2) + 3
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 - 1 << 2 ) + 3
  ORIGINAL[2]: dfa -> nmbcsets - 1 << 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 - 1 << 2
  ORIGINAL[3]: dfa -> nmbcsets - 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 - 1

CENTER_NODE: 30064773407
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++j
  TYPE[1]: CALL
  TOKENIZED[1]: ++j
  ORIGINAL[2]: for (j = 0;j < s -> nelem;++j)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640392
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775179
FRAGMENT_COUNT: 11
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: work_mbls[i] ==  *mbclen
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] == *mbclen
  ORIGINAL[2]: work_mbls[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: *mbclen
  TYPE[3]: CALL
  TOKENIZED[3]: *mbclen
  ORIGINAL[4]: work_mbls
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: work_mbls
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: work_mbls
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: mbclen
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: work_mbls
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: work_mbls
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064776233
FRAGMENT_COUNT: 9
  ORIGINAL[0]: lmp -> is
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: lmp -> is[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: lmp -> right == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[3]: lmp -> is[0]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[4]: lmp -> is
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: lmp -> is
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: is
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: lmp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: lmp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719479789
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: old = enlist(old,new[i],strlen(new[i]))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[2]: enlist(old,new[i],strlen(new[i]))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[3]: old
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719480149
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640704
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477849
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: tindex - 1 - ntoks1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1 - VAR2
  ORIGINAL[2]: tindex - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: ntoks1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ntoks1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775629
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfainit(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775720
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: strncmp(cp,lookfor,len)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lookfor
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640435
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sbit[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: setbit(i,newline)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640620
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478022
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s1 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s2 -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: s2 -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nelem
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774768
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> fails
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *d -> fails
  TYPE[1]: CALL
  TOKENIZED[1]: *d -> VAR1
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: fails
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479666
FRAGMENT_COUNT: 6
  ORIGINAL[0]: oldsize = old == ((void *)0)?0 : strlen(old)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR2 )
  ORIGINAL[1]: newsize = new == ((void *)0)?0 : strlen(new)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR2 )
  ORIGINAL[2]: new == ((void *)0)?0 : strlen(new)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[3]: newsize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: newsize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776334
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 3
  ORIGINAL[0]: MBCSET=273
  TYPE[0]: CALL
  TOKENIZED[0]: MBCSET=273
  ORIGINAL[1]: MBCSET
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: WCHAR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640394
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774853
FRAGMENT_COUNT: 6
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> trans[oldalloc] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] = ( ( void * ) 0 )
  ORIGINAL[2]: d -> trans[oldalloc]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: d -> trans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: oldalloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477914
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: closure()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: addtok(CAT)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: CAT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640869
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480158
FRAGMENT_COUNT: 2
  ORIGINAL[0]: {(\
  TYPE[0]: CALL
  TOKENIZED[0]: { ( \
  ORIGINAL[1]: isalnum
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640700
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !intersectf
  TYPE[0]: CALL
  TOKENIZED[0]: !intersectf

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640895
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776336
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772901
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6
  ORIGINAL[2]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[3]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[4]: tok == ENDLINE
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: tok == BEGWORD
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: BEGWORD
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477144
FRAGMENT_COUNT: 7
  ORIGINAL[0]: equivs_al <= work_mbc -> nequivs + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= VAR2 -> VAR3 + 1
  ORIGINAL[1]: &new_n_alloc
  TYPE[1]: CALL
  TOKENIZED[1]: &new_n_alloc
  ORIGINAL[2]: equivs_al = new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: new_n_alloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_n_alloc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: equivs_al
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_n_alloc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640975
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476834
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640540
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775594
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> multibyte_prop)) == 1?xmalloc(d -> nmultibyte_prop) : xnmalloc(d -> nmultibyte_prop,sizeof(( *d -> multibyte_prop)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *d -> multibyte_prop)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xnmalloc(d -> nmultibyte_prop,sizeof(( *d -> multibyte_prop)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[3]: d -> nmultibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: sizeof(( *d -> multibyte_prop))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *d -> VAR1 ) )

CENTER_NODE: 30064772773
FRAGMENT_COUNT: 10
  ORIGINAL[0]: dfa -> nmultibyte_prop <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: x2nrealloc((dfa -> multibyte_prop),&new_n_alloc,sizeof(( *dfa -> multibyte_prop)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) )
  ORIGINAL[2]: dfa -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: sizeof(( *dfa -> multibyte_prop))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *dfa -> VAR1 ) )
  ORIGINAL[5]: &new_n_alloc
  TYPE[5]: CALL
  TOKENIZED[5]: &new_n_alloc
  ORIGINAL[6]: new_n_alloc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: new_n_alloc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new_n_alloc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640672
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476881
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == '_'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == '_'
  ORIGINAL[1]: iswalnum(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775115
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: for (i = 0;i < d -> states[s] . mbps . nelem;++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774878
FRAGMENT_COUNT: 14
  ORIGINAL[0]: (t = d -> trans[works]) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 [ VAR4 ] ) != ( ( void * ) 0 )
  ORIGINAL[1]: works < 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 0
  ORIGINAL[2]: p == buf_end
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: works = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 0
  ORIGINAL[4]: d -> fails[works]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: d -> fails
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: fails
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: rval
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: works
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> buf_end
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: works
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: works
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773101
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s -> nelem = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640648
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771301
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476845
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772956
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: __ctype_get_mb_cur_max() > 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ) > 1
  ORIGINAL[2]: dfa -> tokens[tindex + i] == MBCSET
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[3]: dfa -> tokens[tindex + i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[4]: MBCSET
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771196
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: s[i] = ~s[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[2]: s[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: ~s[i]
  TYPE[3]: CALL
  TOKENIZED[3]: ~s [ VAR1 ]
  ORIGINAL[4]: s[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> calloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> cindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> charclasses
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: dfa -> charclasses
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dfa -> charclasses
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: charclasses
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 47244640806
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477918
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: branch()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: addtok(OR)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478001
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s -> alloc <= count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 + 1
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: &new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: &new_n_alloc
  ORIGINAL[3]: new_n_alloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_n_alloc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477883
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok == REPMN && (minrep || maxrep)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[1]: tindex = dfa -> tindex - ntokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR1 - VAR3
  ORIGINAL[2]: maxrep < 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < 0
  ORIGINAL[3]: <global> maxrep
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> maxrep
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> maxrep
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 30064773040
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !syntax_bits_set
  TYPE[0]: CALL
  TOKENIZED[0]: !syntax_bits_set
  ORIGINAL[1]: dfaerror((gettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( FUN2 ( \
  ORIGINAL[2]: gettext(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771243
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )c]
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[1]: (int )c
  TYPE[1]: CALL
  TOKENIZED[1]: ( int ) VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640557
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064775241
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *pp
  TYPE[0]: CALL
  TOKENIZED[0]: *pp
  ORIGINAL[1]: rs == TRANSIT_STATE_DONE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: ++ *pp
  TYPE[2]: CALL
  TOKENIZED[2]: ++ *pp
  ORIGINAL[3]: *pp
  TYPE[3]: CALL
  TOKENIZED[3]: *pp
  ORIGINAL[4]: pp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774622
FRAGMENT_COUNT: 12
  ORIGINAL[0]: ( *d) . states[s] . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: ( *d) . states[s] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: ( *d) . states[s] . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: ( *d) . states[s] . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[4]: ( *d) . states[s] . constraint
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[5]: ( *d) . states[s] . constraint
  TYPE[5]: CALL
  TOKENIZED[5]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[6]: 1 & 1
  TYPE[6]: CALL
  TOKENIZED[6]: 1 & 1
  ORIGINAL[7]: ( *d) . states[s] . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[8]: ( *d) . states[s]
  TYPE[8]: CALL
  TOKENIZED[8]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[9]: ( *d) . states
  TYPE[9]: CALL
  TOKENIZED[9]: ( *d ) . VAR1
  ORIGINAL[10]: constraint
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773932
FRAGMENT_COUNT: 13
  ORIGINAL[0]: d -> salloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: sizeof(( *d -> states)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xmalloc((d -> salloc))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[3]: d -> salloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> salloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: salloc
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640384
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478078
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: p . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: index
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640538
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771101
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stat(dirpath, &st) == -1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[1]: retval = mkdir(dirpath, 0700)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[2]: mkdir(dirpath, 0700)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[3]: retval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640830
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771270
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: wc = btowc(b)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[2]: btowc(b)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640884
FRAGMENT_COUNT: 1
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )

