# Tokenized code fragments for 152904-v1.0.0-bad
# Total center nodes processed: 148
# Total code fragments found: 481

CENTER_NODE: 47244640444
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771306
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640602
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640904
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476849
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640605
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476860
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: s2
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640547
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477929
FRAGMENT_COUNT: 6
  ORIGINAL[0]: branch()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: tok == OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: addtok(OR)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> tok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 68719479703
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: strncmp(cp,lookfor,len)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lookfor
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479368
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *pp - p1 < maxlen
  TYPE[0]: CALL
  TOKENIZED[0]: *pp - VAR1 < VAR2
  ORIGINAL[1]: transit_state_consume_1char(d,s1,pp,((void *)0),&mbclen,&follows)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , ( ( void * ) 0 ) , &mbclen , &follows )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064774869
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_DONE
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640325
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476891
FRAGMENT_COUNT: 5
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: (wchar_t )eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771164
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] & 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] & 1 << VAR2 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: 1 << b % (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[3]: b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 30064771252
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum) || c == '_'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) || VAR1 == '_'
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum)
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[2]: c == '_'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == '_'
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640306
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478940
FRAGMENT_COUNT: 8
  ORIGINAL[0]: (((1 & 1?( *d) . states[s] . constraint & 0xf : 0)) | ((1 & 2?( *d) . states[s] . constraint >> 4 & 0xf : 0)) | ((1 & 4?( *d) . states[s] . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( 1 & 1? ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf : 0 ) ) | ( ( 1 & 2? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf : 0 ) ) | ( ( 1 & 4? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf : 0 ) ) ) & VAR4 -> VAR1 [ VAR2 ] . VAR5
  ORIGINAL[1]: d -> success[s] |= 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] |= 1
  ORIGINAL[2]: trans = ((sizeof(( *trans)) == 1?xmalloc((1 << 8)) : xnmalloc((1 << 8),sizeof(( *trans)))))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( ( sizeof ( ( *trans ) ) == 1?xmalloc ( ( 1 << 8 ) ) : FUN1 ( ( 1 << 8 ) , sizeof ( ( *trans ) ) ) ) )
  ORIGINAL[3]: sizeof(( *trans)) == 1?xmalloc((1 << 8)) : xnmalloc((1 << 8),sizeof(( *trans)))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *trans ) ) == 1?xmalloc ( ( 1 << 8 ) ) : FUN1 ( ( 1 << 8 ) , sizeof ( ( *trans ) ) )
  ORIGINAL[4]: trans
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: trans
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: trans
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: trans
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640755
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478292
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: letters[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> letters
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775745
FRAGMENT_COUNT: 18
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (new = icpyalloc(new)) == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 = FUN1 ( VAR1 ) ) == ( ( void * ) 0 )
  ORIGINAL[2]: new = icpyalloc(new)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR1 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: freelist(cpp)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: new[len] = '\\0'
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ] = '\\0'
  ORIGINAL[7]: new[len]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 [ VAR2 ]
  ORIGINAL[8]: i = 0
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 = 0
  ORIGINAL[9]: cpp[i] != ((void *)0)
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[10]: cpp[i]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 [ VAR2 ]
  ORIGINAL[11]: (void *)0
  TYPE[11]: CALL
  TOKENIZED[11]: ( void * ) 0
  ORIGINAL[12]: cpp
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: new
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: len
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: cpp
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: i
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 30064775801
FRAGMENT_COUNT: 4
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: malloc(sizeof(( *cpp)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( ( *cpp ) ) )
  ORIGINAL[2]: sizeof(( *cpp))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *cpp ) )
  ORIGINAL[3]: *cpp
  TYPE[3]: CALL
  TOKENIZED[3]: *cpp

CENTER_NODE: 30064776272
FRAGMENT_COUNT: 9
  ORIGINAL[0]: mp[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: i <= d -> tindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= VAR2 -> VAR3
  ORIGINAL[2]: mp[i] . in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: mp[i] . in
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[4]: mp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: in
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: mp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: mp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640713
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772796
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> tindex + 1 + (!dfa -> tokens)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 + 1 + ( !dfa -> VAR3 )
  ORIGINAL[2]: dfa -> tindex + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1
  ORIGINAL[3]: dfa -> tindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064775193
FRAGMENT_COUNT: 6
  ORIGINAL[0]: work_mbls[i] ==  *mbclen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == *mbclen
  ORIGINAL[1]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[2]: d -> follows[d -> states[s] . mbps . elems[i] . index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ]
  ORIGINAL[3]: d -> states[s] . mbps . elems[i] . index
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ] . VAR7
  ORIGINAL[4]: d -> states[s] . mbps . elems[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ]
  ORIGINAL[5]: index
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775520
FRAGMENT_COUNT: 15
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: free((p -> ch_classes))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[2]: p -> ch_classes
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ch_classes
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: p
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064771527
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c1 == ':'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ':'
  ORIGINAL[1]: *pred = find_pred(class)
  TYPE[1]: CALL
  TOKENIZED[1]: *pred = FUN1 ( VAR1 )
  ORIGINAL[2]: find_pred(class)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: pred
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: class
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640840
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775703
FRAGMENT_COUNT: 3
  ORIGINAL[0]: old == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: old
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773220
FRAGMENT_COUNT: 7
  ORIGINAL[0]: s1 -> elems[i] . index > s2 -> elems[j] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[1]: s2 -> elems[j] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s2 -> elems[j] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: s2 -> elems[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: s2 -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: index
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479654
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> follows[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> follows
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640549
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477781
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: dfa -> mbcsets
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> nmbcsets
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nmbcsets
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640661
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640768
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640393
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640662
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476846
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775056
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < work_mbc -> nequivs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: strcoll(work_mbc -> equivs[i],buffer) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] , VAR4 ) == 0
  ORIGINAL[2]: strcoll(work_mbc -> equivs[i],buffer)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] , VAR4 )
  ORIGINAL[3]: work_mbc -> equivs[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: buffer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064776332
FRAGMENT_COUNT: 2
  ORIGINAL[0]: stonesoup_exit_flag = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: stonesoup_exit_flag
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064775891
FRAGMENT_COUNT: 4
  ORIGINAL[0]: right[rnum] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: temp == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771175
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )

CENTER_NODE: 47244640375
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640346
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775132
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[pos . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: rarray[i] = match_anychar(d,s,pos,idx)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[2]: rarray[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: match_anychar(d,s,pos,idx)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[4]: break;
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: break ;

CENTER_NODE: 47244640383
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640445
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640928
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640683
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774801
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(( *d -> newlines)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[1]: sizeof(( *d -> newlines))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[2]: *d -> newlines
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1

CENTER_NODE: 30064773387
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> states
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: *d -> states
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1
  ORIGINAL[3]: d -> states[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: states
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771075
FRAGMENT_COUNT: 2
  ORIGINAL[0]: va_end(argptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719479802
FRAGMENT_COUNT: 7
  ORIGINAL[0]: ++i
  TYPE[0]: CALL
  TOKENIZED[0]: ++i
  ORIGINAL[1]: old == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477881
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok == QMARK || tok == STAR || tok == PLUS || tok == REPMN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[1]: tok == QMARK
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: QMARK
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: QMARK
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: QMARK
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640403
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479081
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> fails[works]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: works = d -> fails[works][ *p]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 [ VAR1 ] [ *p ]
  ORIGINAL[2]: rval = TRANSIT_STATE_DONE
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: rval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: rval
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: TRANSIT_STATE_DONE
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640773
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479471
FRAGMENT_COUNT: 6
  ORIGINAL[0]: mblen_buf[p - buf_begin]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 - VAR3 ]
  ORIGINAL[1]: *backref = 1
  TYPE[1]: CALL
  TOKENIZED[1]: *backref = 1
  ORIGINAL[2]: free(mblen_buf)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: <global> mblen_buf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: backref
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> mblen_buf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 68719476811
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BACKREF=257
  TYPE[0]: CALL
  TOKENIZED[0]: BACKREF=257
  ORIGINAL[1]: BEGLINE=258
  TYPE[1]: CALL
  TOKENIZED[1]: BEGLINE=258
  ORIGINAL[2]: BEGLINE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640356
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: stonesoup_trace
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_point
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: function_found
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771182
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[3]: 1 << b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 30064773276
FRAGMENT_COUNT: 12
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: --s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: --s -> VAR1
  ORIGINAL[3]: s -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: i < s -> nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < VAR2 -> VAR3
  ORIGINAL[5]: s -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: nelem
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: nelem
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064774234
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !intersectf
  TYPE[0]: CALL
  TOKENIZED[0]: !intersectf
  ORIGINAL[1]: k < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( int )
  ORIGINAL[4]: int
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: int

CENTER_NODE: 30064775719
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640717
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640681
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476807
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771268
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: sbit[i] = char_context(i)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR2 )
  ORIGINAL[2]: sbit[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: char_context(i)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: <global> sbit
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064773083
FRAGMENT_COUNT: 11
  ORIGINAL[0]: dst -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *dst -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: *dst -> VAR1
  ORIGINAL[2]: memcpy((dst -> elems),(src -> elems),sizeof(dst -> elems[0]) * src -> nelem)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , sizeof ( VAR1 -> VAR2 [ 0 ] ) * VAR3 -> VAR4 )
  ORIGINAL[3]: dst -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: src -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sizeof(dst -> elems[0]) * src -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( VAR1 -> VAR2 [ 0 ] ) * VAR3 -> VAR4
  ORIGINAL[6]: dst -> elems[0]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[7]: elems
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: dst
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: src
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: dst
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719477820
FRAGMENT_COUNT: 18
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok >= 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> tok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> tok
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> tok
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> tok
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> tok
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> tok
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> tok
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> tok
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> tok
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> tok
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> tok
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1
  ORIGINAL[17]: <global> tok
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: <global> VAR1

CENTER_NODE: 47244640336
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773103
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[1]: sizeof(( *s -> elems))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[2]: *s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: *s -> VAR1
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640567
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064776285
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640893
FRAGMENT_COUNT: 1
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )

CENTER_NODE: 30064776334
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064772701
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !backslash || syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: !backslash || VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: !backslash
  TYPE[1]: CALL
  TOKENIZED[1]: !backslash
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[4]: <global> syntax_bits
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640324
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640682
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477950
FRAGMENT_COUNT: 5
  ORIGINAL[0]: regexp()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: tok != END
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: END
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640775
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776335
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640878
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640411
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773544
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> tokens[old . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: p . constraint &= 0x050
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 &= 0x050
  ORIGINAL[2]: p . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: break;
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: break ;

CENTER_NODE: 47244640762
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640660
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 1
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122

CENTER_NODE: 47244640977
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640595
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640426
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773786
FRAGMENT_COUNT: 5
  ORIGINAL[0]: nullable[- 2]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ - 2 ]
  ORIGINAL[1]: nfirstpos[- 2] += nfirstpos[- 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ - 2 ] += VAR1 [ - 1 ]
  ORIGINAL[2]: nfirstpos[- 2]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ - 2 ]
  ORIGINAL[3]: nfirstpos[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 1 ]
  ORIGINAL[4]: nfirstpos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480113
FRAGMENT_COUNT: 5
  ORIGINAL[0]: kersmash_sailorproof != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: stonesoup_oc_i < stonesoup_buffer_len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: stonesoup_buffer_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_oc_i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_buffer_len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478025
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i > lo
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2
  ORIGINAL[1]: s -> elems[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476882
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> calloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> calloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: dfa -> cindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dfa -> charclasses
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: charclasses
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1

CENTER_NODE: 47244640886
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476848
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476757
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data_size = mg_get_var(conn, \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[1]: data_size < buffer_size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: data_size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: buffer_size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640815
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640774
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640841
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719479842
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> left[0] = mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = VAR1 -> VAR4 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: in
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640423
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640579
FRAGMENT_COUNT: 1
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5

CENTER_NODE: 30064775631
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> tokens[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> tokens
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tokens
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640629
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640879
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719479634
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaoptimize(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaanalyze(d,searchflag)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: searchflag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480093
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(struct dfa )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( struct VAR1 )
  ORIGINAL[1]: struct dfa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: struct VAR1

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774812
FRAGMENT_COUNT: 91
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: oldalloc = d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: new_state >= d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> realtrans = (xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans))))
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[7]: d -> realtrans
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans)))
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[9]: d -> realtrans
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: d -> tralloc + 1
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 + 1
  ORIGINAL[11]: d -> tralloc
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: sizeof(( *d -> realtrans))
  TYPE[12]: CALL
  TOKENIZED[12]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[13]: *d -> realtrans
  TYPE[13]: CALL
  TOKENIZED[13]: *d -> VAR1
  ORIGINAL[14]: d -> realtrans
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: d -> trans = d -> realtrans + 1
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 = VAR1 -> VAR3 + 1
  ORIGINAL[16]: d -> trans
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: d -> realtrans + 1
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2 + 1
  ORIGINAL[18]: d -> realtrans
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2
  ORIGINAL[19]: d -> fails = (xnrealloc((d -> fails),(d -> tralloc),sizeof(( *d -> fails))))
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[20]: d -> fails
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 -> VAR2
  ORIGINAL[21]: xnrealloc((d -> fails),(d -> tralloc),sizeof(( *d -> fails)))
  TYPE[21]: CALL
  TOKENIZED[21]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[22]: d -> fails
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 -> VAR2
  ORIGINAL[23]: d -> tralloc
  TYPE[23]: CALL
  TOKENIZED[23]: VAR1 -> VAR2
  ORIGINAL[24]: sizeof(( *d -> fails))
  TYPE[24]: CALL
  TOKENIZED[24]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[25]: *d -> fails
  TYPE[25]: CALL
  TOKENIZED[25]: *d -> VAR1
  ORIGINAL[26]: d -> fails
  TYPE[26]: CALL
  TOKENIZED[26]: VAR1 -> VAR2
  ORIGINAL[27]: d -> success = (xnrealloc((d -> success),(d -> tralloc),sizeof(( *d -> success))))
  TYPE[27]: CALL
  TOKENIZED[27]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[28]: d -> success
  TYPE[28]: CALL
  TOKENIZED[28]: VAR1 -> VAR2
  ORIGINAL[29]: xnrealloc((d -> success),(d -> tralloc),sizeof(( *d -> success)))
  TYPE[29]: CALL
  TOKENIZED[29]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[30]: d -> success
  TYPE[30]: CALL
  TOKENIZED[30]: VAR1 -> VAR2
  ORIGINAL[31]: d -> tralloc
  TYPE[31]: CALL
  TOKENIZED[31]: VAR1 -> VAR2
  ORIGINAL[32]: sizeof(( *d -> success))
  TYPE[32]: CALL
  TOKENIZED[32]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[33]: *d -> success
  TYPE[33]: CALL
  TOKENIZED[33]: *d -> VAR1
  ORIGINAL[34]: d -> success
  TYPE[34]: CALL
  TOKENIZED[34]: VAR1 -> VAR2
  ORIGINAL[35]: d -> newlines = (xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines))))
  TYPE[35]: CALL
  TOKENIZED[35]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[36]: d -> newlines
  TYPE[36]: CALL
  TOKENIZED[36]: VAR1 -> VAR2
  ORIGINAL[37]: xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[37]: CALL
  TOKENIZED[37]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[38]: d -> newlines
  TYPE[38]: CALL
  TOKENIZED[38]: VAR1 -> VAR2
  ORIGINAL[39]: d -> tralloc
  TYPE[39]: CALL
  TOKENIZED[39]: VAR1 -> VAR2
  ORIGINAL[40]: sizeof(( *d -> newlines))
  TYPE[40]: CALL
  TOKENIZED[40]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[41]: *d -> newlines
  TYPE[41]: CALL
  TOKENIZED[41]: *d -> VAR1
  ORIGINAL[42]: d -> newlines
  TYPE[42]: CALL
  TOKENIZED[42]: VAR1 -> VAR2
  ORIGINAL[43]: oldalloc < d -> tralloc
  TYPE[43]: CALL
  TOKENIZED[43]: VAR1 < VAR2 -> VAR3
  ORIGINAL[44]: d -> tralloc
  TYPE[44]: CALL
  TOKENIZED[44]: VAR1 -> VAR2
  ORIGINAL[45]: tralloc
  TYPE[45]: FIELD_IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: tralloc
  TYPE[46]: FIELD_IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: realtrans
  TYPE[47]: FIELD_IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: realtrans
  TYPE[48]: FIELD_IDENTIFIER
  TOKENIZED[48]: VAR1
  ORIGINAL[49]: tralloc
  TYPE[49]: FIELD_IDENTIFIER
  TOKENIZED[49]: VAR1
  ORIGINAL[50]: realtrans
  TYPE[50]: FIELD_IDENTIFIER
  TOKENIZED[50]: VAR1
  ORIGINAL[51]: trans
  TYPE[51]: FIELD_IDENTIFIER
  TOKENIZED[51]: VAR1
  ORIGINAL[52]: realtrans
  TYPE[52]: FIELD_IDENTIFIER
  TOKENIZED[52]: VAR1
  ORIGINAL[53]: fails
  TYPE[53]: FIELD_IDENTIFIER
  TOKENIZED[53]: VAR1
  ORIGINAL[54]: fails
  TYPE[54]: FIELD_IDENTIFIER
  TOKENIZED[54]: VAR1
  ORIGINAL[55]: tralloc
  TYPE[55]: FIELD_IDENTIFIER
  TOKENIZED[55]: VAR1
  ORIGINAL[56]: fails
  TYPE[56]: FIELD_IDENTIFIER
  TOKENIZED[56]: VAR1
  ORIGINAL[57]: success
  TYPE[57]: FIELD_IDENTIFIER
  TOKENIZED[57]: VAR1
  ORIGINAL[58]: success
  TYPE[58]: FIELD_IDENTIFIER
  TOKENIZED[58]: VAR1
  ORIGINAL[59]: tralloc
  TYPE[59]: FIELD_IDENTIFIER
  TOKENIZED[59]: VAR1
  ORIGINAL[60]: success
  TYPE[60]: FIELD_IDENTIFIER
  TOKENIZED[60]: VAR1
  ORIGINAL[61]: newlines
  TYPE[61]: FIELD_IDENTIFIER
  TOKENIZED[61]: VAR1
  ORIGINAL[62]: newlines
  TYPE[62]: FIELD_IDENTIFIER
  TOKENIZED[62]: VAR1
  ORIGINAL[63]: tralloc
  TYPE[63]: FIELD_IDENTIFIER
  TOKENIZED[63]: VAR1
  ORIGINAL[64]: newlines
  TYPE[64]: FIELD_IDENTIFIER
  TOKENIZED[64]: VAR1
  ORIGINAL[65]: tralloc
  TYPE[65]: FIELD_IDENTIFIER
  TOKENIZED[65]: VAR1
  ORIGINAL[66]: new_state
  TYPE[66]: IDENTIFIER
  TOKENIZED[66]: VAR1
  ORIGINAL[67]: oldalloc
  TYPE[67]: IDENTIFIER
  TOKENIZED[67]: VAR1
  ORIGINAL[68]: d
  TYPE[68]: IDENTIFIER
  TOKENIZED[68]: VAR1
  ORIGINAL[69]: new_state
  TYPE[69]: IDENTIFIER
  TOKENIZED[69]: VAR1
  ORIGINAL[70]: d
  TYPE[70]: IDENTIFIER
  TOKENIZED[70]: VAR1
  ORIGINAL[71]: d
  TYPE[71]: IDENTIFIER
  TOKENIZED[71]: VAR1
  ORIGINAL[72]: d
  TYPE[72]: IDENTIFIER
  TOKENIZED[72]: VAR1
  ORIGINAL[73]: d
  TYPE[73]: IDENTIFIER
  TOKENIZED[73]: VAR1
  ORIGINAL[74]: d
  TYPE[74]: IDENTIFIER
  TOKENIZED[74]: VAR1
  ORIGINAL[75]: d
  TYPE[75]: IDENTIFIER
  TOKENIZED[75]: VAR1
  ORIGINAL[76]: d
  TYPE[76]: IDENTIFIER
  TOKENIZED[76]: VAR1
  ORIGINAL[77]: d
  TYPE[77]: IDENTIFIER
  TOKENIZED[77]: VAR1
  ORIGINAL[78]: d
  TYPE[78]: IDENTIFIER
  TOKENIZED[78]: VAR1
  ORIGINAL[79]: d
  TYPE[79]: IDENTIFIER
  TOKENIZED[79]: VAR1
  ORIGINAL[80]: d
  TYPE[80]: IDENTIFIER
  TOKENIZED[80]: VAR1
  ORIGINAL[81]: d
  TYPE[81]: IDENTIFIER
  TOKENIZED[81]: VAR1
  ORIGINAL[82]: d
  TYPE[82]: IDENTIFIER
  TOKENIZED[82]: VAR1
  ORIGINAL[83]: d
  TYPE[83]: IDENTIFIER
  TOKENIZED[83]: VAR1
  ORIGINAL[84]: d
  TYPE[84]: IDENTIFIER
  TOKENIZED[84]: VAR1
  ORIGINAL[85]: d
  TYPE[85]: IDENTIFIER
  TOKENIZED[85]: VAR1
  ORIGINAL[86]: d
  TYPE[86]: IDENTIFIER
  TOKENIZED[86]: VAR1
  ORIGINAL[87]: d
  TYPE[87]: IDENTIFIER
  TOKENIZED[87]: VAR1
  ORIGINAL[88]: d
  TYPE[88]: IDENTIFIER
  TOKENIZED[88]: VAR1
  ORIGINAL[89]: oldalloc
  TYPE[89]: IDENTIFIER
  TOKENIZED[89]: VAR1
  ORIGINAL[90]: d
  TYPE[90]: IDENTIFIER
  TOKENIZED[90]: VAR1

CENTER_NODE: 47244640597
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477926
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640434
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640314
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773622
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (s -> elems[j] . constraint >> 1 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[1]: separate_contexts |= 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 2
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: separate_contexts
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479596
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *d
  TYPE[0]: CALL
  TOKENIZED[0]: *d
  ORIGINAL[1]: d -> calloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *d -> charclasses)) == 1
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[4]: d -> calloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> calloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: calloc
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640636
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640353
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476945
FRAGMENT_COUNT: 6
  ORIGINAL[0]: prednames[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: prednames[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> prednames
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640401
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774934
FRAGMENT_COUNT: 9
  ORIGINAL[0]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: wc == ((wchar_t )'\\0')
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) )
  ORIGINAL[4]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0))
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) )
  ORIGINAL[5]: context & 1?pos . constraint & 0xf : 0
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 & 1?pos . VAR2 & 0xf : 0
  ORIGINAL[6]: context & 2?pos . constraint >> 4 & 0xf : 0
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0
  ORIGINAL[7]: context & 4?pos . constraint >> 8 & 0xf : 0
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0
  ORIGINAL[8]: context
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640839
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 4
  ORIGINAL[0]: iswupper(wc)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: towupper(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772947
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 - 1 )
  ORIGINAL[2]: tindex - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771158
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640761
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 0

