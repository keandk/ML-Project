# Tokenized code fragments for 153067-v1.0.0-bad
# Total center nodes processed: 147
# Total code fragments found: 474

CENTER_NODE: 47244640872
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640602
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640812
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640313
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640408
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477361
FRAGMENT_COUNT: 7
  ORIGINAL[0]: cur_mb_len <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: wc1 = _wc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: c1 = wctob(wc1)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[3]: wctob(wc1)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: c1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: c1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479068
FRAGMENT_COUNT: 3
  ORIGINAL[0]: mblen_buf[idx]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: <global> mblen_buf
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: idx
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640400
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640544
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479775
FRAGMENT_COUNT: 9
  ORIGINAL[0]: old == ((void *)0) || new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: new[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: ++i
  TYPE[3]: CALL
  TOKENIZED[3]: ++i
  ORIGINAL[4]: new[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: old == ((void *)0)
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771116
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c - 32
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 32
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775130
FRAGMENT_COUNT: 6
  ORIGINAL[0]: mblen_buf[ *pp - buf_begin] == 0?1 : mblen_buf[ *pp - buf_begin]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ *pp - VAR2 ] == 0?1 : VAR1 [ *pp - VAR2 ]
  ORIGINAL[1]: mblen_buf[ *pp - buf_begin] == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ *pp - VAR2 ] == 0
  ORIGINAL[2]: mblen_buf[ *pp - buf_begin]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ *pp - VAR2 ]
  ORIGINAL[3]: mblen_buf[ *pp - buf_begin]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ *pp - VAR2 ]
  ORIGINAL[4]: *pp - buf_begin
  TYPE[4]: CALL
  TOKENIZED[4]: *pp - VAR1
  ORIGINAL[5]: <global> mblen_buf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 30064775698
FRAGMENT_COUNT: 5
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: oldsize + newsize + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2 + 1
  ORIGINAL[2]: oldsize + newsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: oldsize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: newsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478136
FRAGMENT_COUNT: 8
  ORIGINAL[0]: s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: i < d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: s -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &d -> states[i] . elems
  TYPE[4]: CALL
  TOKENIZED[4]: &d -> VAR1 [ VAR2 ] . VAR3
  ORIGINAL[5]: s -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: nelem
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773048
FRAGMENT_COUNT: 33
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: src -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: new_n_alloc = src -> nelem + (!dst -> elems)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2 -> VAR3 + ( !dst -> VAR4 )
  ORIGINAL[4]: src -> nelem + (!dst -> elems)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 + ( !dst -> VAR3 )
  ORIGINAL[5]: src -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: !dst -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: !dst -> VAR1
  ORIGINAL[7]: dst -> elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: dst -> elems = (x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems))))
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) ) )
  ORIGINAL[9]: dst -> elems
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems)))
  TYPE[10]: CALL
  TOKENIZED[10]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) )
  ORIGINAL[11]: dst -> elems
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: &new_n_alloc
  TYPE[12]: CALL
  TOKENIZED[12]: &new_n_alloc
  ORIGINAL[13]: sizeof(( *dst -> elems))
  TYPE[13]: CALL
  TOKENIZED[13]: sizeof ( ( *dst -> VAR1 ) )
  ORIGINAL[14]: *dst -> elems
  TYPE[14]: CALL
  TOKENIZED[14]: *dst -> VAR1
  ORIGINAL[15]: dst -> elems
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2
  ORIGINAL[16]: dst -> alloc = new_n_alloc
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2 = VAR3
  ORIGINAL[17]: dst -> alloc
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: nelem
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: elems
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: elems
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: elems
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: elems
  TYPE[22]: FIELD_IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: alloc
  TYPE[23]: FIELD_IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: new_n_alloc
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: src
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: dst
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: dst
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: dst
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: new_n_alloc
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: dst
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: dst
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: new_n_alloc
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773581
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (j = 0;j < s -> nelem;++j)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773004
FRAGMENT_COUNT: 10
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN && tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: tok >= 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0
  ORIGINAL[4]: closure()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )
  ORIGINAL[5]: addtok(CAT)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 )
  ORIGINAL[6]: while (tok != RPAREN && tok != OR && tok >= 0)
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: while ( VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0 )
  ORIGINAL[7]: <global> tok
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: RPAREN
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: CAT
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640974
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775521
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < p -> ncoll_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++j
  TYPE[1]: CALL
  TOKENIZED[1]: ++j
  ORIGINAL[2]: for (j = 0;j < p -> ncoll_elems;++j)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640343
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773563
FRAGMENT_COUNT: 3
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: (1 << 8) + 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[2]: 1 << 8
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << 8

CENTER_NODE: 68719479669
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775465
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: prepare_wc_buf(((const char *)p),end)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( const char * ) VAR1 ) , VAR2 )
  ORIGINAL[2]: (const char *)p
  TYPE[2]: CALL
  TOKENIZED[2]: ( const char * ) VAR1
  ORIGINAL[3]: end
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775707
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: *cp
  TYPE[1]: CALL
  TOKENIZED[1]: *cp
  ORIGINAL[2]: strncmp(cp,lookfor,len) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[3]: strncmp(cp,lookfor,len)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: for (cp = lookin;( *cp) != '\\0';++cp)
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: for ( VAR1 = VAR2 ; ( *cp ) != '\\0' ; ++cp )
  ORIGINAL[6]: cp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: lookfor
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: len
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772764
FRAGMENT_COUNT: 10
  ORIGINAL[0]: dfa -> nmultibyte_prop <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: x2nrealloc((dfa -> multibyte_prop),&new_n_alloc,sizeof(( *dfa -> multibyte_prop)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) )
  ORIGINAL[2]: dfa -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: sizeof(( *dfa -> multibyte_prop))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *dfa -> VAR1 ) )
  ORIGINAL[5]: &new_n_alloc
  TYPE[5]: CALL
  TOKENIZED[5]: &new_n_alloc
  ORIGINAL[6]: new_n_alloc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: new_n_alloc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new_n_alloc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771192
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773742
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: tmp . elems = firstpos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 = VAR3
  ORIGINAL[2]: tmp . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: firstpos
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773013
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: branch()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064776323
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640431
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771293
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640592
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774635
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (((1 & 1?( *d) . states[s] . constraint & 0xf : 0)) | ((1 & 2?( *d) . states[s] . constraint >> 4 & 0xf : 0)) | ((1 & 4?( *d) . states[s] . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( 1 & 1? ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf : 0 ) ) | ( ( 1 & 2? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf : 0 ) ) | ( ( 1 & 4? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf : 0 ) ) ) & VAR4 -> VAR1 [ VAR2 ] . VAR5
  ORIGINAL[1]: d -> success[s] |= 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] |= 1
  ORIGINAL[2]: d -> success[s]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: trans
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477925
FRAGMENT_COUNT: 5
  ORIGINAL[0]: regexp()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: tok != END
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: END
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640836
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640624
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775891
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> right[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> is[0] = '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[3]: mp -> is[0]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ]

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773484
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 )
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[2]: d -> tokens[s -> elems[i] . index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[3]: d -> tokens
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: tokens
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476786
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BACKREF=257
  TYPE[0]: CALL
  TOKENIZED[0]: BACKREF=257
  ORIGINAL[1]: BEGLINE=258
  TYPE[1]: CALL
  TOKENIZED[1]: BEGLINE=258
  ORIGINAL[2]: BEGLINE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775723
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479802
FRAGMENT_COUNT: 6
  ORIGINAL[0]: right[rnum] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: left[lnum]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: lnum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: lnum
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: left
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: lnum
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640441
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640398
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476771
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775094
FRAGMENT_COUNT: 9
  ORIGINAL[0]: sizeof(( *rarray)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *rarray ) ) == 1
  ORIGINAL[1]: xnmalloc(d -> states[s] . mbps . nelem,sizeof(( *rarray)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 , sizeof ( ( *rarray ) ) )
  ORIGINAL[2]: d -> states[s] . mbps . nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[3]: d -> states[s] . mbps
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: sizeof(( *rarray))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *rarray ) )
  ORIGINAL[5]: d -> states[s] . mbps . nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[6]: d -> states[s] . mbps
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[7]: nelem
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: rarray
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476769
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ev == MG_AUTH
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: MG_TRUE
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064774855
FRAGMENT_COUNT: 4
  ORIGINAL[0]: works = s
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: works
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640925
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776083
FRAGMENT_COUNT: 13
  ORIGINAL[0]: musts[0] . in[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 0 ] . VAR2 [ VAR3 ] != ( ( void * ) 0 )
  ORIGINAL[1]: strlen(musts[0] . in[i]) > strlen(result)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 [ 0 ] . VAR2 [ VAR3 ] ) > FUN1 ( VAR4 )
  ORIGINAL[2]: strlen(musts[0] . in[i])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 [ 0 ] . VAR2 [ VAR3 ] )
  ORIGINAL[3]: strlen(result)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: result = musts[0] . in[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2 [ 0 ] . VAR3 [ VAR4 ]
  ORIGINAL[5]: musts[0] . in[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ 0 ] . VAR2 [ VAR3 ]
  ORIGINAL[6]: musts[0] . in
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ 0 ] . VAR2
  ORIGINAL[7]: musts[0]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 [ 0 ]
  ORIGINAL[8]: in
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: result
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: musts
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: i
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640626
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773191
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s1 -> elems[i] . index > s2 -> elems[j] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[1]: m -> elems[m -> nelem++] = s1 -> elems[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> nelem++ ] = VAR3 -> VAR2 [ i++ ]
  ORIGINAL[2]: m -> elems[m -> nelem++]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> nelem++ ]
  ORIGINAL[3]: s1 -> elems[i++]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ i++ ]
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640499
FRAGMENT_COUNT: 2
  ORIGINAL[0]: minrep < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 30064771145
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771268
FRAGMENT_COUNT: 8
  ORIGINAL[0]: case_fold && iswalpha(wc)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && FUN1 ( VAR2 )
  ORIGINAL[1]: iswupper(wc)?towlower(wc) : towupper(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) ?towlower ( VAR1 ) : FUN2 ( VAR1 )
  ORIGINAL[2]: iswupper(wc)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: towlower(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: towupper(wc)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: wc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: wc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640633
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771239
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: (wchar_t )eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> eolbyte
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772969
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == REPMN && (minrep || maxrep)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[1]: tok == REPMN
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: minrep || maxrep
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 || VAR2
  ORIGINAL[3]: <global> minrep
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> maxrep
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 68719476916
FRAGMENT_COUNT: 6
  ORIGINAL[0]: prednames[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: strcmp(str,prednames[i] . name) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 [ VAR3 ] . VAR4 ) == 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> prednames
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640390
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: (1 << 8) + 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( int )

CENTER_NODE: 68719479728
FRAGMENT_COUNT: 10
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: cpp[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: *cpp
  TYPE[3]: CALL
  TOKENIZED[3]: *cpp
  ORIGINAL[4]: cpp[i] = new
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ] = VAR3
  ORIGINAL[5]: cpp[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: cpp[i + 1]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 + 1 ]
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: cpp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640901
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771142
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640710
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773110
FRAGMENT_COUNT: 15
  ORIGINAL[0]: lo < count && p . index == s -> elems[lo] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 . VAR4 == VAR5 -> VAR6 [ VAR1 ] . VAR4
  ORIGINAL[1]: lo < count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: p . index == s -> elems[lo] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2 == VAR3 -> VAR4 [ VAR5 ] . VAR2
  ORIGINAL[3]: p . index
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: s -> elems[lo] . index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: s -> elems[lo]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: s -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: index
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: elems
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: index
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: lo
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: count
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: s
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: lo
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 68719479607
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaparse(s,len,d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: dfamust(d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640355
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771226
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> eolbyte
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640756
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479124
FRAGMENT_COUNT: 9
  ORIGINAL[0]: work_mbc -> invert
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: wc < 1 << 8 && work_mbc -> cset != (- 1) && tstbit(((unsigned char )wc),d -> charclasses[work_mbc -> cset])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 1 << 8 && VAR2 -> VAR3 != ( - 1 ) && FUN1 ( ( ( unsigned char ) VAR1 ) , VAR4 -> VAR5 [ VAR2 -> VAR3 ] )
  ORIGINAL[2]: work_mbc -> cset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: work_mbc -> nch_classes
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: iswctype(((wint_t )wc),work_mbc -> ch_classes[i])
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( ( VAR1 ) VAR2 ) , VAR3 -> VAR4 [ VAR5 ] )
  ORIGINAL[5]: nch_classes
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: work_mbc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064775810
FRAGMENT_COUNT: 5
  ORIGINAL[0]: lcp[i] != '\\0' && lcp[i] == rcp[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != '\\0' && VAR1 [ VAR2 ] == VAR3 [ VAR2 ]
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: for (i = 1;lcp[i] != '\\0' && lcp[i] == rcp[i];++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 1 ; VAR2 [ VAR1 ] != '\\0' && VAR2 [ VAR1 ] == VAR3 [ VAR1 ] ; ++i )
  ORIGINAL[3]: lcp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772948
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dfa -> tokens[tindex + i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: __ctype_get_mb_cur_max() > 1
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ) > 1
  ORIGINAL[3]: dfa -> tokens[tindex + i] == MBCSET
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[4]: dfa -> tokens[tindex + i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[5]: dfa -> tokens
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: tindex + i
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 + VAR2
  ORIGINAL[7]: MBCSET
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476810
FRAGMENT_COUNT: 5
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476848
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> calloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> cindex + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1
  ORIGINAL[3]: dfa -> cindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: dfa -> charclasses
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dfa -> charclasses
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: charclasses
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 30064772894
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[2]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3
  ORIGINAL[3]: tok >= 0 && tok < (1 << 8) || tok >= CSET
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2
  ORIGINAL[4]: tok == BACKREF
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: tok == BEGLINE
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: BEGLINE
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064776293
FRAGMENT_COUNT: 7
  ORIGINAL[0]: stonesoup_buff != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: tracepoint(stonesoup_trace, variable_signed_integral, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: &stonesoup_opt_var
  TYPE[2]: CALL
  TOKENIZED[2]: &stonesoup_opt_var
  ORIGINAL[3]: stonesoup_trace
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: variable_signed_integral
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_opt_var
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_oc_i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064776321
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 68719479028
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_DONE=1
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_DONE=1
  ORIGINAL[2]: TRANSIT_STATE_DONE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771251
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: for (i = 0;i < (1 << 8);++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064776269
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640380
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640423
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771172
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064773092
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s -> nelem = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771073
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mg_vprintf_data((struct mg_connection*) stonesoup_printf_context, format, argptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( struct mg_connection* ) VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: (struct mg_connection*) stonesoup_printf_context
  TYPE[1]: CALL
  TOKENIZED[1]: ( struct mg_connection* ) VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: argptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: argptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640599
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479637
FRAGMENT_COUNT: 14
  ORIGINAL[0]: d -> charclasses
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> follows
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: i < (d -> tralloc)
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[8]: d -> tralloc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: free(d -> trans[i])
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] )
  ORIGINAL[10]: d -> fails
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: fails
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640311
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776267
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064774799
FRAGMENT_COUNT: 9
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: oldalloc = d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: tralloc
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: oldalloc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477835
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: tindex - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: tindex
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ntoks1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tindex
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772855
FRAGMENT_COUNT: 4
  ORIGINAL[0]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0 || work_mbc -> ncoll_elems != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0 || VAR1 -> VAR8 != 0
  ORIGINAL[1]: addtok_mb(MBCSET,((dfa -> nmbcsets - 1 << 2) + 3))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( VAR2 -> VAR3 - 1 << 2 ) + 3 ) )
  ORIGINAL[2]: (dfa -> nmbcsets - 1 << 2) + 3
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 -> VAR2 - 1 << 2 ) + 3
  ORIGINAL[3]: dfa -> nmbcsets - 1 << 2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 - 1 << 2

CENTER_NODE: 47244640364
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478817
FRAGMENT_COUNT: 5
  ORIGINAL[0]: separate_contexts & possible_contexts & 4
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & VAR2 & 4
  ORIGINAL[1]: state_newline = state
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: state_newline
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: state
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state_newline
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640563
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640714
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479596
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ++i
  TYPE[0]: CALL
  TOKENIZED[0]: ++i
  ORIGINAL[1]: d -> tokens[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771163
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640353
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476782
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640546
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775566
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> tokens)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[1]: xnmalloc(d -> talloc,sizeof(( *d -> tokens)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[2]: d -> talloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *d -> tokens))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[4]: *d -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: *d -> VAR1

CENTER_NODE: 30064773252
FRAGMENT_COUNT: 16
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: p . index == s -> elems[i] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2 == VAR3 -> VAR4 [ VAR5 ] . VAR2
  ORIGINAL[3]: p . index
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: s -> elems[i] . index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: s -> elems[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: s -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: for (i = 0;i < s -> nelem;++i)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[8]: index
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: elems
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: index
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: s
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 30064774772
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *d -> success))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[1]: *d -> success
  TYPE[1]: CALL
  TOKENIZED[1]: *d -> VAR1
  ORIGINAL[2]: d -> success
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> success
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640883
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640420
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775260
FRAGMENT_COUNT: 28
  ORIGINAL[0]: i < nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: match_lens[i] ==  *pp - p1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] == *pp - VAR3
  ORIGINAL[2]: match_lens[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: *pp - p1
  TYPE[3]: CALL
  TOKENIZED[3]: *pp - VAR1
  ORIGINAL[4]: j = 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = 0
  ORIGINAL[5]: j < d -> follows[d -> states[s1] . mbps . elems[i] . index] . nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[6]: d -> follows[d -> states[s1] . mbps . elems[i] . index] . nelem
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR9
  ORIGINAL[7]: d -> follows[d -> states[s1] . mbps . elems[i] . index]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ]
  ORIGINAL[8]: d -> follows
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: d -> states[s1] . mbps . elems[i] . index
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ] . VAR7
  ORIGINAL[10]: d -> states[s1] . mbps . elems[i]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ]
  ORIGINAL[11]: d -> states[s1] . mbps . elems
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[12]: d -> states[s1] . mbps
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[13]: d -> states[s1]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[14]: d -> states
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: follows
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: states
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: mbps
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: elems
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: index
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: nelem
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: i
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: j
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: j
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: d
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: d
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: s1
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: i
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 0

