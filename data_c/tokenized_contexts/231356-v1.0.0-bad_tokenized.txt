# Tokenized code fragments for 231356-v1.0.0-bad
# Total center nodes processed: 23
# Total code fragments found: 116

CENTER_NODE: 30064775294
FRAGMENT_COUNT: 7
  ORIGINAL[0]: { &hf_cookie,                                   { \
  TYPE[0]: CALL
  TOKENIZED[0]: { &hf_cookie , { \
  ORIGINAL[1]: { \
  TYPE[1]: CALL
  TOKENIZED[1]: { \
  ORIGINAL[2]: FT_BYTES
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: BASE_NONE
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: NULL
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: NULL
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: HFILL
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772625
FRAGMENT_COUNT: 5
  ORIGINAL[0]: msg->fragments
  TYPE[0]: CALL
  TOKENIZED[0]: msg->fragments
  ORIGINAL[1]: msg->fragments = msg->fragments->next
  TYPE[1]: CALL
  TOKENIZED[1]: msg->fragments = msg->fragments->next
  ORIGINAL[2]: msg->fragments
  TYPE[2]: CALL
  TOKENIZED[2]: msg->fragments
  ORIGINAL[3]: msg->fragments->next
  TYPE[3]: CALL
  TOKENIZED[3]: msg->fragments->next
  ORIGINAL[4]: fragment
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774289
FRAGMENT_COUNT: 3
  ORIGINAL[0]: HEARTBEAT_CHUNK_INFO_OFFSET
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: (0 + 1) + 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( 0 + 1 ) + 1
  ORIGINAL[2]: 0 + 1
  TYPE[2]: CALL
  TOKENIZED[2]: 0 + 1

CENTER_NODE: 30064772163
FRAGMENT_COUNT: 6
  ORIGINAL[0]: remaining_length = tvb_reported_length_remaining(parameters_tvb, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: MIN(total_length, tvb_length_remaining(parameters_tvb, offset))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , FUN2 ( VAR2 , VAR3 ) )
  ORIGINAL[2]: tvb_length_remaining(parameters_tvb, offset)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: total_length
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: parameters_tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: offset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771507
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !h || !h->peer
  TYPE[0]: CALL
  TOKENIZED[0]: !h || !h->peer
  ORIGINAL[1]: t = se_tree_lookup32(h->peer->tsns,reltsn)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( h->peer->tsns , VAR2 )
  ORIGINAL[2]: se_tree_lookup32(h->peer->tsns,reltsn)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( h->peer->tsns , VAR1 )
  ORIGINAL[3]: t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: t
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479321
FRAGMENT_COUNT: 7
  ORIGINAL[0]: chunk_length - CHUNK_HEADER_LENGTH
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2
  ORIGINAL[1]: tvb_reported_length_remaining(chunk_tvb, ERROR_CAUSE_IND_CAUSES_OFFSET)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: ERROR_CAUSE_IND_CAUSES_OFFSET
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk_tree
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk_tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk_tvb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chunk_tvb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771087
FRAGMENT_COUNT: 4
  ORIGINAL[0]: COMMON_HEADER_LENGTH
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: 2 + 2 + 4 + 4
  TYPE[1]: CALL
  TOKENIZED[1]: 2 + 2 + 4 + 4
  ORIGINAL[2]: 2 + 2 + 4
  TYPE[2]: CALL
  TOKENIZED[2]: 2 + 2 + 4
  ORIGINAL[3]: 2 + 2
  TYPE[3]: CALL
  TOKENIZED[3]: 2 + 2

CENTER_NODE: 68719479574
FRAGMENT_COUNT: 9
  ORIGINAL[0]: dissect_data_chunk(chunk_tvb, length, pinfo, tree, chunk_tree, chunk_item, flags_item, ha)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 , VAR6 , VAR7 , VAR8 )
  ORIGINAL[1]: length
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: length
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: type
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk_tvb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: length
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pinfo
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: length
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064775787
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data_handle = find_dissector(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( \
  ORIGINAL[1]: find_dissector(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: <global> data_handle
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: sctp_handle
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719478590
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dissect_payload(new_tvb, pinfo, tree, ppi)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: pinfo
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pinfo
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pinfo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tree
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719478009
FRAGMENT_COUNT: 7
  ORIGINAL[0]: next_fragment->tsn == tsn
  TYPE[0]: CALL
  TOKENIZED[0]: next_fragment->tsn == VAR1
  ORIGINAL[1]: next_fragment->tsn
  TYPE[1]: CALL
  TOKENIZED[1]: next_fragment->tsn
  ORIGINAL[2]: next_fragment->next
  TYPE[2]: CALL
  TOKENIZED[2]: next_fragment->next
  ORIGINAL[3]: next
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: next_fragment
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: next_fragment
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: next_fragment
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479279
FRAGMENT_COUNT: 7
  ORIGINAL[0]: HEARTBEAT_CHUNK_INFO_OFFSET
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: MIN(chunk_length - CHUNK_HEADER_LENGTH, tvb_length_remaining(chunk_tvb, HEARTBEAT_CHUNK_INFO_OFFSET))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 - VAR2 , FUN2 ( VAR3 , VAR4 ) )
  ORIGINAL[2]: MIN(chunk_length - CHUNK_HEADER_LENGTH, tvb_reported_length_remaining(chunk_tvb, HEARTBEAT_CHUNK_INFO_OFFSET))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 - VAR2 , FUN2 ( VAR3 , VAR4 ) )
  ORIGINAL[3]: chunk_tree
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: parameter_tvb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk_tvb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chunk_tvb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477957
FRAGMENT_COUNT: 8
  ORIGINAL[0]: key->sport
  TYPE[0]: CALL
  TOKENIZED[0]: key->sport
  ORIGINAL[1]: key->dport
  TYPE[1]: CALL
  TOKENIZED[1]: key->dport
  ORIGINAL[2]: key->verification_tag
  TYPE[2]: CALL
  TOKENIZED[2]: key->verification_tag
  ORIGINAL[3]: key->stream_id
  TYPE[3]: CALL
  TOKENIZED[3]: key->stream_id
  ORIGINAL[4]: key->stream_seq_num
  TYPE[4]: CALL
  TOKENIZED[4]: key->stream_seq_num
  ORIGINAL[5]: stream_seq_num
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064776376
FRAGMENT_COUNT: 1
  ORIGINAL[0]: sctp_data_chunk_i_bit_value
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064775780
FRAGMENT_COUNT: 2
  ORIGINAL[0]: register_heur_dissector_list(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: &sctp_heur_subdissector_list
  TYPE[1]: CALL
  TOKENIZED[1]: &sctp_heur_subdissector_list

CENTER_NODE: 30064775784
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dirs_by_ptvtag = se_tree_create(EMEM_TREE_TYPE_RED_BLACK, \
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[1]: se_tree_create(EMEM_TREE_TYPE_RED_BLACK, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: <global> dirs_by_ptvtag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: EMEM_TREE_TYPE_RED_BLACK
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772584
FRAGMENT_COUNT: 11
  ORIGINAL[0]: key1->sport == key2->sport
  TYPE[0]: CALL
  TOKENIZED[0]: key1->sport == key2->sport
  ORIGINAL[1]: key1->dport == key2->dport
  TYPE[1]: CALL
  TOKENIZED[1]: key1->dport == key2->dport
  ORIGINAL[2]: key1->dport
  TYPE[2]: CALL
  TOKENIZED[2]: key1->dport
  ORIGINAL[3]: key2->dport
  TYPE[3]: CALL
  TOKENIZED[3]: key2->dport
  ORIGINAL[4]: dport
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key2
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: key1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: key1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064776389
FRAGMENT_COUNT: 1
  ORIGINAL[0]: sctp_chunk_bit_2_value
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 68719481171
FRAGMENT_COUNT: 1
  ORIGINAL[0]: sctp_shutdown_complete_chunk_t_bit_value
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064771631
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i <= rel_end-rel_start
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= rel_end-rel_start
  ORIGINAL[1]: rel_tsn = (guint32) (i+rel_start)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( VAR2 ) ( i+rel_start )
  ORIGINAL[2]: (guint32) (i+rel_start)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) ( i+rel_start )
  ORIGINAL[3]: rel_tsn
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pinfo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064776382
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sctp_pktdropk_b_bit_value
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: sctp_pktdropk_t_bit_value
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771101
FRAGMENT_COUNT: 3
  ORIGINAL[0]: SOURCE_PORT_LENGTH + DESTINATION_PORT_LENGTH + VERIFICATION_TAG_LENGTH
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 + VAR3
  ORIGINAL[1]: SOURCE_PORT_LENGTH + DESTINATION_PORT_LENGTH
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: VERIFICATION_TAG_LENGTH
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477867
FRAGMENT_COUNT: 7
  ORIGINAL[0]: remaining_length = tvb_reported_length_remaining(causes_tvb, offset)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: length       = tvb_get_ntohs(causes_tvb, offset + CAUSE_LENGTH_OFFSET)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 + VAR4 )
  ORIGINAL[2]: total_length = ADD_PADDING(length)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[3]: ADD_PADDING(length)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: total_length
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: length
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: total_length
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

