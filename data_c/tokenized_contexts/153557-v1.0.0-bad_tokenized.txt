# Tokenized code fragments for 153557-v1.0.0-bad
# Total center nodes processed: 27
# Total code fragments found: 234

CENTER_NODE: 68719476825
FRAGMENT_COUNT: 6
  ORIGINAL[0]: fct_ptr_addr = (stonesoup_fct_ptr )0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( VAR2 ) 0
  ORIGINAL[1]: var_len = strlen(param) % 3
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) % 3
  ORIGINAL[2]: strlen(param) % 3
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) % 3
  ORIGINAL[3]: var_len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: param
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: var_len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771082
FRAGMENT_COUNT: 22
  ORIGINAL[0]: ss_tc_root != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: size_dirpath = strlen(ss_tc_root) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: strlen(ss_tc_root) + strlen(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[3]: strlen(ss_tc_root) + strlen(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[4]: strlen(ss_tc_root)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: strlen(\
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( \
  ORIGINAL[6]: dirpath = (char*) malloc (size_dirpath * sizeof(char))
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[7]: (char*) malloc (size_dirpath * sizeof(char))
  TYPE[7]: CALL
  TOKENIZED[7]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[8]: malloc (size_dirpath * sizeof(char))
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[9]: size_dirpath * sizeof(char)
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 * sizeof ( char )
  ORIGINAL[10]: sizeof(char)
  TYPE[10]: CALL
  TOKENIZED[10]: sizeof ( char )
  ORIGINAL[11]: dirpath != NULL
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 != VAR2
  ORIGINAL[12]: ss_tc_root
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: NULL
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: size_dirpath
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: ss_tc_root
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: dirpath
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: size_dirpath
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: char
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: char
  ORIGINAL[19]: dirpath
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: NULL
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: <global> stonesoup_printf_context
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: <global> VAR1

CENTER_NODE: 68719477035
FRAGMENT_COUNT: 3
  ORIGINAL[0]: schuit_shovelbill = {0}
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = { 0 }
  ORIGINAL[1]: *pratfalls_chipling = 0
  TYPE[1]: CALL
  TOKENIZED[1]: *pratfalls_chipling = 0
  ORIGINAL[2]: pratfalls_chipling
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477588
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pinfo -> src
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: pinfo -> dst
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pinfo -> srcport
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pinfo -> destport
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: destport
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pinfo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772238
FRAGMENT_COUNT: 15
  ORIGINAL[0]: conversation != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: conversation -> dissector_handle == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: conversation -> dissector_handle
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: ret = call_dissector_only(conversation -> dissector_handle,tvb,pinfo,tree)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR2 -> VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[5]: call_dissector_only(conversation -> dissector_handle,tvb,pinfo,tree)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 -> VAR2 , VAR3 , VAR4 , VAR5 )
  ORIGINAL[6]: conversation -> dissector_handle
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: !ret
  TYPE[7]: CALL
  TOKENIZED[7]: !ret
  ORIGINAL[8]: dissector_handle
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: ret
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: conversation
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: tvb
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: pinfo
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: tree
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: ret
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 68719477116
FRAGMENT_COUNT: 4
  ORIGINAL[0]: conv -> key_ptr
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key_ptr
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: hashtable
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477085
FRAGMENT_COUNT: 10
  ORIGINAL[0]: v1 -> ptype
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: v1 -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: v1 -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: v1 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: (&v1 -> addr1) -> len == (&v2 -> addr1) -> len
  TYPE[4]: CALL
  TOKENIZED[4]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[5]: v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: addr1
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: v1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771220
FRAGMENT_COUNT: 41
  ORIGINAL[0]: conversation -> options & 0x02
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 & 0x02
  ORIGINAL[1]: conversation -> options & 0x01
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 & 0x01
  ORIGINAL[2]: conversation -> options
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: new_conversation_from_template = conversation_new(conversation -> setup_frame,(&conversation -> key_ptr -> addr1),addr2,conversation -> key_ptr -> ptype,conversation -> key_ptr -> port1,conversation -> key_ptr -> port2,options)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = FUN1 ( VAR2 -> VAR3 , ( &conversation -> VAR4 -> VAR5 ) , VAR6 , VAR2 -> VAR4 -> VAR7 , VAR2 -> VAR4 -> VAR8 , VAR2 -> VAR4 -> VAR9 , VAR10 )
  ORIGINAL[4]: conversation_new(conversation -> setup_frame,(&conversation -> key_ptr -> addr1),addr2,conversation -> key_ptr -> ptype,conversation -> key_ptr -> port1,conversation -> key_ptr -> port2,options)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 -> VAR2 , ( &conversation -> VAR3 -> VAR4 ) , VAR5 , VAR1 -> VAR3 -> VAR6 , VAR1 -> VAR3 -> VAR7 , VAR1 -> VAR3 -> VAR8 , VAR9 )
  ORIGINAL[5]: conversation -> setup_frame
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &conversation -> key_ptr -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &conversation -> VAR1 -> VAR2
  ORIGINAL[7]: conversation -> key_ptr -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[8]: conversation -> key_ptr
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: conversation -> key_ptr -> ptype
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[10]: conversation -> key_ptr
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: conversation -> key_ptr -> port1
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[12]: conversation -> key_ptr
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: conversation -> key_ptr -> port2
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[14]: conversation -> key_ptr
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: new_conversation_from_template -> dissector_handle = conversation -> dissector_handle
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 = VAR3 -> VAR2
  ORIGINAL[16]: new_conversation_from_template -> dissector_handle
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: conversation -> dissector_handle
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: setup_frame
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: key_ptr
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: addr1
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: key_ptr
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: ptype
  TYPE[22]: FIELD_IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: key_ptr
  TYPE[23]: FIELD_IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: port1
  TYPE[24]: FIELD_IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: key_ptr
  TYPE[25]: FIELD_IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: port2
  TYPE[26]: FIELD_IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: dissector_handle
  TYPE[27]: FIELD_IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: dissector_handle
  TYPE[28]: FIELD_IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: new_conversation_from_template
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: conversation
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: conversation
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: addr2
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: conversation
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: conversation
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: conversation
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: options
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: conversation
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: new_conversation_from_template
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1
  ORIGINAL[39]: conversation
  TYPE[39]: IDENTIFIER
  TOKENIZED[39]: VAR1
  ORIGINAL[40]: new_conversation_from_template
  TYPE[40]: IDENTIFIER
  TOKENIZED[40]: VAR1

CENTER_NODE: 68719476969
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *v2 = (const conversation_key *)w
  TYPE[0]: CALL
  TOKENIZED[0]: *v2 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: v1 -> ptype
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ptype
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: v1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: v1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771573
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ((&v1 -> addr2) -> type) == AT_NONE || (&v1 -> addr2) -> len == (&v2 -> addr2) -> len && memcmp((&v1 -> addr2) -> data,(&v2 -> addr2) -> data,((&v1 -> addr2) -> len)) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( &v1 -> VAR1 ) -> VAR2 ) == VAR3 || ( &v1 -> VAR1 ) -> VAR4 == ( &v2 -> VAR1 ) -> VAR4 && FUN1 ( ( &v1 -> VAR1 ) -> VAR5 , ( &v2 -> VAR1 ) -> VAR5 , ( ( &v1 -> VAR1 ) -> VAR4 ) ) == 0
  ORIGINAL[1]: ((&v1 -> addr2) -> type) == AT_NONE
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( &v1 -> VAR1 ) -> VAR2 ) == VAR3
  ORIGINAL[2]: (&v1 -> addr2) -> len == (&v2 -> addr2) -> len && memcmp((&v1 -> addr2) -> data,(&v2 -> addr2) -> data,((&v1 -> addr2) -> len)) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2 && FUN1 ( ( &v1 -> VAR1 ) -> VAR3 , ( &v2 -> VAR1 ) -> VAR3 , ( ( &v1 -> VAR1 ) -> VAR2 ) ) == 0
  ORIGINAL[3]: (&v1 -> addr2) -> len == (&v2 -> addr2) -> len
  TYPE[3]: CALL
  TOKENIZED[3]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[4]: memcmp((&v1 -> addr2) -> data,(&v2 -> addr2) -> data,((&v1 -> addr2) -> len)) == 0
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( &v1 -> VAR1 ) -> VAR2 , ( &v2 -> VAR1 ) -> VAR2 , ( ( &v1 -> VAR1 ) -> VAR3 ) ) == 0

CENTER_NODE: 30064771724
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation_hashtable_no_port2 = g_hash_table_new(conversation_hash_no_port2,conversation_match_no_port2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(conversation_hash_no_port2,conversation_match_no_port2)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> conversation_hashtable_no_port2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064772208
FRAGMENT_COUNT: 5
  ORIGINAL[0]: item != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: p1 = ((conv_proto_data *)(item -> data))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( VAR2 * ) ( VAR3 -> VAR4 ) )
  ORIGINAL[2]: (conv_proto_data *)(item -> data)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[3]: p1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771683
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *conv = (conversation_t *)value
  TYPE[0]: CALL
  TOKENIZED[0]: *conv = ( VAR1 * ) VAR2
  ORIGINAL[1]: (conversation_t *)value
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 * ) VAR2
  ORIGINAL[2]: conv
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *key = (const conversation_key *)v
  TYPE[0]: CALL
  TOKENIZED[0]: *key = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const conversation_key *)v
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: v
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772213
FRAGMENT_COUNT: 4
  ORIGINAL[0]: temp . proto = proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: temp . proto
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: proto
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477564
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation -> dissector_handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dissector_handle
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: conversation
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477196
FRAGMENT_COUNT: 9
  ORIGINAL[0]: chain_head -> next
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: cur != conv
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: ((void *)0) == conv -> next
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( void * ) 0 ) == VAR1 -> VAR2
  ORIGINAL[3]: chain_head -> last = prev
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 = VAR3
  ORIGINAL[4]: chain_head -> last
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: chain_head -> latest_found
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: latest_found
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: chain_head
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: chain_head
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064772185
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *p1 = (se_alloc(sizeof(conv_proto_data )))
  TYPE[0]: CALL
  TOKENIZED[0]: *p1 = ( FUN1 ( sizeof ( VAR1 ) ) )
  ORIGINAL[1]: se_alloc(sizeof(conv_proto_data ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[2]: sizeof(conv_proto_data )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: p1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476789
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stonesoup_printf_context != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477607
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *stonesoup_rand_word = \
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_rand_word = \
  ORIGINAL[1]: stonesoup_fp = stonesoup_switch_func(scrogie_transmitter)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[2]: stonesoup_switch_func(scrogie_transmitter)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: stonesoup_fp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: scrogie_transmitter
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_fp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772041
FRAGMENT_COUNT: 10
  ORIGINAL[0]: convo -> setup_frame <= frame_num
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3
  ORIGINAL[1]: convo -> setup_frame
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: convo -> setup_frame
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: setup_frame
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: convo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: convo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: convo
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: frame_num
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: convo
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: convo
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771714
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation_hashtable_no_addr2 = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: <global> conversation_hashtable_no_addr2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771393
FRAGMENT_COUNT: 28
  ORIGINAL[0]: &v1 -> addr1
  TYPE[0]: CALL
  TOKENIZED[0]: &v1 -> VAR1
  ORIGINAL[1]: v1 -> addr1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: &v1 -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: &v1 -> VAR1
  ORIGINAL[3]: v1 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: &v1 -> VAR1
  ORIGINAL[5]: v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: &v1 -> addr1
  TYPE[8]: CALL
  TOKENIZED[8]: &v1 -> VAR1
  ORIGINAL[9]: v1 -> addr1
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: v1 -> port2 == v2 -> port1 && v1 -> port1 == v2 -> port2 && (((&v1 -> addr2) -> type) == ((&v2 -> addr1) -> type) && (((&v1 -> addr2) -> type) == AT_NONE || (&v1 -> addr2) -> len == (&v2 -> addr1) -> len && memcmp((&v1 -> addr2) -> data,(&v2 -> addr1) -> data,((&v1 -> addr2) -> len)) == 0))
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 == VAR3 -> VAR4 && VAR1 -> VAR4 == VAR3 -> VAR2 && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == ( ( &v2 -> VAR7 ) -> VAR6 ) && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == VAR8 || ( &v1 -> VAR5 ) -> VAR9 == ( &v2 -> VAR7 ) -> VAR9 && FUN1 ( ( &v1 -> VAR5 ) -> VAR10 , ( &v2 -> VAR7 ) -> VAR10 , ( ( &v1 -> VAR5 ) -> VAR9 ) ) == 0 ) )
  ORIGINAL[11]: &v1 -> addr1
  TYPE[11]: CALL
  TOKENIZED[11]: &v1 -> VAR1
  ORIGINAL[12]: v1 -> addr1
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: &v1 -> addr1
  TYPE[13]: CALL
  TOKENIZED[13]: &v1 -> VAR1
  ORIGINAL[14]: v1 -> addr1
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: &v1 -> addr1
  TYPE[15]: CALL
  TOKENIZED[15]: &v1 -> VAR1
  ORIGINAL[16]: v1 -> addr1
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: &v1 -> addr1
  TYPE[17]: CALL
  TOKENIZED[17]: &v1 -> VAR1
  ORIGINAL[18]: v1 -> addr1
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2
  ORIGINAL[19]: &v1 -> addr1
  TYPE[19]: CALL
  TOKENIZED[19]: &v1 -> VAR1
  ORIGINAL[20]: v1 -> addr1
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 -> VAR2
  ORIGINAL[21]: addr1
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: v1
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: v1
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: v1
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: v1
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: v1
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: v1
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1

CENTER_NODE: 68719476949
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (const conversation_key *)v
  TYPE[0]: CALL
  TOKENIZED[0]: ( const VAR1 * ) VAR2
  ORIGINAL[1]: v
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064772181
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ap -> proto > bp -> proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 -> VAR2
  ORIGINAL[1]: ap -> proto
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ap -> proto == bp -> proto
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[3]: ap -> proto
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: bp -> proto
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: proto
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ap
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ap
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: bp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771133
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: strcmp(getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( FUN2 ( \
  ORIGINAL[2]: strcmp(getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( FUN2 ( \
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \

CENTER_NODE: 30064771245
FRAGMENT_COUNT: 16
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: (&key -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: ( &key -> VAR1 ) -> VAR2
  ORIGINAL[2]: &key -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: &key -> VAR1
  ORIGINAL[3]: key -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index++
  TYPE[4]: CALL
  TOKENIZED[4]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[5]: hash_val += ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 += VAR2 [ VAR3 ]
  ORIGINAL[6]: ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: for (ADD_ADDRESS_TO_HASH_index = 0;ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len;ADD_ADDRESS_TO_HASH_index++)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( VAR1 = 0 ; VAR1 < ( &key -> VAR2 ) -> VAR3 ; ADD_ADDRESS_TO_HASH_index++ )
  ORIGINAL[8]: addr1
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: len
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: ADD_ADDRESS_TO_HASH_index
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: key
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: ADD_ADDRESS_TO_HASH_index
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: hash_val
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: ADD_ADDRESS_TO_HASH_data
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: ADD_ADDRESS_TO_HASH_index
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

