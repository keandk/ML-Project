# Tokenized code fragments for 153635-v1.0.0-bad
# Total center nodes processed: 83
# Total code fragments found: 407

CENTER_NODE: 30064771368
FRAGMENT_COUNT: 6
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> data[str -> len]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> VAR3 ]
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: len
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771910
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i > 3
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 3
  ORIGINAL[1]: buffer[i - 3]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 - 3 ]
  ORIGINAL[2]: i - 3
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 3
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476980
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476845
FRAGMENT_COUNT: 11
  ORIGINAL[0]: *const _m_b_f_ = membuf
  TYPE[0]: CALL
  TOKENIZED[0]: *const VAR1 = VAR2
  ORIGINAL[1]: _m_b_f_ -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: _m_b_f_ -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: _m_b_f_ -> size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: _m_b_f_ -> data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: _m_b_f_
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: membuf
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: _m_b_f_
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: _m_b_f_
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: _m_b_f_
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: _m_b_f_
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771926
FRAGMENT_COUNT: 2
  ORIGINAL[0]: buffer[2 * 21]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 2 * 21 ]
  ORIGINAL[1]: 2 * 21
  TYPE[1]: CALL
  TOKENIZED[1]: 2 * 21

CENTER_NODE: 30064771138
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *size = minimum_size
  TYPE[0]: CALL
  TOKENIZED[0]: *size = VAR1
  ORIGINAL[1]: *size
  TYPE[1]: CALL
  TOKENIZED[1]: *size
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: minimum_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771410
FRAGMENT_COUNT: 3
  ORIGINAL[0]: __sync_bool_compare_and_swap(&akindle_discreditable,0,1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &akindle_discreditable , 0 , 1 )
  ORIGINAL[1]: mkdir(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: mkdir(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 3
  ORIGINAL[0]: membuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: membuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477299
FRAGMENT_COUNT: 5
  ORIGINAL[0]: next == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (char *)next
  TYPE[1]: CALL
  TOKENIZED[1]: ( char * ) VAR1
  ORIGINAL[2]: next
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: next
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: next
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477255
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_cstring_split_append(a,input,sep_chars,chop_whitespace,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 )
  ORIGINAL[1]: input
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: sep_chars
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chop_whitespace
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771157
FRAGMENT_COUNT: 5
  ORIGINAL[0]: membuf -> pool = pool
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: membuf -> pool
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pool
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: membuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477558
FRAGMENT_COUNT: 10
  ORIGINAL[0]: *strb
  TYPE[0]: CALL
  TOKENIZED[0]: *strb
  ORIGINAL[1]: stra < enda
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: strb < endb
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2
  ORIGINAL[3]: strb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: strb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: strb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: strb
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: endb
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: strb
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477402
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *svn_err__temp = svn_cstring_strtoi64(&val,str,(- 2147483647 - 1),2147483647,10)
  TYPE[0]: CALL
  TOKENIZED[0]: *svn_err__temp = FUN1 ( &val , VAR1 , ( - 2147483647 - 1 ) , 2147483647 , 10 )
  ORIGINAL[1]: svn_cstring_strtoi64(&val,str,(- 2147483647 - 1),2147483647,10)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &val , VAR1 , ( - 2147483647 - 1 ) , 2147483647 , 10 )
  ORIGINAL[2]: svn_err__temp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: svn_err__temp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 1
  ORIGINAL[0]: membuf -> data && old_data && old_data != (membuf -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR3 && VAR3 != ( VAR1 -> VAR2 )

CENTER_NODE: 30064771565
FRAGMENT_COUNT: 9
  ORIGINAL[0]: str -> len > 0 && 0 != (svn_ctype_table[(unsigned char )str -> data[str -> len - 1]] & 0x0002)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 0 && 0 != ( VAR3 [ ( unsigned char ) VAR1 -> VAR4 [ VAR1 -> VAR2 - 1 ] ] & 0x0002 )
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> len--
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> len--
  ORIGINAL[4]: str -> len
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: len
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771225
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new_string -> data = empty_buffer
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: new_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> empty_buffer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_string
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477097
FRAGMENT_COUNT: 7
  ORIGINAL[0]: bytes + count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: apr_pstrndup(str -> pool,bytes,count)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: str -> pool
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: bytes
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: count
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772151
FRAGMENT_COUNT: 8
  ORIGINAL[0]: continuousness_attaches != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: toleware_pseudo[3]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 3 ]
  ORIGINAL[2]: toleware_pseudo[3] != 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 3 ] != 0
  ORIGINAL[3]: toleware_pseudo[3]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 3 ]
  ORIGINAL[4]: toleware_pseudo[3]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ 3 ]
  ORIGINAL[5]: toleware_pseudo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: toleware_pseudo
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: toleware_pseudo
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771382
FRAGMENT_COUNT: 14
  ORIGINAL[0]: mem && mem != (str -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 != ( VAR2 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: memcpy(mem,(str -> data),str -> len + 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 -> VAR4 + 1 )
  ORIGINAL[3]: str -> data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: str -> len + 1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 + 1
  ORIGINAL[5]: str -> len
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: data
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: data
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: len
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: str
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: mem
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: str
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: str
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: str
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 68719477063
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> blocksize > old_len + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 + 1
  ORIGINAL[1]: &b
  TYPE[1]: CALL
  TOKENIZED[1]: &b
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477164
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pos + old_count > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > VAR3 -> VAR4
  ORIGINAL[1]: old_count = str -> len - pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 - VAR4
  ORIGINAL[2]: str -> len - pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 - VAR3
  ORIGINAL[3]: old_count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: old_count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771770
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_cstring_strtoui64(&val,str,0,4294967295U,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &val , VAR1 , 0 , 4294967295U , 10 )
  ORIGINAL[1]: &val
  TYPE[1]: CALL
  TOKENIZED[1]: &val
  ORIGINAL[2]: val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477315
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *p
  TYPE[0]: CALL
  TOKENIZED[0]: *p
  ORIGINAL[1]: ( *(p + 1)) == 10
  TYPE[1]: CALL
  TOKENIZED[1]: ( * ( VAR1 + 1 ) ) == 10
  ORIGINAL[2]: p++
  TYPE[2]: CALL
  TOKENIZED[2]: p++
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476780
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: first_char = buffer_param[0] - 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 [ 0 ] - 97
  ORIGINAL[2]: buffer_param[0] - 97
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ] - 97
  ORIGINAL[3]: first_char
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: buffer_param
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: first_char
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771483
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len - pos - count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 - VAR3 - VAR4 + 1
  ORIGINAL[1]: str -> len - pos - count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 - VAR3 - VAR4
  ORIGINAL[2]: str -> len - pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 - VAR3
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771082
FRAGMENT_COUNT: 10
  ORIGINAL[0]: ev == MG_REQUEST
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: strcmp(ifmatch_header, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: strcmp(ifmatch_header, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: stonesoup_printf_context = conn
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2
  ORIGINAL[4]: stonesoup_handle_taint(stonesoup_tainted_buff)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: if (strcmp(ifmatch_header, \
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: if ( FUN1 ( VAR1 , \
  ORIGINAL[6]: <global> stonesoup_printf_context
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: conn
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_tainted_buff
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: MG_TRUE
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640334
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477459
FRAGMENT_COUNT: 7
  ORIGINAL[0]: number < 100
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 100
  ORIGINAL[1]: &buffer[21] - target
  TYPE[1]: CALL
  TOKENIZED[1]: &buffer [ 21 ] - VAR1
  ORIGINAL[2]: &buffer[21]
  TYPE[2]: CALL
  TOKENIZED[2]: &buffer [ 21 ]
  ORIGINAL[3]: target
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: target
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: target
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: target
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 10
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: !(0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002))
  TYPE[3]: CALL
  TOKENIZED[3]: ! ( 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 ) )
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640338
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771711
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < strings -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: svn_stringbuf_appendbytes(new_str,string,strlen(string))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[2]: strlen(string)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640330
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771730
FRAGMENT_COUNT: 6
  ORIGINAL[0]: val = apr_strtoi64(str,&endptr,base)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , &endptr , VAR3 )
  ORIGINAL[1]: apr_strtoi64(str,&endptr,base)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &endptr , VAR2 )
  ORIGINAL[2]: &endptr
  TYPE[2]: CALL
  TOKENIZED[2]: &endptr
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: base
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771260
FRAGMENT_COUNT: 2
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 68719477031
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640276
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 11
  ORIGINAL[0]: new_size < minimum_size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: prev_size > new_size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 > VAR2
  ORIGINAL[2]: new_size = minimum_size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: break;
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: break ;
  ORIGINAL[4]: new_size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: minimum_size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: prev_size
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new_size
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: new_size
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: minimum_size
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: data
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719476937
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str1 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str2 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477085
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,cstr,strlen(cstr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[1]: targetstr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476942
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476857
FRAGMENT_COUNT: 5
  ORIGINAL[0]: len1 != len2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: memcmp(str1,str2,len1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: str1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771629
FRAGMENT_COUNT: 16
  ORIGINAL[0]: i < list -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: list -> nelts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: *this_str = ((char **)(list -> elts))[i]
  TYPE[2]: CALL
  TOKENIZED[2]: *this_str = ( ( char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[3]: ((char **)(list -> elts))[i]
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[4]: (char **)(list -> elts)
  TYPE[4]: CALL
  TOKENIZED[4]: ( char ** ) ( VAR1 -> VAR2 )
  ORIGINAL[5]: list -> elts
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: strcmp(this_str,str) == 0
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( VAR1 , VAR2 ) == 0
  ORIGINAL[7]: strcmp(this_str,str)
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[8]: for (i = 0;i < list -> nelts;i++)
  TYPE[8]: CONTROL_STRUCTURE
  TOKENIZED[8]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[9]: elts
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: this_str
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: list
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: i
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: this_str
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: str
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 30064771585
FRAGMENT_COUNT: 7
  ORIGINAL[0]: 0 != (svn_ctype_table[(unsigned char )( *p)] & 0x0002)
  TYPE[0]: CALL
  TOKENIZED[0]: 0 != ( VAR1 [ ( unsigned char ) ( *p ) ] & 0x0002 )
  ORIGINAL[1]: svn_ctype_table[(unsigned char )( *p)] & 0x0002
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ ( unsigned char ) ( *p ) ] & 0x0002
  ORIGINAL[2]: svn_ctype_table[(unsigned char )( *p)]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ ( unsigned char ) ( *p ) ]
  ORIGINAL[3]: (unsigned char )( *p)
  TYPE[3]: CALL
  TOKENIZED[3]: ( unsigned char ) ( *p )
  ORIGINAL[4]: chop_whitespace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: svn_ctype_table
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: svn_ctype_table
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771543
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_first_non_whitespace((str -> data),str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477222
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str2 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str1 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771534
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate((original_string -> data),original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: original_string -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771314
FRAGMENT_COUNT: 6
  ORIGINAL[0]: strbuf -> len = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: strbuf -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strbuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strbuf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771264
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_string_ncreate(original_string -> data,original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 8
  ORIGINAL[0]: new_string -> blocksize = blocksize - sizeof(( *new_string))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2 - sizeof ( ( *new_string ) )
  ORIGINAL[1]: new_string -> blocksize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: blocksize - sizeof(( *new_string))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - sizeof ( ( *new_string ) )
  ORIGINAL[3]: blocksize
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: blocksize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_string
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new_string
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771101
FRAGMENT_COUNT: 13
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: strcmp(getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( FUN2 ( \
  ORIGINAL[3]: *stonesoup_server = mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[3]: CALL
  TOKENIZED[3]: *stonesoup_server = FUN1 ( VAR1 , VAR2 )
  ORIGINAL[4]: mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[5]: mg_set_option(stonesoup_server, \
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , \
  ORIGINAL[6]: mg_destroy_server(&stonesoup_server)
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( &stonesoup_server )
  ORIGINAL[7]: &stonesoup_server
  TYPE[7]: CALL
  TOKENIZED[7]: &stonesoup_server
  ORIGINAL[8]: if (getenv(\
  TYPE[8]: CONTROL_STRUCTURE
  TOKENIZED[8]: if ( FUN1 ( \
  ORIGINAL[9]: stonesoup_server
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: NULL
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: stonesoup_server
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: stonesoup_server
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 68719476946
FRAGMENT_COUNT: 2
  ORIGINAL[0]: svn_stringbuf_create_ensure(0,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771919
FRAGMENT_COUNT: 4
  ORIGINAL[0]: buffer[2 * 21]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 2 * 21 ]
  ORIGINAL[1]: buffer[2 * 21]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 2 * 21 ]
  ORIGINAL[2]: buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: number
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477197
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str1 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str2 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *const _m_b_f_ = membuf
  TYPE[0]: CALL
  TOKENIZED[0]: *const VAR1 = VAR2
  ORIGINAL[1]: _m_b_f_
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: membuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _m_b_f_
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771801
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *__errno_location() == 34
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 34
  ORIGINAL[1]: val == - 9223372036854775807L - 1 || val == 9223372036854775807L
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L
  ORIGINAL[2]: val == - 9223372036854775807L - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == - 9223372036854775807L - 1
  ORIGINAL[3]: - 9223372036854775807L - 1
  TYPE[3]: CALL
  TOKENIZED[3]: - 9223372036854775807L - 1
  ORIGINAL[4]: val == 9223372036854775807L
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == 9223372036854775807L
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477010
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memset((str -> data),c,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771316
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771243
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new_string -> len = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: new_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476911
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_string_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: cstring
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771358
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476990
FRAGMENT_COUNT: 7
  ORIGINAL[0]: apr_palloc(pool,sizeof(( *new_string)))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , sizeof ( ( *new_string ) ) )
  ORIGINAL[1]: sizeof(( *new_string))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *new_string ) )
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pool
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476881
FRAGMENT_COUNT: 3
  ORIGINAL[0]: new_string -> data = data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: new_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771270
FRAGMENT_COUNT: 3
  ORIGINAL[0]: string_first_non_whitespace(str -> data,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 30064771121
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c - 32
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 32
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771620
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: apr_fnmatch(this_pattern,str,0) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , 0 ) == 0
  ORIGINAL[2]: for (i = 0;i < list -> nelts;i++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771571
FRAGMENT_COUNT: 5
  ORIGINAL[0]: find_char_backward((str -> data),str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476921
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *data = apr_pvsprintf(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: *data = FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: create_string(data,strlen(data),pool)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771896
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: svn__ui64toa(dest + 1,((apr_uint64_t )(0 - number)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 + 1 , ( ( VAR2 ) ( 0 - VAR3 ) ) )
  ORIGINAL[2]: dest + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: dest
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: apr_uint64_t
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771277
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (svn_string_t *)(&strbuf -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 * ) ( &strbuf -> VAR2 )
  ORIGINAL[1]: &strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: &strbuf -> VAR1
  ORIGINAL[2]: strbuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 68719476915
FRAGMENT_COUNT: 4
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: strbuf -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strbuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771811
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_cstring_strtoi64(n,str,- 9223372036854775807L - 1,9223372036854775807L,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , - 9223372036854775807L - 1 , 9223372036854775807L , 10 )
  ORIGINAL[1]: - 9223372036854775807L - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 9223372036854775807L - 1
  ORIGINAL[2]: n
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477007
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str = svn_stringbuf_createv(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: __builtin_va_end(ap)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: ap
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477020
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len = amt
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: amt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: amt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477343
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !a
  TYPE[0]: CALL
  TOKENIZED[0]: !a
  ORIGINAL[1]: a
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cmp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: a
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477083
FRAGMENT_COUNT: 4
  ORIGINAL[0]: appendstr -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: targetstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: appendstr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476928
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_string_createv(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: fmt
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: fmt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ap
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477510
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stringa . len = strlen(stra)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = FUN1 ( VAR3 )
  ORIGINAL[1]: stringb . data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stringb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719477370
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoui64(n,str,0,18446744073709551615UL,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 , 18446744073709551615UL , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 1
  ORIGINAL[0]: str[--i] == ch
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ --i ] == VAR2

