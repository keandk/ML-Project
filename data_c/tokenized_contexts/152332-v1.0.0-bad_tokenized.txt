# Tokenized code fragments for 152332-v1.0.0-bad
# Total center nodes processed: 73
# Total code fragments found: 287

CENTER_NODE: 68719476936
FRAGMENT_COUNT: 6
  ORIGINAL[0]: link -> dstpad
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: link -> dst
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: link -> dst
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dst
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: filt_dstpad_idx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: link
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476738
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (struct mg_connection*) stonesoup_printf_context
  TYPE[0]: CALL
  TOKENIZED[0]: ( struct mg_connection* ) VAR1
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 68719477318
FRAGMENT_COUNT: 6
  ORIGINAL[0]: link -> srcpad
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: link -> dstpad
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: *cmd = link -> dst -> command_queue
  TYPE[2]: CALL
  TOKENIZED[2]: *cmd = VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: link -> closed
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: closed
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: link
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772211
FRAGMENT_COUNT: 2
  ORIGINAL[0]: av_log(((void *)0),48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , 48 , \
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 68719477045
FRAGMENT_COUNT: 9
  ORIGINAL[0]: link -> type
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: link -> w
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: link -> h
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: link -> format
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: link -> src
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: link -> dst
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: w
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: link
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: link
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064772305
FRAGMENT_COUNT: 2
  ORIGINAL[0]: unvillainously_antichlorotic = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: unvillainously_antichlorotic
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719476763
FRAGMENT_COUNT: 6
  ORIGINAL[0]: strcmp(ifmatch_header, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , \
  ORIGINAL[1]: data_size < buffer_size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: stonesoup_printf_context = conn
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: break;
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: break ;
  ORIGINAL[4]: <global> stonesoup_printf_context
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: conn
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640323
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477175
FRAGMENT_COUNT: 7
  ORIGINAL[0]: **filter_ptr = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: **filter_ptr = ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: filter_ptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: filter_ptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: filter_ptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filter_ptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: filter_ptr
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771695
FRAGMENT_COUNT: 12
  ORIGINAL[0]: pts == ((int64_t )0x8000000000000000UL)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) 0x8000000000000000UL )
  ORIGINAL[1]: link -> graph && link -> age_index >= 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && VAR1 -> VAR3 >= 0
  ORIGINAL[2]: link -> graph
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: link -> age_index >= 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 >= 0
  ORIGINAL[4]: link -> age_index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: link -> graph
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: graph
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: age_index
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: link
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: link
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: link
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: link
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640326
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771210
FRAGMENT_COUNT: 4
  ORIGINAL[0]: filter -> command_queue = c -> next
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3 -> VAR4
  ORIGINAL[1]: filter -> command_queue
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: c -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477086
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ret == -((int )(('E' | 'O' << 8 | 'F' << 16) | ((unsigned int )32) << 24)) && link -> partial_buf
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - ( ( int ) ( ( 'E' | 'O' << 8 | 'F' << 16 ) | ( ( unsigned int ) 32 ) << 24 ) ) && VAR2 -> VAR3
  ORIGINAL[1]: ret == -((int )(('E' | 'O' << 8 | 'F' << 16) | ((unsigned int )32) << 24))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == - ( ( int ) ( ( 'E' | 'O' << 8 | 'F' << 16 ) | ( ( unsigned int ) 32 ) << 24 ) )
  ORIGINAL[2]: link -> closed = 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = 1
  ORIGINAL[3]: ret
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ret
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477536
FRAGMENT_COUNT: 2
  ORIGINAL[0]: .child_class_next = filter_child_class_next
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: child_class_next
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640325
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771756
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memset(registered_avfilters,0,sizeof(registered_avfilters))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR1 ) )
  ORIGINAL[1]: sizeof(registered_avfilters)
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: <global> registered_avfilters
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> next_registered_avfilter_idx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719477309
FRAGMENT_COUNT: 3
  ORIGINAL[0]: pads[pad_idx]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: pads
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pad_idx
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640403
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640324
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772208
FRAGMENT_COUNT: 2
  ORIGINAL[0]: av_log(((void *)0),48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , 48 , \
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 30064771341
FRAGMENT_COUNT: 8
  ORIGINAL[0]: src -> output_pads[srcpad] . type != dst -> input_pads[dstpad] . type
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 != VAR5 -> VAR6 [ VAR7 ] . VAR4
  ORIGINAL[1]: src -> output_pads[srcpad]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: src -> output_pads[srcpad]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: src -> output_pads
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: output_pads
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: src
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: src
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: srcpad
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771771
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !prev && ctx -> filter && ctx -> filter -> priv_class
  TYPE[0]: CALL
  TOKENIZED[0]: !prev && VAR1 -> VAR2 && VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: !prev && ctx -> filter
  TYPE[1]: CALL
  TOKENIZED[1]: !prev && VAR1 -> VAR2
  ORIGINAL[2]: ctx -> filter -> priv_class
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: ctx -> priv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: priv
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ctx
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771142
FRAGMENT_COUNT: 18
  ORIGINAL[0]: av_log(ctx,48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 48 , \
  ORIGINAL[1]: ref -> buf
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ref -> buf -> refcount
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: ff_get_ref_perms_string(buf,sizeof(buf),ref -> perms)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , sizeof ( VAR1 ) , VAR2 -> VAR3 )
  ORIGINAL[4]: ref -> data[0]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[5]: ref -> linesize[0]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[6]: ref -> linesize
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: ref -> linesize[1]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ 1 ]
  ORIGINAL[8]: ref -> linesize
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: ref -> linesize[2]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ 2 ]
  ORIGINAL[10]: ref -> linesize
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: ref -> linesize[3]
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 [ 3 ]
  ORIGINAL[12]: ref -> linesize
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: ref -> pts
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: ref -> pos
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: ctx
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: ref
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: ref
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 30064771366
FRAGMENT_COUNT: 3
  ORIGINAL[0]: link -> channels
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: channels
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: link
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640320
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772230
FRAGMENT_COUNT: 7
  ORIGINAL[0]: (link -> type) == AVMEDIA_TYPE_AUDIO && link -> min_samples
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) == VAR3 && VAR1 -> VAR4
  ORIGINAL[1]: (link -> type) == AVMEDIA_TYPE_AUDIO
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 ) == VAR3
  ORIGINAL[2]: link -> type
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: link -> min_samples
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: min_samples
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: AVMEDIA_TYPE_AUDIO
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: link
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !ret -> output_pads
  TYPE[0]: CALL
  TOKENIZED[0]: !ret -> VAR1

CENTER_NODE: 30064772025
FRAGMENT_COUNT: 4
  ORIGINAL[0]: link -> dst -> outputs[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3 [ 0 ]
  ORIGINAL[1]: link -> dst -> outputs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: link -> dst
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: outputs
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640269
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640400
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771736
FRAGMENT_COUNT: 7
  ORIGINAL[0]: filter -> inputs && filter -> inputs[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[1]: filter -> inputs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: filter -> inputs[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: filter -> inputs
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: inputs
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filter
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771199
FRAGMENT_COUNT: 2
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \

CENTER_NODE: 47244640274
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640268
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477476
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ++stonesoup_global_variable
  TYPE[0]: CALL
  TOKENIZED[0]: ++stonesoup_global_variable
  ORIGINAL[1]: grommets_pinto != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: grommets_pinto
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: grommets_pinto
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476773
FRAGMENT_COUNT: 5
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_server
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: NULL
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771122
FRAGMENT_COUNT: 3
  ORIGINAL[0]: perms & 0x04?\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 0x04?\
  ORIGINAL[1]: perms & 0x04
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & 0x04
  ORIGINAL[2]: perms
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772019
FRAGMENT_COUNT: 3
  ORIGINAL[0]: pads[pad_idx] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: pads[pad_idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: name
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771185
FRAGMENT_COUNT: 2
  ORIGINAL[0]: !(103 >= 100)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( 103 >= 100 )
  ORIGINAL[1]: 103 >= 100
  TYPE[1]: CALL
  TOKENIZED[1]: 103 >= 100

CENTER_NODE: 30064771715
FRAGMENT_COUNT: 10
  ORIGINAL[0]: registered_avfilters[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: !strcmp(registered_avfilters[i] -> name,name)
  TYPE[2]: CALL
  TOKENIZED[2]: !strcmp ( VAR1 [ VAR2 ] -> VAR3 , VAR3 )
  ORIGINAL[3]: strcmp(registered_avfilters[i] -> name,name)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 [ VAR2 ] -> VAR3 , VAR3 )
  ORIGINAL[4]: registered_avfilters[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: <global> registered_avfilters
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: <global> registered_avfilters
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771762
FRAGMENT_COUNT: 5
  ORIGINAL[0]: pads -> name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: count++
  TYPE[1]: CALL
  TOKENIZED[1]: count++
  ORIGINAL[2]: for (count = 0;pads -> name;count++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR2 -> VAR3 ; count++ )
  ORIGINAL[3]: pads
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640278
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476787
FRAGMENT_COUNT: 3
  ORIGINAL[0]: buf[16]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 16 ]
  ORIGINAL[1]: buf[16]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 16 ]
  ORIGINAL[2]: buf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771754
FRAGMENT_COUNT: 4
  ORIGINAL[0]: filter?++filter : &registered_avfilters[0]
  TYPE[0]: CALL
  TOKENIZED[0]: filter?++filter : &registered_avfilters [ 0 ]
  ORIGINAL[1]: &registered_avfilters[0]
  TYPE[1]: CALL
  TOKENIZED[1]: &registered_avfilters [ 0 ]
  ORIGINAL[2]: registered_avfilters[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: filter
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640276
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640401
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772320
FRAGMENT_COUNT: 2
  ORIGINAL[0]: .child_next = filter_child_next
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: child_next
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477166
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *ctx = filter_ctx
  TYPE[0]: CALL
  TOKENIZED[0]: *ctx = VAR1
  ORIGINAL[1]: ctx -> name
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: name
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ctx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477533
FRAGMENT_COUNT: 3
  ORIGINAL[0]: .category = AV_CLASS_CATEGORY_FILTER
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: category
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: AV_CLASS_CATEGORY_FILTER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771933
FRAGMENT_COUNT: 29
  ORIGINAL[0]: link = filter -> inputs[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: &link -> out_formats
  TYPE[1]: CALL
  TOKENIZED[1]: &link -> VAR1
  ORIGINAL[2]: link -> out_formats
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &link -> out_formats
  TYPE[3]: CALL
  TOKENIZED[3]: &link -> VAR1
  ORIGINAL[4]: link -> out_formats
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: out_formats
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: link
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: link
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: link
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: link
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: link
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: link
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: link
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: link
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: link
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: link
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: link
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: link
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: link
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: link
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: link
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: link
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: link
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: link
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: link
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: link
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: link
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: link
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: link
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1

CENTER_NODE: 30064771215
FRAGMENT_COUNT: 6
  ORIGINAL[0]: idx = (idx >  *count? *count : idx)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( VAR1 > *count? *count : VAR1 )
  ORIGINAL[1]: idx >  *count? *count : idx
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 > *count? *count : VAR1
  ORIGINAL[2]: idx >  *count
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 > *count
  ORIGINAL[3]: *count
  TYPE[3]: CALL
  TOKENIZED[3]: *count
  ORIGINAL[4]: idx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: idx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477508
FRAGMENT_COUNT: 7
  ORIGINAL[0]: strlen(tetchiness_bardolater) < 1000 - strlen(stonesoup_command_str)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) < 1000 - FUN1 ( VAR2 )
  ORIGINAL[1]: tracepoint(stonesoup_trace, variable_buffer, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: stonesoup_command_buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_trace
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: variable_buffer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_command_buffer
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_command_buffer
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771359
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *link) -> pool
  TYPE[0]: CALL
  TOKENIZED[0]: ( *link ) -> VAR1
  ORIGINAL[1]: ff_free_pool(( *link) -> pool)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( *link ) -> VAR1 )
  ORIGINAL[2]: ( *link) -> pool
  TYPE[2]: CALL
  TOKENIZED[2]: ( *link ) -> VAR1
  ORIGINAL[3]: *link
  TYPE[3]: CALL
  TOKENIZED[3]: *link
  ORIGINAL[4]: *link
  TYPE[4]: CALL
  TOKENIZED[4]: *link
  ORIGINAL[5]: pool
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771605
FRAGMENT_COUNT: 2
  ORIGINAL[0]: av_log(((void *)0),48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , 48 , \
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 30064771191
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 3 << 16 | 42 << 8
  TYPE[0]: CALL
  TOKENIZED[0]: 3 << 16 | 42 << 8
  ORIGINAL[1]: 3 << 16
  TYPE[1]: CALL
  TOKENIZED[1]: 3 << 16
  ORIGINAL[2]: 42 << 8
  TYPE[2]: CALL
  TOKENIZED[2]: 42 << 8

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477119
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !strcmp(cmd,\
  TYPE[0]: CALL
  TOKENIZED[0]: !strcmp ( VAR1 , \
  ORIGINAL[1]: filter -> filter
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR1
  ORIGINAL[2]: filter
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: filter
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772176
FRAGMENT_COUNT: 16
  ORIGINAL[0]: !pbuf
  TYPE[0]: CALL
  TOKENIZED[0]: !pbuf
  ORIGINAL[1]: !pbuf
  TYPE[1]: CALL
  TOKENIZED[1]: !pbuf
  ORIGINAL[2]: insamples > link -> partial_buf_size - pbuf -> audio -> nb_samples?link -> partial_buf_size - pbuf -> audio -> nb_samples : insamples
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 > VAR2 -> VAR3 - VAR4 -> VAR5 -> nb_samples?link -> VAR3 - VAR4 -> VAR5 -> VAR6 : VAR1
  ORIGINAL[3]: insamples > link -> partial_buf_size - pbuf -> audio -> nb_samples
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 > VAR2 -> VAR3 - VAR4 -> VAR5 -> VAR6
  ORIGINAL[4]: link -> partial_buf_size - pbuf -> audio -> nb_samples
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 - VAR3 -> VAR4 -> VAR5
  ORIGINAL[5]: link -> partial_buf_size - pbuf -> audio -> nb_samples
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 - VAR3 -> VAR4 -> VAR5
  ORIGINAL[6]: link -> partial_buf_size
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: pbuf -> audio -> nb_samples
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[8]: pbuf -> audio
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: partial_buf_size
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: audio
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: nb_samples
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: insamples
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: link
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: pbuf
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: insamples
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 68719476923
FRAGMENT_COUNT: 3
  ORIGINAL[0]: link -> closed = closed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: link -> closed
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: closed
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772010
FRAGMENT_COUNT: 8
  ORIGINAL[0]: filter -> filter -> init_opaque
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR1 -> VAR2
  ORIGINAL[1]: ret = ((filter -> filter -> init_opaque)(filter,args,opaque))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( VAR2 -> VAR2 -> VAR3 ) ( VAR2 , VAR4 , VAR5 ) )
  ORIGINAL[2]: (filter -> filter -> init_opaque)(filter,args,opaque)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 -> VAR1 -> VAR2 ) ( VAR1 , VAR3 , VAR4 )
  ORIGINAL[3]: filter -> filter -> init_opaque
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR1 -> VAR2
  ORIGINAL[4]: ret
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filter
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: args
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: opaque
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477100
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !link -> src -> inputs[i]
  TYPE[0]: CALL
  TOKENIZED[0]: !link -> VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: val = ff_poll_frame(link -> src -> inputs[i])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 -> VAR3 -> VAR4 [ VAR5 ] )
  ORIGINAL[2]: min = (min > val?val : min)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( VAR1 > val?val : VAR1 )
  ORIGINAL[3]: min > val?val : min
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 > val?val : VAR1
  ORIGINAL[4]: min
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: min
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: min
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477531
FRAGMENT_COUNT: 2
  ORIGINAL[0]: .item_name = default_filter_name
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: item_name
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772318
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 52 << 16 | 18 << 8
  TYPE[0]: CALL
  TOKENIZED[0]: 52 << 16 | 18 << 8
  ORIGINAL[1]: 52 << 16
  TYPE[1]: CALL
  TOKENIZED[1]: 52 << 16
  ORIGINAL[2]: 18 << 8
  TYPE[2]: CALL
  TOKENIZED[2]: 18 << 8

CENTER_NODE: 47244640345
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 11
  ORIGINAL[0]: i < filter -> nb_inputs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: filter -> nb_inputs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: !link
  TYPE[2]: CALL
  TOKENIZED[2]: !link
  ORIGINAL[3]: link -> init_state
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: config_link = link -> dstpad -> config_props
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2 -> VAR3 -> VAR4
  ORIGINAL[5]: (ret = config_link(link)) < 0
  TYPE[5]: CALL
  TOKENIZED[5]: ( VAR1 = FUN1 ( VAR2 ) ) < 0
  ORIGINAL[6]: nb_inputs
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: filter
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: filter
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: filter
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

