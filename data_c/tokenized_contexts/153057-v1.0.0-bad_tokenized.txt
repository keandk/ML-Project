# Tokenized code fragments for 153057-v1.0.0-bad
# Total center nodes processed: 34
# Total code fragments found: 168

CENTER_NODE: 30064771228
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 30064771169
FRAGMENT_COUNT: 1
  ORIGINAL[0]: after[200]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 200 ]

CENTER_NODE: 68719476901
FRAGMENT_COUNT: 3
  ORIGINAL[0]: state -> avail_in
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: avail_in
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: state
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771359
FRAGMENT_COUNT: 5
  ORIGINAL[0]: state -> pos = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: state -> pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pos
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: state
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771721
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fh -> err_info == ((void *)0)?((void *)0) : g_strdup(fh -> err_info)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 ) ? ( ( void * ) 0 ) : FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: fh -> err_info == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_tainted_file != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: fclose(stonesoup_tainted_file)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: stonesoup_tainted_file
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_tainted_file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477006
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ft == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: ft
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: ft
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771637
FRAGMENT_COUNT: 5
  ORIGINAL[0]: file -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> next++
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> next++
  ORIGINAL[2]: file -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: next
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: file
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477076
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771585
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> is_compressed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: is_compressed
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640310
FRAGMENT_COUNT: 2
  ORIGINAL[0]: whence == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 68719476855
FRAGMENT_COUNT: 5
  ORIGINAL[0]: state -> eof == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: state -> eof
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> avail_in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: avail_in
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771730
FRAGMENT_COUNT: 2
  ORIGINAL[0]: stream -> eof = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: stream -> eof
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 68719477082
FRAGMENT_COUNT: 5
  ORIGINAL[0]: fstat(stream -> fd,statb) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR3 ) == - 1
  ORIGINAL[1]: err != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: err
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: err
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771167
FRAGMENT_COUNT: 1
  ORIGINAL[0]: before[200]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 200 ]

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[128]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 128 ]

CENTER_NODE: 68719477201
FRAGMENT_COUNT: 9
  ORIGINAL[0]: file -> fd
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> out
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file -> in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file -> fast_seek_cur
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: file -> err = 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 = 0
  ORIGINAL[5]: file -> err
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: file -> err_info
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: err_info
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: file
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476771
FRAGMENT_COUNT: 6
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: sprintf(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: filepath
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771382
FRAGMENT_COUNT: 18
  ORIGINAL[0]: mkdir(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: adays_thermophilous != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: shaps_umbrellaless[29] = adays_thermophilous
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 29 ] = VAR2
  ORIGINAL[3]: shaps_umbrellaless[29]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 29 ]
  ORIGINAL[4]: pheidole_quickwork = &shaps_umbrellaless
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = &shaps_umbrellaless
  ORIGINAL[5]: &shaps_umbrellaless
  TYPE[5]: CALL
  TOKENIZED[5]: &shaps_umbrellaless
  ORIGINAL[6]: yuji_martinton = &pheidole_quickwork
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 = &pheidole_quickwork
  ORIGINAL[7]: &pheidole_quickwork
  TYPE[7]: CALL
  TOKENIZED[7]: &pheidole_quickwork
  ORIGINAL[8]: midwesterners_vandervelde(yuji_martinton)
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 )
  ORIGINAL[9]: adays_thermophilous
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: shaps_umbrellaless
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: adays_thermophilous
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: pheidole_quickwork
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: shaps_umbrellaless
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: yuji_martinton
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: pheidole_quickwork
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: yuji_martinton
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: fd
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 30064771734
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file -> fd = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = - 1
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1

CENTER_NODE: 68719476848
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ret < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: ret == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0
  ORIGINAL[2]: ret
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ret
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477178
FRAGMENT_COUNT: 4
  ORIGINAL[0]: file -> eof
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> avail_in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: avail_in
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640309
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477071
FRAGMENT_COUNT: 9
  ORIGINAL[0]: state -> compression
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: raw_read(state,state -> out,state -> size,&state -> have) == - 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , &state -> VAR4 ) == - 1
  ORIGINAL[2]: state -> out
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: state -> size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: state -> have
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: state -> next
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: next
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: state
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771607
FRAGMENT_COUNT: 16
  ORIGINAL[0]: file -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> have
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file -> have
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file -> have -= n
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -= VAR3
  ORIGINAL[4]: file -> have
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: have
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: file
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: file
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: file
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: n
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: file
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: file
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: file
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: file
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: file
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 68719477079
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> raw_pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: raw_pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771227
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 30064771343
FRAGMENT_COUNT: 4
  ORIGINAL[0]: state -> eof && state -> avail_in == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0
  ORIGINAL[1]: fill_out_buffer(state) == - 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) == - 1
  ORIGINAL[2]: fill_out_buffer(state)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: - 1
  TYPE[3]: CALL
  TOKENIZED[3]: - 1

CENTER_NODE: 30064771744
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1
  ORIGINAL[1]: !0
  TYPE[1]: CALL
  TOKENIZED[1]: !0

CENTER_NODE: 30064771268
FRAGMENT_COUNT: 29
  ORIGINAL[0]: !item || item -> out < out_pos
  TYPE[0]: CALL
  TOKENIZED[0]: !item || VAR1 -> VAR2 < VAR3
  ORIGINAL[1]: !item
  TYPE[1]: CALL
  TOKENIZED[1]: !item
  ORIGINAL[2]: item -> out < out_pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 < VAR3
  ORIGINAL[3]: *val = (struct fast_seek_point *)(g_malloc_n(1,sizeof(struct fast_seek_point )))
  TYPE[3]: CALL
  TOKENIZED[3]: *val = ( struct VAR1 * ) ( FUN1 ( 1 , sizeof ( struct VAR1 ) ) )
  ORIGINAL[4]: (struct fast_seek_point *)(g_malloc_n(1,sizeof(struct fast_seek_point )))
  TYPE[4]: CALL
  TOKENIZED[4]: ( struct VAR1 * ) ( FUN1 ( 1 , sizeof ( struct VAR1 ) ) )
  ORIGINAL[5]: g_malloc_n(1,sizeof(struct fast_seek_point ))
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( 1 , sizeof ( struct VAR1 ) )
  ORIGINAL[6]: sizeof(struct fast_seek_point )
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( struct VAR1 )
  ORIGINAL[7]: val -> in = in_pos
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 = VAR3
  ORIGINAL[8]: val -> in
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: val -> out = out_pos
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 = VAR3
  ORIGINAL[10]: val -> out
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: val -> compression = compression
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 = VAR2
  ORIGINAL[12]: val -> compression
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: g_ptr_array_add(file -> fast_seek,val)
  TYPE[13]: CALL
  TOKENIZED[13]: FUN1 ( VAR1 -> VAR2 , VAR3 )
  ORIGINAL[14]: file -> fast_seek
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: in
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: out
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: compression
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: fast_seek
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: val
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: struct fast_seek_point
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: struct VAR1
  ORIGINAL[21]: val
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: in_pos
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: val
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: out_pos
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: val
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: compression
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: file
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: val
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1

CENTER_NODE: 68719477074
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file_seek(file,delta,1,err)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 1 , VAR3 )
  ORIGINAL[1]: file
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: delta
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771239
FRAGMENT_COUNT: 5
  ORIGINAL[0]: low < max
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i = (low + max) / 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( VAR2 + VAR3 ) / 2
  ORIGINAL[2]: (low + max) / 2
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 + VAR2 ) / 2
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: item
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640342
FRAGMENT_COUNT: 1
  ORIGINAL[0]: file -> seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2

CENTER_NODE: 68719477008
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> fast_seek = seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: stream -> fast_seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: seek
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

