# Tokenized code fragments for 152983-v1.0.0-bad
# Total center nodes processed: 40
# Total code fragments found: 155

CENTER_NODE: 30064771283
FRAGMENT_COUNT: 5
  ORIGINAL[0]: errstart(20,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 20 , \
  ORIGINAL[1]: ('5' - 48 & 0x3F) + (('3' - 48 & 0x3F) << 6) + (('2' - 48 & 0x3F) << 12) + ((48 - 48 & 0x3F) << 18)
  TYPE[1]: CALL
  TOKENIZED[1]: ( '5' - 48 & 0x3F ) + ( ( '3' - 48 & 0x3F ) << 6 ) + ( ( '2' - 48 & 0x3F ) << 12 ) + ( ( 48 - 48 & 0x3F ) << 18 )
  ORIGINAL[2]: ('5' - 48 & 0x3F) + (('3' - 48 & 0x3F) << 6) + (('2' - 48 & 0x3F) << 12)
  TYPE[2]: CALL
  TOKENIZED[2]: ( '5' - 48 & 0x3F ) + ( ( '3' - 48 & 0x3F ) << 6 ) + ( ( '2' - 48 & 0x3F ) << 12 )
  ORIGINAL[3]: ('5' - 48 & 0x3F) + (('3' - 48 & 0x3F) << 6)
  TYPE[3]: CALL
  TOKENIZED[3]: ( '5' - 48 & 0x3F ) + ( ( '3' - 48 & 0x3F ) << 6 )
  ORIGINAL[4]: ('2' - 48 & 0x3F) << 12
  TYPE[4]: CALL
  TOKENIZED[4]: ( '2' - 48 & 0x3F ) << 12

CENTER_NODE: 30064771629
FRAGMENT_COUNT: 9
  ORIGINAL[0]: hashp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: hash_stats(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: MemoryContextDelete(hashp -> hcxt)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[4]: hashp -> hcxt
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: hcxt
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hashp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hashp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: hashp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640385
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771634
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: hashp -> hash
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hashp -> keysize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: keyPtr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640268
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771511
FRAGMENT_COUNT: 2
  ORIGINAL[0]: !hashp -> dir
  TYPE[0]: CALL
  TOKENIZED[0]: !hashp -> VAR1
  ORIGINAL[1]: (bool )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) 0

CENTER_NODE: 68719476791
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_printf_context != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context != stderr
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> stonesoup_printf_context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: stderr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476988
FRAGMENT_COUNT: 5
  ORIGINAL[0]: allocSize / elementSize
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / VAR2
  ORIGINAL[1]: nelem_alloc < 32
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 32
  ORIGINAL[2]: elementSize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: allocSize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: elementSize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771615
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (num_entries - 1) / 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 - 1 ) / 1
  ORIGINAL[1]: num_entries - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: num_entries
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772347
FRAGMENT_COUNT: 8
  ORIGINAL[0]: hctlv -> num_partitions != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != 0
  ORIGINAL[1]: tas(&hctlv -> mutex)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &hctlv -> VAR1 )
  ORIGINAL[2]: &hctlv -> mutex
  TYPE[2]: CALL
  TOKENIZED[2]: &hctlv -> VAR1
  ORIGINAL[3]: s_lock(&hctlv -> mutex,\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( &hctlv -> VAR1 , \
  ORIGINAL[4]: &hctlv -> mutex
  TYPE[4]: CALL
  TOKENIZED[4]: &hctlv -> VAR1
  ORIGINAL[5]: hctlv -> mutex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: mutex
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hctlv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477573
FRAGMENT_COUNT: 5
  ORIGINAL[0]: limit < num
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: limit <<= 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <<= 1
  ORIGINAL[3]: limit
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: limit
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477627
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: seq_scan_level[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> seq_scan_level
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476764
FRAGMENT_COUNT: 6
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: size_filepath = strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: strlen(dirpath) + strlen(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[3]: size_filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size_filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477575
FRAGMENT_COUNT: 2
  ORIGINAL[0]: my_log2(num)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: num
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477508
FRAGMENT_COUNT: 7
  ORIGINAL[0]: (((intptr_t )_vstart) & sizeof(long ) - 1) == 0 && (_len & sizeof(long ) - 1) == 0 && _val == 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( VAR1 ) VAR2 ) & sizeof ( long ) - 1 ) == 0 && ( VAR3 & sizeof ( long ) - 1 ) == 0 && VAR4 == 0
  ORIGINAL[1]: _len <= 1024
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= 1024
  ORIGINAL[2]: _len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: _len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: _len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 4
  ORIGINAL[0]: hctl -> keysize = sizeof(char *)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = sizeof ( char * )
  ORIGINAL[1]: hctl -> keysize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(char *)
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( char * )
  ORIGINAL[3]: hctl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772077
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !status -> hashp -> frozen
  TYPE[0]: CALL
  TOKENIZED[0]: !status -> VAR1 -> VAR2
  ORIGINAL[1]: status -> hashp -> frozen
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: status -> hashp
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: status -> hashp
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: frozen
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772216
FRAGMENT_COUNT: 5
  ORIGINAL[0]: p != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)(((char *)p) + old_dirsize)
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) ( ( ( char * ) VAR1 ) + VAR2 )
  ORIGINAL[2]: ((char *)p) + old_dirsize
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( char * ) VAR1 ) + VAR2
  ORIGINAL[3]: (char *)p
  TYPE[3]: CALL
  TOKENIZED[3]: ( char * ) VAR1
  ORIGINAL[4]: old_dirsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640389
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 68719477318
FRAGMENT_COUNT: 16
  ORIGINAL[0]: (curElem = status -> curEntry) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 ) != ( ( void * ) 0 )
  ORIGINAL[1]: curBucket = status -> curBucket
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR1
  ORIGINAL[2]: hashp = status -> hashp
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR1
  ORIGINAL[3]: status -> hashp
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: hashp -> hctl
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: hashp -> ssize
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: hashp -> sshift
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: hashp -> dir
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: hashp -> dir
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: hashp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: status
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: hashp
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: hashp
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: hashp
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: hashp
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: hashp
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 30064771983
FRAGMENT_COUNT: 5
  ORIGINAL[0]: hashp -> hctl -> nentries
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: hashp -> hctl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hctl
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: nentries
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772454
FRAGMENT_COUNT: 1
  ORIGINAL[0]: *seq_scan_tables[100]
  TYPE[0]: CALL
  TOKENIZED[0]: *seq_scan_tables [ 100 ]

CENTER_NODE: 30064771626
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(HASHHDR ) + (info -> dsize) * sizeof(HASHSEGMENT )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 ) + ( VAR2 -> VAR3 ) * sizeof ( VAR4 )
  ORIGINAL[1]: (info -> dsize) * sizeof(HASHSEGMENT )
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 ) * sizeof ( VAR3 )
  ORIGINAL[2]: info -> dsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(HASHSEGMENT )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( VAR1 )

CENTER_NODE: 47244640351
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !hashp -> frozen
  TYPE[0]: CALL
  TOKENIZED[0]: !hashp -> VAR1

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771705
FRAGMENT_COUNT: 6
  ORIGINAL[0]: hash_search_with_hash_value(hashp,keyPtr,((hashp -> hash)(keyPtr,hashp -> keysize)),action,foundPtr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , ( ( VAR1 -> VAR3 ) ( VAR2 , VAR1 -> VAR4 ) ) , VAR5 , VAR6 )
  ORIGINAL[1]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[2]: hashp -> hash
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hashp -> keysize
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: keyPtr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: action
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477119
FRAGMENT_COUNT: 6
  ORIGINAL[0]: orchel_amroc != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: strlen(stonesoup_source) + 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) + 1
  ORIGINAL[2]: sizeof(stonesoup_buff)
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: stonesoup_buff
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_buff
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_buff
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477576
FRAGMENT_COUNT: 4
  ORIGINAL[0]: num > (2147483647 / 2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > ( 2147483647 / 2 )
  ORIGINAL[1]: 2147483647 / 2
  TYPE[1]: CALL
  TOKENIZED[1]: 2147483647 / 2
  ORIGINAL[2]: num
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: num
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640377
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771562
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((intptr_t )(sizeof(HASHHDR ))) + (8 - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 )
  ORIGINAL[1]: (intptr_t )(sizeof(HASHHDR ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) ( sizeof ( VAR2 ) )
  ORIGINAL[2]: sizeof(HASHHDR )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: intptr_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 4
  ORIGINAL[0]: currElement =  *oldlink
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = *oldlink
  ORIGINAL[1]: currElement != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[2]: currElement = nextElement
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: for (currElement =  *oldlink;currElement != ((void *)0);currElement = nextElement)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = *oldlink ; VAR1 != ( ( void * ) 0 ) ; VAR1 = VAR2 )

CENTER_NODE: 30064772090
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !hashp -> frozen && has_seq_scans(hashp)
  TYPE[0]: CALL
  TOKENIZED[0]: !hashp -> VAR1 && FUN1 ( VAR2 )
  ORIGINAL[1]: elog_finish(20,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( 20 , \
  ORIGINAL[2]: hashp -> tabname
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 47244640342
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771979
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *((volatile slock_t *)(&hctlv -> mutex))
  TYPE[0]: CALL
  TOKENIZED[0]: * ( ( volatile VAR1 * ) ( &hctlv -> VAR2 ) )
  ORIGINAL[1]: hctlv -> num_partitions != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 != 0
  ORIGINAL[2]: *((volatile slock_t *)(&hctlv -> mutex))
  TYPE[2]: CALL
  TOKENIZED[2]: * ( ( volatile VAR1 * ) ( &hctlv -> VAR2 ) )
  ORIGINAL[3]: (volatile slock_t *)(&hctlv -> mutex)
  TYPE[3]: CALL
  TOKENIZED[3]: ( volatile VAR1 * ) ( &hctlv -> VAR2 )
  ORIGINAL[4]: &hctlv -> mutex
  TYPE[4]: CALL
  TOKENIZED[4]: &hctlv -> VAR1

CENTER_NODE: 30064771933
FRAGMENT_COUNT: 6
  ORIGINAL[0]: currBucket == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: action == HASH_ENTER_NULL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: ((char *)currBucket) + (((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1)))
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( char * ) VAR1 ) + ( ( ( VAR2 ) ( sizeof ( VAR3 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) )
  ORIGINAL[3]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) )
  ORIGINAL[4]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1)
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 )
  ORIGINAL[5]: ~((intptr_t )(8 - 1))
  TYPE[5]: CALL
  TOKENIZED[5]: ~ ( ( VAR1 ) ( 8 - 1 ) )

CENTER_NODE: 68719476800
FRAGMENT_COUNT: 5
  ORIGINAL[0]: strncmp(key1,key2,keysize - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 - 1 )
  ORIGINAL[1]: keysize - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: key1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: keysize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

