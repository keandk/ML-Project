# Tokenized code fragments for 152736-v1.0.0-bad
# Total center nodes processed: 141
# Total code fragments found: 417

CENTER_NODE: 47244640557
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719477361
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cur_mb_len <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: cur_mb_len = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: <global> cur_mb_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> cur_mb_len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719479068
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> fails[works]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: rval = TRANSIT_STATE_DONE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: TRANSIT_STATE_DONE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: TRANSIT_STATE_DONE
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775130
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> tokens[pos . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: rarray[i] = match_mb_charset(d,s,pos,idx)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[2]: rarray[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: match_mb_charset(d,s,pos,idx)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: idx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719479620
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaoptimize(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaanalyze(d,searchflag)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: searchflag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640620
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478301
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476898
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sbit[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: setbit(i,letters)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> letters
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719478136
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> salloc <= d -> sindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: d -> salloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_n_alloc = (d -> sindex + 1 + (!d -> states))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( VAR2 -> VAR3 + 1 + ( !d -> VAR4 ) )
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> states
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: states
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775733
FRAGMENT_COUNT: 8
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: cpp[i] = ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[3]: cpp[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: cpp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775521
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < p -> nequivs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++j
  TYPE[1]: CALL
  TOKENIZED[1]: ++j
  ORIGINAL[2]: for (j = 0;j < p -> nequivs;++j)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640618
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775465
FRAGMENT_COUNT: 11
  ORIGINAL[0]: s >= 0 && ((char *)p) <= end && d -> fails[s]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0 && ( ( char * ) VAR2 ) <= VAR3 && VAR4 -> VAR5 [ VAR1 ]
  ORIGINAL[1]: ((char *)p) <= end
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( char * ) VAR1 ) <= VAR2
  ORIGINAL[2]: ((char *)p) <= end && p[- 1] == eol
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( char * ) VAR1 ) <= VAR2 && VAR1 [ - 1 ] == VAR3
  ORIGINAL[3]: ((char *)p) <= end
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( char * ) VAR1 ) <= VAR2
  ORIGINAL[4]: (char *)p
  TYPE[4]: CALL
  TOKENIZED[4]: ( char * ) VAR1
  ORIGINAL[5]: p[- 1] == eol
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ - 1 ] == VAR2
  ORIGINAL[6]: p[- 1]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ - 1 ]
  ORIGINAL[7]: - 1
  TYPE[7]: CALL
  TOKENIZED[7]: - 1
  ORIGINAL[8]: end
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: eol
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064773022
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: branch()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064775707
FRAGMENT_COUNT: 5
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: oldsize + newsize + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2 + 1
  ORIGINAL[2]: oldsize + newsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: oldsize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: newsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640337
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772764
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dfa -> nmultibyte_prop <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: new_n_alloc = dfa -> tindex + 1 + (!dfa -> multibyte_prop)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 + 1 + ( !dfa -> VAR4 )
  ORIGINAL[2]: dfa -> tindex + 1 + (!dfa -> multibyte_prop)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1 + ( !dfa -> VAR3 )
  ORIGINAL[3]: dfa -> tindex + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 + 1
  ORIGINAL[4]: !dfa -> multibyte_prop
  TYPE[4]: CALL
  TOKENIZED[4]: !dfa -> VAR1
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640895
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640586
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774900
FRAGMENT_COUNT: 17
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: (wchar_t )eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[2]: CALL
  TOKENIZED[2]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[3]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[4]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[5]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1
  TYPE[5]: CALL
  TOKENIZED[5]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1
  ORIGINAL[6]: ((unsigned long )1) << 1 << 1 << 1 << 1
  TYPE[6]: CALL
  TOKENIZED[6]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1
  ORIGINAL[7]: ((unsigned long )1) << 1 << 1 << 1
  TYPE[7]: CALL
  TOKENIZED[7]: ( ( unsigned long ) 1 ) << 1 << 1 << 1
  ORIGINAL[8]: ((unsigned long )1) << 1 << 1
  TYPE[8]: CALL
  TOKENIZED[8]: ( ( unsigned long ) 1 ) << 1 << 1
  ORIGINAL[9]: ((unsigned long )1) << 1
  TYPE[9]: CALL
  TOKENIZED[9]: ( ( unsigned long ) 1 ) << 1
  ORIGINAL[10]: (unsigned long )1
  TYPE[10]: CALL
  TOKENIZED[10]: ( unsigned long ) 1
  ORIGINAL[11]: wc == ((wchar_t )'\\0')
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[12]: (wchar_t )'\\0'
  TYPE[12]: CALL
  TOKENIZED[12]: ( VAR1 ) '\\0'
  ORIGINAL[13]: wc
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: <global> syntax_bits
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: wc
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: context
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640830
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640708
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773742
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> tokens[i] != PLUS
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] != VAR4
  ORIGINAL[3]: d -> tokens[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: d -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tokens[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: d -> tokens
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> tokens[i]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[8]: d -> tokens
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: PLUS
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064774635
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ( *d) . states[s] . constraint >> 8 & 0xf
  TYPE[0]: CALL
  TOKENIZED[0]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf
  ORIGINAL[1]: 1 & 4?( *d) . states[s] . constraint >> 8 & 0xf : 0
  TYPE[1]: CALL
  TOKENIZED[1]: 1 & 4? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf : 0
  ORIGINAL[2]: 1 & 4
  TYPE[2]: CALL
  TOKENIZED[2]: 1 & 4
  ORIGINAL[3]: ( *d) . states[s] . constraint >> 8 & 0xf
  TYPE[3]: CALL
  TOKENIZED[3]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf
  ORIGINAL[4]: ( *d) . states[s] . constraint >> 8
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8

CENTER_NODE: 30064775712
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477925
FRAGMENT_COUNT: 4
  ORIGINAL[0]: lexleft = len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: lasttok = END
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: <global> lasttok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: END
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640392
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773484
FRAGMENT_COUNT: 18
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[2]: d -> tokens[s -> elems[i] . index] >= (1 << 8)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 )
  ORIGINAL[3]: d -> tokens[s -> elems[i] . index]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[4]: 1 << 8
  TYPE[4]: CALL
  TOKENIZED[4]: 1 << 8
  ORIGINAL[5]: d -> tokens[s -> elems[i] . index] != BACKREF
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[6]: d -> tokens[s -> elems[i] . index]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[7]: d -> tokens
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: s -> elems[i] . index
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[9]: s -> elems[i]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[10]: s -> elems
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: tokens
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: elems
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: index
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: s
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: i
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: BACKREF
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776351
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 30064776353
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476835
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775851
FRAGMENT_COUNT: 12
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: new[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: ++i
  TYPE[3]: CALL
  TOKENIZED[3]: ++i
  ORIGINAL[4]: old == ((void *)0)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: break;
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: break ;
  ORIGINAL[7]: new
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: old
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: old
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719479802
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *both
  TYPE[0]: CALL
  TOKENIZED[0]: *both
  ORIGINAL[1]: both == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: both[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: both
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: both
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476793
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476771
FRAGMENT_COUNT: 6
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: sprintf(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: filepath
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776083
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !(strcmp((lmp -> is),(rmp -> is)) == 0)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) ) == 0 )
  ORIGINAL[1]: lmp -> is[0] = '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[2]: lmp -> is[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771182
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640672
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773191
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < s1 -> nelem && j < s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 && VAR4 < VAR5 -> VAR3
  ORIGINAL[1]: i < s1 -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: j < s2 -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2 -> VAR3
  ORIGINAL[3]: s2 -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640499
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ++p != lim && ((unsigned int )( *p)) - 48 <= 9
  TYPE[0]: CALL
  TOKENIZED[0]: ++p != VAR1 && ( ( unsigned int ) ( *p ) ) - 48 <= 9
  ORIGINAL[1]: while (++p != lim && ((unsigned int )( *p)) - 48 <= 9)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: while ( ++p != VAR1 && ( ( unsigned int ) ( *p ) ) - 48 <= 9 )

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771268
FRAGMENT_COUNT: 2
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: __ctype_get_mb_cur_max()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )

CENTER_NODE: 47244640866
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: ++dfa -> VAR1
  ORIGINAL[2]: copyset(s,dfa -> charclasses[i])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771239
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum) || c == '_'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) || VAR1 == '_'
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum)
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[2]: ( *__ctype_b_loc())[(int )c]
  TYPE[2]: CALL
  TOKENIZED[2]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[3]: (unsigned short )_ISalnum
  TYPE[3]: CALL
  TOKENIZED[3]: ( unsigned short ) VAR1
  ORIGINAL[4]: c == '_'
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == '_'
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476922
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772969
FRAGMENT_COUNT: 12
  ORIGINAL[0]: tok == QMARK || tok == STAR || tok == PLUS || tok == REPMN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[1]: tok == QMARK || tok == STAR || tok == PLUS
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[2]: tok == QMARK || tok == STAR
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2 || VAR1 == VAR3
  ORIGINAL[3]: tok == QMARK
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == VAR2
  ORIGINAL[4]: tok == REPMN
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: tok == REPMN && (minrep || maxrep)
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[6]: tok == REPMN
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 == VAR2
  ORIGINAL[7]: while (tok == QMARK || tok == STAR || tok == PLUS || tok == REPMN)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: while ( VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 )
  ORIGINAL[8]: <global> tok
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: QMARK
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> tok
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: REPMN
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640806
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479728
FRAGMENT_COUNT: 9
  ORIGINAL[0]: cpp[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: cpp[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: --i == j
  TYPE[2]: CALL
  TOKENIZED[2]: --i == VAR1
  ORIGINAL[3]: cpp[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: cpp[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064773566
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tstbit(eolbyte,c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: context |= 4
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 4
  ORIGINAL[2]: context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640988
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480155
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477796
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: addtok_mb(t,3)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 3 )
  ORIGINAL[2]: t
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773110
FRAGMENT_COUNT: 12
  ORIGINAL[0]: lo < hi
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: s -> elems[mid] . index > p . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 . VAR4
  ORIGINAL[2]: s -> elems[mid] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: p . index
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: lo = mid + 1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2 + 1
  ORIGINAL[5]: mid + 1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 + 1
  ORIGINAL[6]: hi = mid
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 = VAR2
  ORIGINAL[7]: lo
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: lo
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: mid
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: hi
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: mid
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640648
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773019
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: addtok(CAT)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: CAT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479124
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[1]: mblen_buf[idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: match_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> mblen_buf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: idx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775810
FRAGMENT_COUNT: 23
  ORIGINAL[0]: ( *lcp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *lcp ) != '\\0'
  ORIGINAL[1]: rcp != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: i = 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 1
  ORIGINAL[4]: lcp[i] != '\\0' && lcp[i] == rcp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ] != '\\0' && VAR1 [ VAR2 ] == VAR3 [ VAR2 ]
  ORIGINAL[5]: lcp[i] != '\\0'
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ] != '\\0'
  ORIGINAL[6]: lcp[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: i > len
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 > VAR2
  ORIGINAL[8]: rcp = strchr((rcp + 1),( *lcp))
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 = FUN1 ( ( VAR1 + 1 ) , ( *lcp ) )
  ORIGINAL[9]: strchr((rcp + 1),( *lcp))
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( ( VAR1 + 1 ) , ( *lcp ) )
  ORIGINAL[10]: rcp + 1
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 + 1
  ORIGINAL[11]: *lcp
  TYPE[11]: CALL
  TOKENIZED[11]: *lcp
  ORIGINAL[12]: while (rcp != ((void *)0))
  TYPE[12]: CONTROL_STRUCTURE
  TOKENIZED[12]: while ( VAR1 != ( ( void * ) 0 ) )
  ORIGINAL[13]: rcp
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: lcp
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: i
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: i
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: len
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: rcp
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: rcp
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: lcp
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: len
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1

CENTER_NODE: 47244640939
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476810
FRAGMENT_COUNT: 3
  ORIGINAL[0]: LPAREN=270
  TYPE[0]: CALL
  TOKENIZED[0]: LPAREN=270
  ORIGINAL[1]: RPAREN=271
  TYPE[1]: CALL
  TOKENIZED[1]: RPAREN=271
  ORIGINAL[2]: RPAREN
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772894
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064775557
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> charclasses)) == 1?xmalloc(d -> calloc) : xnmalloc(d -> calloc,sizeof(( *d -> charclasses)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *d -> charclasses)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xnmalloc(d -> calloc,sizeof(( *d -> charclasses)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[3]: d -> calloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: sizeof(( *d -> charclasses))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *d -> VAR1 ) )

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640596
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771251
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == '_' || iswalnum(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '_' || FUN1 ( VAR1 )
  ORIGINAL[2]: wc == '_'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == '_'
  ORIGINAL[3]: iswalnum(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640704
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776370
FRAGMENT_COUNT: 3
  ORIGINAL[0]: {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: { { ( \
  ORIGINAL[1]: {(\
  TYPE[1]: CALL
  TOKENIZED[1]: { ( \
  ORIGINAL[2]: isalpha
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771151
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773092
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *s -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: *s -> VAR1
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: elems
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640816
FRAGMENT_COUNT: 1
  ORIGINAL[0]: work_mbls[i] ==  *mbclen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == *mbclen

CENTER_NODE: 68719479637
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> charclasses
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: i < d -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 < VAR2 -> VAR3
  ORIGINAL[6]: d -> tindex
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tindex
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719478090
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640588
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771170
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )

CENTER_NODE: 47244640414
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640384
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 1
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]

CENTER_NODE: 68719476845
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478817
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < ngrps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: (separate_contexts & possible_contexts) != possible_contexts
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 & VAR2 ) != VAR2
  ORIGINAL[2]: separate_contexts & possible_contexts
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & VAR2
  ORIGINAL[3]: possible_contexts
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: possible_contexts
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: possible_contexts
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640394
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479016
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> realtrans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: tralloc
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477855
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: tindex + i
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tindex
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tindex
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479689
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: strncmp(cp,lookfor,len)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lookfor
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776365
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640746
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771163
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479828
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> left[0] = mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = VAR1 -> VAR4 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: in
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640750
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640540
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774772
FRAGMENT_COUNT: 20
  ORIGINAL[0]: d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(( *d -> fails)) == 1
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: xcalloc((d -> tralloc),sizeof(( *d -> fails)))
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( VAR1 -> VAR2 ) , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: sizeof(( *d -> fails))
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[7]: d -> tralloc
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: d -> tralloc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: tralloc
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: d
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773062
FRAGMENT_COUNT: 10
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: src -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: src -> nelem + (!dst -> elems)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + ( !dst -> VAR3 )
  ORIGINAL[3]: src -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: src -> nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nelem
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: src
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dst
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: src
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: src
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775260
FRAGMENT_COUNT: 6
  ORIGINAL[0]: nelem == 0 || maxlen == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 == 0
  ORIGINAL[1]: *pp - p1 < maxlen
  TYPE[1]: CALL
  TOKENIZED[1]: *pp - VAR1 < VAR2
  ORIGINAL[2]: *pp - p1
  TYPE[2]: CALL
  TOKENIZED[2]: *pp - VAR1
  ORIGINAL[3]: *pp
  TYPE[3]: CALL
  TOKENIZED[3]: *pp
  ORIGINAL[4]: p1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: maxlen
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640538
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477841
FRAGMENT_COUNT: 2
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: PLUS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774862
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_DONE
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640869
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640435
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

