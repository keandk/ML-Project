# Tokenized code fragments for 153071-v1.0.0-bad
# Total center nodes processed: 144
# Total code fragments found: 392

CENTER_NODE: 68719480187
FRAGMENT_COUNT: 2
  ORIGINAL[0]: {(\
  TYPE[0]: CALL
  TOKENIZED[0]: { ( \
  ORIGINAL[1]: isalnum
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640872
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640602
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640812
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640313
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640408
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640400
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776401
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640544
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771326
FRAGMENT_COUNT: 8
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISalpha)
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )b]
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[2]: *__ctype_b_loc()
  TYPE[2]: CALL
  TOKENIZED[2]: *__ctype_b_loc ( )
  ORIGINAL[3]: (int )b
  TYPE[3]: CALL
  TOKENIZED[3]: ( int ) VAR1
  ORIGINAL[4]: (unsigned short )_ISalpha
  TYPE[4]: CALL
  TOKENIZED[4]: ( unsigned short ) VAR1
  ORIGINAL[5]: ( *__ctype_b_loc())[(int )b]
  TYPE[5]: CALL
  TOKENIZED[5]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[6]: *__ctype_b_loc()
  TYPE[6]: CALL
  TOKENIZED[6]: *__ctype_b_loc ( )
  ORIGINAL[7]: <global> case_fold
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 68719479835
FRAGMENT_COUNT: 7
  ORIGINAL[0]: both == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: both[0] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ] = ( ( void * ) 0 )
  ORIGINAL[2]: lnum = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: lnum
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lnum
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: lnum
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: lnum
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771747
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cur_mb_len <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: cur_mb_len = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: <global> cur_mb_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> lexleft
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719476876
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773810
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < nlastpos[- 2]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 [ - 2 ]
  ORIGINAL[1]: d -> follows[pos[j] . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 [ VAR4 ] . VAR5 ]
  ORIGINAL[2]: pos[j] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: pos[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: index
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771208
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 8 * sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: 8 * sizeof ( int )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 68719478943
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 2 & 4
  TYPE[0]: CALL
  TOKENIZED[0]: 2 & 4
  ORIGINAL[1]: ( *d) . states[s]
  TYPE[1]: CALL
  TOKENIZED[1]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[2]: ( *d) . states
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773076
FRAGMENT_COUNT: 3
  ORIGINAL[0]: parens = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: __ctype_get_mb_cur_max() > 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ) > 1
  ORIGINAL[2]: __ctype_get_mb_cur_max()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064775745
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new == ((void *)0)?0 : strlen(new)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[1]: new == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: strlen(new)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: new
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771194
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064773311
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640343
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773232
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i < s1 -> nelem && j < s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 && VAR4 < VAR5 -> VAR3
  ORIGINAL[1]: i < s1 -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: s1 -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: j < s2 -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 < VAR2 -> VAR3
  ORIGINAL[4]: s2 -> nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nelem
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: j
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s2
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064775863
FRAGMENT_COUNT: 8
  ORIGINAL[0]: rcp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: i > len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 > VAR2
  ORIGINAL[2]: len = i
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: rcp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640564
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771213
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772976
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: tokens
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> dfa
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478319
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: context
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: context
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477948
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: OR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774959
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )'\\0')
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: ((unsigned long )1) << 1 << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1

CENTER_NODE: 68719479611
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *d
  TYPE[0]: CALL
  TOKENIZED[0]: *d
  ORIGINAL[1]: d -> calloc = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = 1
  ORIGINAL[2]: d -> calloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> charclasses
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> calloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> calloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: charclasses
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640431
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640592
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774782
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> tralloc = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 1
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: tralloc
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640836
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479475
FRAGMENT_COUNT: 10
  ORIGINAL[0]: inputwcs[p - buf_begin] == 0 && mblen_buf[p - buf_begin] > 0 && ((const unsigned char *)p) < buf_end
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 - VAR3 ] == 0 && VAR4 [ VAR2 - VAR3 ] > 0 && ( ( const unsigned char * ) VAR2 ) < VAR5
  ORIGINAL[1]: ++p
  TYPE[1]: CALL
  TOKENIZED[1]: ++p
  ORIGINAL[2]: &p
  TYPE[2]: CALL
  TOKENIZED[2]: &p
  ORIGINAL[3]: &p
  TYPE[3]: CALL
  TOKENIZED[3]: &p
  ORIGINAL[4]: p[- 1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ - 1 ]
  ORIGINAL[5]: p[- 1]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ - 1 ]
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640624
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775891
FRAGMENT_COUNT: 10
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: new[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: enlist(old,new[i],strlen(new[i]))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[3]: new[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: new[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640600
FRAGMENT_COUNT: 1
  ORIGINAL[0]: s -> alloc <= count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 + 1

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476835
FRAGMENT_COUNT: 3
  ORIGINAL[0]: NOTLIMWORD=263
  TYPE[0]: CALL
  TOKENIZED[0]: NOTLIMWORD=263
  ORIGINAL[1]: QMARK=264
  TYPE[1]: CALL
  TOKENIZED[1]: QMARK=264
  ORIGINAL[2]: QMARK
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775670
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> mb_cur_max = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = 1
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 68719479647
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfainit(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaparse(s,len,d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479722
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *cp
  TYPE[0]: CALL
  TOKENIZED[0]: *cp
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: (char *)cp
  TYPE[2]: CALL
  TOKENIZED[2]: ( char * ) VAR1
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775144
FRAGMENT_COUNT: 6
  ORIGINAL[0]: sizeof(( *rarray)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *rarray ) ) == 1
  ORIGINAL[1]: d -> states[s]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> states
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: states
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640441
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640398
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771301
FRAGMENT_COUNT: 15
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: sbit[i] = char_context(i)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] = FUN1 ( VAR2 )
  ORIGINAL[4]: sbit[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: char_context(i)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 )
  ORIGINAL[6]: sbit[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: for (i = 0;i < (1 << 8);++i)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> sbit
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: i
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: <global> sbit
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 68719479687
FRAGMENT_COUNT: 17
  ORIGINAL[0]: d -> charclasses
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> follows
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> tralloc
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: d -> realtrans
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: d -> fails
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: d -> newlines
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: d -> success
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: d -> musts
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: musts
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: dm
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 30064772295
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: backslash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771171
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 47244640626
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771278
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> eolbyte
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772847
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[dfa -> tindex++] = t
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR1 -> tindex++ ] = VAR3
  ORIGINAL[1]: dfa -> tokens[dfa -> tindex++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> tindex++ ]
  ORIGINAL[2]: dfa -> tokens
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> tindex++
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> tindex++
  ORIGINAL[4]: t
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479156
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[1]: mblen_buf[idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: match_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> mblen_buf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: idx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640633
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771239
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: s[i] = ~s[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[2]: s[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: ~s[i]
  TYPE[3]: CALL
  TOKENIZED[3]: ~s [ VAR1 ]
  ORIGINAL[4]: s[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064773133
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[1]: sizeof(( *s -> elems))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[2]: *s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: *s -> VAR1

CENTER_NODE: 68719478163
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> salloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> sindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> states
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> salloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: salloc
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719479859
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> is
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: is
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479723
FRAGMENT_COUNT: 8
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: cpp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771202
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )

CENTER_NODE: 47244640390
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776387
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 68719477943
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok != RPAREN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> tok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 30064773639
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j] . constraint >> 2 & 0x111
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111
  ORIGINAL[2]: s -> elems[j] . constraint >> 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2
  ORIGINAL[3]: s -> elems[j] . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775265
FRAGMENT_COUNT: 7
  ORIGINAL[0]: nelem > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: match_lens = check_matching_with_multibyte_ops(d,s,( *pp - buf_begin))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , ( *pp - VAR4 ) )
  ORIGINAL[2]: check_matching_with_multibyte_ops(d,s,( *pp - buf_begin))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , ( *pp - VAR3 ) )
  ORIGINAL[3]: *pp - buf_begin
  TYPE[3]: CALL
  TOKENIZED[3]: *pp - VAR1
  ORIGINAL[4]: match_lens
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640901
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640710
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640980
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640355
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771275
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> charclasses[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: copyset(s,dfa -> charclasses[i])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[3]: dfa -> charclasses[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: dfa -> charclasses
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640756
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477923
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < minrep
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: copytoks(tindex,ntokens)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: tindex
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ntokens
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tindex
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719478617
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !((((2 & 1?pos . constraint & 0xf : 0)) | ((2 & 2?pos . constraint >> 4 & 0xf : 0)) | ((2 & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( ( ( 2 & 1?pos . VAR1 & 0xf : 0 ) ) | ( ( 2 & 2?pos . VAR1 >> 4 & 0xf : 0 ) ) | ( ( 2 & 4?pos . VAR1 >> 8 & 0xf : 0 ) ) ) & VAR2 -> VAR3 [ VAR4 ] . VAR5 )
  ORIGINAL[1]: j = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[3]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[4]: ++j
  TYPE[4]: CALL
  TOKENIZED[4]: ++j
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: j
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: j
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: j
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640556
FRAGMENT_COUNT: 1
  ORIGINAL[0]: need_or
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774906
FRAGMENT_COUNT: 2
  ORIGINAL[0]: TRANSIT_STATE_END_BUFFER=2
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640380
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476909
FRAGMENT_COUNT: 5
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: (wchar_t )eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640423
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640599
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640311
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774896
FRAGMENT_COUNT: 6
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> trans[oldalloc] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] = ( ( void * ) 0 )
  ORIGINAL[2]: d -> trans[oldalloc]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: d -> trans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: oldalloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640364
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771224
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771080
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ss_tc_root = getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: ss_tc_root
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ss_tc_root
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477885
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[3]: dfa -> multibyte_prop[dfa -> tindex - 1] = dfa -> multibyte_prop[tindex + i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ] = VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771342
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476825
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640714
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476823
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c - 32
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 32
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480172
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771225
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477980
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: src -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dst -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dst
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640353
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772932
FRAGMENT_COUNT: 5
  ORIGINAL[0]: 1 && tok == WCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2
  ORIGINAL[1]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[1]: CALL
  TOKENIZED[1]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[2]: 1 && tok == ANYCHAR
  TYPE[2]: CALL
  TOKENIZED[2]: 1 && VAR1 == VAR2
  ORIGINAL[3]: tok == ANYCHAR
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == VAR2
  ORIGINAL[4]: using_utf8()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )

CENTER_NODE: 30064775785
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (new = icpyalloc(new)) == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR1 ) ) == ( ( void * ) 0 )
  ORIGINAL[1]: freelist(cpp)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cpp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479712
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640546
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773540
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[2]: d -> tokens[s -> elems[i] . index] != ANYCHAR
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[3]: d -> tokens[s -> elems[i] . index]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[4]: ANYCHAR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479604
FRAGMENT_COUNT: 13
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: p -> chars
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: p -> ch_classes
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: p -> range_sts
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: p -> range_ends
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: p -> nequivs
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: p -> equivs
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: j < p -> ncoll_elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 < VAR2 -> VAR3
  ORIGINAL[8]: p -> ncoll_elems
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: p -> coll_elems
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: coll_elems
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 68719479078
FRAGMENT_COUNT: 4
  ORIGINAL[0]: rval == TRANSIT_STATE_IN_PROGRESS
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: rval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: TRANSIT_STATE_IN_PROGRESS
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775238
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[1]: d -> follows[d -> states[s] . mbps . elems[i] . index] . elems[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6 [ VAR9 ]
  ORIGINAL[2]: d -> follows[d -> states[s] . mbps . elems[i] . index] . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6
  ORIGINAL[3]: d -> follows[d -> states[s] . mbps . elems[i] . index]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ]
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640883
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640420
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776191
FRAGMENT_COUNT: 8
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: mp == &musts[1]?((void )0) : __assert_fail(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == &musts [ 1 ] ? ( ( void ) 0 ) : FUN1 ( \
  ORIGINAL[2]: mp == &musts[1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == &musts [ 1 ]
  ORIGINAL[3]: &musts[1]
  TYPE[3]: CALL
  TOKENIZED[3]: &musts [ 1 ]
  ORIGINAL[4]: (void )0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void ) 0
  ORIGINAL[5]: __assert_fail(\
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( \
  ORIGINAL[6]: mp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> __PRETTY_FUNCTION__
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 30064776403
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640931
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476819
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: *stonesoup_tainted_buff
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff
  ORIGINAL[2]: stonesoup_tainted_buff
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 0

