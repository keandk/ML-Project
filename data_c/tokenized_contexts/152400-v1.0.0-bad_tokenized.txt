# Tokenized code fragments for 152400-v1.0.0-bad
# Total center nodes processed: 25
# Total code fragments found: 183

CENTER_NODE: 30064771711
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation_hashtable_exact = g_hash_table_new(conversation_hash_exact,conversation_match_exact)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(conversation_hash_exact,conversation_match_exact)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> conversation_hashtable_exact
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064772222
FRAGMENT_COUNT: 5
  ORIGINAL[0]: conversation -> dissector_handle = handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: conversation -> dissector_handle
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dissector_handle
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conversation
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: handle
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771115
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477063
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (const conversation_key *)w
  TYPE[0]: CALL
  TOKENIZED[0]: ( const VAR1 * ) VAR2
  ORIGINAL[1]: w
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064772225
FRAGMENT_COUNT: 5
  ORIGINAL[0]: find_conversation(pinfo -> fd -> num,addr_a,addr_b,ptype,port_a,port_b,0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 -> VAR3 , VAR4 , VAR5 , VAR6 , VAR7 , VAR8 , 0 )
  ORIGINAL[1]: pinfo -> fd -> num
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: pinfo -> fd
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: num
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: addr_a
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477582
FRAGMENT_COUNT: 12
  ORIGINAL[0]: (conv = find_conversation(pinfo -> fd -> num,(&pinfo -> src),(&pinfo -> dst),pinfo -> ptype,pinfo -> srcport,pinfo -> destport,0)) == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 -> VAR3 -> VAR4 , ( &pinfo -> VAR5 ) , ( &pinfo -> VAR6 ) , VAR2 -> VAR7 , VAR2 -> VAR8 , VAR2 -> VAR9 , 0 ) ) == ( ( void * ) 0 )
  ORIGINAL[1]: pinfo -> src
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pinfo -> dst
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pinfo -> ptype
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pinfo -> srcport
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: pinfo -> destport
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: pinfo -> src
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: &pinfo -> dst
  TYPE[7]: CALL
  TOKENIZED[7]: &pinfo -> VAR1
  ORIGINAL[8]: pinfo -> dst
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: pinfo -> ptype
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: ptype
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: pinfo
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771375
FRAGMENT_COUNT: 8
  ORIGINAL[0]: (&v1 -> addr2) -> len == (&v2 -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR3 ) -> VAR2
  ORIGINAL[1]: (&v1 -> addr2) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[2]: memcmp((&v1 -> addr2) -> data,(&v2 -> addr1) -> data,((&v1 -> addr2) -> len))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( &v1 -> VAR1 ) -> VAR2 , ( &v2 -> VAR3 ) -> VAR2 , ( ( &v1 -> VAR1 ) -> VAR4 ) )
  ORIGINAL[3]: (&v1 -> addr2) -> data
  TYPE[3]: CALL
  TOKENIZED[3]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[4]: (&v2 -> addr1) -> data
  TYPE[4]: CALL
  TOKENIZED[4]: ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[5]: (&v1 -> addr2) -> len
  TYPE[5]: CALL
  TOKENIZED[5]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[6]: &v1 -> addr2
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: len
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477024
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *refugium_interpel = 0
  TYPE[0]: CALL
  TOKENIZED[0]: *refugium_interpel = 0
  ORIGINAL[1]: **dermabrasion_prancingly[10] = {0}
  TYPE[1]: CALL
  TOKENIZED[1]: **dermabrasion_prancingly [ 10 ] = { 0 }
  ORIGINAL[2]: **dermabrasion_prancingly[10] = {0}
  TYPE[2]: CALL
  TOKENIZED[2]: **dermabrasion_prancingly [ 10 ] = { 0 }
  ORIGINAL[3]: dermabrasion_prancingly
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771676
FRAGMENT_COUNT: 6
  ORIGINAL[0]: g_slist_free(conv -> data_list)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: conv -> data_list
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data_list
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: conv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: conv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771159
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *stonesoup_tainted_buff != 0
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff != 0
  ORIGINAL[1]: *stonesoup_tainted_buff
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff
  ORIGINAL[2]: fread(*stonesoup_tainted_buff,1,stonesoup_lsize,stonesoup_tainted_file)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( *stonesoup_tainted_buff , 1 , VAR1 , VAR2 )
  ORIGINAL[3]: *stonesoup_tainted_buff
  TYPE[3]: CALL
  TOKENIZED[3]: *stonesoup_tainted_buff
  ORIGINAL[4]: *stonesoup_tainted_buff
  TYPE[4]: CALL
  TOKENIZED[4]: *stonesoup_tainted_buff
  ORIGINAL[5]: stonesoup_tainted_buff
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_lsize
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_tainted_file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_tainted_buff
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771800
FRAGMENT_COUNT: 8
  ORIGINAL[0]: ((void *)0) == conv -> next
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( void * ) 0 ) == VAR1 -> VAR2
  ORIGINAL[1]: g_hash_table_insert(hashtable,(chain_head -> key_ptr),chain_head)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 )
  ORIGINAL[2]: chain_head -> key_ptr
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key_ptr
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chain_head
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashtable
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chain_head
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: chain_head
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064772075
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !(conversation -> options & 0x01) && ptype != PT_UDP
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 -> VAR2 & 0x01 ) && VAR3 != VAR4
  ORIGINAL[1]: conversation -> options
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: conversation -> options & 0x08
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 & 0x08
  ORIGINAL[3]: conversation -> options
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: options
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: conversation
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: conversation
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: conversation
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: conversation
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: conversation
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477521
FRAGMENT_COUNT: 7
  ORIGINAL[0]: ap -> proto > bp -> proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 -> VAR2
  ORIGINAL[1]: bp -> proto
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ap -> proto
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: bp -> proto
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: proto
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: bp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: bp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771204
FRAGMENT_COUNT: 8
  ORIGINAL[0]: conversation -> key_ptr -> ptype
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: conversation -> options & 0x02
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 & 0x02
  ORIGINAL[2]: conversation -> key_ptr -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: conversation -> key_ptr -> addr2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[4]: conversation -> key_ptr
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: key_ptr
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: addr2
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: conversation
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477011
FRAGMENT_COUNT: 12
  ORIGINAL[0]: v1 -> ptype
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: v1 -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: v1 -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: v1 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: (&v1 -> addr1) -> len == (&v2 -> addr1) -> len
  TYPE[4]: CALL
  TOKENIZED[4]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[5]: v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: (&v2 -> addr1) -> data
  TYPE[7]: CALL
  TOKENIZED[7]: ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[8]: v1 -> addr1
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: addr1
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: v1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: v1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771419
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: (&key -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: ( &key -> VAR1 ) -> VAR2
  ORIGINAL[2]: &key -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: &key -> VAR1
  ORIGINAL[3]: len
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771484
FRAGMENT_COUNT: 16
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: (&key -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: ( &key -> VAR1 ) -> VAR2
  ORIGINAL[2]: &key -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: &key -> VAR1
  ORIGINAL[3]: key -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index++
  TYPE[4]: CALL
  TOKENIZED[4]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[5]: hash_val += ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 += VAR2 [ VAR3 ]
  ORIGINAL[6]: ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: for (ADD_ADDRESS_TO_HASH_index = 0;ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len;ADD_ADDRESS_TO_HASH_index++)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( VAR1 = 0 ; VAR1 < ( &key -> VAR2 ) -> VAR3 ; ADD_ADDRESS_TO_HASH_index++ )
  ORIGINAL[8]: addr1
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: len
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: ADD_ADDRESS_TO_HASH_index
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: key
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: ADD_ADDRESS_TO_HASH_index
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: hash_val
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: ADD_ADDRESS_TO_HASH_data
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: ADD_ADDRESS_TO_HASH_index
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 30064772263
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_query_buffer[1000]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1000 ]
  ORIGINAL[1]: stonesoup_query_buffer[1000]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 1000 ]
  ORIGINAL[2]: stonesoup_query_buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_dbport
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476877
FRAGMENT_COUNT: 10
  ORIGINAL[0]: key -> addr1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key -> addr1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key -> port1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key -> addr2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index < (&key -> addr2) -> len
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[5]: key -> addr2
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: addr2
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ADD_ADDRESS_TO_HASH_index
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: key
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477549
FRAGMENT_COUNT: 6
  ORIGINAL[0]: conv -> data_list
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: conv -> data_list
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: conv -> data_list
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data_list
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: item
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: conv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476952
FRAGMENT_COUNT: 19
  ORIGINAL[0]: *v1 = (const conversation_key *)v
  TYPE[0]: CALL
  TOKENIZED[0]: *v1 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const conversation_key *)v
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: v1 -> ptype
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: v1 -> port1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: v1 -> port2
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: v1 -> addr1
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: v1 -> addr1
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: v1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: v1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: v1
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: v1
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: v1
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: v1
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: v1
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: v1
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: v1
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 30064772202
FRAGMENT_COUNT: 5
  ORIGINAL[0]: item != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: p1 -> proto_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: proto_data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771994
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *match = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: *match = ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: match
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477527
FRAGMENT_COUNT: 3
  ORIGINAL[0]: p1 -> proto_data = proto_data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: p1 -> proto_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: proto_data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477106
FRAGMENT_COUNT: 8
  ORIGINAL[0]: ((void *)0) == chain_head
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( void * ) 0 ) == VAR1
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: chain_head -> last
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: chain_head
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chain_head
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chain_head
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chain_head
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: chain_head
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

