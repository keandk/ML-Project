# Tokenized code fragments for 152992-v1.0.0-bad
# Total center nodes processed: 143
# Total code fragments found: 403

CENTER_NODE: 47244640833
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640675
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640437
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771307
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640290
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640754
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775882
FRAGMENT_COUNT: 5
  ORIGINAL[0]: left[lnum] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: right[rnum] != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[2]: right[rnum]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: both == ((void *)0)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == ( ( void * ) 0 )

CENTER_NODE: 47244640587
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773023
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: closure()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: CAT
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775039
FRAGMENT_COUNT: 11
  ORIGINAL[0]: i < work_mbc -> nch_classes
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: buffer[match_len] = '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = '\\0'
  ORIGINAL[2]: buffer[match_len]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: match_len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: buffer
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: buffer
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: buffer
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: buffer
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: buffer
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: buffer
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064775909
FRAGMENT_COUNT: 4
  ORIGINAL[0]: freelist(mp -> in)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: mp -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: in
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064776343
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640306
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640972
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476937
FRAGMENT_COUNT: 5
  ORIGINAL[0]: prednames[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> prednames
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640923
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476838
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771194
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: (1 << 8) + 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[2]: 1 << 8
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << 8

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640561
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640621
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480147
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064776358
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640559
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773104
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s -> alloc = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: s -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: alloc
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771210
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ++i
  TYPE[0]: CALL
  TOKENIZED[0]: ++i
  ORIGINAL[1]: equal(s,dfa -> charclasses[i])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[2]: for (i = 0;i < dfa -> cindex;++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640328
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479239
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *rarray
  TYPE[0]: CALL
  TOKENIZED[0]: *rarray
  ORIGINAL[1]: *rarray
  TYPE[1]: CALL
  TOKENIZED[1]: *rarray
  ORIGINAL[2]: i < d -> states[s] . mbps . nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[3]: rarray[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: rarray[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: rarray
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: rarray
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640267
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771254
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: wc == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640393
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773026
FRAGMENT_COUNT: 10
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: branch()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: addtok(OR)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: while (tok == OR)
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: while ( VAR1 == VAR2 )
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: OR
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: <global> tok
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: OR
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719480021
FRAGMENT_COUNT: 7
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: new = inboth(lmp -> in,rmp -> in)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 -> VAR3 , VAR4 -> VAR3 )
  ORIGINAL[2]: new == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640580
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640287
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640308
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771175
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )

CENTER_NODE: 47244640375
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476797
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064771302
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN1 ( VAR1 )
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[2]: tolower(b)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719478017
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i > lo
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775838
FRAGMENT_COUNT: 4
  ORIGINAL[0]: p == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: cpp = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: cpp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771185
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640868
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476875
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c == eolbyte
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> eolbyte
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640403
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640747
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479799
FRAGMENT_COUNT: 8
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: old = enlist(old,new[i],strlen(new[i]))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[2]: old == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: old
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: old
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719479564
FRAGMENT_COUNT: 10
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: j = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: j < p -> nequivs
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2 -> VAR3
  ORIGINAL[3]: p -> nequivs
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ++j
  TYPE[4]: CALL
  TOKENIZED[4]: ++j
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: j
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: j
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477959
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dst -> alloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dst -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dst -> alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dst -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dst
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775716
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640338
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479044
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER=2
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772944
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: ntoks1 = nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 - 1 )
  ORIGINAL[2]: nsubtoks(tindex - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 - 1 )
  ORIGINAL[3]: tindex - 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 1
  ORIGINAL[4]: ntoks1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771933
FRAGMENT_COUNT: 13
  ORIGINAL[0]: work_mbc -> chars
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: work_mbc -> chars
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: work_mbc -> chars
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: work_mbc -> chars
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: !setbit_wc(wc,ccl)
  TYPE[4]: CALL
  TOKENIZED[4]: !setbit_wc ( VAR1 , VAR2 )
  ORIGINAL[5]: work_mbc -> chars
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: work_mbc -> chars
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: work_mbc -> chars
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: work_mbc -> chars[work_mbc -> nchars++] = wc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ VAR1 -> nchars++ ] = VAR3
  ORIGINAL[9]: work_mbc -> chars[work_mbc -> nchars++]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR1 -> nchars++ ]
  ORIGINAL[10]: work_mbc -> chars
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: work_mbc -> nchars++
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> nchars++
  ORIGINAL[12]: wc
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771133
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 68719479040
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> trans
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> realtrans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> success
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> newlines
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: oldalloc < d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 < VAR2 -> VAR3
  ORIGINAL[6]: d -> tralloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> trans[oldalloc] = ((void *)0)
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ] = ( ( void * ) 0 )
  ORIGINAL[8]: d -> fails
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: fails
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064775361
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: prepare_wc_buf(((const char *)p),end)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( const char * ) VAR1 ) , VAR2 )
  ORIGINAL[2]: (const char *)p
  TYPE[2]: CALL
  TOKENIZED[2]: ( const char * ) VAR1
  ORIGINAL[3]: end
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640878
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773184
FRAGMENT_COUNT: 10
  ORIGINAL[0]: m -> alloc <= s1 -> nelem + s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4 + VAR5 -> VAR4
  ORIGINAL[1]: m -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: x2nrealloc((m -> elems),&new_n_alloc,sizeof(( *m -> elems)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *m -> VAR2 ) ) )
  ORIGINAL[3]: m -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &new_n_alloc
  TYPE[4]: CALL
  TOKENIZED[4]: &new_n_alloc
  ORIGINAL[5]: sizeof(( *m -> elems))
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( ( *m -> VAR1 ) )
  ORIGINAL[6]: *m -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: *m -> VAR1
  ORIGINAL[7]: elems
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: m
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new_n_alloc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640896
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478942
FRAGMENT_COUNT: 6
  ORIGINAL[0]: trans[i] >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] >= VAR3 -> VAR4
  ORIGINAL[1]: oldalloc = d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3
  ORIGINAL[2]: d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: oldalloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: oldalloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772799
FRAGMENT_COUNT: 19
  ORIGINAL[0]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> tokens = (x2nrealloc((dfa -> tokens),&new_n_alloc,sizeof(( *dfa -> tokens))))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) ) )
  ORIGINAL[3]: dfa -> tokens
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: x2nrealloc((dfa -> tokens),&new_n_alloc,sizeof(( *dfa -> tokens)))
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) )
  ORIGINAL[5]: dfa -> tokens
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: tokens
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> dfa
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> dfa
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> dfa
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> dfa
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> dfa
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> dfa
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> dfa
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1
  ORIGINAL[17]: <global> dfa
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: <global> VAR1
  ORIGINAL[18]: <global> dfa
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: <global> VAR1

CENTER_NODE: 30064774759
FRAGMENT_COUNT: 20
  ORIGINAL[0]: d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: sizeof(( *d -> realtrans)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> tralloc + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 + 1
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> tralloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tralloc
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: d
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775715
FRAGMENT_COUNT: 6
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: memcpy((result + oldsize),new,newsize + 1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 + VAR2 ) , VAR3 , VAR4 + 1 )
  ORIGINAL[2]: result + oldsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: newsize + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: newsize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771156
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640426
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477776
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < work_mbc -> nchars
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: need_or = 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478273
FRAGMENT_COUNT: 7
  ORIGINAL[0]: tstbit(eolbyte,c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: context |= 4
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 4
  ORIGINAL[2]: context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: context
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: context
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: context
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775298
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < d -> follows[d -> states[s1] . mbps . elems[i] . index] . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[1]: d -> states[s1] . mbps . elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[2]: d -> states[s1] . mbps
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[s1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: mbps
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640807
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640348
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773821
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: nullable[- 2] = nullable[- 1] && nullable[- 2]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ - 2 ] = VAR1 [ - 1 ] && VAR1 [ - 2 ]
  ORIGINAL[2]: nullable[- 2]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ - 2 ]
  ORIGINAL[3]: nullable[- 1] && nullable[- 2]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 1 ] && VAR1 [ - 2 ]
  ORIGINAL[4]: nullable
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772967
FRAGMENT_COUNT: 7
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: dfa -> multibyte_prop[dfa -> tindex - 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[2]: dfa -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> multibyte_prop[tindex + i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[4]: multibyte_prop
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1

CENTER_NODE: 47244640395
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640589
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640628
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (t = d -> trans[works]) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 [ VAR4 ] ) != ( ( void * ) 0 )
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 47244640709
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477939
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> depth
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: depth
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> depth
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640317
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775681
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < (d -> tralloc)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[1]: d -> fails[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: fails
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476886
FRAGMENT_COUNT: 2
  ORIGINAL[0]: syntax_bits_set = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: <global> syntax_bits_set
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 30064775196
FRAGMENT_COUNT: 9
  ORIGINAL[0]: work_mbls[i] ==  *mbclen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == *mbclen
  ORIGINAL[1]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[2]: d -> states[s]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: d -> states
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: states
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064775725
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: strncmp(cp,lookfor,len)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lookfor
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719478090
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: s -> elems[i] = s -> elems[i + 1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] = VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640415
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771155
FRAGMENT_COUNT: 2
  ORIGINAL[0]: CSET=275
  TYPE[0]: CALL
  TOKENIZED[0]: CSET=275
  ORIGINAL[1]: CSET
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771204
FRAGMENT_COUNT: 2
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )

CENTER_NODE: 47244640359
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640541
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479625
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfaanalyze(d,searchflag)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: searchflag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640871
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640385
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775598
FRAGMENT_COUNT: 18
  ORIGINAL[0]: d -> nmultibyte_prop
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: sizeof(( *d -> multibyte_prop)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xmalloc(d -> nmultibyte_prop)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[3]: d -> nmultibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> nmultibyte_prop
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nmultibyte_prop
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640597
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775626
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: i < d -> tindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: d -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> tokens[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: tindex
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640418
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772651
FRAGMENT_COUNT: 4
  ORIGINAL[0]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: clrbit('\\0',ccl)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( '\\0' , VAR1 )
  ORIGINAL[2]: ccl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> laststart
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640783
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )

CENTER_NODE: 68719476764
FRAGMENT_COUNT: 6
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: size_filepath = strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: strlen(dirpath) + strlen(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[3]: size_filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size_filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775729
FRAGMENT_COUNT: 3
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: cpp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640705
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640619
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478724
FRAGMENT_COUNT: 8
  ORIGINAL[0]: *grps
  TYPE[0]: CALL
  TOKENIZED[0]: *grps
  ORIGINAL[1]: *grps
  TYPE[1]: CALL
  TOKENIZED[1]: *grps
  ORIGINAL[2]: j == ngrps
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: grps[ngrps] . nelem = 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] . VAR3 = 1
  ORIGINAL[4]: grps[ngrps]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: grps
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: grps
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ngrps
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064776356
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478100
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: hash ^= s -> elems[i] . index + s -> elems[i] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 ^= VAR2 -> VAR3 [ VAR4 ] . VAR5 + VAR2 -> VAR3 [ VAR4 ] . VAR6
  ORIGINAL[2]: s -> elems[i] . index + s -> elems[i] . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 + VAR1 -> VAR2 [ VAR3 ] . VAR5
  ORIGINAL[3]: hash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hash
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hash
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hash
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640345
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640539
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775779
FRAGMENT_COUNT: 4
  ORIGINAL[0]: --i == j
  TYPE[0]: CALL
  TOKENIZED[0]: --i == VAR1
  ORIGINAL[1]: cpp[i] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 68719478303
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773553
FRAGMENT_COUNT: 7
  ORIGINAL[0]: visited[old . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 . VAR3 ]
  ORIGINAL[1]: j < d -> follows[old . index] . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3 [ VAR4 . VAR5 ] . VAR6
  ORIGINAL[2]: d -> follows[old . index] . nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 . VAR4 ] . VAR5
  ORIGINAL[3]: d -> follows[old . index]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[4]: d -> follows
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: old . index
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2
  ORIGINAL[6]: nelem
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640761
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

