# Tokenized code fragments for 152552-v1.0.0-bad
# Total center nodes processed: 79
# Total code fragments found: 338

CENTER_NODE: 68719477468
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(input)
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: input
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: input
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771319
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *new_string = (apr_palloc(pool,sizeof(( *new_string))))
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string = ( FUN1 ( VAR1 , sizeof ( ( *new_string ) ) ) )
  ORIGINAL[1]: apr_palloc(pool,sizeof(( *new_string)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , sizeof ( ( *new_string ) ) )
  ORIGINAL[2]: new_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477108
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477149
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> blocksize
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: old_len + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + 1
  ORIGINAL[2]: old_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: old_len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old_len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477424
FRAGMENT_COUNT: 7
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str -> len -= offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -= VAR3
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> blocksize
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: blocksize
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772147
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: ui64toa_sep(((apr_uint64_t )(-number)),seperator,&buffer[1])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( VAR1 ) ( -number ) ) , VAR2 , &buffer [ 1 ] )
  ORIGINAL[2]: &buffer[1]
  TYPE[2]: CALL
  TOKENIZED[2]: &buffer [ 1 ]
  ORIGINAL[3]: buffer[1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 1 ]

CENTER_NODE: 30064771471
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *mem = (void *)0
  TYPE[0]: CALL
  TOKENIZED[0]: *mem = ( void * ) 0
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: mem
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477486
FRAGMENT_COUNT: 6
  ORIGINAL[0]: list -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: list -> elts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: strcmp(this_str,str) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 ) == 0
  ORIGINAL[3]: nelts
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: list
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477593
FRAGMENT_COUNT: 4
  ORIGINAL[0]: &val
  TYPE[0]: CALL
  TOKENIZED[0]: &val
  ORIGINAL[1]: (unsigned int )val
  TYPE[1]: CALL
  TOKENIZED[1]: ( unsigned int ) VAR1
  ORIGINAL[2]: val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771354
FRAGMENT_COUNT: 4
  ORIGINAL[0]: create_string(data,strlen(data),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(data)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771753
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare((str1 -> data),(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str2 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771416
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(str -> data,str -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771408
FRAGMENT_COUNT: 11
  ORIGINAL[0]: memcpy((strbuf -> data),bytes,size)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR4 )
  ORIGINAL[1]: strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: strbuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: strbuf
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strbuf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: bytes
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: size
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: strbuf
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: strbuf
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: strbuf
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719476921
FRAGMENT_COUNT: 3
  ORIGINAL[0]: membuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: membuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477120
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476864
FRAGMENT_COUNT: 5
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: stonesoup_envKey != NULL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: stonesoup_envKey
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_envKey
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771947
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *__errno_location() == 22 || endptr == str || str[0] == '\\0' || ( *endptr) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 22 || VAR1 == VAR2 || VAR2 [ 0 ] == '\\0' || ( *endptr ) != '\\0'
  ORIGINAL[1]: *__errno_location() == 22 || endptr == str || str[0] == '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: *__errno_location ( ) == 22 || VAR1 == VAR2 || VAR2 [ 0 ] == '\\0'
  ORIGINAL[2]: *__errno_location() == 22 || endptr == str
  TYPE[2]: CALL
  TOKENIZED[2]: *__errno_location ( ) == 22 || VAR1 == VAR2
  ORIGINAL[3]: str[0] == '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 0 ] == '\\0'
  ORIGINAL[4]: ( *endptr) != '\\0'
  TYPE[4]: CALL
  TOKENIZED[4]: ( *endptr ) != '\\0'
  ORIGINAL[5]: *endptr
  TYPE[5]: CALL
  TOKENIZED[5]: *endptr
  ORIGINAL[6]: endptr
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771981
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoui64(n,str,0,18446744073709551615UL,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 , 18446744073709551615UL , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476998
FRAGMENT_COUNT: 7
  ORIGINAL[0]: data = ((char *)mem) + sizeof(( *new_string))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( char * ) VAR2 ) + sizeof ( ( *new_string ) )
  ORIGINAL[1]: new_string = mem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: new_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mem
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_string
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772154
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stringa . len = strlen(stra)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = FUN1 ( VAR3 )
  ORIGINAL[1]: stringa . len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: strlen(stra)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: stringb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771370
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_first_non_whitespace(str -> data,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477031
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477516
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *str
  TYPE[0]: CALL
  TOKENIZED[0]: *str
  ORIGINAL[1]: next == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: *((char *)next) = '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: * ( ( char * ) VAR1 ) = '\\0'
  ORIGINAL[3]: *str
  TYPE[3]: CALL
  TOKENIZED[3]: *str
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476919
FRAGMENT_COUNT: 6
  ORIGINAL[0]: membuf_create(&membuf -> data,&membuf -> size,size,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 )
  ORIGINAL[1]: membuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: membuf -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf -> pool
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pool
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: membuf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772106
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: *dest = 45
  TYPE[1]: CALL
  TOKENIZED[1]: *dest = 45
  ORIGINAL[2]: *dest
  TYPE[2]: CALL
  TOKENIZED[2]: *dest
  ORIGINAL[3]: dest
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771466
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> data[str -> len]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR1 -> VAR3 ]
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476897
FRAGMENT_COUNT: 6
  ORIGINAL[0]: minimum_size >  *size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > *size
  ORIGINAL[1]: new_size =  *size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = *size
  ORIGINAL[2]: *size
  TYPE[2]: CALL
  TOKENIZED[2]: *size
  ORIGINAL[3]: new_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771234
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !minimum_size?((void *)0) : apr_palloc(pool,minimum_size)
  TYPE[0]: CALL
  TOKENIZED[0]: !minimum_size? ( ( void * ) 0 ) : FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: !minimum_size
  TYPE[1]: CALL
  TOKENIZED[1]: !minimum_size
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0

CENTER_NODE: 68719477035
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str1 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771378
FRAGMENT_COUNT: 2
  ORIGINAL[0]: svn_stringbuf_create_ensure(0,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771373
FRAGMENT_COUNT: 5
  ORIGINAL[0]: find_char_backward(str -> data,str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771927
FRAGMENT_COUNT: 5
  ORIGINAL[0]: new_str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: new_str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477435
FRAGMENT_COUNT: 3
  ORIGINAL[0]: find_char_backward((str -> data),str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ch
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771678
FRAGMENT_COUNT: 4
  ORIGINAL[0]: bytes + count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: str -> len += count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 += VAR3
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771317
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_string -> len = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: new_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771468
FRAGMENT_COUNT: 2
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 68719477438
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str2 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str1 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771447
FRAGMENT_COUNT: 8
  ORIGINAL[0]: memcpy((str -> data),value,amt + 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR4 + 1 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: amt + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: value
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064772122
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i > 3
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 3
  ORIGINAL[1]: memmove((&buffer[i - 2]),(&buffer[i - 3]),length - i + 3)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( &buffer [ VAR1 - 2 ] ) , ( &buffer [ VAR1 - 3 ] ) , VAR2 - VAR1 + 3 )
  ORIGINAL[2]: &buffer[i - 2]
  TYPE[2]: CALL
  TOKENIZED[2]: &buffer [ VAR1 - 2 ]
  ORIGINAL[3]: &buffer[i - 3]
  TYPE[3]: CALL
  TOKENIZED[3]: &buffer [ VAR1 - 3 ]
  ORIGINAL[4]: buffer[i - 3]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 - 3 ]
  ORIGINAL[5]: length - i + 3
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 - VAR2 + 3
  ORIGINAL[6]: length
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772027
FRAGMENT_COUNT: 2
  ORIGINAL[0]: - 9223372036854775807L - 1
  TYPE[0]: CALL
  TOKENIZED[0]: - 9223372036854775807L - 1
  ORIGINAL[1]: - 9223372036854775807L
  TYPE[1]: CALL
  TOKENIZED[1]: - 9223372036854775807L

CENTER_NODE: 30064771380
FRAGMENT_COUNT: 6
  ORIGINAL[0]: membuf_create(&mem,&blocksize,blocksize + sizeof(( *new_string)),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &mem , &blocksize , VAR1 + sizeof ( ( *new_string ) ) , VAR2 )
  ORIGINAL[1]: &mem
  TYPE[1]: CALL
  TOKENIZED[1]: &mem
  ORIGINAL[2]: &blocksize
  TYPE[2]: CALL
  TOKENIZED[2]: &blocksize
  ORIGINAL[3]: blocksize + sizeof(( *new_string))
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + sizeof ( ( *new_string ) )
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771644
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,(appendstr -> data),appendstr -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 -> VAR4 )
  ORIGINAL[1]: appendstr -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: appendstr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771129
FRAGMENT_COUNT: 4
  ORIGINAL[0]: st = {0}
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = { 0 }
  ORIGINAL[1]: {0}
  TYPE[1]: CALL
  TOKENIZED[1]: { 0 }
  ORIGINAL[2]: st
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ss_tc_root
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476855
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stonesoup_printf_context != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477010
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_string_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: cstring
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476969
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771348
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_string_ncreate((strbuf -> data),strbuf -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: strbuf -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476942
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *const _m_b_f_ = membuf
  TYPE[0]: CALL
  TOKENIZED[0]: *const VAR1 = VAR2
  ORIGINAL[1]: _m_b_f_ -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _m_b_f_
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _m_b_f_
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771834
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: apr_fnmatch(this_pattern,str,0) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , 0 ) == 0
  ORIGINAL[2]: for (i = 0;i < list -> nelts;i++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771362
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_string_ncreate(original_string -> data,original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: original_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476952
FRAGMENT_COUNT: 6
  ORIGINAL[0]: _s_z_ > _m_b_f_ -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: _m_b_f_ -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: _m_b_f_ -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _m_b_f_
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: _m_b_f_
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640370
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771414
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771757
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_first_non_whitespace((str -> data),str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477107
FRAGMENT_COUNT: 3
  ORIGINAL[0]: __builtin_va_end(ap)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: str
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772083
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number < 100
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 100
  ORIGINAL[1]: reduced = ((apr_uint32_t )number)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: (apr_uint32_t )number
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: reduced
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: reduced
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772207
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stra < enda && strb < endb
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 < VAR4
  ORIGINAL[1]: restb = (endb - strb)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( VAR2 - VAR3 )
  ORIGINAL[2]: endb - strb
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - VAR2
  ORIGINAL[3]: restb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: endb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771356
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str = svn_string_createv(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: svn_string_createv(pool,fmt,ap)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771910
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *(p + 1)
  TYPE[0]: CALL
  TOKENIZED[0]: * ( VAR1 + 1 )
  ORIGINAL[1]: ( *p) == 13
  TYPE[1]: CALL
  TOKENIZED[1]: ( *p ) == 13
  ORIGINAL[2]: *(p + 1)
  TYPE[2]: CALL
  TOKENIZED[2]: * ( VAR1 + 1 )
  ORIGINAL[3]: p + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771749
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_stringbuf_ncreate((original_string -> data),original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: original_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477624
FRAGMENT_COUNT: 4
  ORIGINAL[0]: &val
  TYPE[0]: CALL
  TOKENIZED[0]: &val
  ORIGINAL[1]: (int )val
  TYPE[1]: CALL
  TOKENIZED[1]: ( int ) VAR1
  ORIGINAL[2]: val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771820
FRAGMENT_COUNT: 5
  ORIGINAL[0]: p[0] != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 0 ] != '\\0'
  ORIGINAL[1]: *((const char **)(apr_array_push(array))) = p
  TYPE[1]: CALL
  TOKENIZED[1]: * ( ( const char ** ) ( FUN1 ( VAR1 ) ) ) = VAR2
  ORIGINAL[2]: *((const char **)(apr_array_push(array)))
  TYPE[2]: CALL
  TOKENIZED[2]: * ( ( const char ** ) ( FUN1 ( VAR1 ) ) )
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477301
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,cstr,strlen(cstr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[1]: targetstr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477084
FRAGMENT_COUNT: 4
  ORIGINAL[0]: apr_pvsprintf(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fmt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772005
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *__errno_location() == 22 || endptr == str || str[0] == '\\0' || ( *endptr) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 22 || VAR1 == VAR2 || VAR2 [ 0 ] == '\\0' || ( *endptr ) != '\\0'
  ORIGINAL[1]: svn_error_createf(SVN_ERR_INCORRECT_PARAMS,((void *)0),(dgettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( void * ) 0 ) , ( FUN2 ( \
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: dgettext(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: SVN_ERR_INCORRECT_PARAMS
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477044
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: strbuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640302
FRAGMENT_COUNT: 2
  ORIGINAL[0]: memcmp(str1,str2,len1) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771106
FRAGMENT_COUNT: 7
  ORIGINAL[0]: shmid = shmget(key, shmsz, IPC_CREAT | 0666)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 | 0666 )
  ORIGINAL[1]: shmget(key, shmsz, IPC_CREAT | 0666)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 | 0666 )
  ORIGINAL[2]: IPC_CREAT | 0666
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 | 0666
  ORIGINAL[3]: errors
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: shmid
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: shmsz
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640362
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719477183
FRAGMENT_COUNT: 6
  ORIGINAL[0]: &entangler_calculate
  TYPE[0]: CALL
  TOKENIZED[0]: &entangler_calculate
  ORIGINAL[1]: entangler_calculate != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: plaustral_prethrill . unlaudable_cheefuller = entangler_calculate
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2 = VAR3
  ORIGINAL[3]: plaustral_prethrill . unlaudable_cheefuller
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: entangler_calculate
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: entangler_calculate
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771265
FRAGMENT_COUNT: 4
  ORIGINAL[0]: old_size = membuf -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3
  ORIGINAL[1]: membuf -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: old_size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: membuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771719
FRAGMENT_COUNT: 7
  ORIGINAL[0]: bytes + new_count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: pos + old_count > str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2 > VAR3 -> VAR4
  ORIGINAL[2]: pos + old_count
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: old_count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772135
FRAGMENT_COUNT: 2
  ORIGINAL[0]: buffer[2 * 21]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 2 * 21 ]
  ORIGINAL[1]: 2 * 21
  TYPE[1]: CALL
  TOKENIZED[1]: 2 * 21

CENTER_NODE: 30064771304
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: svn_ctype_table[(unsigned char )str[i]]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ]
  ORIGINAL[2]: (unsigned char )str[i]
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned char ) VAR1 [ VAR2 ]
  ORIGINAL[3]: str[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]

CENTER_NODE: 68719477351
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> data + pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 + VAR3
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pos
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pos
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477553
FRAGMENT_COUNT: 7
  ORIGINAL[0]: a = ( *(str1++))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( * ( str1++ ) )
  ORIGINAL[1]: b = ( *(str2++))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( * ( str2++ ) )
  ORIGINAL[2]: *(str2++)
  TYPE[2]: CALL
  TOKENIZED[2]: * ( str2++ )
  ORIGINAL[3]: cmp || !a || !b
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 || !a || !b
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str2
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: b
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

