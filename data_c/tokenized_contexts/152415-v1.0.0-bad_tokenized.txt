# Tokenized code fragments for 152415-v1.0.0-bad
# Total center nodes processed: 141
# Total code fragments found: 446

CENTER_NODE: 68719478984
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> trcount = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = 0
  ORIGINAL[2]: d -> trcount
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> realtrans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: realtrans
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064775475
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: prepare_wc_buf(((const char *)p),end)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( const char * ) VAR1 ) , VAR2 )
  ORIGINAL[2]: (const char *)p
  TYPE[2]: CALL
  TOKENIZED[2]: ( const char * ) VAR1
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: end
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640821
FRAGMENT_COUNT: 1
  ORIGINAL[0]: match_lens[i] > maxlen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] > VAR3

CENTER_NODE: 30064775855
FRAGMENT_COUNT: 3
  ORIGINAL[0]: left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: left
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775524
FRAGMENT_COUNT: 8
  ORIGINAL[0]: j < p -> nequivs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: p -> equivs[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: p -> equivs
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: p -> equivs
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: equivs
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: j
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640961
FRAGMENT_COUNT: 2
  ORIGINAL[0]: t < END
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 30064775734
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064776384
FRAGMENT_COUNT: 3
  ORIGINAL[0]: {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: { { ( \
  ORIGINAL[1]: {(\
  TYPE[1]: CALL
  TOKENIZED[1]: { ( \
  ORIGINAL[2]: ispunct
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640620
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479680
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775616
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: !1
  TYPE[1]: CALL
  TOKENIZED[1]: !1
  ORIGINAL[2]: !using_utf8()
  TYPE[2]: CALL
  TOKENIZED[2]: !using_utf8 ( )
  ORIGINAL[3]: using_utf8()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )

CENTER_NODE: 30064774880
FRAGMENT_COUNT: 3
  ORIGINAL[0]: p == buf_end
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: abort()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: works
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476852
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: charclasses
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 30064776374
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477305
FRAGMENT_COUNT: 13
  ORIGINAL[0]: &new_n_alloc
  TYPE[0]: CALL
  TOKENIZED[0]: &new_n_alloc
  ORIGINAL[1]: &new_n_alloc
  TYPE[1]: CALL
  TOKENIZED[1]: &new_n_alloc
  ORIGINAL[2]: &new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: &new_n_alloc
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: &new_n_alloc
  TYPE[4]: CALL
  TOKENIZED[4]: &new_n_alloc
  ORIGINAL[5]: range_ends_al <= work_mbc -> nranges + 1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 <= VAR2 -> VAR3 + 1
  ORIGINAL[6]: work_mbc -> range_ends
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: &new_n_alloc
  TYPE[7]: CALL
  TOKENIZED[7]: &new_n_alloc
  ORIGINAL[8]: &new_n_alloc
  TYPE[8]: CALL
  TOKENIZED[8]: &new_n_alloc
  ORIGINAL[9]: &new_n_alloc
  TYPE[9]: CALL
  TOKENIZED[9]: &new_n_alloc
  ORIGINAL[10]: new_n_alloc
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: new_n_alloc
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: new_n_alloc
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640866
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774593
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ((2 & 1?( *d) . states[s] . constraint & 0xf : 0)) | ((2 & 2?( *d) . states[s] . constraint >> 4 & 0xf : 0))
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( 2 & 1? ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf : 0 ) ) | ( ( 2 & 2? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf : 0 ) )
  ORIGINAL[1]: 2 & 1?( *d) . states[s] . constraint & 0xf : 0
  TYPE[1]: CALL
  TOKENIZED[1]: 2 & 1? ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf : 0
  ORIGINAL[2]: 2 & 2?( *d) . states[s] . constraint >> 4 & 0xf : 0
  TYPE[2]: CALL
  TOKENIZED[2]: 2 & 2? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf : 0
  ORIGINAL[3]: 2 & 2
  TYPE[3]: CALL
  TOKENIZED[3]: 2 & 2
  ORIGINAL[4]: ( *d) . states[s] . constraint >> 4 & 0xf
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf

CENTER_NODE: 47244640337
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772964
FRAGMENT_COUNT: 9
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: dfa -> tindex - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 - 1
  ORIGINAL[2]: dfa -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tindex
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1

CENTER_NODE: 68719476793
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640746
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640392
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640586
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479038
FRAGMENT_COUNT: 2
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771275
FRAGMENT_COUNT: 4
  ORIGINAL[0]: case_fold && iswalpha(wc)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && FUN1 ( VAR2 )
  ORIGINAL[1]: setbit_wc((iswupper(wc)?towlower(wc) : towupper(wc)),c)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( FUN2 ( VAR1 ) ?towlower ( VAR1 ) : FUN3 ( VAR1 ) ) , VAR2 )
  ORIGINAL[2]: iswupper(wc)?towlower(wc) : towupper(wc)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) ?towlower ( VAR1 ) : FUN2 ( VAR1 )
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640708
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775699
FRAGMENT_COUNT: 5
  ORIGINAL[0]: newsize = new == ((void *)0)?0 : strlen(new)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR2 )
  ORIGINAL[1]: new == ((void *)0)?0 : strlen(new)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[2]: new == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: strlen(new)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: newsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640394
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640588
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479276
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: work_mbls[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: work_mbls
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: work_mbls
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: work_mbls
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640596
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773076
FRAGMENT_COUNT: 11
  ORIGINAL[0]: dst -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *dst -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: *dst -> VAR1
  ORIGINAL[2]: memcpy((dst -> elems),(src -> elems),sizeof(dst -> elems[0]) * src -> nelem)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , sizeof ( VAR1 -> VAR2 [ 0 ] ) * VAR3 -> VAR4 )
  ORIGINAL[3]: dst -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: src -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sizeof(dst -> elems[0]) * src -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( VAR1 -> VAR2 [ 0 ] ) * VAR3 -> VAR4
  ORIGINAL[6]: dst -> elems[0]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[7]: elems
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: dst
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: src
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: dst
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719477917
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 68719476766
FRAGMENT_COUNT: 6
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: size_filepath = strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[3]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640895
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476830
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772812
FRAGMENT_COUNT: 8
  ORIGINAL[0]: depth > dfa -> depth
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR1
  ORIGINAL[1]: dfa -> depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> depth = depth
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = VAR2
  ORIGINAL[3]: dfa -> depth
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: depth
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> depth
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> depth
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 47244640618
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640704
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479081
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mblen_buf[idx] == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == 0
  ORIGINAL[1]: mblen_buf[idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: <global> mblen_buf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: idx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640882
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cp = lookin
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: ( *cp) != '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: ( *cp ) != '\\0'
  ORIGINAL[2]: ++cp
  TYPE[2]: CALL
  TOKENIZED[2]: ++cp
  ORIGINAL[3]: for (cp = lookin;( *cp) != '\\0';++cp)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = VAR2 ; ( *cp ) != '\\0' ; ++cp )

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478170
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771240
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum)
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )c]
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[2]: *__ctype_b_loc()
  TYPE[2]: CALL
  TOKENIZED[2]: *__ctype_b_loc ( )
  ORIGINAL[3]: (int )c
  TYPE[3]: CALL
  TOKENIZED[3]: ( int ) VAR1
  ORIGINAL[4]: (unsigned short )_ISalnum
  TYPE[4]: CALL
  TOKENIZED[4]: ( unsigned short ) VAR1

CENTER_NODE: 47244640435
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772939
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: ntoks1 = nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 - 1 )
  ORIGINAL[2]: nsubtoks(tindex - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 - 1 )
  ORIGINAL[3]: tindex - 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 1
  ORIGINAL[4]: ntoks1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773825
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: nfirstpos[- 2] += nfirstpos[- 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ - 2 ] += VAR1 [ - 1 ]
  ORIGINAL[2]: nfirstpos[- 2]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ - 2 ]
  ORIGINAL[3]: nfirstpos[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 1 ]
  ORIGINAL[4]: nfirstpos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479743
FRAGMENT_COUNT: 5
  ORIGINAL[0]: left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: right == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: right
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: right
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776375
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640557
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 68719478082
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477792
FRAGMENT_COUNT: 5
  ORIGINAL[0]: work_mbc -> cset != (- 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[1]: using_utf8()?((void )0) : __assert_fail(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ) ? ( ( void ) 0 ) : FUN2 ( \
  ORIGINAL[2]: CSET + work_mbc -> cset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2 -> VAR3
  ORIGINAL[3]: CSET
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: work_mbc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640806
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771301
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479224
FRAGMENT_COUNT: 12
  ORIGINAL[0]: d -> states
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> states
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> tokens[pos . index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[3]: d -> tokens
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: rarray[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: match_anychar(d,s,pos,idx)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771199
FRAGMENT_COUNT: 2
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773195
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s1 -> nelem && j < s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 && VAR4 < VAR5 -> VAR3
  ORIGINAL[1]: s1 -> elems[i] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s1 -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s1 -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: index
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771185
FRAGMENT_COUNT: 23
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: (1 << 8) + 8 * sizeof(int ) - 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( 1 << 8 ) + 8 * sizeof ( int ) - 1
  ORIGINAL[3]: (1 << 8) + 8 * sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[4]: 1 << 8
  TYPE[4]: CALL
  TOKENIZED[4]: 1 << 8
  ORIGINAL[5]: 8 * sizeof(int )
  TYPE[5]: CALL
  TOKENIZED[5]: 8 * sizeof ( int )
  ORIGINAL[6]: sizeof(int )
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( int )
  ORIGINAL[7]: 8 * sizeof(int )
  TYPE[7]: CALL
  TOKENIZED[7]: 8 * sizeof ( int )
  ORIGINAL[8]: sizeof(int )
  TYPE[8]: CALL
  TOKENIZED[8]: sizeof ( int )
  ORIGINAL[9]: ++i
  TYPE[9]: CALL
  TOKENIZED[9]: ++i
  ORIGINAL[10]: s[i] = ~s[i]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[11]: s[i]
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 [ VAR2 ]
  ORIGINAL[12]: ~s[i]
  TYPE[12]: CALL
  TOKENIZED[12]: ~s [ VAR1 ]
  ORIGINAL[13]: s[i]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 [ VAR2 ]
  ORIGINAL[14]: for (i = 0;i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++i)
  TYPE[14]: CONTROL_STRUCTURE
  TOKENIZED[14]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++i )
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: int
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: int
  ORIGINAL[17]: int
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: int
  ORIGINAL[18]: i
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: s
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: i
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: s
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: i
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1

CENTER_NODE: 30064773019
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: addtok(CAT)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: CAT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775741
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (new = icpyalloc(new)) == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 = FUN1 ( VAR1 ) ) == ( ( void * ) 0 )
  ORIGINAL[2]: new = icpyalloc(new)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR1 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 68719478273
FRAGMENT_COUNT: 3
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 68719479825
FRAGMENT_COUNT: 3
  ORIGINAL[0]: mp -> left
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: left
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: mp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (i = 0;i < (1 << 8);++i)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480169
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640631
FRAGMENT_COUNT: 4
  ORIGINAL[0]: visited[old . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 . VAR3 ]
  ORIGINAL[1]: --i
  TYPE[1]: CALL
  TOKENIZED[1]: --i
  ORIGINAL[2]: continue;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: continue ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477901
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok == REPMN && (minrep || maxrep)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[1]: i < maxrep
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: tok = lex()
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( )
  ORIGINAL[3]: lex()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> tok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640538
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771175
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[3]: 1 << b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640923
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773044
FRAGMENT_COUNT: 9
  ORIGINAL[0]: depth = d -> depth
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR1
  ORIGINAL[1]: d -> depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: depth
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> depth
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477620
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !((!backslash || p != lim && ( *(p++)) == '\\\\') && p != lim && ( *(p++)) == '}' && 0 <= minrep && (maxrep < 0 || minrep <= maxrep))
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( !backslash || VAR1 != VAR2 && ( * ( p++ ) ) == '\\\\' ) && VAR1 != VAR2 && ( * ( p++ ) ) == ' } ' && 0 <= VAR3 && ( VAR4 < 0 || VAR3 <= VAR4 ) )
  ORIGINAL[1]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: 0x7fff < maxrep
  TYPE[2]: CALL
  TOKENIZED[2]: 0x7fff < VAR1
  ORIGINAL[3]: dfaerror((gettext(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( FUN2 ( \
  ORIGINAL[4]: lexptr = p
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2
  ORIGINAL[5]: <global> lexptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479648
FRAGMENT_COUNT: 14
  ORIGINAL[0]: d -> charclasses
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> follows
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: i < (d -> tralloc)
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[8]: d -> tralloc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: free(d -> trans[i])
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] )
  ORIGINAL[10]: d -> fails
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: fails
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771250
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == '_' || iswalnum(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '_' || FUN1 ( VAR1 )
  ORIGINAL[2]: wc == '_'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == '_'
  ORIGINAL[3]: iswalnum(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640672
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772892
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: add_utf8_anychar()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064775632
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfaoptimize(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771151
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640540
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476803
FRAGMENT_COUNT: 3
  ORIGINAL[0]: NOTLIMWORD=263
  TYPE[0]: CALL
  TOKENIZED[0]: NOTLIMWORD=263
  ORIGINAL[1]: QMARK=264
  TYPE[1]: CALL
  TOKENIZED[1]: QMARK=264
  ORIGINAL[2]: QMARK
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640830
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773981
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < d -> states[s] . elems . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: d -> states[s] . elems . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[2]: d -> states[s] . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[s]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: nelem
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640750
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479139
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < work_mbc -> nch_classes
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: work_mbc -> ch_classes[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: work_mbc -> ch_classes
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771182
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640648
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775601
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: d -> mbcsets = ((sizeof(( *d -> mbcsets)) == 1?xmalloc(d -> mbcsets_alloc) : xnmalloc(d -> mbcsets_alloc,sizeof(( *d -> mbcsets)))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( sizeof ( ( *d -> VAR2 ) ) == 1?xmalloc ( VAR1 -> VAR3 ) : FUN1 ( VAR1 -> VAR3 , sizeof ( ( *d -> VAR2 ) ) ) ) )
  ORIGINAL[2]: d -> mbcsets
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *d -> mbcsets)) == 1?xmalloc(d -> mbcsets_alloc) : xnmalloc(d -> mbcsets_alloc,sizeof(( *d -> mbcsets)))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )

CENTER_NODE: 47244640414
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773595
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: (s -> elems[j] . constraint >> 2 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[2]: s -> elems[j] . constraint >> 2 & 0x111
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111
  ORIGINAL[3]: s -> elems[j] . constraint >> 2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2
  ORIGINAL[4]: s -> elems[j] . constraint & 0x111
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064773143
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s -> alloc <= count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 + 1
  ORIGINAL[1]: x2nrealloc((s -> elems),&new_n_alloc,sizeof(( *s -> elems)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *s -> VAR2 ) ) )
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: sizeof(( *s -> elems))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[5]: *s -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: *s -> VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776359
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 30064774805
FRAGMENT_COUNT: 91
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: oldalloc = d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: new_state >= d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> realtrans = (xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans))))
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[7]: d -> realtrans
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans)))
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[9]: d -> realtrans
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: d -> tralloc + 1
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 + 1
  ORIGINAL[11]: d -> tralloc
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: sizeof(( *d -> realtrans))
  TYPE[12]: CALL
  TOKENIZED[12]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[13]: *d -> realtrans
  TYPE[13]: CALL
  TOKENIZED[13]: *d -> VAR1
  ORIGINAL[14]: d -> realtrans
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: d -> trans = d -> realtrans + 1
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 = VAR1 -> VAR3 + 1
  ORIGINAL[16]: d -> trans
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: d -> realtrans + 1
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2 + 1
  ORIGINAL[18]: d -> realtrans
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2
  ORIGINAL[19]: d -> fails = (xnrealloc((d -> fails),(d -> tralloc),sizeof(( *d -> fails))))
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[20]: d -> fails
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 -> VAR2
  ORIGINAL[21]: xnrealloc((d -> fails),(d -> tralloc),sizeof(( *d -> fails)))
  TYPE[21]: CALL
  TOKENIZED[21]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[22]: d -> fails
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 -> VAR2
  ORIGINAL[23]: d -> tralloc
  TYPE[23]: CALL
  TOKENIZED[23]: VAR1 -> VAR2
  ORIGINAL[24]: sizeof(( *d -> fails))
  TYPE[24]: CALL
  TOKENIZED[24]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[25]: *d -> fails
  TYPE[25]: CALL
  TOKENIZED[25]: *d -> VAR1
  ORIGINAL[26]: d -> fails
  TYPE[26]: CALL
  TOKENIZED[26]: VAR1 -> VAR2
  ORIGINAL[27]: d -> success = (xnrealloc((d -> success),(d -> tralloc),sizeof(( *d -> success))))
  TYPE[27]: CALL
  TOKENIZED[27]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[28]: d -> success
  TYPE[28]: CALL
  TOKENIZED[28]: VAR1 -> VAR2
  ORIGINAL[29]: xnrealloc((d -> success),(d -> tralloc),sizeof(( *d -> success)))
  TYPE[29]: CALL
  TOKENIZED[29]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[30]: d -> success
  TYPE[30]: CALL
  TOKENIZED[30]: VAR1 -> VAR2
  ORIGINAL[31]: d -> tralloc
  TYPE[31]: CALL
  TOKENIZED[31]: VAR1 -> VAR2
  ORIGINAL[32]: sizeof(( *d -> success))
  TYPE[32]: CALL
  TOKENIZED[32]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[33]: *d -> success
  TYPE[33]: CALL
  TOKENIZED[33]: *d -> VAR1
  ORIGINAL[34]: d -> success
  TYPE[34]: CALL
  TOKENIZED[34]: VAR1 -> VAR2
  ORIGINAL[35]: d -> newlines = (xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines))))
  TYPE[35]: CALL
  TOKENIZED[35]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[36]: d -> newlines
  TYPE[36]: CALL
  TOKENIZED[36]: VAR1 -> VAR2
  ORIGINAL[37]: xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[37]: CALL
  TOKENIZED[37]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[38]: d -> newlines
  TYPE[38]: CALL
  TOKENIZED[38]: VAR1 -> VAR2
  ORIGINAL[39]: d -> tralloc
  TYPE[39]: CALL
  TOKENIZED[39]: VAR1 -> VAR2
  ORIGINAL[40]: sizeof(( *d -> newlines))
  TYPE[40]: CALL
  TOKENIZED[40]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[41]: *d -> newlines
  TYPE[41]: CALL
  TOKENIZED[41]: *d -> VAR1
  ORIGINAL[42]: d -> newlines
  TYPE[42]: CALL
  TOKENIZED[42]: VAR1 -> VAR2
  ORIGINAL[43]: oldalloc < d -> tralloc
  TYPE[43]: CALL
  TOKENIZED[43]: VAR1 < VAR2 -> VAR3
  ORIGINAL[44]: d -> tralloc
  TYPE[44]: CALL
  TOKENIZED[44]: VAR1 -> VAR2
  ORIGINAL[45]: tralloc
  TYPE[45]: FIELD_IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: tralloc
  TYPE[46]: FIELD_IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: realtrans
  TYPE[47]: FIELD_IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: realtrans
  TYPE[48]: FIELD_IDENTIFIER
  TOKENIZED[48]: VAR1
  ORIGINAL[49]: tralloc
  TYPE[49]: FIELD_IDENTIFIER
  TOKENIZED[49]: VAR1
  ORIGINAL[50]: realtrans
  TYPE[50]: FIELD_IDENTIFIER
  TOKENIZED[50]: VAR1
  ORIGINAL[51]: trans
  TYPE[51]: FIELD_IDENTIFIER
  TOKENIZED[51]: VAR1
  ORIGINAL[52]: realtrans
  TYPE[52]: FIELD_IDENTIFIER
  TOKENIZED[52]: VAR1
  ORIGINAL[53]: fails
  TYPE[53]: FIELD_IDENTIFIER
  TOKENIZED[53]: VAR1
  ORIGINAL[54]: fails
  TYPE[54]: FIELD_IDENTIFIER
  TOKENIZED[54]: VAR1
  ORIGINAL[55]: tralloc
  TYPE[55]: FIELD_IDENTIFIER
  TOKENIZED[55]: VAR1
  ORIGINAL[56]: fails
  TYPE[56]: FIELD_IDENTIFIER
  TOKENIZED[56]: VAR1
  ORIGINAL[57]: success
  TYPE[57]: FIELD_IDENTIFIER
  TOKENIZED[57]: VAR1
  ORIGINAL[58]: success
  TYPE[58]: FIELD_IDENTIFIER
  TOKENIZED[58]: VAR1
  ORIGINAL[59]: tralloc
  TYPE[59]: FIELD_IDENTIFIER
  TOKENIZED[59]: VAR1
  ORIGINAL[60]: success
  TYPE[60]: FIELD_IDENTIFIER
  TOKENIZED[60]: VAR1
  ORIGINAL[61]: newlines
  TYPE[61]: FIELD_IDENTIFIER
  TOKENIZED[61]: VAR1
  ORIGINAL[62]: newlines
  TYPE[62]: FIELD_IDENTIFIER
  TOKENIZED[62]: VAR1
  ORIGINAL[63]: tralloc
  TYPE[63]: FIELD_IDENTIFIER
  TOKENIZED[63]: VAR1
  ORIGINAL[64]: newlines
  TYPE[64]: FIELD_IDENTIFIER
  TOKENIZED[64]: VAR1
  ORIGINAL[65]: tralloc
  TYPE[65]: FIELD_IDENTIFIER
  TOKENIZED[65]: VAR1
  ORIGINAL[66]: new_state
  TYPE[66]: IDENTIFIER
  TOKENIZED[66]: VAR1
  ORIGINAL[67]: oldalloc
  TYPE[67]: IDENTIFIER
  TOKENIZED[67]: VAR1
  ORIGINAL[68]: d
  TYPE[68]: IDENTIFIER
  TOKENIZED[68]: VAR1
  ORIGINAL[69]: new_state
  TYPE[69]: IDENTIFIER
  TOKENIZED[69]: VAR1
  ORIGINAL[70]: d
  TYPE[70]: IDENTIFIER
  TOKENIZED[70]: VAR1
  ORIGINAL[71]: d
  TYPE[71]: IDENTIFIER
  TOKENIZED[71]: VAR1
  ORIGINAL[72]: d
  TYPE[72]: IDENTIFIER
  TOKENIZED[72]: VAR1
  ORIGINAL[73]: d
  TYPE[73]: IDENTIFIER
  TOKENIZED[73]: VAR1
  ORIGINAL[74]: d
  TYPE[74]: IDENTIFIER
  TOKENIZED[74]: VAR1
  ORIGINAL[75]: d
  TYPE[75]: IDENTIFIER
  TOKENIZED[75]: VAR1
  ORIGINAL[76]: d
  TYPE[76]: IDENTIFIER
  TOKENIZED[76]: VAR1
  ORIGINAL[77]: d
  TYPE[77]: IDENTIFIER
  TOKENIZED[77]: VAR1
  ORIGINAL[78]: d
  TYPE[78]: IDENTIFIER
  TOKENIZED[78]: VAR1
  ORIGINAL[79]: d
  TYPE[79]: IDENTIFIER
  TOKENIZED[79]: VAR1
  ORIGINAL[80]: d
  TYPE[80]: IDENTIFIER
  TOKENIZED[80]: VAR1
  ORIGINAL[81]: d
  TYPE[81]: IDENTIFIER
  TOKENIZED[81]: VAR1
  ORIGINAL[82]: d
  TYPE[82]: IDENTIFIER
  TOKENIZED[82]: VAR1
  ORIGINAL[83]: d
  TYPE[83]: IDENTIFIER
  TOKENIZED[83]: VAR1
  ORIGINAL[84]: d
  TYPE[84]: IDENTIFIER
  TOKENIZED[84]: VAR1
  ORIGINAL[85]: d
  TYPE[85]: IDENTIFIER
  TOKENIZED[85]: VAR1
  ORIGINAL[86]: d
  TYPE[86]: IDENTIFIER
  TOKENIZED[86]: VAR1
  ORIGINAL[87]: d
  TYPE[87]: IDENTIFIER
  TOKENIZED[87]: VAR1
  ORIGINAL[88]: d
  TYPE[88]: IDENTIFIER
  TOKENIZED[88]: VAR1
  ORIGINAL[89]: oldalloc
  TYPE[89]: IDENTIFIER
  TOKENIZED[89]: VAR1
  ORIGINAL[90]: d
  TYPE[90]: IDENTIFIER
  TOKENIZED[90]: VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640384
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477968
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s -> alloc = size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3
  ORIGINAL[2]: s -> alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: s -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: nelem
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771155
FRAGMENT_COUNT: 4
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640869
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640972
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775838
FRAGMENT_COUNT: 5
  ORIGINAL[0]: old == ((void *)0) || new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: old == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: new == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

