# Tokenized code fragments for 152693-v1.0.0-bad
# Total center nodes processed: 10
# Total code fragments found: 58

CENTER_NODE: 68719476813
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *stonesoup_tainted_buff != 0
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff != 0
  ORIGINAL[1]: fread(*stonesoup_tainted_buff,1,stonesoup_lsize,stonesoup_tainted_file)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( *stonesoup_tainted_buff , 1 , VAR1 , VAR2 )
  ORIGINAL[2]: *stonesoup_tainted_buff
  TYPE[2]: CALL
  TOKENIZED[2]: *stonesoup_tainted_buff
  ORIGINAL[3]: stonesoup_lsize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_lsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_tainted_file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_lsize
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476864
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: in += chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: chunk
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: in
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476957
FRAGMENT_COUNT: 3
  ORIGINAL[0]: &bf_cfb64
  TYPE[0]: CALL
  TOKENIZED[0]: &bf_cfb64
  ORIGINAL[1]: <global> bf_cfb64
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: bf_cfb64
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476997
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tracepoint(stonesoup_trace, variable_buffer, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: variable_buffer
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stonesoup_trace
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: variable_buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dbdatabase
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: variable_buffer
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771249
FRAGMENT_COUNT: 11
  ORIGINAL[0]: inl < bl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: inl -= bl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -= VAR2
  ORIGINAL[2]: i = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: i <= inl
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 <= VAR2
  ORIGINAL[4]: inl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: bl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: bl
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: inl
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771109
FRAGMENT_COUNT: 5
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[2]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771170
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: sizeof(long ) * 8
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( long ) * 8

CENTER_NODE: 30064771331
FRAGMENT_COUNT: 6
  ORIGINAL[0]: mkdir(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: stonesoup_read_taint(&donsky_superarseniate,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &donsky_superarseniate , \
  ORIGINAL[2]: &donsky_superarseniate
  TYPE[2]: CALL
  TOKENIZED[2]: &donsky_superarseniate
  ORIGINAL[3]: donsky_superarseniate
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: donsky_superarseniate
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: donsky_superarseniate
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771387
FRAGMENT_COUNT: 4
  ORIGINAL[0]: &((EVP_BF_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[0]: CALL
  TOKENIZED[0]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[1]: ((EVP_BF_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[2]: (EVP_BF_KEY *)(ctx -> cipher_data)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[3]: ks
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771296
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: long
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: long

