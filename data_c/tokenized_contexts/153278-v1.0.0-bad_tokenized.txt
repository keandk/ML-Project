# Tokenized code fragments for 153278-v1.0.0-bad
# Total center nodes processed: 143
# Total code fragments found: 406

CENTER_NODE: 30064771314
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sbit[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: setbit(i,letters)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> letters
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064774853
FRAGMENT_COUNT: 2
  ORIGINAL[0]: build_state(0,d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064775769
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: strncmp(cp,lookfor,len)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lookfor
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640296
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640681
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773330
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[i + 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[2]: i + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640334
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640545
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478001
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: elems
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774768
FRAGMENT_COUNT: 4
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> fails[oldalloc++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ oldalloc++ ]
  ORIGINAL[2]: oldalloc++
  TYPE[2]: CALL
  TOKENIZED[2]: oldalloc++
  ORIGINAL[3]: oldalloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774895
FRAGMENT_COUNT: 13
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[3]: d -> newlines
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sizeof(( *d -> newlines))
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[6]: d -> tralloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tralloc
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640564
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 68719479119
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (wchar_t )eolbyte
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 ) VAR2
  ORIGINAL[1]: <global> eolbyte
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 47244640660
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640323
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775241
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[1]: j++
  TYPE[1]: CALL
  TOKENIZED[1]: j++
  ORIGINAL[2]: for (j = 0;j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem;j++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10 ; j++ )
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640421
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771349
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775355
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *pp - p1 < maxlen
  TYPE[0]: CALL
  TOKENIZED[0]: *pp - VAR1 < VAR2
  ORIGINAL[1]: realloc_trans_if_necessary(d,s1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: pp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640443
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476857
FRAGMENT_COUNT: 5
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BACKREF=257
  TYPE[0]: CALL
  TOKENIZED[0]: BACKREF=257
  ORIGINAL[1]: BACKREF
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: BEGLINE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479495
FRAGMENT_COUNT: 10
  ORIGINAL[0]: *end
  TYPE[0]: CALL
  TOKENIZED[0]: *end
  ORIGINAL[1]: free(inputwcs)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: *end
  TYPE[2]: CALL
  TOKENIZED[2]: *end
  ORIGINAL[3]: end
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: end
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: end
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: backref
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: end
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: end
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: end
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719476854
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476870
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 1
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0

CENTER_NODE: 68719477883
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: 1 + ntoks1
  TYPE[1]: CALL
  TOKENIZED[1]: 1 + VAR1
  ORIGINAL[2]: ntoks1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ntoks1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ntoks1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640634
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478324
FRAGMENT_COUNT: 5
  ORIGINAL[0]: separate_contexts = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: separate_contexts
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: separate_contexts
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: separate_contexts
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: separate_contexts
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478271
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET && d -> tokens[s -> elems[i] . index] < CSET
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < VAR10
  ORIGINAL[1]: old . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: old . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: index
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: visited
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: old
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476826
FRAGMENT_COUNT: 5
  ORIGINAL[0]: message_param = ((struct stonesoup_message_buffer *)param)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( struct VAR2 * ) VAR3 )
  ORIGINAL[1]: message_param -> message_type
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: message_type
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: message_param
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: message_param
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775667
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !1
  TYPE[0]: CALL
  TOKENIZED[0]: !1
  ORIGINAL[1]: !using_utf8()
  TYPE[1]: CALL
  TOKENIZED[1]: !using_utf8 ( )
  ORIGINAL[2]: using_utf8()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 30064771996
FRAGMENT_COUNT: 4
  ORIGINAL[0]: equal(ccl,zeroclass)?(- 1) : charclass_index(ccl)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 ) ? ( - 1 ) : FUN2 ( VAR1 )
  ORIGINAL[1]: equal(ccl,zeroclass)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: charclass_index(ccl)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: ccl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771358
FRAGMENT_COUNT: 6
  ORIGINAL[0]: prednames[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: strcmp(str,prednames[i] . name)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 [ VAR3 ] . VAR4 )
  ORIGINAL[2]: prednames[i] . name
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: prednames[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: prednames[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: name
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640813
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773045
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < maxrep
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: copytoks(tindex,ntokens)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: tindex
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ntokens
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: QMARK
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774917
FRAGMENT_COUNT: 6
  ORIGINAL[0]: rval == TRANSIT_STATE_IN_PROGRESS
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: (t = d -> trans[works]) != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 = VAR2 -> VAR3 [ VAR4 ] ) != ( ( void * ) 0 )
  ORIGINAL[2]: t = d -> trans[works]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[3]: d -> trans[works]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: t
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775560
FRAGMENT_COUNT: 15
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: free((p -> chars))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[2]: p -> chars
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: chars
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: p
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064775924
FRAGMENT_COUNT: 24
  ORIGINAL[0]: left[lnum] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: left[lnum]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: ++lnum
  TYPE[3]: CALL
  TOKENIZED[3]: ++lnum
  ORIGINAL[4]: right[rnum] != ((void *)0)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[5]: right[rnum]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: (void *)0
  TYPE[6]: CALL
  TOKENIZED[6]: ( void * ) 0
  ORIGINAL[7]: temp = comsubs(left[lnum],right[rnum])
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = FUN1 ( VAR2 [ VAR3 ] , VAR4 [ VAR5 ] )
  ORIGINAL[8]: comsubs(left[lnum],right[rnum])
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 [ VAR2 ] , VAR3 [ VAR4 ] )
  ORIGINAL[9]: left[lnum]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 [ VAR2 ]
  ORIGINAL[10]: right[rnum]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 [ VAR2 ]
  ORIGINAL[11]: temp == ((void *)0)
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[12]: (void *)0
  TYPE[12]: CALL
  TOKENIZED[12]: ( void * ) 0
  ORIGINAL[13]: both == ((void *)0)
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[14]: for (rnum = 0;right[rnum] != ((void *)0);++rnum)
  TYPE[14]: CONTROL_STRUCTURE
  TOKENIZED[14]: for ( VAR1 = 0 ; VAR2 [ VAR1 ] != ( ( void * ) 0 ) ; ++rnum )
  ORIGINAL[15]: left
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: lnum
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: lnum
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: temp
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: left
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: lnum
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: right
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: rnum
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: temp
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1

CENTER_NODE: 68719479650
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfainit(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640715
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640603
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478022
FRAGMENT_COUNT: 8
  ORIGINAL[0]: lo < hi
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: lo < count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: lo
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: lo
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: lo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: lo
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: lo
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640625
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476868
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771101
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stat(dirpath, &st) == -1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[1]: retval = mkdir(dirpath, 0700)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[2]: mkdir(dirpath, 0700)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[3]: retval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640424
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640839
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640304
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771270
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> charclasses = (x2nrealloc((dfa -> charclasses),&new_n_alloc,sizeof(( *dfa -> charclasses))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) ) )
  ORIGINAL[2]: dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: x2nrealloc((dfa -> charclasses),&new_n_alloc,sizeof(( *dfa -> charclasses)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) )
  ORIGINAL[4]: dfa -> charclasses
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &new_n_alloc
  TYPE[5]: CALL
  TOKENIZED[5]: &new_n_alloc
  ORIGINAL[6]: sizeof(( *dfa -> charclasses))
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *dfa -> VAR1 ) )

CENTER_NODE: 30064771316
FRAGMENT_COUNT: 13
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: __ctype_get_mb_cur_max()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: wc = btowc(b)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[3]: btowc(b)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: wc == 0xffffffffu
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == 0xffffffffu
  ORIGINAL[5]: setbit(b,c)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[6]: case_fold && ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISalpha)
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 && ( *__ctype_b_loc ( ) ) [ ( int ) VAR2 ] & ( ( unsigned short ) VAR3 )
  ORIGINAL[7]: wc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: b
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: wc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: b
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: c
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: <global> case_fold
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479759
FRAGMENT_COUNT: 7
  ORIGINAL[0]: istrstr(new,cpp[j]) == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 [ VAR3 ] ) == ( ( void * ) 0 )
  ORIGINAL[1]: cpp[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771200
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064773085
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: memset((&mbs),0,sizeof(mbs))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( &mbs ) , 0 , sizeof ( VAR1 ) )
  ORIGINAL[2]: &mbs
  TYPE[2]: CALL
  TOKENIZED[2]: &mbs
  ORIGINAL[3]: sizeof(mbs)
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( VAR1 )
  ORIGINAL[4]: <global> mbs
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640929
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776373
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 68719479716
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640293
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773069
FRAGMENT_COUNT: 2
  ORIGINAL[0]: branch()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 47244640401
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640884
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640354
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775876
FRAGMENT_COUNT: 5
  ORIGINAL[0]: len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: **p = enlist(cpp,lcp,len)
  TYPE[1]: CALL
  TOKENIZED[1]: **p = FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: enlist(cpp,lcp,len)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479702
FRAGMENT_COUNT: 6
  ORIGINAL[0]: oldsize = old == ((void *)0)?0 : strlen(old)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR2 )
  ORIGINAL[1]: newsize = new == ((void *)0)?0 : strlen(new)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR2 )
  ORIGINAL[2]: new == ((void *)0)?0 : strlen(new)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[3]: newsize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: newsize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776233
FRAGMENT_COUNT: 6
  ORIGINAL[0]: lmp -> right[0] != '\\0' && rmp -> left[0] != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] != '\\0' && VAR3 -> VAR4 [ 0 ] != '\\0'
  ORIGINAL[1]: tp = icatalloc(tp,(rmp -> left))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR1 , ( VAR2 -> VAR3 ) )
  ORIGINAL[2]: icatalloc(tp,(rmp -> left))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) )
  ORIGINAL[3]: rmp -> left
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: tp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772151
FRAGMENT_COUNT: 4
  ORIGINAL[0]: lexleft > 1 && lexptr[0] == '\\\\' && lexptr[1] == '|'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 1 && VAR2 [ 0 ] == '\\\\' && VAR2 [ 1 ] == '|'
  ORIGINAL[1]: lexleft > 1 && lexptr[0] == '\\\\'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 > 1 && VAR2 [ 0 ] == '\\\\'
  ORIGINAL[2]: lexptr[1] == '|'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 1 ] == '|'
  ORIGINAL[3]: lexptr[1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 1 ]

CENTER_NODE: 30064775946
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mp -> left[0] = mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = VAR1 -> VAR4 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> left[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = '\\0'
  ORIGINAL[3]: mp -> right[0]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[4]: mp -> is[0] = '\\0'
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ 0 ] = '\\0'

CENTER_NODE: 47244640874
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775895
FRAGMENT_COUNT: 5
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: old = enlist(old,new[i],strlen(new[i]))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[2]: enlist(old,new[i],strlen(new[i]))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[3]: old
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476915
FRAGMENT_COUNT: 5
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: wc == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477988
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: dst -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: dst
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775730
FRAGMENT_COUNT: 3
  ORIGINAL[0]: free((d -> newlines))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[1]: d -> newlines
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476881
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640409
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480171
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640549
FRAGMENT_COUNT: 1
  ORIGINAL[0]: t
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064772956
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok >= 0 && tok < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0 && VAR1 < ( 1 << 8 )
  ORIGINAL[1]: tok >= 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0
  ORIGINAL[2]: tok < (1 << 8)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < ( 1 << 8 )
  ORIGINAL[3]: 1 << 8
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << 8
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640978
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476829
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 68719477946
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: RPAREN
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640391
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775655
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: sizeof(( *d -> mbcsets))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[2]: *d -> mbcsets
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1
  ORIGINAL[3]: d -> mbcsets
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> mbcsets
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2

CENTER_NODE: 30064776375
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771243
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: for (i = 0;i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640600
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640700
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int )) && !matches[j]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) && !matches [ VAR1 ]
  ORIGINAL[1]: for (j = 0;j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int )) && !matches[j];++j)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) && !matches [ VAR1 ] ; ++j )
  ORIGINAL[2]: continue;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: continue ;
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_tainted_file != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: *stonesoup_tainted_buff = ((char *)(malloc(sizeof(char ) * (stonesoup_lsize + 1))))
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff = ( ( char * ) ( FUN1 ( sizeof ( char ) * ( VAR1 + 1 ) ) ) )
  ORIGINAL[2]: *stonesoup_tainted_buff
  TYPE[2]: CALL
  TOKENIZED[2]: *stonesoup_tainted_buff
  ORIGINAL[3]: (char *)(malloc(sizeof(char ) * (stonesoup_lsize + 1)))
  TYPE[3]: CALL
  TOKENIZED[3]: ( char * ) ( FUN1 ( sizeof ( char ) * ( VAR1 + 1 ) ) )
  ORIGINAL[4]: stonesoup_tainted_buff
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478319
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: letters[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> letters
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773513
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> sindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ++d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: ++d -> VAR1
  ORIGINAL[4]: d -> sindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sindex
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477890
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tokens
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064775179
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> tokens[pos . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: rarray[i] = match_mb_charset(d,s,pos,idx)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[2]: rarray[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: match_mb_charset(d,s,pos,idx)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: idx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719479733
FRAGMENT_COUNT: 6
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640373
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640365
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640547
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640773
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773932
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> tokens[i] < (1 << 8)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] < ( 1 << 8 )
  ORIGINAL[2]: d -> tokens[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: 1 << 8
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << 8

CENTER_NODE: 30064776387
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640595
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772865
FRAGMENT_COUNT: 31
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: __ctype_get_mb_cur_max() > 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ) > 1
  ORIGINAL[2]: t == MBCSET
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: need_or = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 0
  ORIGINAL[4]: *work_mbc = &dfa -> mbcsets[dfa -> nmbcsets - 1]
  TYPE[4]: CALL
  TOKENIZED[4]: *work_mbc = &dfa -> VAR1 [ VAR2 -> VAR3 - 1 ]
  ORIGINAL[5]: &dfa -> mbcsets[dfa -> nmbcsets - 1]
  TYPE[5]: CALL
  TOKENIZED[5]: &dfa -> VAR1 [ VAR2 -> VAR3 - 1 ]
  ORIGINAL[6]: dfa -> mbcsets[dfa -> nmbcsets - 1]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[7]: dfa -> mbcsets
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: dfa -> nmbcsets - 1
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 - 1
  ORIGINAL[9]: dfa -> nmbcsets
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: !work_mbc -> invert
  TYPE[10]: CALL
  TOKENIZED[10]: !work_mbc -> VAR1
  ORIGINAL[11]: work_mbc -> invert
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0 || work_mbc -> ncoll_elems != 0
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0 || VAR1 -> VAR8 != 0
  ORIGINAL[13]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0
  ORIGINAL[14]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0
  ORIGINAL[15]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0
  ORIGINAL[16]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0
  ORIGINAL[17]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1)
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 )
  ORIGINAL[18]: work_mbc -> invert
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2
  ORIGINAL[19]: addtok_mb(t,3)
  TYPE[19]: CALL
  TOKENIZED[19]: FUN1 ( VAR1 , 3 )
  ORIGINAL[20]: mbcsets
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: nmbcsets
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: invert
  TYPE[22]: FIELD_IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: invert
  TYPE[23]: FIELD_IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: need_or
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: work_mbc
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: <global> dfa
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: <global> VAR1
  ORIGINAL[27]: <global> dfa
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: <global> VAR1
  ORIGINAL[28]: work_mbc
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: work_mbc
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: t
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1

CENTER_NODE: 68719479076
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER=2
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640314
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640381
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775115
FRAGMENT_COUNT: 13
  ORIGINAL[0]: i < work_mbc -> ncoll_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: work_mbc -> ncoll_elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: strcoll(work_mbc -> coll_elems[i],buffer) == 0
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] , VAR4 ) == 0
  ORIGINAL[4]: strcoll(work_mbc -> coll_elems[i],buffer)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] , VAR4 )
  ORIGINAL[5]: match_len = op_len
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = VAR2
  ORIGINAL[6]: goto charset_matched;
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: goto VAR1 ;
  ORIGINAL[7]: ncoll_elems
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: work_mbc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: match_len
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: op_len
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 30064773260
FRAGMENT_COUNT: 8
  ORIGINAL[0]: s1 -> elems[i] . index > s2 -> elems[j] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[1]: s1 -> elems[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ i++ ]
  ORIGINAL[2]: s1 -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s1 -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: s1 -> elems[i++]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ i++ ]
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640902
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640351
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640356
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640711
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640432
FRAGMENT_COUNT: 0

