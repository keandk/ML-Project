# Tokenized code fragments for 152351-v1.0.0-bad
# Total center nodes processed: 32
# Total code fragments found: 179

CENTER_NODE: 30064771718
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file -> fd = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = - 1
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1

CENTER_NODE: 68719477073
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> is_compressed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: is_compressed
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771749
FRAGMENT_COUNT: 3
  ORIGINAL[0]: * stonesoup_printf_context = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: * VAR1 = VAR2
  ORIGINAL[1]: stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477063
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file_seek(file,delta,1,err)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 1 , VAR3 )
  ORIGINAL[1]: file
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: delta
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771281
FRAGMENT_COUNT: 30
  ORIGINAL[0]: state -> avail_in == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: state -> avail_in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fill_in_buffer(state) == - 1
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) == - 1
  ORIGINAL[3]: fill_in_buffer(state)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1
  ORIGINAL[5]: state -> fast_seek
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: state -> raw = state -> pos
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[7]: state -> raw
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: state -> pos
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: state -> next = state -> out
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[10]: state -> next
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: state -> out
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: state -> avail_in
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: state -> compression = 1
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 = 1
  ORIGINAL[14]: state -> compression
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: fast_seek
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: raw
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: pos
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: next
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: out
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: avail_in
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: compression
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: state
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: state
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: state
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: state
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: state
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: state
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: state
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: state
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 8
  ORIGINAL[0]: state -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: state -> eof
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> compression
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: state -> seek = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 = 0
  ORIGINAL[4]: state -> seek
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: state -> err
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: err
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771553
FRAGMENT_COUNT: 7
  ORIGINAL[0]: stream -> seek?stream -> skip : 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> seek?stream -> VAR2 : 0
  ORIGINAL[1]: stream -> seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: stream -> skip
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: seek
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: skip
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stream
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stream
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771225
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771688
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file -> eof && file -> avail_in == 0 && file -> have == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0 && VAR1 -> VAR4 == 0
  ORIGINAL[1]: file -> eof && file -> avail_in == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0
  ORIGINAL[2]: file -> have == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == 0

CENTER_NODE: 68719476855
FRAGMENT_COUNT: 5
  ORIGINAL[0]: state -> eof == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: state -> eof
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> avail_in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: avail_in
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771555
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> raw_pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: raw_pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771466
FRAGMENT_COUNT: 5
  ORIGINAL[0]: offset < 0 && file -> next
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0 && VAR2 -> VAR3
  ORIGINAL[1]: had = (unsigned int )(file -> next - file -> out)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( unsigned int ) ( VAR2 -> VAR3 - VAR2 -> VAR4 )
  ORIGINAL[2]: (unsigned int )(file -> next - file -> out)
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned int ) ( VAR1 -> VAR2 - VAR1 -> VAR3 )
  ORIGINAL[3]: file -> next - file -> out
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 - VAR1 -> VAR3
  ORIGINAL[4]: had
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477083
FRAGMENT_COUNT: 7
  ORIGINAL[0]: file -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> have > len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 > VAR3
  ORIGINAL[2]: file -> have
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477176
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stream -> err
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: stream -> err_info = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[2]: stream -> err_info
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: stream -> eof
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: eof
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stream
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771106
FRAGMENT_COUNT: 4
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[2]: strlen(dirpath)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: dirpath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771442
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1
  ORIGINAL[1]: ft == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: ft
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771416
FRAGMENT_COUNT: 12
  ORIGINAL[0]: state == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: state -> size = want
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3
  ORIGINAL[2]: state -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: size
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: want
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: state
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: state
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: state
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: state
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771564
FRAGMENT_COUNT: 5
  ORIGINAL[0]: err != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: *err =  *__errno_location()
  TYPE[1]: CALL
  TOKENIZED[1]: *err = *__errno_location ( )
  ORIGINAL[2]: *err
  TYPE[2]: CALL
  TOKENIZED[2]: *err
  ORIGINAL[3]: *__errno_location()
  TYPE[3]: CALL
  TOKENIZED[3]: *__errno_location ( )
  ORIGINAL[4]: __errno_location()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )

CENTER_NODE: 68719476996
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> fast_seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: fast_seek
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771224
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 68719476897
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !item || item -> out < out_pos
  TYPE[0]: CALL
  TOKENIZED[0]: !item || VAR1 -> VAR2 < VAR3
  ORIGINAL[1]: val -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: val -> out = out_pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = VAR3
  ORIGINAL[3]: val -> out
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: val -> compression
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: compression
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: val
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771234
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !file -> fast_seek
  TYPE[0]: CALL
  TOKENIZED[0]: !file -> VAR1
  ORIGINAL[1]: file -> fast_seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file -> fast_seek -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: file -> fast_seek
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: fast_seek
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: file
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477056
FRAGMENT_COUNT: 10
  ORIGINAL[0]: state -> compression == 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 1
  ORIGINAL[1]: state -> compression
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: raw_read(state,state -> out,state -> size,&state -> have)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , &state -> VAR4 )
  ORIGINAL[3]: state -> have
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: state -> out
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: state
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: state
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477183
FRAGMENT_COUNT: 5
  ORIGINAL[0]: fd = file -> fd
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR1
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fd
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: fd
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640309
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476846
FRAGMENT_COUNT: 6
  ORIGINAL[0]: state -> fd
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: state -> raw_pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ret < 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < 0
  ORIGINAL[3]: state -> err
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: err
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771719
FRAGMENT_COUNT: 9
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1
  ORIGINAL[1]: fd = open(path,0 | 0,0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 )
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: file -> fd = fd
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 = VAR2
  ORIGINAL[4]: file -> fd
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: !0
  TYPE[5]: CALL
  TOKENIZED[5]: !0
  ORIGINAL[6]: fd
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: fd
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771703
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fh -> err_info == ((void *)0)?((void *)0) : g_strdup(fh -> err_info)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 ) ? ( ( void * ) 0 ) : FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: fh -> err_info == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064771620
FRAGMENT_COUNT: 5
  ORIGINAL[0]: file -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: ret = file_read(buf,1,file)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , 1 , VAR3 )
  ORIGINAL[2]: file_read(buf,1,file)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , 1 , VAR2 )
  ORIGINAL[3]: ret
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ret
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 1
  ORIGINAL[0]: stonesoup_tainted_file != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0

CENTER_NODE: 68719477137
FRAGMENT_COUNT: 7
  ORIGINAL[0]: file -> have == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: file -> have == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == 0
  ORIGINAL[2]: n = (file -> have > left?left : file -> have)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( VAR2 -> VAR3 > left?left : VAR2 -> VAR3 )
  ORIGINAL[3]: file -> have > left?left : file -> have
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 > left?left : VAR1 -> VAR2
  ORIGINAL[4]: n
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: n
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

