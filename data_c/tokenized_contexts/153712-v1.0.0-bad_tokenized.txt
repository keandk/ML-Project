# Tokenized code fragments for 153712-v1.0.0-bad
# Total center nodes processed: 141
# Total code fragments found: 611

CENTER_NODE: 47244640435
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476793
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064776310
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064775127
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> tokens[pos . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: rarray[i] = match_anychar(d,s,pos,idx)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[2]: rarray[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: match_anychar(d,s,pos,idx)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: idx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478581
FRAGMENT_COUNT: 11
  ORIGINAL[0]: pos . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: pos . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: pos . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: pos . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: pos . constraint
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: pos . constraint
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2
  ORIGINAL[6]: 2 & 4
  TYPE[6]: CALL
  TOKENIZED[6]: 2 & 4
  ORIGINAL[7]: pos . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . VAR2
  ORIGINAL[8]: constraint
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: pos
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: pos
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064772962
FRAGMENT_COUNT: 7
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: dfa -> multibyte_prop[dfa -> tindex - 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[2]: dfa -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> multibyte_prop[tindex + i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[4]: multibyte_prop
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1

CENTER_NODE: 68719477951
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: &new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: &new_n_alloc
  ORIGINAL[3]: new_n_alloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_n_alloc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640864
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: j < p -> nequivs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: ++j
  TYPE[2]: CALL
  TOKENIZED[2]: ++j
  ORIGINAL[3]: free(p -> equivs[j])
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] )
  ORIGINAL[4]: for (j = 0;j < p -> nequivs;++j)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )

CENTER_NODE: 47244640586
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478290
FRAGMENT_COUNT: 12
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: j < s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ++j
  TYPE[3]: CALL
  TOKENIZED[3]: ++j
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: j
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: j
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: j
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: j
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: j
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771171
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: b / (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[3]: ~(1 << b % (8 * sizeof(int )))
  TYPE[3]: CALL
  TOKENIZED[3]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640884
FRAGMENT_COUNT: 1
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )

CENTER_NODE: 47244640384
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640708
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640588
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775998
FRAGMENT_COUNT: 195
  ORIGINAL[0]: ri < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> tindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ++ri
  TYPE[2]: CALL
  TOKENIZED[2]: ++ri
  ORIGINAL[3]: t = d -> tokens[ri]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[4]: d -> tokens[ri]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: !\
  TYPE[5]: CALL
  TOKENIZED[5]: !\
  ORIGINAL[6]: !\
  TYPE[6]: CALL
  TOKENIZED[6]: !\
  ORIGINAL[7]: resetmust(mp)
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( VAR1 )
  ORIGINAL[8]: musts < mp?((void )0) : __assert_fail(\
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 < mp? ( ( void ) 0 ) : FUN1 ( \
  ORIGINAL[9]: musts < mp
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 < VAR2
  ORIGINAL[10]: --mp
  TYPE[10]: CALL
  TOKENIZED[10]: --mp
  ORIGINAL[11]: resetmust(mp)
  TYPE[11]: CALL
  TOKENIZED[11]: FUN1 ( VAR1 )
  ORIGINAL[12]: &musts[2] <= mp?((void )0) : __assert_fail(\
  TYPE[12]: CALL
  TOKENIZED[12]: &musts [ 2 ] <= mp? ( ( void ) 0 ) : FUN1 ( \
  ORIGINAL[13]: &musts[2] <= mp
  TYPE[13]: CALL
  TOKENIZED[13]: &musts [ 2 ] <= VAR1
  ORIGINAL[14]: &musts[2]
  TYPE[14]: CALL
  TOKENIZED[14]: &musts [ 2 ]
  ORIGINAL[15]: musts[2]
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 [ 2 ]
  ORIGINAL[16]: rmp = --mp
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 = --mp
  ORIGINAL[17]: --mp
  TYPE[17]: CALL
  TOKENIZED[17]: --mp
  ORIGINAL[18]: lmp = --mp
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 = --mp
  ORIGINAL[19]: --mp
  TYPE[19]: CALL
  TOKENIZED[19]: --mp
  ORIGINAL[20]: !(strcmp((lmp -> is),(rmp -> is)) == 0)
  TYPE[20]: CALL
  TOKENIZED[20]: ! ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) ) == 0 )
  ORIGINAL[21]: strcmp((lmp -> is),(rmp -> is)) == 0
  TYPE[21]: CALL
  TOKENIZED[21]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) ) == 0
  ORIGINAL[22]: strcmp((lmp -> is),(rmp -> is))
  TYPE[22]: CALL
  TOKENIZED[22]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) )
  ORIGINAL[23]: lmp -> is
  TYPE[23]: CALL
  TOKENIZED[23]: VAR1 -> VAR2
  ORIGINAL[24]: rmp -> is
  TYPE[24]: CALL
  TOKENIZED[24]: VAR1 -> VAR2
  ORIGINAL[25]: i = 0
  TYPE[25]: CALL
  TOKENIZED[25]: VAR1 = 0
  ORIGINAL[26]: lmp -> left[i] != '\\0' && lmp -> left[i] == rmp -> left[i]
  TYPE[26]: CALL
  TOKENIZED[26]: VAR1 -> VAR2 [ VAR3 ] != '\\0' && VAR1 -> VAR2 [ VAR3 ] == VAR4 -> VAR2 [ VAR3 ]
  ORIGINAL[27]: lmp -> left[i] != '\\0'
  TYPE[27]: CALL
  TOKENIZED[27]: VAR1 -> VAR2 [ VAR3 ] != '\\0'
  ORIGINAL[28]: lmp -> left[i]
  TYPE[28]: CALL
  TOKENIZED[28]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[29]: lmp -> left
  TYPE[29]: CALL
  TOKENIZED[29]: VAR1 -> VAR2
  ORIGINAL[30]: lmp -> left[i] = '\\0'
  TYPE[30]: CALL
  TOKENIZED[30]: VAR1 -> VAR2 [ VAR3 ] = '\\0'
  ORIGINAL[31]: lmp -> left[i]
  TYPE[31]: CALL
  TOKENIZED[31]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[32]: lmp -> left
  TYPE[32]: CALL
  TOKENIZED[32]: VAR1 -> VAR2
  ORIGINAL[33]: ln = strlen((lmp -> right))
  TYPE[33]: CALL
  TOKENIZED[33]: VAR1 = FUN1 ( ( VAR2 -> VAR3 ) )
  ORIGINAL[34]: strlen((lmp -> right))
  TYPE[34]: CALL
  TOKENIZED[34]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[35]: lmp -> right
  TYPE[35]: CALL
  TOKENIZED[35]: VAR1 -> VAR2
  ORIGINAL[36]: rn = strlen((rmp -> right))
  TYPE[36]: CALL
  TOKENIZED[36]: VAR1 = FUN1 ( ( VAR2 -> VAR3 ) )
  ORIGINAL[37]: strlen((rmp -> right))
  TYPE[37]: CALL
  TOKENIZED[37]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[38]: rmp -> right
  TYPE[38]: CALL
  TOKENIZED[38]: VAR1 -> VAR2
  ORIGINAL[39]: n = ln
  TYPE[39]: CALL
  TOKENIZED[39]: VAR1 = VAR2
  ORIGINAL[40]: n > rn
  TYPE[40]: CALL
  TOKENIZED[40]: VAR1 > VAR2
  ORIGINAL[41]: i = 0
  TYPE[41]: CALL
  TOKENIZED[41]: VAR1 = 0
  ORIGINAL[42]: i < n
  TYPE[42]: CALL
  TOKENIZED[42]: VAR1 < VAR2
  ORIGINAL[43]: j = 0
  TYPE[43]: CALL
  TOKENIZED[43]: VAR1 = 0
  ORIGINAL[44]: j < i
  TYPE[44]: CALL
  TOKENIZED[44]: VAR1 < VAR2
  ORIGINAL[45]: lmp -> right[j] = '\\0'
  TYPE[45]: CALL
  TOKENIZED[45]: VAR1 -> VAR2 [ VAR3 ] = '\\0'
  ORIGINAL[46]: lmp -> right[j]
  TYPE[46]: CALL
  TOKENIZED[46]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[47]: lmp -> right
  TYPE[47]: CALL
  TOKENIZED[47]: VAR1 -> VAR2
  ORIGINAL[48]: new = inboth(lmp -> in,rmp -> in)
  TYPE[48]: CALL
  TOKENIZED[48]: VAR1 = FUN1 ( VAR2 -> VAR3 , VAR4 -> VAR3 )
  ORIGINAL[49]: inboth(lmp -> in,rmp -> in)
  TYPE[49]: CALL
  TOKENIZED[49]: FUN1 ( VAR1 -> VAR2 , VAR3 -> VAR2 )
  ORIGINAL[50]: lmp -> in
  TYPE[50]: CALL
  TOKENIZED[50]: VAR1 -> VAR2
  ORIGINAL[51]: rmp -> in
  TYPE[51]: CALL
  TOKENIZED[51]: VAR1 -> VAR2
  ORIGINAL[52]: new == ((void *)0)
  TYPE[52]: CALL
  TOKENIZED[52]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[53]: (void *)0
  TYPE[53]: CALL
  TOKENIZED[53]: ( void * ) 0
  ORIGINAL[54]: musts < mp?((void )0) : __assert_fail(\
  TYPE[54]: CALL
  TOKENIZED[54]: VAR1 < mp? ( ( void ) 0 ) : FUN1 ( \
  ORIGINAL[55]: musts < mp
  TYPE[55]: CALL
  TOKENIZED[55]: VAR1 < VAR2
  ORIGINAL[56]: --mp
  TYPE[56]: CALL
  TOKENIZED[56]: --mp
  ORIGINAL[57]: mp -> is[0] = '\\0'
  TYPE[57]: CALL
  TOKENIZED[57]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[58]: mp -> is[0]
  TYPE[58]: CALL
  TOKENIZED[58]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[59]: mp -> is
  TYPE[59]: CALL
  TOKENIZED[59]: VAR1 -> VAR2
  ORIGINAL[60]: mp == &musts[1]?((void )0) : __assert_fail(\
  TYPE[60]: CALL
  TOKENIZED[60]: VAR1 == &musts [ 1 ] ? ( ( void ) 0 ) : FUN1 ( \
  ORIGINAL[61]: mp == &musts[1]
  TYPE[61]: CALL
  TOKENIZED[61]: VAR1 == &musts [ 1 ]
  ORIGINAL[62]: &musts[1]
  TYPE[62]: CALL
  TOKENIZED[62]: &musts [ 1 ]
  ORIGINAL[63]: musts[1]
  TYPE[63]: CALL
  TOKENIZED[63]: VAR1 [ 1 ]
  ORIGINAL[64]: i = 0
  TYPE[64]: CALL
  TOKENIZED[64]: VAR1 = 0
  ORIGINAL[65]: musts[0] . in[i] != ((void *)0)
  TYPE[65]: CALL
  TOKENIZED[65]: VAR1 [ 0 ] . VAR2 [ VAR3 ] != ( ( void * ) 0 )
  ORIGINAL[66]: musts[0] . in[i]
  TYPE[66]: CALL
  TOKENIZED[66]: VAR1 [ 0 ] . VAR2 [ VAR3 ]
  ORIGINAL[67]: musts[0] . in
  TYPE[67]: CALL
  TOKENIZED[67]: VAR1 [ 0 ] . VAR2
  ORIGINAL[68]: musts[0]
  TYPE[68]: CALL
  TOKENIZED[68]: VAR1 [ 0 ]
  ORIGINAL[69]: (void *)0
  TYPE[69]: CALL
  TOKENIZED[69]: ( void * ) 0
  ORIGINAL[70]: strcmp(result,musts[0] . is) == 0
  TYPE[70]: CALL
  TOKENIZED[70]: FUN1 ( VAR1 , VAR2 [ 0 ] . VAR3 ) == 0
  ORIGINAL[71]: strcmp(result,musts[0] . is)
  TYPE[71]: CALL
  TOKENIZED[71]: FUN1 ( VAR1 , VAR2 [ 0 ] . VAR3 )
  ORIGINAL[72]: musts[0] . is
  TYPE[72]: CALL
  TOKENIZED[72]: VAR1 [ 0 ] . VAR2
  ORIGINAL[73]: musts[0]
  TYPE[73]: CALL
  TOKENIZED[73]: VAR1 [ 0 ]
  ORIGINAL[74]: &musts[2] <= mp?((void )0) : __assert_fail(\
  TYPE[74]: CALL
  TOKENIZED[74]: &musts [ 2 ] <= mp? ( ( void ) 0 ) : FUN1 ( \
  ORIGINAL[75]: &musts[2] <= mp
  TYPE[75]: CALL
  TOKENIZED[75]: &musts [ 2 ] <= VAR1
  ORIGINAL[76]: &musts[2]
  TYPE[76]: CALL
  TOKENIZED[76]: &musts [ 2 ]
  ORIGINAL[77]: musts[2]
  TYPE[77]: CALL
  TOKENIZED[77]: VAR1 [ 2 ]
  ORIGINAL[78]: rmp = --mp
  TYPE[78]: CALL
  TOKENIZED[78]: VAR1 = --mp
  ORIGINAL[79]: --mp
  TYPE[79]: CALL
  TOKENIZED[79]: --mp
  ORIGINAL[80]: lmp = --mp
  TYPE[80]: CALL
  TOKENIZED[80]: VAR1 = --mp
  ORIGINAL[81]: --mp
  TYPE[81]: CALL
  TOKENIZED[81]: --mp
  ORIGINAL[82]: lmp -> in = addlists(lmp -> in,rmp -> in)
  TYPE[82]: CALL
  TOKENIZED[82]: VAR1 -> VAR2 = FUN1 ( VAR1 -> VAR2 , VAR3 -> VAR2 )
  ORIGINAL[83]: lmp -> in
  TYPE[83]: CALL
  TOKENIZED[83]: VAR1 -> VAR2
  ORIGINAL[84]: addlists(lmp -> in,rmp -> in)
  TYPE[84]: CALL
  TOKENIZED[84]: FUN1 ( VAR1 -> VAR2 , VAR3 -> VAR2 )
  ORIGINAL[85]: lmp -> in
  TYPE[85]: CALL
  TOKENIZED[85]: VAR1 -> VAR2
  ORIGINAL[86]: rmp -> in
  TYPE[86]: CALL
  TOKENIZED[86]: VAR1 -> VAR2
  ORIGINAL[87]: lmp -> in == ((void *)0)
  TYPE[87]: CALL
  TOKENIZED[87]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[88]: lmp -> in
  TYPE[88]: CALL
  TOKENIZED[88]: VAR1 -> VAR2
  ORIGINAL[89]: (void *)0
  TYPE[89]: CALL
  TOKENIZED[89]: ( void * ) 0
  ORIGINAL[90]: t < END
  TYPE[90]: CALL
  TOKENIZED[90]: VAR1 < VAR2
  ORIGINAL[91]: ++mp
  TYPE[91]: CALL
  TOKENIZED[91]: ++mp
  ORIGINAL[92]: break;
  TYPE[92]: CONTROL_STRUCTURE
  TOKENIZED[92]: break ;
  ORIGINAL[93]: break;
  TYPE[93]: CONTROL_STRUCTURE
  TOKENIZED[93]: break ;
  ORIGINAL[94]: break;
  TYPE[94]: CONTROL_STRUCTURE
  TOKENIZED[94]: break ;
  ORIGINAL[95]: goto done;
  TYPE[95]: CONTROL_STRUCTURE
  TOKENIZED[95]: goto VAR1 ;
  ORIGINAL[96]: tindex
  TYPE[96]: FIELD_IDENTIFIER
  TOKENIZED[96]: VAR1
  ORIGINAL[97]: is
  TYPE[97]: FIELD_IDENTIFIER
  TOKENIZED[97]: VAR1
  ORIGINAL[98]: is
  TYPE[98]: FIELD_IDENTIFIER
  TOKENIZED[98]: VAR1
  ORIGINAL[99]: left
  TYPE[99]: FIELD_IDENTIFIER
  TOKENIZED[99]: VAR1
  ORIGINAL[100]: left
  TYPE[100]: FIELD_IDENTIFIER
  TOKENIZED[100]: VAR1
  ORIGINAL[101]: right
  TYPE[101]: FIELD_IDENTIFIER
  TOKENIZED[101]: VAR1
  ORIGINAL[102]: right
  TYPE[102]: FIELD_IDENTIFIER
  TOKENIZED[102]: VAR1
  ORIGINAL[103]: right
  TYPE[103]: FIELD_IDENTIFIER
  TOKENIZED[103]: VAR1
  ORIGINAL[104]: in
  TYPE[104]: FIELD_IDENTIFIER
  TOKENIZED[104]: VAR1
  ORIGINAL[105]: in
  TYPE[105]: FIELD_IDENTIFIER
  TOKENIZED[105]: VAR1
  ORIGINAL[106]: is
  TYPE[106]: FIELD_IDENTIFIER
  TOKENIZED[106]: VAR1
  ORIGINAL[107]: in
  TYPE[107]: FIELD_IDENTIFIER
  TOKENIZED[107]: VAR1
  ORIGINAL[108]: is
  TYPE[108]: FIELD_IDENTIFIER
  TOKENIZED[108]: VAR1
  ORIGINAL[109]: in
  TYPE[109]: FIELD_IDENTIFIER
  TOKENIZED[109]: VAR1
  ORIGINAL[110]: in
  TYPE[110]: FIELD_IDENTIFIER
  TOKENIZED[110]: VAR1
  ORIGINAL[111]: in
  TYPE[111]: FIELD_IDENTIFIER
  TOKENIZED[111]: VAR1
  ORIGINAL[112]: in
  TYPE[112]: FIELD_IDENTIFIER
  TOKENIZED[112]: VAR1
  ORIGINAL[113]: ri
  TYPE[113]: IDENTIFIER
  TOKENIZED[113]: VAR1
  ORIGINAL[114]: d
  TYPE[114]: IDENTIFIER
  TOKENIZED[114]: VAR1
  ORIGINAL[115]: ri
  TYPE[115]: IDENTIFIER
  TOKENIZED[115]: VAR1
  ORIGINAL[116]: t
  TYPE[116]: IDENTIFIER
  TOKENIZED[116]: VAR1
  ORIGINAL[117]: LPAREN
  TYPE[117]: IDENTIFIER
  TOKENIZED[117]: VAR1
  ORIGINAL[118]: RPAREN
  TYPE[118]: IDENTIFIER
  TOKENIZED[118]: VAR1
  ORIGINAL[119]: EMPTY
  TYPE[119]: IDENTIFIER
  TOKENIZED[119]: VAR1
  ORIGINAL[120]: BEGLINE
  TYPE[120]: IDENTIFIER
  TOKENIZED[120]: VAR1
  ORIGINAL[121]: ENDLINE
  TYPE[121]: IDENTIFIER
  TOKENIZED[121]: VAR1
  ORIGINAL[122]: BEGWORD
  TYPE[122]: IDENTIFIER
  TOKENIZED[122]: VAR1
  ORIGINAL[123]: ENDWORD
  TYPE[123]: IDENTIFIER
  TOKENIZED[123]: VAR1
  ORIGINAL[124]: LIMWORD
  TYPE[124]: IDENTIFIER
  TOKENIZED[124]: VAR1
  ORIGINAL[125]: NOTLIMWORD
  TYPE[125]: IDENTIFIER
  TOKENIZED[125]: VAR1
  ORIGINAL[126]: BACKREF
  TYPE[126]: IDENTIFIER
  TOKENIZED[126]: VAR1
  ORIGINAL[127]: mp
  TYPE[127]: IDENTIFIER
  TOKENIZED[127]: VAR1
  ORIGINAL[128]: STAR
  TYPE[128]: IDENTIFIER
  TOKENIZED[128]: VAR1
  ORIGINAL[129]: QMARK
  TYPE[129]: IDENTIFIER
  TOKENIZED[129]: VAR1
  ORIGINAL[130]: musts
  TYPE[130]: IDENTIFIER
  TOKENIZED[130]: VAR1
  ORIGINAL[131]: mp
  TYPE[131]: IDENTIFIER
  TOKENIZED[131]: VAR1
  ORIGINAL[132]: mp
  TYPE[132]: IDENTIFIER
  TOKENIZED[132]: VAR1
  ORIGINAL[133]: mp
  TYPE[133]: IDENTIFIER
  TOKENIZED[133]: VAR1
  ORIGINAL[134]: OR
  TYPE[134]: IDENTIFIER
  TOKENIZED[134]: VAR1
  ORIGINAL[135]: musts
  TYPE[135]: IDENTIFIER
  TOKENIZED[135]: VAR1
  ORIGINAL[136]: mp
  TYPE[136]: IDENTIFIER
  TOKENIZED[136]: VAR1
  ORIGINAL[137]: rmp
  TYPE[137]: IDENTIFIER
  TOKENIZED[137]: VAR1
  ORIGINAL[138]: mp
  TYPE[138]: IDENTIFIER
  TOKENIZED[138]: VAR1
  ORIGINAL[139]: lmp
  TYPE[139]: IDENTIFIER
  TOKENIZED[139]: VAR1
  ORIGINAL[140]: mp
  TYPE[140]: IDENTIFIER
  TOKENIZED[140]: VAR1
  ORIGINAL[141]: lmp
  TYPE[141]: IDENTIFIER
  TOKENIZED[141]: VAR1
  ORIGINAL[142]: rmp
  TYPE[142]: IDENTIFIER
  TOKENIZED[142]: VAR1
  ORIGINAL[143]: i
  TYPE[143]: IDENTIFIER
  TOKENIZED[143]: VAR1
  ORIGINAL[144]: lmp
  TYPE[144]: IDENTIFIER
  TOKENIZED[144]: VAR1
  ORIGINAL[145]: i
  TYPE[145]: IDENTIFIER
  TOKENIZED[145]: VAR1
  ORIGINAL[146]: lmp
  TYPE[146]: IDENTIFIER
  TOKENIZED[146]: VAR1
  ORIGINAL[147]: i
  TYPE[147]: IDENTIFIER
  TOKENIZED[147]: VAR1
  ORIGINAL[148]: ln
  TYPE[148]: IDENTIFIER
  TOKENIZED[148]: VAR1
  ORIGINAL[149]: lmp
  TYPE[149]: IDENTIFIER
  TOKENIZED[149]: VAR1
  ORIGINAL[150]: rn
  TYPE[150]: IDENTIFIER
  TOKENIZED[150]: VAR1
  ORIGINAL[151]: rmp
  TYPE[151]: IDENTIFIER
  TOKENIZED[151]: VAR1
  ORIGINAL[152]: n
  TYPE[152]: IDENTIFIER
  TOKENIZED[152]: VAR1
  ORIGINAL[153]: ln
  TYPE[153]: IDENTIFIER
  TOKENIZED[153]: VAR1
  ORIGINAL[154]: n
  TYPE[154]: IDENTIFIER
  TOKENIZED[154]: VAR1
  ORIGINAL[155]: rn
  TYPE[155]: IDENTIFIER
  TOKENIZED[155]: VAR1
  ORIGINAL[156]: i
  TYPE[156]: IDENTIFIER
  TOKENIZED[156]: VAR1
  ORIGINAL[157]: i
  TYPE[157]: IDENTIFIER
  TOKENIZED[157]: VAR1
  ORIGINAL[158]: n
  TYPE[158]: IDENTIFIER
  TOKENIZED[158]: VAR1
  ORIGINAL[159]: j
  TYPE[159]: IDENTIFIER
  TOKENIZED[159]: VAR1
  ORIGINAL[160]: j
  TYPE[160]: IDENTIFIER
  TOKENIZED[160]: VAR1
  ORIGINAL[161]: i
  TYPE[161]: IDENTIFIER
  TOKENIZED[161]: VAR1
  ORIGINAL[162]: lmp
  TYPE[162]: IDENTIFIER
  TOKENIZED[162]: VAR1
  ORIGINAL[163]: j
  TYPE[163]: IDENTIFIER
  TOKENIZED[163]: VAR1
  ORIGINAL[164]: new
  TYPE[164]: IDENTIFIER
  TOKENIZED[164]: VAR1
  ORIGINAL[165]: lmp
  TYPE[165]: IDENTIFIER
  TOKENIZED[165]: VAR1
  ORIGINAL[166]: rmp
  TYPE[166]: IDENTIFIER
  TOKENIZED[166]: VAR1
  ORIGINAL[167]: new
  TYPE[167]: IDENTIFIER
  TOKENIZED[167]: VAR1
  ORIGINAL[168]: PLUS
  TYPE[168]: IDENTIFIER
  TOKENIZED[168]: VAR1
  ORIGINAL[169]: musts
  TYPE[169]: IDENTIFIER
  TOKENIZED[169]: VAR1
  ORIGINAL[170]: mp
  TYPE[170]: IDENTIFIER
  TOKENIZED[170]: VAR1
  ORIGINAL[171]: mp
  TYPE[171]: IDENTIFIER
  TOKENIZED[171]: VAR1
  ORIGINAL[172]: mp
  TYPE[172]: IDENTIFIER
  TOKENIZED[172]: VAR1
  ORIGINAL[173]: END
  TYPE[173]: IDENTIFIER
  TOKENIZED[173]: VAR1
  ORIGINAL[174]: mp
  TYPE[174]: IDENTIFIER
  TOKENIZED[174]: VAR1
  ORIGINAL[175]: musts
  TYPE[175]: IDENTIFIER
  TOKENIZED[175]: VAR1
  ORIGINAL[176]: i
  TYPE[176]: IDENTIFIER
  TOKENIZED[176]: VAR1
  ORIGINAL[177]: musts
  TYPE[177]: IDENTIFIER
  TOKENIZED[177]: VAR1
  ORIGINAL[178]: i
  TYPE[178]: IDENTIFIER
  TOKENIZED[178]: VAR1
  ORIGINAL[179]: result
  TYPE[179]: IDENTIFIER
  TOKENIZED[179]: VAR1
  ORIGINAL[180]: musts
  TYPE[180]: IDENTIFIER
  TOKENIZED[180]: VAR1
  ORIGINAL[181]: CAT
  TYPE[181]: IDENTIFIER
  TOKENIZED[181]: VAR1
  ORIGINAL[182]: musts
  TYPE[182]: IDENTIFIER
  TOKENIZED[182]: VAR1
  ORIGINAL[183]: mp
  TYPE[183]: IDENTIFIER
  TOKENIZED[183]: VAR1
  ORIGINAL[184]: rmp
  TYPE[184]: IDENTIFIER
  TOKENIZED[184]: VAR1
  ORIGINAL[185]: mp
  TYPE[185]: IDENTIFIER
  TOKENIZED[185]: VAR1
  ORIGINAL[186]: lmp
  TYPE[186]: IDENTIFIER
  TOKENIZED[186]: VAR1
  ORIGINAL[187]: mp
  TYPE[187]: IDENTIFIER
  TOKENIZED[187]: VAR1
  ORIGINAL[188]: lmp
  TYPE[188]: IDENTIFIER
  TOKENIZED[188]: VAR1
  ORIGINAL[189]: lmp
  TYPE[189]: IDENTIFIER
  TOKENIZED[189]: VAR1
  ORIGINAL[190]: rmp
  TYPE[190]: IDENTIFIER
  TOKENIZED[190]: VAR1
  ORIGINAL[191]: lmp
  TYPE[191]: IDENTIFIER
  TOKENIZED[191]: VAR1
  ORIGINAL[192]: t
  TYPE[192]: IDENTIFIER
  TOKENIZED[192]: VAR1
  ORIGINAL[193]: END
  TYPE[193]: IDENTIFIER
  TOKENIZED[193]: VAR1
  ORIGINAL[194]: mp
  TYPE[194]: IDENTIFIER
  TOKENIZED[194]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775255
FRAGMENT_COUNT: 7
  ORIGINAL[0]: nelem == 0 || maxlen == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 == 0
  ORIGINAL[1]: s1 = state_index(d,(&follows),wchar_context(wc))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , ( &follows ) , FUN2 ( VAR3 ) )
  ORIGINAL[2]: state_index(d,(&follows),wchar_context(wc))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( &follows ) , FUN2 ( VAR2 ) )
  ORIGINAL[3]: &follows
  TYPE[3]: CALL
  TOKENIZED[3]: &follows
  ORIGINAL[4]: wchar_context(wc)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: s1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775156
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> states[s1] . elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[1]: d -> states[s1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> states
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477909
FRAGMENT_COUNT: 8
  ORIGINAL[0]: closure()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: addtok(CAT)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: RPAREN
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> tok
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 30064773095
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[1]: xnmalloc(size,sizeof(( *s -> elems)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , sizeof ( ( *s -> VAR2 ) ) )
  ORIGINAL[2]: sizeof(( *s -> elems))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[3]: *s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: *s -> VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640392
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771116
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479688
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: strncmp(cp,lookfor,len)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: lookfor
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lookfor
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771301
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640830
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 2
  ORIGINAL[0]: works < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 68719476794
FRAGMENT_COUNT: 2
  ORIGINAL[0]: END=-1
  TYPE[0]: CALL
  TOKENIZED[0]: END=-1
  ORIGINAL[1]: END
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719478275
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: c[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771158
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b % (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640394
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771259
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478006
FRAGMENT_COUNT: 6
  ORIGINAL[0]: lo < count && p . index == s -> elems[lo] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 . VAR4 == VAR5 -> VAR6 [ VAR1 ] . VAR4
  ORIGINAL[1]: i = count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: count
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776327
FRAGMENT_COUNT: 2
  ORIGINAL[0]: {(((void *)0)), (((void *)0)), (0)}
  TYPE[0]: CALL
  TOKENIZED[0]: { ( ( ( void * ) 0 ) ) , ( ( ( void * ) 0 ) ) , ( 0 ) }
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 30064775024
FRAGMENT_COUNT: 20
  ORIGINAL[0]: wc < 1 << 8 && work_mbc -> cset != (- 1) && tstbit(((unsigned char )wc),d -> charclasses[work_mbc -> cset])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 1 << 8 && VAR2 -> VAR3 != ( - 1 ) && FUN1 ( ( ( unsigned char ) VAR1 ) , VAR4 -> VAR5 [ VAR2 -> VAR3 ] )
  ORIGINAL[1]: i < work_mbc -> nch_classes
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: work_mbc -> nch_classes
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: iswctype(((wint_t )wc),work_mbc -> ch_classes[i])
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( ( VAR1 ) VAR2 ) , VAR3 -> VAR4 [ VAR5 ] )
  ORIGINAL[4]: nch_classes
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: work_mbc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: work_mbc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: work_mbc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: work_mbc
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: work_mbc
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: work_mbc
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: work_mbc
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: work_mbc
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: work_mbc
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: work_mbc
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: work_mbc
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: work_mbc
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: work_mbc
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640618
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476844
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640920
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774931
FRAGMENT_COUNT: 9
  ORIGINAL[0]: context & 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 1
  ORIGINAL[1]: pos . constraint & 0xf
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 & 0xf
  ORIGINAL[2]: pos . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: pos . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: pos . constraint
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: constraint
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pos
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: pos
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771618
FRAGMENT_COUNT: 9
  ORIGINAL[0]: !lexleft
  TYPE[0]: CALL
  TOKENIZED[0]: !lexleft
  ORIGINAL[1]: gettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: gettext(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: dfaerror((gettext(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( FUN2 ( \
  ORIGINAL[4]: gettext(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \
  ORIGINAL[5]: lasttok = END
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = VAR2
  ORIGINAL[6]: if (gettext(\
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: if ( FUN1 ( \
  ORIGINAL[7]: <global> lasttok
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: END
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479618
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaparse(s,len,d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: dfamust(d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775867
FRAGMENT_COUNT: 9
  ORIGINAL[0]: both == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: both[0] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ] = ( ( void * ) 0 )
  ORIGINAL[2]: both[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: both
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: both
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: both
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: both
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: both
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640895
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772871
FRAGMENT_COUNT: 4
  ORIGINAL[0]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0 || work_mbc -> ncoll_elems != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0 || VAR1 -> VAR8 != 0
  ORIGINAL[1]: work_mbc -> cset != (- 1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[2]: work_mbc -> cset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: - 1
  TYPE[3]: CALL
  TOKENIZED[3]: - 1

CENTER_NODE: 68719478203
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775902
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> is[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> is
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: is
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064776297
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775656
FRAGMENT_COUNT: 16
  ORIGINAL[0]: free((d -> states))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[1]: d -> states
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: states
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640746
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640881
FRAGMENT_COUNT: 1
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0

CENTER_NODE: 47244640672
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773025
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: addtok(OR)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640806
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640969
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640337
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640414
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776311
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640648
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478084
FRAGMENT_COUNT: 11
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: --s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: --s -> VAR1
  ORIGINAL[2]: i < s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2 -> VAR3
  ORIGINAL[3]: s -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ++i
  TYPE[4]: CALL
  TOKENIZED[4]: ++i
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775615
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: !1
  TYPE[1]: CALL
  TOKENIZED[1]: !1
  ORIGINAL[2]: !using_utf8()
  TYPE[2]: CALL
  TOKENIZED[2]: !using_utf8 ( )
  ORIGINAL[3]: i = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 0
  ORIGINAL[4]: i < d -> tindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < VAR2 -> VAR3
  ORIGINAL[5]: d -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: tindex
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640538
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640558
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064775583
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: d -> nmultibyte_prop = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = 1
  ORIGINAL[2]: d -> nmultibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640862
FRAGMENT_COUNT: 4
  ORIGINAL[0]: p[- 1] == eol && allow_nl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ - 1 ] == VAR2 && VAR3
  ORIGINAL[1]: s = d -> newlines[s1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[2]: continue;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: continue ;
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640750
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640704
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640596
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774769
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *d -> fails)) == 1?xzalloc((d -> tralloc)) : xcalloc((d -> tralloc),sizeof(( *d -> fails)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1?xzalloc ( ( VAR2 -> VAR3 ) ) : FUN1 ( ( VAR2 -> VAR3 ) , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *d -> fails)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xzalloc((d -> tralloc))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771216
FRAGMENT_COUNT: 15
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> cindex + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1
  ORIGINAL[3]: dfa -> cindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: dfa -> cindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: cindex
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> dfa
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> dfa
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> dfa
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> dfa
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> dfa
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1

CENTER_NODE: 68719476835
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772939
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: ntoks1 = nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 - 1 )
  ORIGINAL[2]: nsubtoks(tindex - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 - 1 )
  ORIGINAL[3]: tindex - 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 1
  ORIGINAL[4]: ntoks1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772287
FRAGMENT_COUNT: 16
  ORIGINAL[0]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: backslash != ((syntax_bits & ((unsigned long )1) << 1) != 0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != ( ( VAR2 & ( ( unsigned long ) 1 ) << 1 ) != 0 )
  ORIGINAL[3]: (syntax_bits & ((unsigned long )1) << 1) != 0
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 & ( ( unsigned long ) 1 ) << 1 ) != 0
  ORIGINAL[4]: syntax_bits & ((unsigned long )1) << 1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 & ( ( unsigned long ) 1 ) << 1
  ORIGINAL[5]: ((unsigned long )1) << 1
  TYPE[5]: CALL
  TOKENIZED[5]: ( ( unsigned long ) 1 ) << 1
  ORIGINAL[6]: (unsigned long )1
  TYPE[6]: CALL
  TOKENIZED[6]: ( unsigned long ) 1
  ORIGINAL[7]: laststart = 0
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = 0
  ORIGINAL[8]: __ctype_get_mb_cur_max() > 1
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( ) > 1
  ORIGINAL[9]: __ctype_get_mb_cur_max()
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( )
  ORIGINAL[10]: goto normal_char;
  TYPE[10]: CONTROL_STRUCTURE
  TOKENIZED[10]: goto VAR1 ;
  ORIGINAL[11]: c
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: <global> syntax_bits
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: backslash
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: <global> syntax_bits
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> laststart
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1

CENTER_NODE: 47244640869
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479733
FRAGMENT_COUNT: 13
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: cpp[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: xnrealloc(cpp,i + 2,sizeof(( *cpp)))
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 + 2 , sizeof ( ( *cpp ) ) )
  ORIGINAL[6]: i + 2
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 + 2
  ORIGINAL[7]: sizeof(( *cpp))
  TYPE[7]: CALL
  TOKENIZED[7]: sizeof ( ( *cpp ) )
  ORIGINAL[8]: *cpp
  TYPE[8]: CALL
  TOKENIZED[8]: *cpp
  ORIGINAL[9]: cpp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: cpp
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: cpp
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: i
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771165
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 8 * sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: 8 * sizeof ( int )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 30064771183
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: charclass
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771234
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: 1 && (( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum) || c == '_')
  TYPE[3]: CALL
  TOKENIZED[3]: 1 && ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) || VAR1 == '_' )

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774595
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *d) . states[s] . constraint >> 4 & 0xf
  TYPE[0]: CALL
  TOKENIZED[0]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf
  ORIGINAL[1]: 2 & 2?( *d) . states[s] . constraint >> 4 & 0xf : 0
  TYPE[1]: CALL
  TOKENIZED[1]: 2 & 2? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf : 0
  ORIGINAL[2]: 2 & 2
  TYPE[2]: CALL
  TOKENIZED[2]: 2 & 2
  ORIGINAL[3]: ( *d) . states[s] . constraint >> 4 & 0xf
  TYPE[3]: CALL
  TOKENIZED[3]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf
  ORIGINAL[4]: ( *d) . states[s] . constraint >> 4
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4
  ORIGINAL[5]: ( *d) . states[s] . constraint >> 4 & 0xf
  TYPE[5]: CALL
  TOKENIZED[5]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf

CENTER_NODE: 68719477803
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == ANYCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: ANYCHAR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640620
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476877
FRAGMENT_COUNT: 5
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: (wchar_t )eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476830
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479680
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771269
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: wc = btowc(b)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[2]: btowc(b)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776296
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 68719479040
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER=2
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478033
FRAGMENT_COUNT: 6
  ORIGINAL[0]: m -> alloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: m -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: m -> alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: m -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: nelem
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: m
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775787
FRAGMENT_COUNT: 7
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: left == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: right == ((void *)0)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: left
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: right
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640908
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: new[i] != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: for (i = 0;new[i] != ((void *)0);++i)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR2 [ VAR1 ] != ( ( void * ) 0 ) ; ++i )

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719479024
FRAGMENT_COUNT: 9
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> trans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> success
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> tralloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: success
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640540
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640866
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477751
FRAGMENT_COUNT: 3
  ORIGINAL[0]: break;
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: break ;
  ORIGINAL[1]: t
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: PLUS
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477942
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> nregexps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: addtok(OR)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: OR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773755
FRAGMENT_COUNT: 20
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: nlastpos[- 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ - 1 ]
  ORIGINAL[2]: lastpos + nlastpos[- 1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2 [ - 1 ]
  ORIGINAL[3]: nlastpos[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 1 ]
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1
  ORIGINAL[5]: nlastpos[- 1]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ - 1 ]
  ORIGINAL[6]: nlastpos[- 1]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ - 1 ]
  ORIGINAL[7]: nlastpos[- 1]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 [ - 1 ]
  ORIGINAL[8]: nlastpos[- 1]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 [ - 1 ]
  ORIGINAL[9]: nlastpos
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: nlastpos
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: nlastpos
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: nlastpos
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: nlastpos
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: nlastpos
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: nlastpos
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: nlastpos
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: nlastpos
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: nlastpos
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: nlastpos
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 30064771151
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 68719477878
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok == REPMN && (minrep || maxrep)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[1]: ntokens = nsubtoks(dfa -> tindex)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 -> VAR3 )
  ORIGINAL[2]: nsubtoks(dfa -> tindex)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[3]: ntokens
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: ntokens
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719478160
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> salloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> sindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> states
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> salloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> states
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: states
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

