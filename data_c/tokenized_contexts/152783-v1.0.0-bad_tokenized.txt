# Tokenized code fragments for 152783-v1.0.0-bad
# Total center nodes processed: 34
# Total code fragments found: 189

CENTER_NODE: 68719476864
FRAGMENT_COUNT: 18
  ORIGINAL[0]: src[i] == ';'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == ' ; '
  ORIGINAL[1]: i == 0 || src[i-1] != '\\\\'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[2]: i == 0 || src[i-1] != '\\\\'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[3]: src[i] == '&'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] == '&'
  ORIGINAL[4]: i == 0 || src[i-1] != '\\\\'
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[5]: i++
  TYPE[5]: CALL
  TOKENIZED[5]: i++
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: i
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: i
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: i
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: i
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 30064771170
FRAGMENT_COUNT: 8
  ORIGINAL[0]: *src
  TYPE[0]: CALL
  TOKENIZED[0]: *src
  ORIGINAL[1]: *src == '%'
  TYPE[1]: CALL
  TOKENIZED[1]: *src == '%'
  ORIGINAL[2]: *src
  TYPE[2]: CALL
  TOKENIZED[2]: *src
  ORIGINAL[3]: (a = src[1]) && (b = src[2])
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 = VAR2 [ 1 ] ) && ( VAR3 = VAR2 [ 2 ] )
  ORIGINAL[4]: a = src[1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2 [ 1 ]
  ORIGINAL[5]: src[1]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ 1 ]
  ORIGINAL[6]: a
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: src
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640319
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771109
FRAGMENT_COUNT: 5
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[2]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640313
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477208
FRAGMENT_COUNT: 5
  ORIGINAL[0]: &falsie_fardage
  TYPE[0]: CALL
  TOKENIZED[0]: &falsie_fardage
  ORIGINAL[1]: falsie_fardage != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: devex_shelley(falsie_fardage)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: falsie_fardage
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: falsie_fardage
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771234
FRAGMENT_COUNT: 17
  ORIGINAL[0]: i < pkt -> side_data_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: pkt -> side_data_elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: av_free(pkt -> side_data[i] . data)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 )
  ORIGINAL[4]: pkt -> side_data[i] . data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: pkt -> side_data[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: pkt -> side_data
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: for (i = 0;i < pkt -> side_data_elems;i++)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[8]: side_data_elems
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: side_data
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: data
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: pkt
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: i
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: pkt
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: pkt
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771753
FRAGMENT_COUNT: 25
  ORIGINAL[0]: !pkt -> side_data
  TYPE[0]: CALL
  TOKENIZED[0]: !pkt -> VAR1
  ORIGINAL[1]: !pkt -> side_data[i] . data
  TYPE[1]: CALL
  TOKENIZED[1]: !pkt -> VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: pkt -> side_data[i] . data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: - 12
  TYPE[3]: CALL
  TOKENIZED[3]: - 12
  ORIGINAL[4]: memcpy(pkt -> side_data[i] . data,(p - size),size)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 , ( VAR5 - VAR6 ) , VAR6 )
  ORIGINAL[5]: pkt -> side_data[i] . data
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[6]: pkt -> side_data[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[7]: pkt -> side_data
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: p - size
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 - VAR2
  ORIGINAL[9]: pkt -> size -= size + 5
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 -= VAR2 + 5
  ORIGINAL[10]: pkt -> size
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: size + 5
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 + 5
  ORIGINAL[12]: p[4] & 128
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 [ 4 ] & 128
  ORIGINAL[13]: p[4]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 [ 4 ]
  ORIGINAL[14]: side_data
  TYPE[14]: FIELD_IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: data
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: size
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: pkt
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: i
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: p
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: size
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: size
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: pkt
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: size
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: p
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771247
FRAGMENT_COUNT: 5
  ORIGINAL[0]: av_free((pkt -> data))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[1]: pkt -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477001
FRAGMENT_COUNT: 3
  ORIGINAL[0]: pkt -> destruct
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: destruct
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pkt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477228
FRAGMENT_COUNT: 4
  ORIGINAL[0]: isValid(oneirocritic_grots) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) == 1
  ORIGINAL[1]: strlen(oneirocritic_grots)+1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) +1
  ORIGINAL[2]: sizeof(char)
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( char )
  ORIGINAL[3]: char
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: char

CENTER_NODE: 30064771338
FRAGMENT_COUNT: 6
  ORIGINAL[0]: !new_ptr
  TYPE[0]: CALL
  TOKENIZED[0]: !new_ptr
  ORIGINAL[1]: pkt -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt -> data + pkt -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + VAR1 -> VAR3
  ORIGINAL[3]: pkt -> size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: size
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pkt
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640310
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 68719477187
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_setup_printf_context()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: &forcement_prorestriction
  TYPE[1]: CALL
  TOKENIZED[1]: &forcement_prorestriction
  ORIGINAL[2]: forcement_prorestriction
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: forcement_prorestriction
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640306
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771571
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: pkt -> side_data[i] . type == type
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 == VAR4
  ORIGINAL[2]: for (i = 0;i < pkt -> side_data_elems;i++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771301
FRAGMENT_COUNT: 5
  ORIGINAL[0]: pkt -> size <= size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR2
  ORIGINAL[1]: pkt -> size = size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: pkt -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771264
FRAGMENT_COUNT: 3
  ORIGINAL[0]: pkt -> convergence_duration = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: pkt -> convergence_duration
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476984
FRAGMENT_COUNT: 7
  ORIGINAL[0]: src -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: src -> side_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: !data
  TYPE[2]: CALL
  TOKENIZED[2]: !data
  ORIGINAL[3]: src -> side_data[i] . data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: src -> side_data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: side_data
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: src
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771506
FRAGMENT_COUNT: 18
  ORIGINAL[0]: i < pkt -> side_data_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: pkt -> side_data_elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: av_free(pkt -> side_data[i] . data)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 )
  ORIGINAL[4]: pkt -> side_data[i] . data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: pkt -> side_data[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: pkt -> side_data
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: for (i = 0;i < pkt -> side_data_elems;i++)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[8]: side_data_elems
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: side_data
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: data
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: pkt
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: i
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: pkt
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: pkt
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: i
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: pkt
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 68719477032
FRAGMENT_COUNT: 10
  ORIGINAL[0]: ((unsigned int )size) > (2147483647 - 16)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned int ) VAR1 ) > ( 2147483647 - 16 )
  ORIGINAL[1]: pkt -> side_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: elems + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: elems
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: elems
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: elems
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: elems
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: elems
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: elems
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: elems
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719476813
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *stonesoup_tainted_buff != 0
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff != 0
  ORIGINAL[1]: fread(*stonesoup_tainted_buff,1,stonesoup_lsize,stonesoup_tainted_file)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( *stonesoup_tainted_buff , 1 , VAR1 , VAR2 )
  ORIGINAL[2]: *stonesoup_tainted_buff
  TYPE[2]: CALL
  TOKENIZED[2]: *stonesoup_tainted_buff
  ORIGINAL[3]: stonesoup_lsize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_lsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_tainted_file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_lsize
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640304
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477010
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *src
  TYPE[0]: CALL
  TOKENIZED[0]: *src
  ORIGINAL[1]: copy_packet_data(dst,src)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771296
FRAGMENT_COUNT: 4
  ORIGINAL[0]: pkt -> destruct = av_destruct_packet
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: pkt -> destruct
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: destruct
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771779
FRAGMENT_COUNT: 19
  ORIGINAL[0]: i < pkt -> side_data_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: pkt -> side_data_elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: pkt -> side_data[i] . type == type
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 == VAR4
  ORIGINAL[4]: pkt -> side_data[i] . type
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: size > pkt -> side_data[i] . size
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 > VAR2 -> VAR3 [ VAR4 ] . VAR1
  ORIGINAL[6]: pkt -> side_data[i] . size
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[7]: pkt -> side_data[i]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[8]: pkt -> side_data
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: side_data_elems
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: side_data
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: size
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: i
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: pkt
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: type
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: size
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: pkt
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: i
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 30064771609
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !p
  TYPE[0]: CALL
  TOKENIZED[0]: !p
  ORIGINAL[1]: pkt -> destruct = av_destruct_packet
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3
  ORIGINAL[2]: pkt -> destruct
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640339
FRAGMENT_COUNT: 0

