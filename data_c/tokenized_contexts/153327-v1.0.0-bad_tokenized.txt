# Tokenized code fragments for 153327-v1.0.0-bad
# Total center nodes processed: 26
# Total code fragments found: 152

CENTER_NODE: 30064771619
FRAGMENT_COUNT: 9
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: &ctx -> num
  TYPE[1]: CALL
  TOKENIZED[1]: &ctx -> VAR1
  ORIGINAL[2]: ctx -> num
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: num
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ctx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ctx
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ctx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ctx
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 9
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: Camellia_ofb128_encrypt(in,out,((long )(((size_t )1) << sizeof(long ) * 8 - 2)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( ( ( VAR3 ) 1 ) << sizeof ( long ) * 8 - 2 ) ) , ( & ( ( VAR4 * ) ( VAR5 -> VAR6 ) ) -> VAR7 ) , VAR5 -> VAR8 , &ctx -> VAR9 )
  ORIGINAL[2]: (long )(((size_t )1) << sizeof(long ) * 8 - 2)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ctx -> iv
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: &ctx -> VAR1
  ORIGINAL[6]: in
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: out
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: out
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477027
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 128 == 1
  TYPE[0]: CALL
  TOKENIZED[0]: 128 == 1
  ORIGINAL[1]: ctx -> flags
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ctx -> iv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ctx -> num
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: ctx -> encrypt
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: flags
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ctx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476848
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ctx -> cipher
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: cipher
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: bl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ctx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476901
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: in += ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: out += ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[3]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[4]: out
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: out
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771873
FRAGMENT_COUNT: 3
  ORIGINAL[0]: * stonesoup_printf_context = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: * VAR1 = VAR2
  ORIGINAL[1]: stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771743
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: inl >= chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= VAR2
  ORIGINAL[2]: inl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: inl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476990
FRAGMENT_COUNT: 7
  ORIGINAL[0]: __sync_bool_compare_and_swap(&satrapical_septenaries,0,1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &satrapical_septenaries , 0 , 1 )
  ORIGINAL[1]: mkdir(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: allelotropism_poltinnik != 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != 0
  ORIGINAL[3]: SUBDEBUTANTE_NOVITIOUS(williamsville_azurine)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: initiate_cadmopone((thirion_sarcosporida *)williamsville_azurine)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( VAR1 * ) VAR2 )
  ORIGINAL[5]: &camellia_192_cbc
  TYPE[5]: CALL
  TOKENIZED[5]: &camellia_192_cbc
  ORIGINAL[6]: <global> camellia_192_cbc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1

CENTER_NODE: 30064771651
FRAGMENT_COUNT: 9
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: (EVP_CAMELLIA_KEY *)(ctx -> cipher_data)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: cipher_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ctx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ctx
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ctx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ctx
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771861
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stonesoup_i < stonesoup_opt_var
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: stonesoup_data->after(stonesoup_data->buffer[stonesoup_i])
  TYPE[1]: CALL
  TOKENIZED[1]: stonesoup_data->after ( stonesoup_data->buffer [ VAR1 ] )
  ORIGINAL[2]: stonesoup_data->after
  TYPE[2]: CALL
  TOKENIZED[2]: stonesoup_data->after
  ORIGINAL[3]: after
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_data
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771343
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 128 == 1
  TYPE[0]: CALL
  TOKENIZED[0]: 128 == 1
  ORIGINAL[1]: !(ctx -> flags & 0x2000)
  TYPE[1]: CALL
  TOKENIZED[1]: ! ( VAR1 -> VAR2 & 0x2000 )
  ORIGINAL[2]: ctx -> flags & 0x2000
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 & 0x2000
  ORIGINAL[3]: ctx -> flags
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 68719477201
FRAGMENT_COUNT: 9
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: out += chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: inl < chunk
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2
  ORIGINAL[3]: inl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: inl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: inl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: chunk
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: inl
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771537
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i <= inl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= VAR2
  ORIGINAL[1]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[1]: CALL
  TOKENIZED[1]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[2]: ((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[3]: (EVP_CAMELLIA_KEY *)(ctx -> cipher_data)
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[4]: ks
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771165
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: out += ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[3]: inl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: out
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477267
FRAGMENT_COUNT: 6
  ORIGINAL[0]: Camellia_set_key(key,ctx -> key_len * 8,(ctx -> cipher_data))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 -> VAR3 * 8 , ( VAR2 -> VAR4 ) )
  ORIGINAL[1]: ctx -> key_len * 8
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 * 8
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ret
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ctx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640263
FRAGMENT_COUNT: 1
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122

CENTER_NODE: 30064771421
FRAGMENT_COUNT: 5
  ORIGINAL[0]: &ctx -> num
  TYPE[0]: CALL
  TOKENIZED[0]: &ctx -> VAR1
  ORIGINAL[1]: ctx -> num
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: num
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: inl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476954
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i <= inl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= VAR2
  ORIGINAL[1]: ctx -> cipher_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ctx -> encrypt
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: cipher_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771449
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: sizeof(long ) * 8
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( long ) * 8

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 5
  ORIGINAL[0]: chunk = ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: chunk
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771775
FRAGMENT_COUNT: 7
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: inl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: inl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771954
FRAGMENT_COUNT: 3
  ORIGINAL[0]: {(756), (16), (32), (0), ((0 | 0x1)), (camellia_init_key), (camellia_256_ecb_cipher), (((void *)0)), ((sizeof(EVP_CAMELLIA_KEY ))), (EVP_CIPHER_set_asn1_iv), (EVP_CIPHER_get_asn1_iv), (((void *)0)), ((void *)0)}
  TYPE[0]: CALL
  TOKENIZED[0]: { ( 756 ) , ( 16 ) , ( 32 ) , ( 0 ) , ( ( 0 | 0x1 ) ) , ( VAR1 ) , ( VAR2 ) , ( ( ( void * ) 0 ) ) , ( ( sizeof ( VAR3 ) ) ) , ( VAR4 ) , ( VAR5 ) , ( ( ( void * ) 0 ) ) , ( ( void * ) 0 ) }
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: EVP_CAMELLIA_KEY
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476771
FRAGMENT_COUNT: 6
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: sprintf(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: filepath
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771133
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 68719477065
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: (size_t )1
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) 1
  ORIGINAL[2]: sizeof(long )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long )
  ORIGINAL[3]: long
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: long

CENTER_NODE: 30064771690
FRAGMENT_COUNT: 15
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: Camellia_cfb1_encrypt(in,out,((long )(1 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num,ctx -> encrypt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( 1 == 1 && ! ( VAR3 -> VAR4 & 0x2000 ) ?inl * 8 : VAR5 ) ) , ( & ( ( VAR6 * ) ( VAR3 -> VAR7 ) ) -> VAR8 ) , VAR3 -> VAR9 , &ctx -> VAR10 , VAR3 -> VAR11 )
  ORIGINAL[2]: (long )(1 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( 1 == 1 && ! ( VAR1 -> VAR2 & 0x2000 ) ?inl * 8 : VAR3 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ctx -> iv
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: &ctx -> VAR1
  ORIGINAL[6]: ctx -> encrypt
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: encrypt
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: in
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: out
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: ctx
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: ctx
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: ctx
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: ctx
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: ctx
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

