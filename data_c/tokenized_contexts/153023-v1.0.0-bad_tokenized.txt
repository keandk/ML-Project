# Tokenized code fragments for 153023-v1.0.0-bad
# Total center nodes processed: 32
# Total code fragments found: 148

CENTER_NODE: 68719476862
FRAGMENT_COUNT: 3
  ORIGINAL[0]: pkt -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: size
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pkt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640299
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771234
FRAGMENT_COUNT: 4
  ORIGINAL[0]: pkt -> destruct = av_destruct_packet
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: pkt -> destruct
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: destruct
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476844
FRAGMENT_COUNT: 12
  ORIGINAL[0]: pkt -> pts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: pkt -> dts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt -> pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pkt -> duration
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pkt -> convergence_duration
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: pkt -> flags
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: pkt -> stream_index
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: pkt -> destruct = ((void *)0)
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[8]: pkt -> destruct
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: pkt -> side_data
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: side_data
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: pkt
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640290
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771720
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < pkt -> side_data_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: pkt -> side_data[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: pkt -> side_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: side_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640287
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771116
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771437
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pkt -> destruct
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: (pkt -> destruct)(pkt)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 ) ( VAR1 )
  ORIGINAL[2]: pkt -> destruct
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: destruct
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pkt
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771793
FRAGMENT_COUNT: 8
  ORIGINAL[0]: winklehole_musettes != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: tacitus_knitch[37]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 37 ]
  ORIGINAL[2]: tacitus_knitch[37] - 5
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 37 ] - 5
  ORIGINAL[3]: tacitus_knitch[37]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 37 ]
  ORIGINAL[4]: tacitus_knitch[37]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ 37 ]
  ORIGINAL[5]: tacitus_knitch
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tacitus_knitch
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: tacitus_knitch
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771640
FRAGMENT_COUNT: 35
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: size = av_bswap32(((const union unaligned_32 *)p) -> l)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( ( ( const union VAR2 * ) VAR3 ) -> VAR4 )
  ORIGINAL[2]: av_bswap32(((const union unaligned_32 *)p) -> l)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( ( const union VAR1 * ) VAR2 ) -> VAR3 )
  ORIGINAL[3]: ((const union unaligned_32 *)p) -> l
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( const union VAR1 * ) VAR2 ) -> VAR3
  ORIGINAL[4]: (const union unaligned_32 *)p
  TYPE[4]: CALL
  TOKENIZED[4]: ( const union VAR1 * ) VAR2
  ORIGINAL[5]: size > 2147483647 || p - pkt -> data < size
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 > 2147483647 || VAR2 - VAR3 -> VAR4 < VAR1
  ORIGINAL[6]: size > 2147483647
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 > 2147483647
  ORIGINAL[7]: p[4] & 128
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 [ 4 ] & 128
  ORIGINAL[8]: p[4]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 [ 4 ]
  ORIGINAL[9]: p -= size + 5
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -= VAR2 + 5
  ORIGINAL[10]: size + 5
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 + 5
  ORIGINAL[11]: pkt -> side_data = (av_malloc(i * sizeof(( *pkt -> side_data))))
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 = ( FUN1 ( VAR3 * sizeof ( ( *pkt -> VAR2 ) ) ) )
  ORIGINAL[12]: pkt -> side_data
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: av_malloc(i * sizeof(( *pkt -> side_data)))
  TYPE[13]: CALL
  TOKENIZED[13]: FUN1 ( VAR1 * sizeof ( ( *pkt -> VAR2 ) ) )
  ORIGINAL[14]: i * sizeof(( *pkt -> side_data))
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 * sizeof ( ( *pkt -> VAR2 ) )
  ORIGINAL[15]: sizeof(( *pkt -> side_data))
  TYPE[15]: CALL
  TOKENIZED[15]: sizeof ( ( *pkt -> VAR1 ) )
  ORIGINAL[16]: *pkt -> side_data
  TYPE[16]: CALL
  TOKENIZED[16]: *pkt -> VAR1
  ORIGINAL[17]: pkt -> side_data
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: !pkt -> side_data
  TYPE[18]: CALL
  TOKENIZED[18]: !pkt -> VAR1
  ORIGINAL[19]: pkt -> side_data
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2
  ORIGINAL[20]: break;
  TYPE[20]: CONTROL_STRUCTURE
  TOKENIZED[20]: break ;
  ORIGINAL[21]: l
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: side_data
  TYPE[22]: FIELD_IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: side_data
  TYPE[23]: FIELD_IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: side_data
  TYPE[24]: FIELD_IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: i
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: size
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: p
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: size
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: p
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: size
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: pkt
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: i
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: pkt
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: pkt
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1

CENTER_NODE: 68719477013
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < pkt -> side_data_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: pkt -> side_data_elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt -> side_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: side_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771429
FRAGMENT_COUNT: 4
  ORIGINAL[0]: pkt -> destruct == ((void *)0) && pkt -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 ) && VAR1 -> VAR3
  ORIGINAL[1]: copy_packet_data(pkt,&tmp_pkt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &tmp_pkt )
  ORIGINAL[2]: &tmp_pkt
  TYPE[2]: CALL
  TOKENIZED[2]: &tmp_pkt
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97
  ORIGINAL[1]: c <= 122
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= 122
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476894
FRAGMENT_COUNT: 9
  ORIGINAL[0]: !data
  TYPE[0]: CALL
  TOKENIZED[0]: !data
  ORIGINAL[1]: memcpy(data,(src -> data),(dst -> size))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( VAR2 -> VAR1 ) , ( VAR3 -> VAR4 ) )
  ORIGINAL[2]: src -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dst -> size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: data
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: src
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: data
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: data
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771259
FRAGMENT_COUNT: 9
  ORIGINAL[0]: !pkt -> size
  TYPE[0]: CALL
  TOKENIZED[0]: !pkt -> VAR1
  ORIGINAL[1]: pkt -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt -> size + 16
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 16
  ORIGINAL[3]: pkt -> size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pkt -> size
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: size
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pkt
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pkt
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: pkt
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640280
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640296
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771161
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *stonesoup_tainted_buff != 0
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff != 0
  ORIGINAL[1]: (*stonesoup_tainted_buff)[stonesoup_lsize] = '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: ( *stonesoup_tainted_buff ) [ VAR1 ] = '\\0'
  ORIGINAL[2]: (*stonesoup_tainted_buff)[stonesoup_lsize]
  TYPE[2]: CALL
  TOKENIZED[2]: ( *stonesoup_tainted_buff ) [ VAR1 ]
  ORIGINAL[3]: *stonesoup_tainted_buff
  TYPE[3]: CALL
  TOKENIZED[3]: *stonesoup_tainted_buff
  ORIGINAL[4]: stonesoup_lsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771470
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ((unsigned int )size) > (2147483647 - 16)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned int ) VAR1 ) > ( 2147483647 - 16 )
  ORIGINAL[1]: pkt -> side_data = (av_realloc((pkt -> side_data),(elems + 1) * sizeof(( *pkt -> side_data))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 + 1 ) * sizeof ( ( *pkt -> VAR2 ) ) ) )
  ORIGINAL[2]: pkt -> side_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: av_realloc((pkt -> side_data),(elems + 1) * sizeof(( *pkt -> side_data)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 + 1 ) * sizeof ( ( *pkt -> VAR2 ) ) )
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771432
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *dst =  *src
  TYPE[0]: CALL
  TOKENIZED[0]: *dst = *src
  ORIGINAL[1]: *dst
  TYPE[1]: CALL
  TOKENIZED[1]: *dst
  ORIGINAL[2]: *src
  TYPE[2]: CALL
  TOKENIZED[2]: *src
  ORIGINAL[3]: dst
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: src
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dst
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476834
FRAGMENT_COUNT: 5
  ORIGINAL[0]: av_free((pkt -> data))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[1]: pkt -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771547
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !p
  TYPE[0]: CALL
  TOKENIZED[0]: !p
  ORIGINAL[1]: pkt -> destruct = av_destruct_packet
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3
  ORIGINAL[2]: pkt -> destruct
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < pkt -> side_data_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: for (i = 0;i < pkt -> side_data_elems;i++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477147
FRAGMENT_COUNT: 3
  ORIGINAL[0]: aquariiums_gypsologist != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: *progeneration_chatty
  TYPE[1]: CALL
  TOKENIZED[1]: *progeneration_chatty
  ORIGINAL[2]: progeneration_chatty
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

