# Tokenized code fragments for 152462-v1.0.0-bad
# Total center nodes processed: 45
# Total code fragments found: 108

CENTER_NODE: 47244640377
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476840
FRAGMENT_COUNT: 5
  ORIGINAL[0]: apr_pool_cleanup_register(subpool,((void *)0),xlate_cleanup,apr_pool_cleanup_null)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( ( void * ) 0 ) , VAR2 , VAR3 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: err
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: subpool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: apr_pool_cleanup_null
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640381
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640373
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477304
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_utf__is_valid(data,len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: data
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771701
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !svn_utf__cstring_is_valid(data)
  TYPE[0]: CALL
  TOKENIZED[0]: !svn_utf__cstring_is_valid ( VAR1 )
  ORIGINAL[1]: svn_utf__cstring_is_valid(data)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771803
FRAGMENT_COUNT: 16
  ORIGINAL[0]: node -> handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: !err
  TYPE[1]: CALL
  TOKENIZED[1]: !err
  ORIGINAL[2]: err = convert_to_stringbuf(node,(src -> data),src -> len,dest,pool)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR2 , ( VAR3 -> VAR4 ) , VAR3 -> VAR5 , VAR6 , VAR7 )
  ORIGINAL[3]: convert_to_stringbuf(node,(src -> data),src -> len,dest,pool)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 -> VAR4 , VAR5 , VAR6 )
  ORIGINAL[4]: src -> data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: src -> len
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: data
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: len
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: err
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: err
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: node
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: src
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: src
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: dest
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: pool
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: err
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640389
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771879
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_utf__cstring_from_utf8_fuzzy(src,pool,svn_utf_cstring_from_utf8)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477188
FRAGMENT_COUNT: 7
  ORIGINAL[0]: src_orig < src_end
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: *new
  TYPE[1]: CALL
  TOKENIZED[1]: *new
  ORIGINAL[2]: *new
  TYPE[2]: CALL
  TOKENIZED[2]: *new
  ORIGINAL[3]: new
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771870
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_utf_cstring_from_utf8_ex2(dest,src,topage,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: dest
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: src
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: topage
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477441
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_utf_cstring_to_utf8_ex2(dest,src,frompage,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[1]: dest
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: src
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771654
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data - data_start
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2
  ORIGINAL[1]: *((const unsigned char *)data)
  TYPE[1]: CALL
  TOKENIZED[1]: * ( ( const unsigned char * ) VAR1 )
  ORIGINAL[2]: (const unsigned char *)data
  TYPE[2]: CALL
  TOKENIZED[2]: ( const unsigned char * ) VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477580
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_utf_stringbuf_from_utf8(&destbuf,src,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &destbuf , VAR1 , VAR2 )
  ORIGINAL[1]: &destbuf
  TYPE[1]: CALL
  TOKENIZED[1]: &destbuf
  ORIGINAL[2]: src
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771681
FRAGMENT_COUNT: 5
  ORIGINAL[0]: data + len - last
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 - VAR3
  ORIGINAL[1]: data + len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: last
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771136
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: * stonesoup_tainted_file = 0
  TYPE[1]: CALL
  TOKENIZED[1]: * VAR1 = 0
  ORIGINAL[2]: stonesoup_tainted_file
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771173
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *node = arg
  TYPE[0]: CALL
  TOKENIZED[0]: *node = VAR1
  ORIGINAL[1]: node
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: arg
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: node
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640400
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640408
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640383
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477211
FRAGMENT_COUNT: 7
  ORIGINAL[0]: src_length == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: ( *dest) -> data + ( *dest) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: ( *dest ) -> VAR1 + ( *dest ) -> VAR2
  ORIGINAL[2]: &destlen
  TYPE[2]: CALL
  TOKENIZED[2]: &destlen
  ORIGINAL[3]: apr_err == 0 && srclen != 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == 0 && VAR2 != 0
  ORIGINAL[4]: destlen
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: destlen
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: destlen
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640406
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 6
  ORIGINAL[0]: apr_err == 22 || apr_err == 20000 + 50000 + 23
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 22 || VAR1 == 20000 + 50000 + 23
  ORIGINAL[1]: apr_err != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: apr_palloc(pool,sizeof(xlate_handle_node_t ))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , sizeof ( VAR2 ) )
  ORIGINAL[3]: sizeof(xlate_handle_node_t )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( VAR1 )
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: xlate_handle_node_t
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477012
FRAGMENT_COUNT: 9
  ORIGINAL[0]: mysql_query(stonesoup_conn, stonesoup_use_str) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 ) == 0
  ORIGINAL[1]: mysql_query(stonesoup_conn,stonesoup_query_buffer)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: stonesoup_printf(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: stonesoup_printf(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[5]: stonesoup_trace
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_trace
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: trace_point
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_trace
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640362
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640379
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477565
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strlen(src)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: src
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640375
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xlate_handle_hash = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: <global> xlate_handle_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 47244640370
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640398
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476745
FRAGMENT_COUNT: 3
  ORIGINAL[0]: size_filepath = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: retval = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: retval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640396
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640356
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771200
FRAGMENT_COUNT: 4
  ORIGINAL[0]: topage == ((const char *)1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( const char * ) 1 )
  ORIGINAL[1]: topage = \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = \
  ORIGINAL[2]: topage
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640318
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640279
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640328
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640330
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477384
FRAGMENT_COUNT: 6
  ORIGINAL[0]: node -> handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len = strlen(src)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[2]: strlen(src)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: src
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

