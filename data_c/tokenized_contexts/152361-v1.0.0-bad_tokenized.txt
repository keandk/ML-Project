# Tokenized code fragments for 152361-v1.0.0-bad
# Total center nodes processed: 33
# Total code fragments found: 152

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !validate_codec_tag(s,st)
  TYPE[0]: CALL
  TOKENIZED[0]: !validate_codec_tag ( VAR1 , VAR2 )
  ORIGINAL[1]: tagbuf[32]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 32 ]
  ORIGINAL[2]: tagbuf[32]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 32 ]
  ORIGINAL[3]: tagbuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640364
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477617
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !s -> oformat
  TYPE[0]: CALL
  TOKENIZED[0]: !s -> VAR1
  ORIGINAL[1]: s -> oformat
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: s -> oformat
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: oformat
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772471
FRAGMENT_COUNT: 6
  ORIGINAL[0]: gamari_elastin > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: tracepoint(stonesoup_trace, variable_buffer, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: stonesoup_trace
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: variable_buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_base_cmd
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476839
FRAGMENT_COUNT: 3
  ORIGINAL[0]: f -> num + incr
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 + VAR3
  ORIGINAL[1]: f -> num
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: incr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640403
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !flush
  TYPE[0]: CALL
  TOKENIZED[0]: !flush

CENTER_NODE: 47244640427
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 17
  ORIGINAL[0]: avctag -> id
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: avpriv_toupper4(avctag -> tag) == avpriv_toupper4(st -> codec -> codec_tag)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 ) == FUN1 ( VAR3 -> VAR4 -> VAR5 )
  ORIGINAL[2]: avctag -> tag
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: avctag -> id
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: id == (st -> codec -> codec_id)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == ( VAR2 -> VAR3 -> VAR4 )
  ORIGINAL[5]: (avctag -> id) == (st -> codec -> codec_id)
  TYPE[5]: CALL
  TOKENIZED[5]: ( VAR1 -> VAR2 ) == ( VAR3 -> VAR4 -> VAR5 )
  ORIGINAL[6]: avctag -> id
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tag = avctag -> tag
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = VAR2 -> VAR1
  ORIGINAL[8]: avctag -> tag
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: avctag++
  TYPE[9]: CALL
  TOKENIZED[9]: avctag++
  ORIGINAL[10]: avctag
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: avctag
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: avctag
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: avctag
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: avctag
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: avctag
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: avctag
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 68719476825
FRAGMENT_COUNT: 6
  ORIGINAL[0]: num >= den
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2
  ORIGINAL[1]: val += num / den
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2 / VAR3
  ORIGINAL[2]: num / den
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 / VAR2
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: num
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772029
FRAGMENT_COUNT: 6
  ORIGINAL[0]: max && (st -> interleaver_chunk_duration) > max
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && ( VAR2 -> VAR3 ) > VAR1
  ORIGINAL[1]: (av_rescale(pkt -> dts + syncoffset,1,max)) * max - syncoffset
  TYPE[1]: CALL
  TOKENIZED[1]: ( FUN1 ( VAR1 -> VAR2 + VAR3 , 1 , VAR4 ) ) * VAR4 - VAR3
  ORIGINAL[2]: (av_rescale(pkt -> dts + syncoffset,1,max)) * max
  TYPE[2]: CALL
  TOKENIZED[2]: ( FUN1 ( VAR1 -> VAR2 + VAR3 , 1 , VAR4 ) ) * VAR4
  ORIGINAL[3]: av_rescale(pkt -> dts + syncoffset,1,max)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 + VAR3 , 1 , VAR4 )
  ORIGINAL[4]: max
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: syncoffset
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477528
FRAGMENT_COUNT: 7
  ORIGINAL[0]: s -> oformat -> interleave_packet
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: (s -> oformat -> interleave_packet)(s,out,in,flush)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 -> VAR3 ) ( VAR1 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: out
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: in
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: flush
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: in
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j = 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 2
  ORIGINAL[1]: j < 14
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 14
  ORIGINAL[2]: j += 1 + (j > 2)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += 1 + ( VAR1 > 2 )
  ORIGINAL[3]: for (j = 2;j < 14;j += 1 + (j > 2))
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 2 ; VAR1 < 14 ; VAR1 += 1 + ( VAR1 > 2 ) )
  ORIGINAL[4]: while (q . den / q . num < min_precission && q . num % j == 0)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: while ( VAR1 . VAR2 / VAR1 . VAR3 < VAR4 && VAR1 . VAR3 % VAR5 == 0 )

CENTER_NODE: 47244640422
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640428
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719477295
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ret >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: s -> streams
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pkt -> stream_index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: stream_index
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pkt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pkt
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477680
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ++stonesoup_global_variable
  TYPE[0]: CALL
  TOKENIZED[0]: ++stonesoup_global_variable
  ORIGINAL[1]: norrie_benedictional(maugansville_ladonna,troparion_counterfallacy)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: maugansville_ladonna
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: troparion_counterfallacy
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640421
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771575
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s -> nb_streams
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> streams[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> streams
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: streams
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476914
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s -> oformat
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s -> oformat -> priv_data_size > 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3 > 0
  ORIGINAL[2]: s -> priv_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: priv_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772416
FRAGMENT_COUNT: 16
  ORIGINAL[0]: ret == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: s -> pb?s -> pb -> error : 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> pb?s -> VAR2 -> VAR3 : 0
  ORIGINAL[2]: s -> pb
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: s -> pb -> error
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[4]: s -> pb
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: pb
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pb
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: error
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: s
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: s
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: s
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: s
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640433
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771835
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pkt -> pts != ((int64_t )0x8000000000000000UL)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != ( ( VAR3 ) 0x8000000000000000UL )
  ORIGINAL[1]: pkt -> dts != ((int64_t )0x8000000000000000UL) && pkt -> pts != ((int64_t )0x8000000000000000UL)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 != ( ( VAR3 ) 0x8000000000000000UL ) && VAR1 -> VAR4 != ( ( VAR3 ) 0x8000000000000000UL )
  ORIGINAL[2]: pkt -> dts != ((int64_t )0x8000000000000000UL)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 != ( ( VAR3 ) 0x8000000000000000UL )
  ORIGINAL[3]: pkt -> pts != ((int64_t )0x8000000000000000UL)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 != ( ( VAR3 ) 0x8000000000000000UL )
  ORIGINAL[4]: pkt -> pts
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: (int64_t )0x8000000000000000UL
  TYPE[5]: CALL
  TOKENIZED[5]: ( VAR1 ) 0x8000000000000000UL

CENTER_NODE: 68719477565
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ret <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: ret
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: ret
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640426
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640363
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771624
FRAGMENT_COUNT: 6
  ORIGINAL[0]: mkdir(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: stonesoup_read_taint(&pelomedusa_gladius,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &pelomedusa_gladius , \
  ORIGINAL[2]: &pelomedusa_gladius
  TYPE[2]: CALL
  TOKENIZED[2]: &pelomedusa_gladius
  ORIGINAL[3]: pelomedusa_gladius
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pelomedusa_gladius
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pelomedusa_gladius
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477263
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ret = ((s -> oformat -> write_packet)(s,pkt))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( VAR2 -> VAR3 -> VAR4 ) ( VAR2 , VAR5 ) )
  ORIGINAL[1]: av_packet_merge_side_data(pkt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: did_split
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pkt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ret
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640351
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477684
FRAGMENT_COUNT: 3
  ORIGINAL[0]: * stonesoup_printf_context = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: * VAR1 = VAR2
  ORIGINAL[1]: stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771096
FRAGMENT_COUNT: 9
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stat(dirpath, &st) == -1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[2]: stat(dirpath, &st)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , &st )
  ORIGINAL[3]: -1
  TYPE[3]: CALL
  TOKENIZED[3]: -1
  ORIGINAL[4]: retval = mkdir(dirpath, 0700)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[5]: mkdir(dirpath, 0700)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[6]: retval
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dirpath
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: retval
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064772114
FRAGMENT_COUNT: 17
  ORIGINAL[0]: st -> time_base
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s -> audio_preload && (st -> codec -> codec_type) == AVMEDIA_TYPE_AUDIO != ((st2 -> codec -> codec_type) == AVMEDIA_TYPE_AUDIO)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && ( VAR3 -> VAR4 -> VAR5 ) == VAR6 != ( ( VAR7 -> VAR4 -> VAR5 ) == VAR6 )
  ORIGINAL[2]: av_rescale_q(pkt -> dts,st -> time_base,((AVRational ){(1), (1000000)}))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , VAR3 -> VAR4 , ( ( VAR5 ) { ( 1 ) , ( 1000000 ) } ) )
  ORIGINAL[3]: pkt -> dts
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: st -> time_base
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: (AVRational ){(1), (1000000)}
  TYPE[5]: CALL
  TOKENIZED[5]: ( VAR1 ) { ( 1 ) , ( 1000000 ) }
  ORIGINAL[6]: st -> time_base
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: st -> time_base
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: st -> time_base
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: time_base
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: st
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: st
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: st
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: st
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: st
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: st
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: st
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

