# Tokenized code fragments for 152932-v1.0.0-bad
# Total center nodes processed: 82
# Total code fragments found: 404

CENTER_NODE: 30064771884
FRAGMENT_COUNT: 17
  ORIGINAL[0]: number >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: svn__ui64toa(dest,((apr_uint64_t )number))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( VAR2 ) VAR3 ) )
  ORIGINAL[2]: (apr_uint64_t )number
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: *dest = 45
  TYPE[3]: CALL
  TOKENIZED[3]: *dest = 45
  ORIGINAL[4]: *dest
  TYPE[4]: CALL
  TOKENIZED[4]: *dest
  ORIGINAL[5]: svn__ui64toa(dest + 1,((apr_uint64_t )(0 - number))) + 1
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 + 1 , ( ( VAR2 ) ( 0 - VAR3 ) ) ) + 1
  ORIGINAL[6]: svn__ui64toa(dest + 1,((apr_uint64_t )(0 - number)))
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( VAR1 + 1 , ( ( VAR2 ) ( 0 - VAR3 ) ) )
  ORIGINAL[7]: dest + 1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 + 1
  ORIGINAL[8]: (apr_uint64_t )(0 - number)
  TYPE[8]: CALL
  TOKENIZED[8]: ( VAR1 ) ( 0 - VAR2 )
  ORIGINAL[9]: 0 - number
  TYPE[9]: CALL
  TOKENIZED[9]: 0 - VAR1
  ORIGINAL[10]: number
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: dest
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: number
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: dest
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: dest
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: apr_uint64_t
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: number
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 68719476931
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str1 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str2 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477472
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i > 3
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 3
  ORIGINAL[1]: &buffer[i - 2]
  TYPE[1]: CALL
  TOKENIZED[1]: &buffer [ VAR1 - 2 ]
  ORIGINAL[2]: buffer[i - 2]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 - 2 ]
  ORIGINAL[3]: buffer[i - 3]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 - 3 ]
  ORIGINAL[4]: buffer[i - 3]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 - 3 ]
  ORIGINAL[5]: buffer
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: buffer
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477214
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str1 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476926
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771272
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (svn_string_t *)(&strbuf -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 * ) ( &strbuf -> VAR2 )
  ORIGINAL[1]: &strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: &strbuf -> VAR1
  ORIGINAL[2]: strbuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 30064771338
FRAGMENT_COUNT: 6
  ORIGINAL[0]: memset((str -> data),c,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: len
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771427
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,cstr,strlen(cstr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[1]: strlen(cstr)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477127
FRAGMENT_COUNT: 6
  ORIGINAL[0]: str -> data + pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 + VAR3
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pos
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pos
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771365
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477166
FRAGMENT_COUNT: 19
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> blocksize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: old_count < new_count
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 < VAR2
  ORIGINAL[4]: delta = new_count - old_count
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2 - VAR3
  ORIGINAL[5]: svn_stringbuf_ensure(str,str -> len + delta)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR1 -> VAR2 + VAR3 )
  ORIGINAL[6]: str -> len
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: str -> data
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: str -> data
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: str -> len
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: str -> data
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: str -> len
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: str
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: str
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: str
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: str
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: str
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: str
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: str
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 30064771535
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare((str1 -> data),(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str1 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476851
FRAGMENT_COUNT: 5
  ORIGINAL[0]: len1 != len2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: memcmp(str1,str2,len1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: str1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771194
FRAGMENT_COUNT: 14
  ORIGINAL[0]: i < len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: !(0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002))
  TYPE[1]: CALL
  TOKENIZED[1]: ! ( 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 ) )
  ORIGINAL[2]: 0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002)
  TYPE[2]: CALL
  TOKENIZED[2]: 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 )
  ORIGINAL[3]: svn_ctype_table[(unsigned char )str[i]] & 0x0002
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002
  ORIGINAL[4]: svn_ctype_table[(unsigned char )str[i]]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ]
  ORIGINAL[5]: (unsigned char )str[i]
  TYPE[5]: CALL
  TOKENIZED[5]: ( unsigned char ) VAR1 [ VAR2 ]
  ORIGINAL[6]: str[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: for (i = 0;i < len;i++)
  TYPE[7]: CONTROL_STRUCTURE
  TOKENIZED[7]: for ( VAR1 = 0 ; VAR1 < VAR2 ; i++ )
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: len
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: svn_ctype_table
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: str
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: i
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: len
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 68719477330
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str1++
  TYPE[0]: CALL
  TOKENIZED[0]: str1++
  ORIGINAL[1]: cmp || !a || !b
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 || !a || !b
  ORIGINAL[2]: a
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476957
FRAGMENT_COUNT: 9
  ORIGINAL[0]: new_string -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: new_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_string -> blocksize = blocksize - sizeof(( *new_string))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = VAR2 - sizeof ( ( *new_string ) )
  ORIGINAL[3]: new_string -> blocksize
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: *new_string
  TYPE[4]: CALL
  TOKENIZED[4]: *new_string
  ORIGINAL[5]: new_string -> pool
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: pool
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new_string
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: new_string
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476813
FRAGMENT_COUNT: 4
  ORIGINAL[0]: membuf_create(&membuf -> data,&membuf -> size,size,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 )
  ORIGINAL[1]: size
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771779
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *__errno_location() == 22
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 22
  ORIGINAL[1]: *__errno_location()
  TYPE[1]: CALL
  TOKENIZED[1]: *__errno_location ( )
  ORIGINAL[2]: __errno_location()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: __errno_location()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )

CENTER_NODE: 30064771210
FRAGMENT_COUNT: 6
  ORIGINAL[0]: sizeof(( *new_string))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *new_string ) )
  ORIGINAL[1]: *new_string
  TYPE[1]: CALL
  TOKENIZED[1]: *new_string
  ORIGINAL[2]: new_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640334
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771531
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_stringbuf_ncreate((original_string -> data),original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771740
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *__errno_location() == 22 || endptr == str || str[0] == '\\0' || ( *endptr) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 22 || VAR1 == VAR2 || VAR2 [ 0 ] == '\\0' || ( *endptr ) != '\\0'
  ORIGINAL[1]: svn_error_createf(SVN_ERR_INCORRECT_PARAMS,((void *)0),(dgettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( void * ) 0 ) , ( FUN2 ( \
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: dgettext(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: SVN_ERR_INCORRECT_PARAMS
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772104
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_buffer != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_opt_var = strlen(stonesoup_buffer)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[2]: strlen(stonesoup_buffer)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: stonesoup_opt_var
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_buffer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476908
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: strbuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771807
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoi64(n,str,- 9223372036854775807L - 1,9223372036854775807L,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , - 9223372036854775807L - 1 , 9223372036854775807L , 10 )
  ORIGINAL[1]: - 9223372036854775807L - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 9223372036854775807L - 1
  ORIGINAL[2]: - 9223372036854775807L
  TYPE[2]: CALL
  TOKENIZED[2]: - 9223372036854775807L

CENTER_NODE: 68719477399
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *svn_err__temp = svn_cstring_strtoi64(&val,str,(- 2147483647 - 1),2147483647,10)
  TYPE[0]: CALL
  TOKENIZED[0]: *svn_err__temp = FUN1 ( &val , VAR1 , ( - 2147483647 - 1 ) , 2147483647 , 10 )
  ORIGINAL[1]: svn_err__temp
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: svn_err__temp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771154
FRAGMENT_COUNT: 4
  ORIGINAL[0]: membuf_ensure(&membuf -> data,&membuf -> size,size,membuf -> pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 -> VAR4 )
  ORIGINAL[1]: &membuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: &membuf -> VAR1
  ORIGINAL[2]: membuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771391
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> blocksize > old_len + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 + 1
  ORIGINAL[1]: str -> len = old_len + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3 + 1
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: old_len + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: old_len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476776
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mg_poll_server(stonesoup_server, 1000) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 1000 ) == 0
  ORIGINAL[1]: stonesoup_exit_flag == 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 1
  ORIGINAL[2]: <global> stonesoup_exit_flag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: stonesoup_exit_flag
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477103
FRAGMENT_COUNT: 10
  ORIGINAL[0]: bytes + count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> blocksize
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: svn_stringbuf_ensure(str,str -> len + count)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR1 -> VAR2 + VAR3 )
  ORIGINAL[5]: str -> len
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: str -> data
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: data
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: str
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719476738
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (struct mg_connection*) stonesoup_printf_context
  TYPE[0]: CALL
  TOKENIZED[0]: ( struct mg_connection* ) VAR1
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 30064771124
FRAGMENT_COUNT: 4
  ORIGINAL[0]: minimum_size + (8 - 1) & (~(8 - 1))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + ( 8 - 1 ) & ( ~ ( 8 - 1 ) )
  ORIGINAL[1]: minimum_size + (8 - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + ( 8 - 1 )
  ORIGINAL[2]: ~(8 - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 8 - 1 )
  ORIGINAL[3]: 8 - 1
  TYPE[3]: CALL
  TOKENIZED[3]: 8 - 1

CENTER_NODE: 47244640338
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771182
FRAGMENT_COUNT: 15
  ORIGINAL[0]: _s_z_ > _m_b_f_ -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: _m_b_f_ -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: memset(_m_b_f_ -> data,0,_m_b_f_ -> size)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , 0 , VAR1 -> VAR3 )
  ORIGINAL[3]: _m_b_f_ -> data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: _m_b_f_ -> size
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: memset(_m_b_f_ -> data,0,_s_z_)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 -> VAR2 , 0 , VAR3 )
  ORIGINAL[6]: _m_b_f_ -> data
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: data
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: size
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: data
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: _s_z_
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: _m_b_f_
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: _m_b_f_
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: _m_b_f_
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: _s_z_
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 68719476915
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *data = apr_pvsprintf(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: *data = FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: create_string(data,strlen(data),pool)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640276
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771566
FRAGMENT_COUNT: 5
  ORIGINAL[0]: find_char_backward((str -> data),str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771138
FRAGMENT_COUNT: 10
  ORIGINAL[0]: minimum_size >  *size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > *size
  ORIGINAL[1]: new_size == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0
  ORIGINAL[2]: new_size = minimum_size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: new_size < minimum_size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 < VAR2
  ORIGINAL[4]: new_size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: minimum_size
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new_size
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: minimum_size
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: data
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771609
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *a = apr_array_make(pool,5,(sizeof(input)))
  TYPE[0]: CALL
  TOKENIZED[0]: *a = FUN1 ( VAR1 , 5 , ( sizeof ( VAR2 ) ) )
  ORIGINAL[1]: apr_array_make(pool,5,(sizeof(input)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 5 , ( sizeof ( VAR2 ) ) )
  ORIGINAL[2]: sizeof(input)
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: a
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476751
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(char)
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( char )
  ORIGINAL[1]: buffer_size
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: char
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: char

CENTER_NODE: 30064771923
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: buffer[0] = 45
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ] = 45
  ORIGINAL[2]: buffer[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: apr_uint64_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477304
FRAGMENT_COUNT: 8
  ORIGINAL[0]: ( *p) == 10
  TYPE[0]: CALL
  TOKENIZED[0]: ( *p ) == 10
  ORIGINAL[1]: *p
  TYPE[1]: CALL
  TOKENIZED[1]: *p
  ORIGINAL[2]: count++
  TYPE[2]: CALL
  TOKENIZED[2]: count++
  ORIGINAL[3]: p + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771370
FRAGMENT_COUNT: 8
  ORIGINAL[0]: membuf_ensure(&mem,&str -> blocksize,minimum_size,str -> pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &mem , &str -> VAR1 , VAR2 , VAR3 -> VAR4 )
  ORIGINAL[1]: &mem
  TYPE[1]: CALL
  TOKENIZED[1]: &mem
  ORIGINAL[2]: mem
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: mem
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: mem
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: mem
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: mem
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771178
FRAGMENT_COUNT: 6
  ORIGINAL[0]: memset(_m_b_f_ -> data,0,_m_b_f_ -> size)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , 0 , VAR1 -> VAR3 )
  ORIGINAL[1]: _m_b_f_ -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: _m_b_f_ -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _m_b_f_
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: _m_b_f_
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771355
FRAGMENT_COUNT: 8
  ORIGINAL[0]: nbytes > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: len
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: nbytes
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476889
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *new_string)) + size
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *new_string ) ) + VAR1
  ORIGINAL[1]: sizeof(( *new_string))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *new_string ) )
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476936
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477597
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pstr < enda
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i <= slots
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= VAR2
  ORIGINAL[2]: slots
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: slots
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: slots
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640330
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719477228
FRAGMENT_COUNT: 9
  ORIGINAL[0]: 0 != (svn_ctype_table[(unsigned char )( *p)] & 0x0002)
  TYPE[0]: CALL
  TOKENIZED[0]: 0 != ( VAR1 [ ( unsigned char ) ( *p ) ] & 0x0002 )
  ORIGINAL[1]: *p
  TYPE[1]: CALL
  TOKENIZED[1]: *p
  ORIGINAL[2]: p++
  TYPE[2]: CALL
  TOKENIZED[2]: p++
  ORIGINAL[3]: p[0]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 0 ]
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477207
FRAGMENT_COUNT: 9
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str -> blocksize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len > 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 > 0
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: str -> data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: str -> len
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: len
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771945
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_string__similarity((&stringa),(&stringb),buffer,rlcs)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( &stringa ) , ( &stringb ) , VAR1 , VAR2 )
  ORIGINAL[1]: &stringb
  TYPE[1]: CALL
  TOKENIZED[1]: &stringb
  ORIGINAL[2]: stringb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771352
FRAGMENT_COUNT: 2
  ORIGINAL[0]: str -> len = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 68719476906
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strlen(cstring)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: cstring
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476882
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *new_string = (apr_palloc(pool,sizeof(( *new_string))))
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string = ( FUN1 ( VAR1 , sizeof ( ( *new_string ) ) ) )
  ORIGINAL[1]: *new_string
  TYPE[1]: CALL
  TOKENIZED[1]: *new_string
  ORIGINAL[2]: new_string -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771310
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771331
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new_string -> pool = pool
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: new_string -> pool
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pool
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771305
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strbuf -> data[size] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] = '\\0'
  ORIGINAL[1]: strbuf -> data[size]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: strbuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476923
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_string_createv(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: ap
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fmt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ap
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771266
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_first_non_whitespace(str -> data,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771170
FRAGMENT_COUNT: 9
  ORIGINAL[0]: membuf -> data && old_data && old_data != (membuf -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR3 && VAR3 != ( VAR1 -> VAR2 )
  ORIGINAL[1]: membuf -> data && old_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && VAR3
  ORIGINAL[2]: membuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: old_data != (membuf -> data)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != ( VAR2 -> VAR3 )
  ORIGINAL[4]: membuf -> data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: data
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: old_data
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: old_data
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: membuf
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476974
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771425
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,(appendstr -> data),appendstr -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 -> VAR4 )
  ORIGINAL[1]: appendstr -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: appendstr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771537
FRAGMENT_COUNT: 3
  ORIGINAL[0]: string_first_non_whitespace((str -> data),str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 30064771117
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476940
FRAGMENT_COUNT: 2
  ORIGINAL[0]: svn_stringbuf_create_ensure(0,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477484
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ui64toa_sep(number,seperator,buffer)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: number
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: seperator
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771840
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number >= 100000000
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 100000000
  ORIGINAL[1]: reduced = ((apr_uint32_t )(number % 100000000))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( VAR2 ) ( VAR3 % 100000000 ) )
  ORIGINAL[2]: (apr_uint32_t )(number % 100000000)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) ( VAR2 % 100000000 )
  ORIGINAL[3]: reduced
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: number
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476995
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __builtin_va_start(ap,fmt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: ap
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fmt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771340
FRAGMENT_COUNT: 4
  ORIGINAL[0]: amt = strlen(value)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: strlen(value)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: amt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477257
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < list -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: *this_pattern = ((char **)(list -> elts))[i]
  TYPE[1]: CALL
  TOKENIZED[1]: *this_pattern = ( ( char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[2]: ((char **)(list -> elts))[i]
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[3]: this_pattern
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this_pattern
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477370
FRAGMENT_COUNT: 2
  ORIGINAL[0]: *n
  TYPE[0]: CALL
  TOKENIZED[0]: *n
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477363
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoui64(n,str,0,18446744073709551615UL,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 , 18446744073709551615UL , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476928
FRAGMENT_COUNT: 4
  ORIGINAL[0]: original_string -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477279
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *str
  TYPE[0]: CALL
  TOKENIZED[0]: *str
  ORIGINAL[1]: csep == '\\0' || sep[1] != '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '\\0' || VAR2 [ 1 ] != '\\0'
  ORIGINAL[2]: apr_strtok(((void *)0),sep,str)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( ( void * ) 0 ) , VAR1 , VAR2 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: sep
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771695
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sep_len = strlen(separator)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: strlen(separator)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: sep_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477265
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: strcmp(this_str,str) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 ) == 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 1
  ORIGINAL[0]: str[--i] == ch
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ --i ] == VAR2

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 2
  ORIGINAL[0]: mkdir(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: if (mkdir(\
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: if ( FUN1 ( \

