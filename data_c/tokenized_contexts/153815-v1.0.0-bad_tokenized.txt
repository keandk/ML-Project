# Tokenized code fragments for 153815-v1.0.0-bad
# Total center nodes processed: 35
# Total code fragments found: 142

CENTER_NODE: 47244640274
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771515
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pdu_counter = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> pdu_counter
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 30064771108
FRAGMENT_COUNT: 5
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[2]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477189
FRAGMENT_COUNT: 9
  ORIGINAL[0]: frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: (void )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void ) 0
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: getenv(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: frag -> pdu
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: frag
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: frag
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477113
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: conv
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p2p_dir
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: conv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477099
FRAGMENT_COUNT: 7
  ORIGINAL[0]: val -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: val -> pdu = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[2]: val -> pdu
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: val -> final_fragment
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: final_fragment
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771541
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *key1 = (const fragment_key_t *)a
  TYPE[0]: CALL
  TOKENIZED[0]: *key1 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const fragment_key_t *)a
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: a
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771171
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719477074
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (const char *)__func__
  TYPE[1]: CALL
  TOKENIZED[1]: ( const char * ) VAR1
  ORIGINAL[2]: <global> __func__
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719477105
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: circuit
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p2p_dir
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: circuit
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477123
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: conv
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771565
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash = g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771265
FRAGMENT_COUNT: 5
  ORIGINAL[0]: vaudoux_amenable != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: reechoing_puntilla = &meditatively_exhalants
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = &meditatively_exhalants
  ORIGINAL[2]: &meditatively_exhalants
  TYPE[2]: CALL
  TOKENIZED[2]: &meditatively_exhalants
  ORIGINAL[3]: reechoing_puntilla
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: meditatively_exhalants
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477053
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (const fragment_key_t *)k
  TYPE[0]: CALL
  TOKENIZED[0]: ( const VAR1 * ) VAR2
  ORIGINAL[1]: k
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771740
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (void )(frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: ( void ) ( frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: frag?((void )0) : ((getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[2]: frag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477148
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tvb_reported_length(tvb)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: tvb
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> stream_reassembled_table
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477002
FRAGMENT_COUNT: 5
  ORIGINAL[0]: key . is_circuit = !0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = !0
  ORIGINAL[1]: key . is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: key . circ
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: circ
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477194
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ++stonesoup_global_variable
  TYPE[0]: CALL
  TOKENIZED[0]: ++stonesoup_global_variable
  ORIGINAL[1]: estab_bondship = ((char *)((char *)ringed_antigene))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( char * ) ( ( char * ) VAR2 ) )
  ORIGINAL[2]: (char *)((char *)ringed_antigene)
  TYPE[2]: CALL
  TOKENIZED[2]: ( char * ) ( ( char * ) VAR1 )
  ORIGINAL[3]: estab_bondship
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: estab_bondship
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640278
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771569
FRAGMENT_COUNT: 4
  ORIGINAL[0]: key . framenum = framenum
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: key . framenum
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: framenum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771523
FRAGMENT_COUNT: 8
  ORIGINAL[0]: pdu -> pdu_number = stream -> pdu_counter++
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3 -> pdu_counter++
  ORIGINAL[1]: pdu -> pdu_number
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: stream -> pdu_counter++
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> pdu_counter++
  ORIGINAL[3]: pdu_number
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pdu
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stream
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pdu
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pdu
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477127
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash_lookup(stream,framenum,offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: framenum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771556
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771145
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (unsigned long )key -> circ . circuit
  TYPE[0]: CALL
  TOKENIZED[0]: ( unsigned long ) VAR1 -> VAR2 . VAR3
  ORIGINAL[1]: key -> circ . circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 . VAR3
  ORIGINAL[2]: key -> circ
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: circuit
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771151
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *key2 = (const stream_key_t *)b
  TYPE[0]: CALL
  TOKENIZED[0]: *key2 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const stream_key_t *)b
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477032
FRAGMENT_COUNT: 6
  ORIGINAL[0]: key -> is_circuit
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key -> circ . circuit = circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 . VAR3 = VAR3
  ORIGINAL[2]: key -> p2p_dir
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: p2p_dir
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476795
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: var_len = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: var_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771467
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key . is_circuit = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = 0
  ORIGINAL[1]: key . is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771628
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: circuit
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771455
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash = g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771731
FRAGMENT_COUNT: 3
  ORIGINAL[0]: frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: (void )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void ) 0
  ORIGINAL[2]: frag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771479
FRAGMENT_COUNT: 3
  ORIGINAL[0]: se_alloc(sizeof(stream_t ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[1]: sizeof(stream_t )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: stream_t
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477042
FRAGMENT_COUNT: 6
  ORIGINAL[0]: key -> is_circuit
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key -> p2p_dir = p2p_dir
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: key -> p2p_dir
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: new_stream(key)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771632
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cleanup_fragment_hash()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: stream_cleanup_pdu_data()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )

CENTER_NODE: 68719477184
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !frag -> final_fragment
  TYPE[0]: CALL
  TOKENIZED[0]: !frag -> VAR1
  ORIGINAL[1]: process_reassembled_data(tvb,offset,pinfo,name,pdu -> fd_head,fit,update_col_infop,tree)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 -> VAR6 , VAR7 , VAR8 , VAR9 )
  ORIGINAL[2]: pdu -> fd_head
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pinfo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: name
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: fit
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: update_col_infop
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: tree
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

