# Tokenized code fragments for 152639-v1.0.0-bad
# Total center nodes processed: 142
# Total code fragments found: 423

CENTER_NODE: 30064774234
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[pos . index] >= 0 && d -> tokens[pos . index] < (1 << 8) && !tstbit(d -> tokens[pos . index],labels[j])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ] >= 0 && VAR1 -> VAR2 [ VAR3 . VAR4 ] < ( 1 << 8 ) && !tstbit ( VAR1 -> VAR2 [ VAR3 . VAR4 ] , VAR5 [ VAR6 ] )
  ORIGINAL[1]: k = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: for (k = 0;k < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++k)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++k )
  ORIGINAL[3]: k
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: k
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640598
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640756
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640310
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775193
FRAGMENT_COUNT: 4
  ORIGINAL[0]: &d -> states[s1] . elems
  TYPE[0]: CALL
  TOKENIZED[0]: &d -> VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: d -> states[s1] . elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: d -> states[s1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640563
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064776401
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 30064771189
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640389
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640768
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640872
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640579
FRAGMENT_COUNT: 1
  ORIGINAL[0]: minrep == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0

CENTER_NODE: 68719476801
FRAGMENT_COUNT: 5
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: fopen(stonesoup_tainted_file_name,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: stonesoup_tainted_file_name
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_tainted_file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_tainted_file_name
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771273
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> eolbyte
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775886
FRAGMENT_COUNT: 10
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: new[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: enlist(old,new[i],strlen(new[i]))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[3]: new[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: new[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064773103
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> elems = (x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) ) )
  ORIGINAL[2]: dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) )
  ORIGINAL[4]: dst
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640441
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477993
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: elems
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775801
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp[j] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: istrstr(new,cpp[j]) == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 [ VAR3 ] ) == ( ( void * ) 0 )
  ORIGINAL[2]: istrstr(new,cpp[j])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772701
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !backslash
  TYPE[0]: CALL
  TOKENIZED[0]: !backslash
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771187
FRAGMENT_COUNT: 3
  ORIGINAL[0]: WCHAR=274
  TYPE[0]: CALL
  TOKENIZED[0]: WCHAR=274
  ORIGINAL[1]: WCHAR
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: CSET
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640713
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773220
FRAGMENT_COUNT: 12
  ORIGINAL[0]: m -> alloc <= s1 -> nelem + s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4 + VAR5 -> VAR4
  ORIGINAL[1]: m -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: m -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *m -> elems))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *m -> VAR1 ) )
  ORIGINAL[4]: *m -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: *m -> VAR1
  ORIGINAL[5]: m -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: m -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: m -> elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: m -> elems
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: m -> elems
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: m -> elems
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: m -> elems
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2

CENTER_NODE: 30064774894
FRAGMENT_COUNT: 5
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> fails[oldalloc++] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ oldalloc++ ] = ( ( void * ) 0 )
  ORIGINAL[2]: d -> fails[oldalloc++]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ oldalloc++ ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: oldalloc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771109
FRAGMENT_COUNT: 5
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[2]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479471
FRAGMENT_COUNT: 10
  ORIGINAL[0]: inputwcs[p - buf_begin] == 0 && mblen_buf[p - buf_begin] > 0 && ((const unsigned char *)p) < buf_end
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 - VAR3 ] == 0 && VAR4 [ VAR2 - VAR3 ] > 0 && ( ( const unsigned char * ) VAR2 ) < VAR5
  ORIGINAL[1]: ++p
  TYPE[1]: CALL
  TOKENIZED[1]: ++p
  ORIGINAL[2]: &p
  TYPE[2]: CALL
  TOKENIZED[2]: &p
  ORIGINAL[3]: &p
  TYPE[3]: CALL
  TOKENIZED[3]: &p
  ORIGINAL[4]: p[- 1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ - 1 ]
  ORIGINAL[5]: p[- 1]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ - 1 ]
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771226
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: (1 << 8) + 8 * sizeof(int ) - 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( 1 << 8 ) + 8 * sizeof ( int ) - 1
  ORIGINAL[2]: (1 << 8) + 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[3]: 1 << 8
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << 8
  ORIGINAL[4]: 8 * sizeof(int )
  TYPE[4]: CALL
  TOKENIZED[4]: 8 * sizeof ( int )

CENTER_NODE: 47244640835
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476951
FRAGMENT_COUNT: 6
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: utf8 == - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == - 1
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: utf8
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: utf8
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640397
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640762
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774812
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> fails)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[1]: d -> fails
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(( *d -> fails))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[3]: *d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: d -> fails
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2

CENTER_NODE: 30064773387
FRAGMENT_COUNT: 32
  ORIGINAL[0]: d -> salloc <= d -> sindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> sindex + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> sindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sindex
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: d
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: d
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: d
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: d
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: d
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: d
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: d
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: d
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: d
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: d
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: d
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: d
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: d
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1

CENTER_NODE: 68719477820
FRAGMENT_COUNT: 5
  ORIGINAL[0]: work_mbc -> cset != (- 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[1]: using_utf8()?((void )0) : __assert_fail(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ) ? ( ( void ) 0 ) : FUN2 ( \
  ORIGINAL[2]: CSET + work_mbc -> cset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2 -> VAR3
  ORIGINAL[3]: CSET
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: work_mbc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773626
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[j] & ~(letters[j] | newline[j])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] & ~ ( VAR3 [ VAR2 ] | VAR4 [ VAR2 ] )
  ORIGINAL[1]: context |= 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 1
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640623
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478113
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i < s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2 -> VAR3
  ORIGINAL[3]: s -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: nelem
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640422
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: sbit[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> sbit
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775324
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < d -> follows[d -> states[s1] . mbps . elems[i] . index] . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[1]: insert(d -> follows[d -> states[s1] . mbps . elems[i] . index] . elems[j],&follows)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6 [ VAR9 ] , &follows )
  ORIGINAL[2]: d -> follows[d -> states[s1] . mbps . elems[i] . index] . elems[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6 [ VAR9 ]
  ORIGINAL[3]: d -> follows[d -> states[s1] . mbps . elems[i] . index] . elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: follows
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640320
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640371
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640601
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476895
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: ++dfa -> VAR1
  ORIGINAL[2]: copyset(s,dfa -> charclasses[i])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640354
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640929
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640407
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640632
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477781
FRAGMENT_COUNT: 3
  ORIGINAL[0]: t
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: OR
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> depth
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064774900
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_DONE
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773058
FRAGMENT_COUNT: 2
  ORIGINAL[0]: branch()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 68719478025
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s -> alloc <= count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 + 1
  ORIGINAL[1]: count + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + 1
  ORIGINAL[2]: count
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new_n_alloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479710
FRAGMENT_COUNT: 4
  ORIGINAL[0]: strlen(lookfor)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: lookfor
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: lookfor
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771218
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640352
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479081
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (t = d -> trans[works]) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 [ VAR4 ] ) != ( ( void * ) 0 )
  ORIGINAL[1]: works = t[ *p]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 [ *p ]
  ORIGINAL[2]: rval = TRANSIT_STATE_DONE
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: rval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: rval
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: TRANSIT_STATE_DONE
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774934
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mbclen = (mblen_buf[idx] == 0?1 : mblen_buf[idx])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( VAR2 [ VAR3 ] == 0?1 : VAR2 [ VAR3 ] )
  ORIGINAL[1]: mblen_buf[idx] == 0?1 : mblen_buf[idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] == 0?1 : VAR1 [ VAR2 ]
  ORIGINAL[2]: mblen_buf[idx] == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] == 0
  ORIGINAL[3]: mblen_buf[idx]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: mbclen
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640882
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775056
FRAGMENT_COUNT: 5
  ORIGINAL[0]: wc < 1 << 8 && work_mbc -> cset != (- 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 1 << 8 && VAR2 -> VAR3 != ( - 1 )
  ORIGINAL[1]: tstbit(((unsigned char )wc),d -> charclasses[work_mbc -> cset])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( unsigned char ) VAR1 ) , VAR2 -> VAR3 [ VAR4 -> VAR5 ] )
  ORIGINAL[2]: (unsigned char )wc
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned char ) VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640874
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771192
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640889
FRAGMENT_COUNT: 1
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )

CENTER_NODE: 68719480199
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773786
FRAGMENT_COUNT: 10
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: tmp . nelem = nfirstpos[- 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 = VAR3 [ - 1 ]
  ORIGINAL[2]: tmp . nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: nfirstpos[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 1 ]
  ORIGINAL[4]: nelem
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tmp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tmp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: nfirstpos
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: tmp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: tmp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640430
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640755
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477950
FRAGMENT_COUNT: 3
  ORIGINAL[0]: lexptr = s
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: <global> lexptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640342
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640871
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476849
FRAGMENT_COUNT: 5
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640545
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640677
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775649
FRAGMENT_COUNT: 13
  ORIGINAL[0]: d -> mbcsets_alloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: sizeof(( *d -> mbcsets)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: d -> mbcsets_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnmalloc(d -> mbcsets_alloc,sizeof(( *d -> mbcsets)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[4]: d -> mbcsets_alloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sizeof(( *d -> mbcsets))
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[6]: mbcsets_alloc
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 30064771210
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064776416
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640294
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773052
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN && tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: tok != OR
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != VAR2
  ORIGINAL[4]: tok >= 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 >= 0
  ORIGINAL[5]: <global> tok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771527
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !lexleft
  TYPE[0]: CALL
  TOKENIZED[0]: !lexleft
  ORIGINAL[1]: gettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: gettext(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \

CENTER_NODE: 47244640379
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476874
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: s2
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640363
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640978
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476945
FRAGMENT_COUNT: 7
  ORIGINAL[0]: setbit_c((( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)),c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN2 ( VAR1 ) ) , VAR3 )
  ORIGINAL[1]: (int )b
  TYPE[1]: CALL
  TOKENIZED[1]: ( int ) VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: b
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: b
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640440
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640591
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477865
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfa -> tokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: tokens
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064774747
FRAGMENT_COUNT: 7
  ORIGINAL[0]: trans[i] >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] >= VAR3 -> VAR4
  ORIGINAL[1]: d -> newlines
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: *d -> newlines
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1
  ORIGINAL[3]: d -> newlines
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: newlines
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 68719476908
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == '_'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '_'
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776272
FRAGMENT_COUNT: 9
  ORIGINAL[0]: lmp -> is[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: lmp -> right[0] != '\\0' && rmp -> left[0] != '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ] != '\\0' && VAR3 -> VAR4 [ 0 ] != '\\0'
  ORIGINAL[2]: lmp -> in == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[3]: lmp -> is[0] != '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ] != '\\0'
  ORIGINAL[4]: lmp -> is[0]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[5]: lmp -> is
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: lmp -> is[0]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[7]: lmp -> is
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: lmp -> is[0]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ 0 ]

CENTER_NODE: 30064775132
FRAGMENT_COUNT: 26
  ORIGINAL[0]: sizeof(( *rarray)) == 1?xmalloc(d -> states[s] . mbps . nelem) : xnmalloc(d -> states[s] . mbps . nelem,sizeof(( *rarray)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *rarray ) ) == 1?xmalloc ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 ) : FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 , sizeof ( ( *rarray ) ) )
  ORIGINAL[1]: sizeof(( *rarray)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *rarray ) ) == 1
  ORIGINAL[2]: sizeof(( *rarray))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *rarray ) )
  ORIGINAL[3]: xmalloc(d -> states[s] . mbps . nelem)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 )
  ORIGINAL[4]: d -> states[s] . mbps . nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[5]: d -> states[s] . mbps
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[6]: d -> states[s]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[7]: d -> states
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: xnmalloc(d -> states[s] . mbps . nelem,sizeof(( *rarray)))
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 , sizeof ( ( *rarray ) ) )
  ORIGINAL[9]: d -> states[s] . mbps . nelem
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[10]: d -> states[s] . mbps
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[11]: d -> states[s]
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[12]: d -> states
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: sizeof(( *rarray))
  TYPE[13]: CALL
  TOKENIZED[13]: sizeof ( ( *rarray ) )
  ORIGINAL[14]: *rarray
  TYPE[14]: CALL
  TOKENIZED[14]: *rarray
  ORIGINAL[15]: states
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: mbps
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: nelem
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: states
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: mbps
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: nelem
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: d
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: s
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: d
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: s
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: rarray
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1

CENTER_NODE: 30064775538
FRAGMENT_COUNT: 10
  ORIGINAL[0]: d -> multibyte_prop = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[1]: d -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: multibyte_prop
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064775934
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> left[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> left
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: left
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479648
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaoptimize(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaanalyze(d,searchflag)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: searchflag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640709
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640625
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640543
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640836
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479802
FRAGMENT_COUNT: 10
  ORIGINAL[0]: *cpp
  TYPE[0]: CALL
  TOKENIZED[0]: *cpp
  ORIGINAL[1]: cpp[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ]
  ORIGINAL[2]: len == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: enlist(cpp,lcp,len)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: lcp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: cpp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: cpp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479654
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: free_mbdata(d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: i = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640291
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775655
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: !1
  TYPE[1]: CALL
  TOKENIZED[1]: !1
  ORIGINAL[2]: !using_utf8()
  TYPE[2]: CALL
  TOKENIZED[2]: !using_utf8 ( )
  ORIGINAL[3]: using_utf8()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776414
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 68719477884
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: tindex + i
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640419
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775891
FRAGMENT_COUNT: 13
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: left == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: right == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: both = (malloc(sizeof(( *both))))
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = ( FUN1 ( sizeof ( ( *both ) ) ) )
  ORIGINAL[5]: malloc(sizeof(( *both)))
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( sizeof ( ( *both ) ) )
  ORIGINAL[6]: sizeof(( *both))
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *both ) )
  ORIGINAL[7]: *both
  TYPE[7]: CALL
  TOKENIZED[7]: *both
  ORIGINAL[8]: both == ((void *)0)
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[9]: (void *)0
  TYPE[9]: CALL
  TOKENIZED[9]: ( void * ) 0
  ORIGINAL[10]: both
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: both
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: both
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640302
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772934
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD || tok == LIMWORD || tok == NOTLIMWORD
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9 || VAR1 == VAR10 || VAR1 == VAR11
  ORIGINAL[2]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD || tok == LIMWORD
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9 || VAR1 == VAR10
  ORIGINAL[3]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9
  ORIGINAL[4]: tok == LIMWORD
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: tok == NOTLIMWORD
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: NOTLIMWORD
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064773544
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[2]: s -> elems[i] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: s -> elems[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: index
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640900
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775750
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773647
FRAGMENT_COUNT: 7
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s -> elems[j] . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: s -> elems[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: s -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: constraint
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640332
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640811
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776424
FRAGMENT_COUNT: 3
  ORIGINAL[0]: {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: { { ( \
  ORIGINAL[1]: {(\
  TYPE[1]: CALL
  TOKENIZED[1]: { ( \
  ORIGINAL[2]: isspace
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479703
FRAGMENT_COUNT: 7
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: result = (xrealloc(old,oldsize + newsize + 1))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 , VAR3 + VAR4 + 1 ) )
  ORIGINAL[2]: result + oldsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: result
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: oldsize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: result
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

