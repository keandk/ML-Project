# Tokenized code fragments for 153315-v1.0.0-bad
# Total center nodes processed: 148
# Total code fragments found: 433

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640660
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477295
FRAGMENT_COUNT: 13
  ORIGINAL[0]: &new_n_alloc
  TYPE[0]: CALL
  TOKENIZED[0]: &new_n_alloc
  ORIGINAL[1]: &new_n_alloc
  TYPE[1]: CALL
  TOKENIZED[1]: &new_n_alloc
  ORIGINAL[2]: &new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: &new_n_alloc
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: range_sts_al <= work_mbc -> nranges + 1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 <= VAR2 -> VAR3 + 1
  ORIGINAL[5]: work_mbc -> range_sts
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &new_n_alloc
  TYPE[6]: CALL
  TOKENIZED[6]: &new_n_alloc
  ORIGINAL[7]: &new_n_alloc
  TYPE[7]: CALL
  TOKENIZED[7]: &new_n_alloc
  ORIGINAL[8]: &new_n_alloc
  TYPE[8]: CALL
  TOKENIZED[8]: &new_n_alloc
  ORIGINAL[9]: &new_n_alloc
  TYPE[9]: CALL
  TOKENIZED[9]: &new_n_alloc
  ORIGINAL[10]: new_n_alloc
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: new_n_alloc
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: new_n_alloc
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640304
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772269
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: backslash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476914
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: setbit(b,c)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479681
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476926
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775196
FRAGMENT_COUNT: 8
  ORIGINAL[0]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[1]: d -> follows[d -> states[s] . mbps . elems[i] . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ]
  ORIGINAL[2]: d -> follows
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: follows
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719478612
FRAGMENT_COUNT: 4
  ORIGINAL[0]: pos . constraint != 0x777
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 != 0x777
  ORIGINAL[1]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int )) && !matches[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) && !matches [ VAR1 ]
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )
  ORIGINAL[3]: int
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: int

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BACKREF=257
  TYPE[0]: CALL
  TOKENIZED[0]: BACKREF=257
  ORIGINAL[1]: BACKREF
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: BEGLINE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773211
FRAGMENT_COUNT: 7
  ORIGINAL[0]: s1 -> elems[i] . index > s2 -> elems[j] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[1]: s2 -> elems[j] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s1 -> elems[i] . index < s2 -> elems[j] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 < VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[3]: s1 -> elems[i] . index
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: s2 -> elems[j] . index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: s2 -> elems[j]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: index
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640545
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773786
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: --nfirstpos
  TYPE[1]: CALL
  TOKENIZED[1]: --nfirstpos
  ORIGINAL[2]: nfirstpos
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: nullable
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640443
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773020
FRAGMENT_COUNT: 10
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: branch()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: addtok(OR)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: while (tok == OR)
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: while ( VAR1 == VAR2 )
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: OR
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: <global> tok
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: OR
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771180
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640926
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479691
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *cp
  TYPE[0]: CALL
  TOKENIZED[0]: *cp
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: (char *)cp
  TYPE[2]: CALL
  TOKENIZED[2]: ( char * ) VAR1
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478083
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774861
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_DONE
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640432
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772984
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok == REPMN && (minrep || maxrep)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[1]: maxrep < 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 0
  ORIGINAL[2]: addtok(PLUS)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: <global> maxrep
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: PLUS
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> minrep
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640547
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771116
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c - 32
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 32
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479025
FRAGMENT_COUNT: 9
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> trans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> success
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> tralloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: success
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771209
FRAGMENT_COUNT: 16
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[2]: dfa -> calloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> cindex + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 + 1
  ORIGINAL[4]: dfa -> calloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: calloc
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> dfa
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> dfa
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> dfa
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> dfa
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> dfa
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> dfa
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774639
FRAGMENT_COUNT: 5
  ORIGINAL[0]: 1 & 4
  TYPE[0]: CALL
  TOKENIZED[0]: 1 & 4
  ORIGINAL[1]: ( *d) . states
  TYPE[1]: CALL
  TOKENIZED[1]: ( *d ) . VAR1
  ORIGINAL[2]: *d
  TYPE[2]: CALL
  TOKENIZED[2]: *d
  ORIGINAL[3]: states
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640373
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773285
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: for (i = 0;i < s -> nelem;++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640600
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478259
FRAGMENT_COUNT: 12
  ORIGINAL[0]: p . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: p . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: p . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: p . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: p . constraint
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: p . constraint
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2
  ORIGINAL[6]: p . constraint
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . VAR2
  ORIGINAL[7]: j < d -> follows[old . index] . nelem
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 < VAR2 -> VAR3 [ VAR4 . VAR5 ] . VAR6
  ORIGINAL[8]: p . index
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 . VAR2
  ORIGINAL[9]: index
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640323
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771182
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: charclass
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719478298
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (s -> elems[j] . constraint >> 2 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[1]: separate_contexts |= 4
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 4
  ORIGINAL[2]: separate_contexts
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: separate_contexts
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: separate_contexts
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: separate_contexts
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477913
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771172
FRAGMENT_COUNT: 4
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775793
FRAGMENT_COUNT: 4
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: malloc(sizeof(( *cpp)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( ( *cpp ) ) )
  ORIGINAL[2]: sizeof(( *cpp))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *cpp ) )
  ORIGINAL[3]: *cpp
  TYPE[3]: CALL
  TOKENIZED[3]: *cpp

CENTER_NODE: 47244640421
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479692
FRAGMENT_COUNT: 8
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: cpp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719479607
FRAGMENT_COUNT: 6
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: d -> tindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> tokens[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: tindex
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640314
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640424
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772794
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> tokens = (x2nrealloc((dfa -> tokens),&new_n_alloc,sizeof(( *dfa -> tokens))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) ) )
  ORIGINAL[2]: dfa -> tokens
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: x2nrealloc((dfa -> tokens),&new_n_alloc,sizeof(( *dfa -> tokens)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) )
  ORIGINAL[4]: dfa -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &new_n_alloc
  TYPE[5]: CALL
  TOKENIZED[5]: &new_n_alloc
  ORIGINAL[6]: sizeof(( *dfa -> tokens))
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *dfa -> VAR1 ) )

CENTER_NODE: 47244640334
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640564
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771120
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: stonesoup_trace
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_location
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buff
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476762
FRAGMENT_COUNT: 6
  ORIGINAL[0]: data_size < buffer_size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: buffer_size = buffer_size * 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR1 * 2
  ORIGINAL[2]: free(stonesoup_tainted_buff)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: stonesoup_tainted_buff
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_tainted_buff
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_tainted_buff
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640296
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776316
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771150
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775332
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *mblen_buf)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *mblen_buf ) ) == 1
  ORIGINAL[1]: xmalloc((end - begin + 2))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 - VAR2 + 2 ) )
  ORIGINAL[2]: end - begin + 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - VAR2 + 2
  ORIGINAL[3]: end - begin
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - VAR2

CENTER_NODE: 30064772945
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (i = 0;i < ntokens;++i)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < VAR2 ; ++i )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640401
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776302
FRAGMENT_COUNT: 4
  ORIGINAL[0]: eagerness_nudely != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: eagerness_nudely != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: free(((char *)eagerness_nudely))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( ( char * ) VAR1 ) )
  ORIGINAL[3]: stonesoup_close_printf_context()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )

CENTER_NODE: 30064775855
FRAGMENT_COUNT: 5
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: left == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: right == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: right
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775837
FRAGMENT_COUNT: 5
  ORIGINAL[0]: old == ((void *)0) || new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: old == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: new == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775257
FRAGMENT_COUNT: 5
  ORIGINAL[0]: nelem == 0 || maxlen == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 == 0
  ORIGINAL[1]: realloc_trans_if_necessary(d,s1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771199
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(charclass )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719479136
FRAGMENT_COUNT: 9
  ORIGINAL[0]: work_mbc -> invert
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: wc < 1 << 8 && work_mbc -> cset != (- 1) && tstbit(((unsigned char )wc),d -> charclasses[work_mbc -> cset])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 1 << 8 && VAR2 -> VAR3 != ( - 1 ) && FUN1 ( ( ( unsigned char ) VAR1 ) , VAR4 -> VAR5 [ VAR2 -> VAR3 ] )
  ORIGINAL[2]: work_mbc -> cset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: work_mbc -> nch_classes
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: iswctype(((wint_t )wc),work_mbc -> ch_classes[i])
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( ( VAR1 ) VAR2 ) , VAR3 -> VAR4 [ VAR5 ] )
  ORIGINAL[5]: nch_classes
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: work_mbc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476794
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064772845
FRAGMENT_COUNT: 17
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: work_mbc -> invert
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 )
  ORIGINAL[3]: work_mbc -> invert
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: !using_utf8() && work_mbc -> cset != (- 1)
  TYPE[4]: CALL
  TOKENIZED[4]: !using_utf8 ( ) && VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[5]: !using_utf8()
  TYPE[5]: CALL
  TOKENIZED[5]: !using_utf8 ( )
  ORIGINAL[6]: using_utf8()
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( )
  ORIGINAL[7]: invert
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: work_mbc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: work_mbc
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: work_mbc
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: work_mbc
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: work_mbc
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: work_mbc
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: work_mbc
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: work_mbc
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 47244640603
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640711
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640595
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640288
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1

CENTER_NODE: 30064775781
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i + 1] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 + 1 ] = ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i + 1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 + 1 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775691
FRAGMENT_COUNT: 4
  ORIGINAL[0]: free(dm)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dm
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: dm
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: dm
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480080
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(struct dfa )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( struct VAR1 )
  ORIGINAL[1]: struct dfa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: struct VAR1

CENTER_NODE: 30064774740
FRAGMENT_COUNT: 27
  ORIGINAL[0]: d -> trcount = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: d -> trcount
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: trcount
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: d
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: d
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: d
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: d
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: d
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: d
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: d
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: d
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640874
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640354
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771255
FRAGMENT_COUNT: 4
  ORIGINAL[0]: eolbyte = eol
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: <global> eolbyte
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: eol
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771246
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: (wchar_t )eolbyte
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: wc == 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == 0
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477849
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: 1 + ntoks1
  TYPE[1]: CALL
  TOKENIZED[1]: 1 + VAR1
  ORIGINAL[2]: tindex - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640409
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719479581
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *d
  TYPE[0]: CALL
  TOKENIZED[0]: *d
  ORIGINAL[1]: d -> calloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> charclasses
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> calloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> calloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: charclasses
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064775897
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> right[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> right
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: mp -> is[0] = '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[4]: mp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640634
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476771
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775697
FRAGMENT_COUNT: 4
  ORIGINAL[0]: newsize = new == ((void *)0)?0 : strlen(new)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR2 )
  ORIGINAL[1]: new == ((void *)0)?0 : strlen(new)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[2]: newsize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: newsize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064776131
FRAGMENT_COUNT: 5
  ORIGINAL[0]: lmp -> right[0] != '\\0' && rmp -> left[0] != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] != '\\0' && VAR3 -> VAR4 [ 0 ] != '\\0'
  ORIGINAL[1]: tp = icpyalloc((lmp -> right))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( ( VAR2 -> VAR3 ) )
  ORIGINAL[2]: icpyalloc((lmp -> right))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[3]: tp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640625
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640839
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640381
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 1
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0

CENTER_NODE: 68719479547
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> multibyte_prop
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: multibyte_prop
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640293
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640351
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476839
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 47244640681
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774925
FRAGMENT_COUNT: 9
  ORIGINAL[0]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: wc == ((wchar_t )'\\0')
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: (((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1
  ORIGINAL[4]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) )
  ORIGINAL[5]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0))
  TYPE[5]: CALL
  TOKENIZED[5]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) )
  ORIGINAL[6]: context & 4?pos . constraint >> 8 & 0xf : 0
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0
  ORIGINAL[7]: d -> states[s] . context
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640356
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776315
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064776277
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477928
FRAGMENT_COUNT: 3
  ORIGINAL[0]: lasttok = END
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: laststart = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: <global> laststart
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064773563
FRAGMENT_COUNT: 3
  ORIGINAL[0]: context = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> eolbyte
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 47244640715
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773094
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[1]: xnmalloc(size,sizeof(( *s -> elems)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , sizeof ( ( *s -> VAR2 ) ) )
  ORIGINAL[2]: sizeof(( *s -> elems))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[3]: *s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: *s -> VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775631
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfaoptimize(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640813
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640773
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719479220
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: pos = d -> states[s] . mbps . elems[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ]
  ORIGINAL[2]: d -> tokens
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tokens
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 47244640902
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476739
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mg_vprintf_data((struct mg_connection*) stonesoup_printf_context, format, argptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( struct mg_connection* ) VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: (struct mg_connection*) stonesoup_printf_context
  TYPE[1]: CALL
  TOKENIZED[1]: ( struct mg_connection* ) VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: argptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772921
FRAGMENT_COUNT: 16
  ORIGINAL[0]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD || tok == LIMWORD || tok == NOTLIMWORD
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9 || VAR1 == VAR10 || VAR1 == VAR11
  ORIGINAL[1]: tok == LPAREN
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: tok = lex()
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( )
  ORIGINAL[3]: lex()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: regexp()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )
  ORIGINAL[5]: tok != RPAREN
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 != VAR2
  ORIGINAL[6]: tok = lex()
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 = FUN1 ( )
  ORIGINAL[7]: lex()
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( )
  ORIGINAL[8]: addtok(EMPTY)
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 )
  ORIGINAL[9]: <global> tok
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: LPAREN
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: <global> tok
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> tok
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: RPAREN
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: <global> tok
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: EMPTY
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 30064773157
FRAGMENT_COUNT: 6
  ORIGINAL[0]: lo < count && p . index == s -> elems[lo] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 . VAR4 == VAR5 -> VAR6 [ VAR1 ] . VAR4
  ORIGINAL[1]: s -> elems[lo] = p
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] = VAR4
  ORIGINAL[2]: s -> elems[lo]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: lo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477959
FRAGMENT_COUNT: 6
  ORIGINAL[0]: src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: src -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(dst -> elems[0])
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 -> VAR2 [ 0 ] )
  ORIGINAL[3]: src -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: nelem
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: src
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640365
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640391
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640975
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771152
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] & 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] & 1 << VAR2 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: b / (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[3]: 1 << b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774889
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> fails[works]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: build_state(works,d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: rval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: works
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640884
FRAGMENT_COUNT: 0

