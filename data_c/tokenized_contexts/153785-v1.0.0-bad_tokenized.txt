# Tokenized code fragments for 153785-v1.0.0-bad
# Total center nodes processed: 144
# Total code fragments found: 482

CENTER_NODE: 47244640708
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640886
FRAGMENT_COUNT: 1
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476825
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773069
FRAGMENT_COUNT: 12
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> elems = (x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) ) )
  ORIGINAL[2]: dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) )
  ORIGINAL[4]: dst -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dst -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: elems
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dst
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: dst
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: dst
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: dst
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: dst
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640830
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640648
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 1
  ORIGINAL[0]: after[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 30064776342
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 68719477737
FRAGMENT_COUNT: 11
  ORIGINAL[0]: dfa -> nmultibyte_prop
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dfa -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> nmultibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[4]: dfa -> talloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dfa -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: dfa -> tindex
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: dfa -> tokens
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: tindex
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new_n_alloc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1

CENTER_NODE: 68719477844
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: OR
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: ntoks1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479810
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ++rnum
  TYPE[0]: CALL
  TOKENIZED[0]: ++rnum
  ORIGINAL[1]: both == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: rnum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rnum
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: rnum
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: rnum
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476918
FRAGMENT_COUNT: 3
  ORIGINAL[0]: setbit_c((( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)),c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN2 ( VAR1 ) ) , VAR3 )
  ORIGINAL[1]: (unsigned short )_ISupper
  TYPE[1]: CALL
  TOKENIZED[1]: ( unsigned short ) VAR1
  ORIGINAL[2]: _ISupper
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476845
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775714
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640806
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640384
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640596
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775727
FRAGMENT_COUNT: 3
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: cpp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640869
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640588
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771256
FRAGMENT_COUNT: 3
  ORIGINAL[0]: syntax_bits_set = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: <global> syntax_bits_set
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: <global> syntax_bits
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478862
FRAGMENT_COUNT: 9
  ORIGINAL[0]: trans[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: trans[eolbyte]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: trans[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: trans[c]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: 1 && (( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum) || c == '_')
  TYPE[4]: CALL
  TOKENIZED[4]: 1 && ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) || VAR1 == '_' )
  ORIGINAL[5]: trans[c]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: trans[c]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: trans
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: c
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640971
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776280
FRAGMENT_COUNT: 9
  ORIGINAL[0]: mp -> is
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: t >= CSET || !1 || t == ANYCHAR || t == MBCSET
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= VAR2 || !1 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[2]: mp -> is
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: mp -> is[1] = mp -> left[1] = mp -> right[1] = '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 1 ] = VAR1 -> VAR3 [ 1 ] = VAR1 -> VAR4 [ 1 ] = '\\0'
  ORIGINAL[4]: mp -> is[1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ 1 ]
  ORIGINAL[5]: mp -> is
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: mp -> left[1] = mp -> right[1] = '\\0'
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ 1 ] = VAR1 -> VAR3 [ 1 ] = '\\0'
  ORIGINAL[7]: mp -> is
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: mp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640866
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771157
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773004
FRAGMENT_COUNT: 23
  ORIGINAL[0]: tok == REPMN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok == REPMN && (minrep || maxrep)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[2]: tok == REPMN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: dfa -> tindex -= nsubtoks(dfa -> tindex)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -= FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[4]: dfa -> tindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nsubtoks(dfa -> tindex)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[6]: dfa -> tindex
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tok = lex()
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = FUN1 ( )
  ORIGINAL[8]: lex()
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( )
  ORIGINAL[9]: closure()
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( )
  ORIGINAL[10]: addtok(tok)
  TYPE[10]: CALL
  TOKENIZED[10]: FUN1 ( VAR1 )
  ORIGINAL[11]: tok = lex()
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 = FUN1 ( )
  ORIGINAL[12]: lex()
  TYPE[12]: CALL
  TOKENIZED[12]: FUN1 ( )
  ORIGINAL[13]: tindex
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: tindex
  TYPE[14]: FIELD_IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: <global> tok
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> tok
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1
  ORIGINAL[17]: REPMN
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: <global> dfa
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: <global> VAR1
  ORIGINAL[19]: <global> dfa
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: <global> VAR1
  ORIGINAL[20]: <global> tok
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1
  ORIGINAL[21]: <global> tok
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: <global> VAR1
  ORIGINAL[22]: <global> tok
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: <global> VAR1

CENTER_NODE: 30064775839
FRAGMENT_COUNT: 7
  ORIGINAL[0]: old == ((void *)0) || new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: old == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: new == ((void *)0)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477856
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: tindex + i
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476802
FRAGMENT_COUNT: 3
  ORIGINAL[0]: LIMWORD=262
  TYPE[0]: CALL
  TOKENIZED[0]: LIMWORD=262
  ORIGINAL[1]: NOTLIMWORD=263
  TYPE[1]: CALL
  TOKENIZED[1]: NOTLIMWORD=263
  ORIGINAL[2]: NOTLIMWORD
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640586
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640750
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476830
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640394
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771252
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: wc == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775117
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: d -> states[s]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> states
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: states
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775574
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *d -> tokens)) == 1?xmalloc(d -> talloc) : xnmalloc(d -> talloc,sizeof(( *d -> tokens)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *d -> tokens)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xmalloc(d -> talloc)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[3]: d -> talloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640540
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479827
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> is
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: is
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479036
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> trans
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> realtrans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> success
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> newlines
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: oldalloc < d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 < VAR2 -> VAR3
  ORIGINAL[6]: d -> tralloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> trans[oldalloc] = ((void *)0)
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ] = ( ( void * ) 0 )
  ORIGINAL[8]: d -> fails
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: fails
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640620
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772838
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < work_mbc -> nchars
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: work_mbc -> chars[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: work_mbc -> chars
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: chars
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: work_mbc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: work_mbc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775185
FRAGMENT_COUNT: 49
  ORIGINAL[0]: work_mbls[i] ==  *mbclen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == *mbclen
  ORIGINAL[1]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[2]: d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR9
  ORIGINAL[3]: d -> follows[d -> states[s] . mbps . elems[i] . index]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ]
  ORIGINAL[4]: d -> follows
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> states[s] . mbps . elems[i] . index
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ] . VAR7
  ORIGINAL[6]: d -> states[s] . mbps . elems[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ]
  ORIGINAL[7]: d -> states[s] . mbps . elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[8]: d -> states[s] . mbps
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[9]: d -> states[s]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[10]: d -> states
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: j++
  TYPE[11]: CALL
  TOKENIZED[11]: j++
  ORIGINAL[12]: insert(d -> follows[d -> states[s] . mbps . elems[i] . index] . elems[j],pps)
  TYPE[12]: CALL
  TOKENIZED[12]: FUN1 ( VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6 [ VAR9 ] , VAR10 )
  ORIGINAL[13]: d -> follows[d -> states[s] . mbps . elems[i] . index] . elems[j]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6 [ VAR9 ]
  ORIGINAL[14]: d -> follows[d -> states[s] . mbps . elems[i] . index] . elems
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR6
  ORIGINAL[15]: d -> follows[d -> states[s] . mbps . elems[i] . index]
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ]
  ORIGINAL[16]: d -> follows
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: d -> states[s] . mbps . elems[i] . index
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ] . VAR7
  ORIGINAL[18]: d -> states[s] . mbps . elems[i]
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ]
  ORIGINAL[19]: d -> states[s] . mbps . elems
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[20]: d -> states[s] . mbps
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[21]: d -> states[s]
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[22]: d -> states
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 -> VAR2
  ORIGINAL[23]: for (j = 0;j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem;j++)
  TYPE[23]: CONTROL_STRUCTURE
  TOKENIZED[23]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10 ; j++ )
  ORIGINAL[24]: follows
  TYPE[24]: FIELD_IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: states
  TYPE[25]: FIELD_IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: mbps
  TYPE[26]: FIELD_IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: elems
  TYPE[27]: FIELD_IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: index
  TYPE[28]: FIELD_IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: nelem
  TYPE[29]: FIELD_IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: follows
  TYPE[30]: FIELD_IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: states
  TYPE[31]: FIELD_IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: mbps
  TYPE[32]: FIELD_IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: elems
  TYPE[33]: FIELD_IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: index
  TYPE[34]: FIELD_IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: elems
  TYPE[35]: FIELD_IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: i
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: j
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: d
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1
  ORIGINAL[39]: d
  TYPE[39]: IDENTIFIER
  TOKENIZED[39]: VAR1
  ORIGINAL[40]: s
  TYPE[40]: IDENTIFIER
  TOKENIZED[40]: VAR1
  ORIGINAL[41]: i
  TYPE[41]: IDENTIFIER
  TOKENIZED[41]: VAR1
  ORIGINAL[42]: j
  TYPE[42]: IDENTIFIER
  TOKENIZED[42]: VAR1
  ORIGINAL[43]: d
  TYPE[43]: IDENTIFIER
  TOKENIZED[43]: VAR1
  ORIGINAL[44]: d
  TYPE[44]: IDENTIFIER
  TOKENIZED[44]: VAR1
  ORIGINAL[45]: s
  TYPE[45]: IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: i
  TYPE[46]: IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: j
  TYPE[47]: IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: pps
  TYPE[48]: IDENTIFIER
  TOKENIZED[48]: VAR1

CENTER_NODE: 30064776355
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 68719480151
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640435
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640704
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476961
FRAGMENT_COUNT: 4
  ORIGINAL[0]: gettext(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: lasttok = END
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: <global> lasttok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: END
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479552
FRAGMENT_COUNT: 25
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: *p = &d -> mbcsets[i]
  TYPE[1]: CALL
  TOKENIZED[1]: *p = &d -> VAR1 [ VAR2 ]
  ORIGINAL[2]: &d -> mbcsets[i]
  TYPE[2]: CALL
  TOKENIZED[2]: &d -> VAR1 [ VAR2 ]
  ORIGINAL[3]: p -> chars
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: p -> ch_classes
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: p -> range_sts
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: p -> range_ends
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: p -> nequivs
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: p -> equivs
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: p -> equivs
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: p -> ncoll_elems
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: p -> coll_elems
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: p -> coll_elems
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: p
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: p
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: p
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: p
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: p
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: p
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: p
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: p
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: p
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: p
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1

CENTER_NODE: 30064773587
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[j] & ~(letters[j] | newline[j])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] & ~ ( VAR3 [ VAR2 ] | VAR4 [ VAR2 ] )
  ORIGINAL[2]: c[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: ~(letters[j] | newline[j])
  TYPE[3]: CALL
  TOKENIZED[3]: ~ ( VAR1 [ VAR2 ] | VAR3 [ VAR2 ] )
  ORIGINAL[4]: letters[j] | newline[j]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ] | VAR3 [ VAR2 ]

CENTER_NODE: 30064773266
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ++i
  TYPE[0]: CALL
  TOKENIZED[0]: ++i
  ORIGINAL[1]: p . index == s -> elems[i] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 == VAR3 -> VAR4 [ VAR5 ] . VAR2
  ORIGINAL[2]: for (i = 0;i < s -> nelem;++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477967
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s -> alloc = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: s -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477916
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: OR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774962
FRAGMENT_COUNT: 3
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: ((unsigned long )1) << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1
  ORIGINAL[2]: (unsigned long )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned long ) 1

CENTER_NODE: 47244640922
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773016
FRAGMENT_COUNT: 10
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN && tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: tok >= 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0
  ORIGINAL[4]: closure()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )
  ORIGINAL[5]: addtok(CAT)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 )
  ORIGINAL[6]: while (tok != RPAREN && tok != OR && tok >= 0)
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: while ( VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0 )
  ORIGINAL[7]: <global> tok
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: RPAREN
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: CAT
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476834
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640557
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640538
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478983
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tralloc = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 1
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> trcount
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: trcount
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774568
FRAGMENT_COUNT: 20
  ORIGINAL[0]: ( *d) . states[s] . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: 4 & 2
  TYPE[1]: CALL
  TOKENIZED[1]: 4 & 2
  ORIGINAL[2]: ( *d) . states[s] . constraint >> 4
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4
  ORIGINAL[3]: ( *d) . states[s] . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[4]: ( *d) . states[s]
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[5]: ( *d) . states[s] . constraint
  TYPE[5]: CALL
  TOKENIZED[5]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[6]: ( *d) . states[s]
  TYPE[6]: CALL
  TOKENIZED[6]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[7]: ( *d) . states[s] . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[8]: ( *d) . states[s]
  TYPE[8]: CALL
  TOKENIZED[8]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[9]: ( *d) . states[s] . constraint
  TYPE[9]: CALL
  TOKENIZED[9]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[10]: ( *d) . states[s]
  TYPE[10]: CALL
  TOKENIZED[10]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[11]: ( *d) . states[s] . constraint
  TYPE[11]: CALL
  TOKENIZED[11]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[12]: ( *d) . states[s]
  TYPE[12]: CALL
  TOKENIZED[12]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[13]: ( *d) . states[s] . constraint
  TYPE[13]: CALL
  TOKENIZED[13]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[14]: ( *d) . states[s]
  TYPE[14]: CALL
  TOKENIZED[14]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[15]: ( *d) . states[s] . constraint
  TYPE[15]: CALL
  TOKENIZED[15]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[16]: ( *d) . states[s]
  TYPE[16]: CALL
  TOKENIZED[16]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[17]: ( *d) . states[s] . constraint
  TYPE[17]: CALL
  TOKENIZED[17]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[18]: ( *d) . states[s]
  TYPE[18]: CALL
  TOKENIZED[18]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[19]: constraint
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640392
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771188
FRAGMENT_COUNT: 23
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: (1 << 8) + 8 * sizeof(int ) - 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( 1 << 8 ) + 8 * sizeof ( int ) - 1
  ORIGINAL[3]: (1 << 8) + 8 * sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[4]: 1 << 8
  TYPE[4]: CALL
  TOKENIZED[4]: 1 << 8
  ORIGINAL[5]: 8 * sizeof(int )
  TYPE[5]: CALL
  TOKENIZED[5]: 8 * sizeof ( int )
  ORIGINAL[6]: sizeof(int )
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( int )
  ORIGINAL[7]: 8 * sizeof(int )
  TYPE[7]: CALL
  TOKENIZED[7]: 8 * sizeof ( int )
  ORIGINAL[8]: sizeof(int )
  TYPE[8]: CALL
  TOKENIZED[8]: sizeof ( int )
  ORIGINAL[9]: ++i
  TYPE[9]: CALL
  TOKENIZED[9]: ++i
  ORIGINAL[10]: s[i] = ~s[i]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[11]: s[i]
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 [ VAR2 ]
  ORIGINAL[12]: ~s[i]
  TYPE[12]: CALL
  TOKENIZED[12]: ~s [ VAR1 ]
  ORIGINAL[13]: s[i]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 [ VAR2 ]
  ORIGINAL[14]: for (i = 0;i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++i)
  TYPE[14]: CONTROL_STRUCTURE
  TOKENIZED[14]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++i )
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: int
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: int
  ORIGINAL[17]: int
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: int
  ORIGINAL[18]: i
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: s
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: i
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: s
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: i
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1

CENTER_NODE: 30064774894
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *next_state = works
  TYPE[0]: CALL
  TOKENIZED[0]: *next_state = VAR1
  ORIGINAL[1]: *next_state
  TYPE[1]: CALL
  TOKENIZED[1]: *next_state
  ORIGINAL[2]: works
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771129
FRAGMENT_COUNT: 1
  ORIGINAL[0]: before[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 30064772626
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: laststart = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: <global> laststart
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> lasttok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640746
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477804
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == ANYCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: ANYCHAR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ANYCHAR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476874
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (int )c
  TYPE[0]: CALL
  TOKENIZED[0]: ( int ) VAR1
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775722
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: *cp
  TYPE[1]: CALL
  TOKENIZED[1]: *cp
  ORIGINAL[2]: ++cp
  TYPE[2]: CALL
  TOKENIZED[2]: ++cp
  ORIGINAL[3]: strncmp(cp,lookfor,len) == 0
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[4]: strncmp(cp,lookfor,len)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[5]: (char *)cp
  TYPE[5]: CALL
  TOKENIZED[5]: ( char * ) VAR1
  ORIGINAL[6]: cp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: cp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719479621
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfaanalyze(d,searchflag)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: searchflag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640618
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773609
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: (s -> elems[j] . constraint >> 1 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[2]: s -> elems[j] . constraint >> 1 & 0x111
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111
  ORIGINAL[3]: s -> elems[j] . constraint >> 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1
  ORIGINAL[4]: s -> elems[j] . constraint & 0x111
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775792
FRAGMENT_COUNT: 5
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: left == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: right == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: right
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773721
FRAGMENT_COUNT: 5
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: tmp . elems = firstpos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 = VAR3
  ORIGINAL[2]: tmp . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: firstpos
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476922
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640895
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479424
FRAGMENT_COUNT: 12
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: (const char *)p
  TYPE[1]: CALL
  TOKENIZED[1]: ( const char * ) VAR1
  ORIGINAL[2]: p
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640672
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771234
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: copyset(s,dfa -> charclasses[i])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[2]: dfa -> charclasses[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775688
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dm = d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3
  ORIGINAL[1]: d -> musts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: for (dm = d -> musts;dm;dm = ndm)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = VAR2 -> VAR3 ; VAR1 ; VAR1 = VAR4 )
  ORIGINAL[3]: dm
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dm
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476745
FRAGMENT_COUNT: 3
  ORIGINAL[0]: size_filepath = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: retval = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: retval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775225
FRAGMENT_COUNT: 7
  ORIGINAL[0]: nelem > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: match_lens = check_matching_with_multibyte_ops(d,s,( *pp - buf_begin))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , ( *pp - VAR4 ) )
  ORIGINAL[2]: check_matching_with_multibyte_ops(d,s,( *pp - buf_begin))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , ( *pp - VAR3 ) )
  ORIGINAL[3]: *pp - buf_begin
  TYPE[3]: CALL
  TOKENIZED[3]: *pp - VAR1
  ORIGINAL[4]: match_lens
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064776365
FRAGMENT_COUNT: 3
  ORIGINAL[0]: {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: { { ( \
  ORIGINAL[1]: {(\
  TYPE[1]: CALL
  TOKENIZED[1]: { ( \
  ORIGINAL[2]: isspace
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064774866
FRAGMENT_COUNT: 2
  ORIGINAL[0]: TRANSIT_STATE_END_BUFFER=2
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719479097
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[1]: mbclen
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: mbclen
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640337
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775698
FRAGMENT_COUNT: 6
  ORIGINAL[0]: old == ((void *)0)?0 : strlen(old)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[1]: old == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: strlen(old)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719478007
FRAGMENT_COUNT: 10
  ORIGINAL[0]: lo < count && p . index == s -> elems[lo] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 . VAR4 == VAR5 -> VAR6 [ VAR1 ] . VAR4
  ORIGINAL[1]: i = count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: i > lo
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 > VAR2
  ORIGINAL[3]: i--
  TYPE[3]: CALL
  TOKENIZED[3]: i--
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: lo
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771169
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] |= 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] |= 1 << VAR2 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: 1 << b % (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[3]: b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480145
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775624
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: i < d -> tindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: d -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> tokens[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: tindex
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640622
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> tokens[s -> elems[j] . index] < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < 0
  ORIGINAL[1]: for (j = 0;j < s -> nelem;++j)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[2]: else
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: else

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476793
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064773501
FRAGMENT_COUNT: 14
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[2]: d -> tokens
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> tokens[s -> elems[i] . index]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[4]: d -> tokens[s -> elems[i] . index] != ANYCHAR
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[5]: d -> tokens[s -> elems[i] . index]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[6]: d -> tokens
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: s -> elems[i] . index
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[8]: d -> tokens[s -> elems[i] . index]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[9]: d -> tokens
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: d -> tokens[s -> elems[i] . index]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[11]: d -> tokens
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: d -> tokens
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: ANYCHAR
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773037
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: cur_mb_len = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: <global> cur_mb_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> mbs
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064771154
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064771130
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640414
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478066
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s1 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s1 -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: m -> elems[m -> nelem++]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> nelem++ ]
  ORIGINAL[3]: s1 -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

