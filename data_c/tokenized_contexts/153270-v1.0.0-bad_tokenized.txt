# Tokenized code fragments for 153270-v1.0.0-bad
# Total center nodes processed: 42
# Total code fragments found: 165

CENTER_NODE: 30064772384
FRAGMENT_COUNT: 3
  ORIGINAL[0]: hashp -> isshared
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: elog_finish(21,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( 21 , \
  ORIGINAL[2]: hashp -> tabname
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 30064772146
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ((uint32 )new_bucket) > hctl -> high_mask
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( VAR1 ) VAR2 ) > VAR3 -> VAR4
  ORIGINAL[1]: hctl -> high_mask = ((uint32 )new_bucket) | hctl -> low_mask
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( VAR3 ) VAR4 ) | VAR1 -> VAR5
  ORIGINAL[2]: hctl -> high_mask
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ((uint32 )new_bucket) | hctl -> low_mask
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( VAR1 ) VAR2 ) | VAR3 -> VAR4
  ORIGINAL[4]: old_segnum
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640381
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771171
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 30064771674
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: hashp -> hash
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hash
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: keyPtr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477294
FRAGMENT_COUNT: 3
  ORIGINAL[0]: hashp -> hctl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hctl
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: hashp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640382
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (((intptr_t )_vstart) & sizeof(long ) - 1) == 0 && (_len & sizeof(long ) - 1) == 0 && _val == 0 && _len <= 1024 && 1024 != 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( VAR1 ) VAR2 ) & sizeof ( long ) - 1 ) == 0 && ( VAR3 & sizeof ( long ) - 1 ) == 0 && VAR4 == 0 && VAR3 <= 1024 && 1024 != 0
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 30064772093
FRAGMENT_COUNT: 6
  ORIGINAL[0]: !status -> hashp -> frozen
  TYPE[0]: CALL
  TOKENIZED[0]: !status -> VAR1 -> VAR2
  ORIGINAL[1]: status -> hashp -> frozen
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: deregister_seq_scan(status -> hashp)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[3]: status -> hashp
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: hashp
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: status
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771987
FRAGMENT_COUNT: 8
  ORIGINAL[0]: newElement != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: hctlv -> nentries++
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> nentries++
  ORIGINAL[2]: hctlv -> nentries
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nentries
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hctlv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hctlv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hctlv
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hctlv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064772395
FRAGMENT_COUNT: 2
  ORIGINAL[0]: 1L << my_log2(num)
  TYPE[0]: CALL
  TOKENIZED[0]: 1L << FUN1 ( VAR1 )
  ORIGINAL[1]: my_log2(num)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )

CENTER_NODE: 47244640348
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640389
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771672
FRAGMENT_COUNT: 6
  ORIGINAL[0]: hashp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: MemoryContextDelete(hashp -> hcxt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[2]: hashp -> hcxt
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hcxt
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771654
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (num_entries - 1) / 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 - 1 ) / 1
  ORIGINAL[1]: num_entries - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: num_entries
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640337
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477362
FRAGMENT_COUNT: 4
  ORIGINAL[0]: hashp -> isshared
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hashp -> tabname
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: tabname
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476817
FRAGMENT_COUNT: 10
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: stonesoup_tainted_file != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: *stonesoup_tainted_buff != 0
  TYPE[2]: CALL
  TOKENIZED[2]: *stonesoup_tainted_buff != 0
  ORIGINAL[3]: (*stonesoup_tainted_buff)[stonesoup_lsize] = '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: ( *stonesoup_tainted_buff ) [ VAR1 ] = '\\0'
  ORIGINAL[4]: stonesoup_tainted_file != 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 != 0
  ORIGINAL[5]: stonesoup_tainted_file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_tainted_file
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_tainted_file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_tainted_file
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: stonesoup_tainted_file
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771718
FRAGMENT_COUNT: 6
  ORIGINAL[0]: hash_search_with_hash_value(hashp,keyPtr,((hashp -> hash)(keyPtr,hashp -> keysize)),action,foundPtr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , ( ( VAR1 -> VAR3 ) ( VAR2 , VAR1 -> VAR4 ) ) , VAR5 , VAR6 )
  ORIGINAL[1]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[2]: hashp -> hash
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hashp -> keysize
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: keyPtr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: action
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771608
FRAGMENT_COUNT: 5
  ORIGINAL[0]: size = add_size(size,mul_size(nDirEntries,sizeof(HASHSEGMENT )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR1 , FUN2 ( VAR2 , sizeof ( VAR3 ) ) )
  ORIGINAL[1]: add_size(size,mul_size(nDirEntries,sizeof(HASHSEGMENT )))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , FUN2 ( VAR2 , sizeof ( VAR3 ) ) )
  ORIGINAL[2]: mul_size(nDirEntries,sizeof(HASHSEGMENT ))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , sizeof ( VAR2 ) )
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477549
FRAGMENT_COUNT: 8
  ORIGINAL[0]: hctlv -> entrysize
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hctlv -> num_partitions
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: tas(&hctlv -> mutex)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( &hctlv -> VAR1 )
  ORIGINAL[3]: hctlv -> mutex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: hctlv -> mutex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: mutex
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hctlv
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hctlv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771522
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (nelem - 1) / hctl -> ffactor + 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 - 1 ) / VAR2 -> VAR3 + 1
  ORIGINAL[1]: (nelem - 1) / hctl -> ffactor
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 - 1 ) / VAR2 -> VAR3
  ORIGINAL[2]: nelem - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: hctl -> ffactor
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 30064771097
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stat(dirpath, &st) == -1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[2]: stat(dirpath, &st)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , &st )
  ORIGINAL[3]: &st
  TYPE[3]: CALL
  TOKENIZED[3]: &st
  ORIGINAL[4]: -1
  TYPE[4]: CALL
  TOKENIZED[4]: -1
  ORIGINAL[5]: dirpath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772482
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stonesoup_i < 64
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 64
  ORIGINAL[1]: stonesoup_data.buffer[stonesoup_i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 [ VAR3 ]
  ORIGINAL[2]: stonesoup_data.buffer
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: buffer
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772029
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (curElem = status -> curEntry) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 ) != ( ( void * ) 0 )
  ORIGINAL[1]: (intptr_t )(8 - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) ( 8 - 1 )
  ORIGINAL[2]: 8 - 1
  TYPE[2]: CALL
  TOKENIZED[2]: 8 - 1

CENTER_NODE: 68719477569
FRAGMENT_COUNT: 4
  ORIGINAL[0]: limit < num
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640376
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476969
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *hctl = hashp -> hctl
  TYPE[0]: CALL
  TOKENIZED[0]: *hctl = VAR1 -> VAR2
  ORIGINAL[1]: hashp -> hctl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hctl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hctl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477457
FRAGMENT_COUNT: 5
  ORIGINAL[0]: p != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (char *)p
  TYPE[1]: CALL
  TOKENIZED[1]: ( char * ) VAR1
  ORIGINAL[2]: p
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772544
FRAGMENT_COUNT: 1
  ORIGINAL[0]: *seq_scan_tables[100]
  TYPE[0]: CALL
  TOKENIZED[0]: *seq_scan_tables [ 100 ]

CENTER_NODE: 30064772397
FRAGMENT_COUNT: 6
  ORIGINAL[0]: num > (2147483647 / 2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > ( 2147483647 / 2 )
  ORIGINAL[1]: 2147483647 / 2
  TYPE[1]: CALL
  TOKENIZED[1]: 2147483647 / 2
  ORIGINAL[2]: num = (2147483647 / 2)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( 2147483647 / 2 )
  ORIGINAL[3]: 2147483647 / 2
  TYPE[3]: CALL
  TOKENIZED[3]: 2147483647 / 2
  ORIGINAL[4]: num
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: num
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771491
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 )
  ORIGINAL[1]: (intptr_t )(sizeof(HASHELEMENT ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) ( sizeof ( VAR2 ) )
  ORIGINAL[2]: sizeof(HASHELEMENT )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: intptr_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477139
FRAGMENT_COUNT: 5
  ORIGINAL[0]: &valeted_epitaphize
  TYPE[0]: CALL
  TOKENIZED[0]: &valeted_epitaphize
  ORIGINAL[1]: valeted_epitaphize != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: (char *)valeted_epitaphize
  TYPE[2]: CALL
  TOKENIZED[2]: ( char * ) VAR1
  ORIGINAL[3]: valeted_epitaphize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: valeted_epitaphize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772447
FRAGMENT_COUNT: 10
  ORIGINAL[0]: i >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: i--
  TYPE[1]: CALL
  TOKENIZED[1]: i--
  ORIGINAL[2]: seq_scan_level[i] >= nestDepth
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] >= VAR3
  ORIGINAL[3]: seq_scan_level[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: for (i = num_seq_scans - 1;i >= 0;i--)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = VAR2 - 1 ; VAR1 >= 0 ; i-- )
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> seq_scan_level
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: nestDepth
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97
  ORIGINAL[1]: c <= 122
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= 122
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476852
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (((intptr_t )_vstart) & sizeof(long ) - 1) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( VAR1 ) VAR2 ) & sizeof ( long ) - 1 ) == 0
  ORIGINAL[1]: sizeof(long )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long )
  ORIGINAL[2]: _len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: long
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: long

CENTER_NODE: 68719477295
FRAGMENT_COUNT: 3
  ORIGINAL[0]: status -> hashp
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hashp
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: status
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477112
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(HASHHDR )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: info -> dsize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dsize
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: info
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771793
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *foundPtr = ((bool )(currBucket != ((void *)0)))
  TYPE[0]: CALL
  TOKENIZED[0]: *foundPtr = ( ( VAR1 ) ( VAR2 != ( ( void * ) 0 ) ) )
  ORIGINAL[1]: *foundPtr
  TYPE[1]: CALL
  TOKENIZED[1]: *foundPtr
  ORIGINAL[2]: (bool )(currBucket != ((void *)0))
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) ( VAR2 != ( ( void * ) 0 ) )
  ORIGINAL[3]: currBucket != ((void *)0)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[4]: foundPtr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: bool
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640346
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719476828
FRAGMENT_COUNT: 5
  ORIGINAL[0]: strncmp(key1,key2,keysize - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 - 1 )
  ORIGINAL[1]: keysize - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: key1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: keysize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

