# Tokenized code fragments for 153147-v1.0.0-bad
# Total center nodes processed: 145
# Total code fragments found: 470

CENTER_NODE: 47244640444
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640904
FRAGMENT_COUNT: 1
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )

CENTER_NODE: 30064775162
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: d -> states[s] . mbps . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[2]: d -> states[s] . mbps . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[3]: d -> states[s] . mbps
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: d -> states[s]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: mbps
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: elems
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640779
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 68719479070
FRAGMENT_COUNT: 2
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640313
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640885
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775197
FRAGMENT_COUNT: 4
  ORIGINAL[0]: copy((&d -> states[s1] . elems),pps)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( &d -> VAR1 [ VAR2 ] . VAR3 ) , VAR4 )
  ORIGINAL[1]: &d -> states[s1] . elems
  TYPE[1]: CALL
  TOKENIZED[1]: &d -> VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: d -> states[s1] . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: pps
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c >= 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640754
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640400
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775804
FRAGMENT_COUNT: 6
  ORIGINAL[0]: cpp[j] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: istrstr(new,cpp[j]) == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 [ VAR3 ] ) == ( ( void * ) 0 )
  ORIGINAL[2]: istrstr(new,cpp[j])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] )
  ORIGINAL[3]: cpp[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064773190
FRAGMENT_COUNT: 12
  ORIGINAL[0]: s -> alloc <= count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 + 1
  ORIGINAL[1]: s -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: s -> alloc = new_n_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = VAR3
  ORIGINAL[3]: s -> alloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: alloc
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new_n_alloc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064775908
FRAGMENT_COUNT: 2
  ORIGINAL[0]: both == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 68719479506
FRAGMENT_COUNT: 8
  ORIGINAL[0]: (t = trans[s]) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 [ VAR3 ] ) != ( ( void * ) 0 )
  ORIGINAL[1]: s1 = t[ *(p++)]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 [ * ( p++ ) ]
  ORIGINAL[2]: t = trans[s1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 [ VAR3 ]
  ORIGINAL[3]: trans[s1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: t[ *(p++)]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ * ( p++ ) ]
  ORIGINAL[5]: t
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: trans
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: t
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640443
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640874
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771279
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771344
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640422
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479342
FRAGMENT_COUNT: 10
  ORIGINAL[0]: nelem > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i < nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2
  ORIGINAL[3]: i++
  TYPE[3]: CALL
  TOKENIZED[3]: i++
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: nelem
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771194
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064776368
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640548
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479114
FRAGMENT_COUNT: 7
  ORIGINAL[0]: mbclen = (mblen_buf[idx] == 0?1 : mblen_buf[idx])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( VAR2 [ VAR3 ] == 0?1 : VAR2 [ VAR3 ] )
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: (wchar_t )eolbyte
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: wc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640840
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640716
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640981
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476840
FRAGMENT_COUNT: 3
  ORIGINAL[0]: CAT=268
  TYPE[0]: CALL
  TOKENIZED[0]: CAT=268
  ORIGINAL[1]: OR=269
  TYPE[1]: CALL
  TOKENIZED[1]: OR=269
  ORIGINAL[2]: OR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640712
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479029
FRAGMENT_COUNT: 12
  ORIGINAL[0]: d -> trcount
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> trans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> success
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> success
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: d -> tralloc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: d -> tralloc
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: success
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771258
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> cindex + 1 + (!dfa -> charclasses)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 + 1 + ( !dfa -> VAR3 )
  ORIGINAL[2]: dfa -> cindex + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1
  ORIGINAL[3]: dfa -> cindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479997
FRAGMENT_COUNT: 13
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: lmp -> is
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: lmp -> left[i] != '\\0' && lmp -> left[i] == rmp -> left[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] != '\\0' && VAR1 -> VAR2 [ VAR3 ] == VAR4 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: lmp -> left
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: lmp -> right
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: lmp -> in
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: lmp -> in
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: lmp -> in
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: lmp -> left
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: lmp -> right
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: left
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: lmp
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: lmp
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640274
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773943
FRAGMENT_COUNT: 10
  ORIGINAL[0]: &merged
  TYPE[0]: CALL
  TOKENIZED[0]: &merged
  ORIGINAL[1]: &merged
  TYPE[1]: CALL
  TOKENIZED[1]: &merged
  ORIGINAL[2]: &merged
  TYPE[2]: CALL
  TOKENIZED[2]: &merged
  ORIGINAL[3]: d -> tokens[i] < (1 << 8) || d -> tokens[i] == BACKREF || d -> tokens[i] == ANYCHAR || d -> tokens[i] == MBCSET || d -> tokens[i] >= CSET
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] < ( 1 << 8 ) || VAR1 -> VAR2 [ VAR3 ] == VAR4 || VAR1 -> VAR2 [ VAR3 ] == VAR5 || VAR1 -> VAR2 [ VAR3 ] == VAR6 || VAR1 -> VAR2 [ VAR3 ] >= VAR7
  ORIGINAL[4]: copy((&d -> follows[i]),&merged)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( &d -> VAR1 [ VAR2 ] ) , &merged )
  ORIGINAL[5]: &merged
  TYPE[5]: CALL
  TOKENIZED[5]: &merged
  ORIGINAL[6]: &merged
  TYPE[6]: CALL
  TOKENIZED[6]: &merged
  ORIGINAL[7]: &merged
  TYPE[7]: CALL
  TOKENIZED[7]: &merged
  ORIGINAL[8]: merged
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: merged
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640661
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640768
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640392
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640584
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i < maxrep
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: for (;i < maxrep;++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( ; VAR1 < VAR2 ; ++i )

CENTER_NODE: 30064775754
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771348
FRAGMENT_COUNT: 6
  ORIGINAL[0]: prednames[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: prednames[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: strcmp(str,prednames[i] . name) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] . VAR4 ) == 0
  ORIGINAL[3]: name
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> prednames
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772885
FRAGMENT_COUNT: 9
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0
  ORIGINAL[2]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0
  ORIGINAL[3]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0
  ORIGINAL[4]: work_mbc -> nranges != 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 != 0
  ORIGINAL[5]: work_mbc -> nequivs != 0
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 != 0
  ORIGINAL[6]: work_mbc -> nequivs
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: nequivs
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719479710
FRAGMENT_COUNT: 5
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: newsize + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + 1
  ORIGINAL[2]: newsize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: new
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: newsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640773
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479713
FRAGMENT_COUNT: 5
  ORIGINAL[0]: len = strlen(lookfor)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: strlen(lookfor)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: lookfor
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640635
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774855
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> tralloc *= 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 *= 2
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: tralloc
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640357
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640903
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640626
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477993
FRAGMENT_COUNT: 3
  ORIGINAL[0]: s -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: elems
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772582
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: ((unsigned long )1) << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640681
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775663
FRAGMENT_COUNT: 16
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: i < d -> tindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: d -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> tokens[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: d -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: free_mbdata(d)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 )
  ORIGINAL[6]: d -> mb_cur_max = 1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 = 1
  ORIGINAL[7]: d -> mb_cur_max
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: for (i = 0;i < d -> tindex;++i)
  TYPE[8]: CONTROL_STRUCTURE
  TOKENIZED[8]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[9]: tokens
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: mb_cur_max
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: i
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 30064771195
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] & 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] & 1 << VAR2 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: 1 << b % (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 47244640566
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640601
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640335
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476864
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771292
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: wc == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640294
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477945
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok != RPAREN && tok != OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[1]: tok >= 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064771136
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: strcmp(getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( FUN2 ( \
  ORIGINAL[2]: strcmp(getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( FUN2 ( \
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \

CENTER_NODE: 30064773109
FRAGMENT_COUNT: 12
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> elems = (x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) ) )
  ORIGINAL[2]: dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) )
  ORIGINAL[4]: dst -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dst -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: elems
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dst
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: dst
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: dst
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: dst
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: dst
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640682
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640878
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640324
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477950
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: branch()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: addtok(OR)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771325
FRAGMENT_COUNT: 5
  ORIGINAL[0]: case_fold && ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISalpha)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && ( *__ctype_b_loc ( ) ) [ ( int ) VAR2 ] & ( ( unsigned short ) VAR3 )
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISalpha)
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[2]: ( *__ctype_b_loc())[(int )b]
  TYPE[2]: CALL
  TOKENIZED[2]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[3]: (unsigned short )_ISalpha
  TYPE[3]: CALL
  TOKENIZED[3]: ( unsigned short ) VAR1
  ORIGINAL[4]: <global> case_fold
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 68719480191
FRAGMENT_COUNT: 35
  ORIGINAL[0]: (c = getopt(argc, argv, \
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , VAR3 , \
  ORIGINAL[1]: c = getopt(argc, argv, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , \
  ORIGINAL[2]: getopt(argc, argv, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[3]: -1
  TYPE[3]: CALL
  TOKENIZED[3]: -1
  ORIGINAL[4]: (key = strtol(optarg, NULL, 10)) < 1000
  TYPE[4]: CALL
  TOKENIZED[4]: ( VAR1 = FUN1 ( VAR2 , VAR3 , 10 ) ) < 1000
  ORIGINAL[5]: key = strtol(optarg, NULL, 10)
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = FUN1 ( VAR2 , VAR3 , 10 )
  ORIGINAL[6]: strtol(optarg, NULL, 10)
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( VAR1 , VAR2 , 10 )
  ORIGINAL[7]: (shmsz = atoi(optarg)) <= 0
  TYPE[7]: CALL
  TOKENIZED[7]: ( VAR1 = FUN1 ( VAR2 ) ) <= 0
  ORIGINAL[8]: shmsz = atoi(optarg)
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[9]: atoi(optarg)
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( VAR1 )
  ORIGINAL[10]: out_filename = optarg
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 = VAR2
  ORIGINAL[11]: str = optarg
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 = VAR2
  ORIGINAL[12]: printf(\
  TYPE[12]: CALL
  TOKENIZED[12]: FUN1 ( \
  ORIGINAL[13]: fprintf(stderr, \
  TYPE[13]: CALL
  TOKENIZED[13]: FUN1 ( VAR1 , \
  ORIGINAL[14]: errors++
  TYPE[14]: CALL
  TOKENIZED[14]: errors++
  ORIGINAL[15]: break;
  TYPE[15]: CONTROL_STRUCTURE
  TOKENIZED[15]: break ;
  ORIGINAL[16]: break;
  TYPE[16]: CONTROL_STRUCTURE
  TOKENIZED[16]: break ;
  ORIGINAL[17]: break;
  TYPE[17]: CONTROL_STRUCTURE
  TOKENIZED[17]: break ;
  ORIGINAL[18]: break;
  TYPE[18]: CONTROL_STRUCTURE
  TOKENIZED[18]: break ;
  ORIGINAL[19]: break;
  TYPE[19]: CONTROL_STRUCTURE
  TOKENIZED[19]: break ;
  ORIGINAL[20]: c
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: argc
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: argv
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: c
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: key
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: optarg
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: NULL
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: shmsz
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: optarg
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: out_filename
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: optarg
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: str
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: optarg
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: stderr
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: errors
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1

CENTER_NODE: 68719478861
FRAGMENT_COUNT: 8
  ORIGINAL[0]: separate_contexts & possible_contexts & 4
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & VAR2 & 4
  ORIGINAL[1]: state_newline = state
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: state
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: state
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state_newline
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640604
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640660
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775715
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < (d -> tralloc)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[1]: free(d -> trans[i])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] )
  ORIGINAL[2]: d -> trans[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: d -> trans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640382
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640355
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640433
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476745
FRAGMENT_COUNT: 3
  ORIGINAL[0]: size_filepath = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: retval = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: retval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775655
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> mbcsets)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[1]: xnmalloc(d -> mbcsets_alloc,sizeof(( *d -> mbcsets)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[2]: d -> mbcsets_alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *d -> mbcsets))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[4]: *d -> mbcsets
  TYPE[4]: CALL
  TOKENIZED[4]: *d -> VAR1

CENTER_NODE: 30064773367
FRAGMENT_COUNT: 7
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j] . constraint != d -> states[i] . elems . elems[j] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 != VAR5 -> VAR6 [ VAR7 ] . VAR2 . VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s -> elems[j] . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[i] . elems . elems[j] . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4 [ VAR5 ] . VAR6
  ORIGINAL[4]: d -> states[i] . elems . elems[j]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4 [ VAR5 ]
  ORIGINAL[5]: d -> states[i] . elems . elems[j]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4 [ VAR5 ]
  ORIGINAL[6]: constraint
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479653
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfaanalyze(d,searchflag)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: searchflag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640596
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640628
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640774
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477957
FRAGMENT_COUNT: 4
  ORIGINAL[0]: lexleft = len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: lasttok = END
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: <global> lasttok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: END
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640323
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776370
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771584
FRAGMENT_COUNT: 64
  ORIGINAL[0]: ch_classes_al <= work_mbc -> nch_classes + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= VAR2 -> VAR3 + 1
  ORIGINAL[1]: work_mbc -> ch_classes
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: work_mbc -> ch_classes = (x2nrealloc((work_mbc -> ch_classes),&new_n_alloc,sizeof(( *work_mbc -> ch_classes))))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *work_mbc -> VAR2 ) ) ) )
  ORIGINAL[3]: work_mbc -> ch_classes
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: x2nrealloc((work_mbc -> ch_classes),&new_n_alloc,sizeof(( *work_mbc -> ch_classes)))
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *work_mbc -> VAR2 ) ) )
  ORIGINAL[5]: work_mbc -> ch_classes
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: ch_classes
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: work_mbc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: work_mbc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: work_mbc
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: work_mbc
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: work_mbc
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: work_mbc
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: work_mbc
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: work_mbc
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: work_mbc
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: work_mbc
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: work_mbc
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: work_mbc
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: work_mbc
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: work_mbc
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: work_mbc
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: work_mbc
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: work_mbc
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: work_mbc
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: work_mbc
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: work_mbc
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: work_mbc
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: work_mbc
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: work_mbc
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: work_mbc
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: work_mbc
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: work_mbc
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: work_mbc
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: work_mbc
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: work_mbc
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: work_mbc
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: work_mbc
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1
  ORIGINAL[39]: work_mbc
  TYPE[39]: IDENTIFIER
  TOKENIZED[39]: VAR1
  ORIGINAL[40]: work_mbc
  TYPE[40]: IDENTIFIER
  TOKENIZED[40]: VAR1
  ORIGINAL[41]: work_mbc
  TYPE[41]: IDENTIFIER
  TOKENIZED[41]: VAR1
  ORIGINAL[42]: work_mbc
  TYPE[42]: IDENTIFIER
  TOKENIZED[42]: VAR1
  ORIGINAL[43]: work_mbc
  TYPE[43]: IDENTIFIER
  TOKENIZED[43]: VAR1
  ORIGINAL[44]: work_mbc
  TYPE[44]: IDENTIFIER
  TOKENIZED[44]: VAR1
  ORIGINAL[45]: work_mbc
  TYPE[45]: IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: work_mbc
  TYPE[46]: IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: work_mbc
  TYPE[47]: IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: work_mbc
  TYPE[48]: IDENTIFIER
  TOKENIZED[48]: VAR1
  ORIGINAL[49]: work_mbc
  TYPE[49]: IDENTIFIER
  TOKENIZED[49]: VAR1
  ORIGINAL[50]: work_mbc
  TYPE[50]: IDENTIFIER
  TOKENIZED[50]: VAR1
  ORIGINAL[51]: work_mbc
  TYPE[51]: IDENTIFIER
  TOKENIZED[51]: VAR1
  ORIGINAL[52]: work_mbc
  TYPE[52]: IDENTIFIER
  TOKENIZED[52]: VAR1
  ORIGINAL[53]: work_mbc
  TYPE[53]: IDENTIFIER
  TOKENIZED[53]: VAR1
  ORIGINAL[54]: work_mbc
  TYPE[54]: IDENTIFIER
  TOKENIZED[54]: VAR1
  ORIGINAL[55]: work_mbc
  TYPE[55]: IDENTIFIER
  TOKENIZED[55]: VAR1
  ORIGINAL[56]: work_mbc
  TYPE[56]: IDENTIFIER
  TOKENIZED[56]: VAR1
  ORIGINAL[57]: work_mbc
  TYPE[57]: IDENTIFIER
  TOKENIZED[57]: VAR1
  ORIGINAL[58]: work_mbc
  TYPE[58]: IDENTIFIER
  TOKENIZED[58]: VAR1
  ORIGINAL[59]: work_mbc
  TYPE[59]: IDENTIFIER
  TOKENIZED[59]: VAR1
  ORIGINAL[60]: work_mbc
  TYPE[60]: IDENTIFIER
  TOKENIZED[60]: VAR1
  ORIGINAL[61]: work_mbc
  TYPE[61]: IDENTIFIER
  TOKENIZED[61]: VAR1
  ORIGINAL[62]: work_mbc
  TYPE[62]: IDENTIFIER
  TOKENIZED[62]: VAR1
  ORIGINAL[63]: work_mbc
  TYPE[63]: IDENTIFIER
  TOKENIZED[63]: VAR1

CENTER_NODE: 47244640932
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772980
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 - 1 )
  ORIGINAL[2]: tindex - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064776383
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064775777
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640613
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: for (i = 0;i < s -> nelem;++i)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )

CENTER_NODE: 68719476865
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640352
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774995
FRAGMENT_COUNT: 5
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[1]: CALL
  TOKENIZED[1]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[4]: <global> syntax_bits
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640871
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < d -> nmbcsets
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: for (i = 0;i < d -> nmbcsets;++i)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )

CENTER_NODE: 47244640814
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (i = 0;i < (1 << 8);++i)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774718
FRAGMENT_COUNT: 7
  ORIGINAL[0]: trans[i] >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] >= VAR3 -> VAR4
  ORIGINAL[1]: d -> realtrans = (xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[4]: d -> realtrans
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tralloc + 1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 + 1
  ORIGINAL[6]: sizeof(( *d -> realtrans))
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *d -> VAR1 ) )

CENTER_NODE: 68719476854
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( int )
  ORIGINAL[1]: int
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: int

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477889
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tokens
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 68719476825
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064775942
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> right
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: right
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772973
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == LPAREN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064773622
FRAGMENT_COUNT: 10
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[j] & letters[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] & VAR3 [ VAR2 ]
  ORIGINAL[2]: c[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: letters[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: c[j]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: c
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: j
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: <global> letters
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: c
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771229
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: (1 << 8) + 8 * sizeof(int ) - 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( 1 << 8 ) + 8 * sizeof ( int ) - 1
  ORIGINAL[3]: 8 * sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: 8 * sizeof ( int )
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771167
FRAGMENT_COUNT: 1
  ORIGINAL[0]: base_path[20]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 20 ]

CENTER_NODE: 30064776384
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640546
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640639
FRAGMENT_COUNT: 4
  ORIGINAL[0]: visited[old . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 . VAR3 ]
  ORIGINAL[1]: --i
  TYPE[1]: CALL
  TOKENIZED[1]: --i
  ORIGINAL[2]: continue;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: continue ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640410
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771243
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(charclass )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771218
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[3]: 1 << b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640345
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773292
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < s1 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s1 -> elems[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ i++ ]
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640839
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477775
FRAGMENT_COUNT: 11
  ORIGINAL[0]: dfa -> nmultibyte_prop
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dfa -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> nmultibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[4]: dfa -> talloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dfa -> tindex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: dfa -> tokens = (x2nrealloc((dfa -> tokens),&new_n_alloc,sizeof(( *dfa -> tokens))))
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) ) )
  ORIGINAL[7]: dfa -> tokens
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: dfa -> talloc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: talloc
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1

CENTER_NODE: 30064775892
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: enlist(old,new[i],strlen(new[i]))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[2]: strlen(new[i])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 [ VAR2 ] )
  ORIGINAL[3]: new[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]

CENTER_NODE: 47244640761
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478327
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: s -> elems[j] . constraint >> 2 & 0x111
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

