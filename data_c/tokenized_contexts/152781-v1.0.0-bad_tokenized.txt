# Tokenized code fragments for 152781-v1.0.0-bad
# Total center nodes processed: 78
# Total code fragments found: 363

CENTER_NODE: 30064771654
FRAGMENT_COUNT: 9
  ORIGINAL[0]: pos > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pos = str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: str -> len
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: len
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771676
FRAGMENT_COUNT: 11
  ORIGINAL[0]: pos + count > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > VAR3 -> VAR4
  ORIGINAL[1]: pos + count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: count = str -> len - pos
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2 -> VAR3 - VAR4
  ORIGINAL[4]: str -> len - pos
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 - VAR3
  ORIGINAL[5]: str -> len
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: len
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: count
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: pos
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: str
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771826
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i++
  TYPE[0]: CALL
  TOKENIZED[0]: i++
  ORIGINAL[1]: apr_fnmatch(this_pattern,str,0) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , 0 ) == 0
  ORIGINAL[2]: for (i = 0;i < list -> nelts;i++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771746
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare((str1 -> data),(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str1 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771469
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771347
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_string_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477035
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str1 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772020
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *svn_err__temp = svn_cstring_strtoi64(&val,str,(- 2147483647 - 1),2147483647,10)
  TYPE[0]: CALL
  TOKENIZED[0]: *svn_err__temp = FUN1 ( &val , VAR1 , ( - 2147483647 - 1 ) , 2147483647 , 10 )
  ORIGINAL[1]: svn_cstring_strtoi64(&val,str,(- 2147483647 - 1),2147483647,10)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &val , VAR1 , ( - 2147483647 - 1 ) , 2147483647 , 10 )
  ORIGINAL[2]: svn_err__temp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: svn_err__temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771312
FRAGMENT_COUNT: 5
  ORIGINAL[0]: new_string = (apr_palloc(pool,sizeof(( *new_string))))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( FUN1 ( VAR2 , sizeof ( ( *new_string ) ) ) )
  ORIGINAL[1]: apr_palloc(pool,sizeof(( *new_string)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , sizeof ( ( *new_string ) ) )
  ORIGINAL[2]: sizeof(( *new_string))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *new_string ) )
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771442
FRAGMENT_COUNT: 6
  ORIGINAL[0]: memset((str -> data),c,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: len
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477067
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_create_ensure(size,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: size
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477539
FRAGMENT_COUNT: 7
  ORIGINAL[0]: a = ( *(str1++))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( * ( str1++ ) )
  ORIGINAL[1]: b = ( *(str2++))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( * ( str2++ ) )
  ORIGINAL[2]: *(str2++)
  TYPE[2]: CALL
  TOKENIZED[2]: * ( str2++ )
  ORIGINAL[3]: cmp || !a || !b
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 || !a || !b
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str2
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: b
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771750
FRAGMENT_COUNT: 4
  ORIGINAL[0]: string_first_non_whitespace((str -> data),str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771374
FRAGMENT_COUNT: 5
  ORIGINAL[0]: find_char_backward(str -> data,str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ch
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771258
FRAGMENT_COUNT: 4
  ORIGINAL[0]: membuf_ensure(&membuf -> data,&membuf -> size,size,membuf -> pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 -> VAR4 )
  ORIGINAL[1]: &membuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: &membuf -> VAR1
  ORIGINAL[2]: membuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771400
FRAGMENT_COUNT: 5
  ORIGINAL[0]: new_string -> blocksize = blocksize - sizeof(( *new_string))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2 - sizeof ( ( *new_string ) )
  ORIGINAL[1]: new_string -> blocksize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: blocksize - sizeof(( *new_string))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - sizeof ( ( *new_string ) )
  ORIGINAL[3]: sizeof(( *new_string))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *new_string ) )
  ORIGINAL[4]: blocksize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771450
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> len = amt
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: amt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771359
FRAGMENT_COUNT: 2
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 68719476919
FRAGMENT_COUNT: 6
  ORIGINAL[0]: membuf_create(&membuf -> data,&membuf -> size,size,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 )
  ORIGINAL[1]: membuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: membuf -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf -> pool
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pool
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: membuf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771716
FRAGMENT_COUNT: 17
  ORIGINAL[0]: bytes + new_count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: old_count < new_count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: delta = new_count - old_count
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 - VAR3
  ORIGINAL[3]: new_count - old_count
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - VAR2
  ORIGINAL[4]: svn_stringbuf_ensure(str,str -> len + delta)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR1 -> VAR2 + VAR3 )
  ORIGINAL[5]: str -> len + delta
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 + VAR3
  ORIGINAL[6]: str -> len
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: len
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: old_count
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new_count
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: delta
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: new_count
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: old_count
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: str
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: str
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: delta
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: old_count
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 68719477158
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> blocksize > old_len + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 + 1
  ORIGINAL[1]: old_len + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + 1
  ORIGINAL[2]: old_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: dest
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old_len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477104
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_stringbuf_createv(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: fmt
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: fmt
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ap
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771973
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoui64(n,str,0,18446744073709551615UL,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 , 18446744073709551615UL , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771781
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare(str1 -> data,(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str2 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477080
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771912
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < strings -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: *string = ((const char **)(strings -> elts))[i]
  TYPE[1]: CALL
  TOKENIZED[1]: *string = ( ( const char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[2]: ((const char **)(strings -> elts))[i]
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( const char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[3]: string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477718
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_string__similarity((&stringa),(&stringb),buffer,rlcs)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( &stringa ) , ( &stringb ) , VAR1 , VAR2 )
  ORIGINAL[1]: &stringb
  TYPE[1]: CALL
  TOKENIZED[1]: &stringb
  ORIGINAL[2]: buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rlcs
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640377
FRAGMENT_COUNT: 2
  ORIGINAL[0]: number >= 100000000
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 100000000
  ORIGINAL[1]: while (number >= 100000000)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: while ( VAR1 >= 100000000 )

CENTER_NODE: 30064771431
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_string -> blocksize = size + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3 + 1
  ORIGINAL[1]: new_string -> blocksize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477603
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoi64(n,str,- 9223372036854775807L - 1,9223372036854775807L,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , - 9223372036854775807L - 1 , 9223372036854775807L , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476972
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: --i
  TYPE[1]: CALL
  TOKENIZED[1]: --i
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771819
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *a = apr_array_make(pool,5,(sizeof(input)))
  TYPE[0]: CALL
  TOKENIZED[0]: *a = FUN1 ( VAR1 , 5 , ( sizeof ( VAR2 ) ) )
  ORIGINAL[1]: apr_array_make(pool,5,(sizeof(input)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 5 , ( sizeof ( VAR2 ) ) )
  ORIGINAL[2]: a
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: a
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477002
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: new_string -> data = data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: new_string -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: new_string -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: len
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_string
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < list -> nelts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: for (i = 0;i < list -> nelts;i++)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )

CENTER_NODE: 68719477665
FRAGMENT_COUNT: 3
  ORIGINAL[0]: number >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: svn__ui64toa(dest,((apr_uint64_t )number))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( VAR2 ) VAR3 ) )
  ORIGINAL[2]: dest
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477034
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_string_ncreate(original_string -> data,original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477015
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_string_ncreate((strbuf -> data),strbuf -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: strbuf -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476990
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: new_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_string -> len = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = 0
  ORIGINAL[3]: new_string -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: new_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771858
FRAGMENT_COUNT: 7
  ORIGINAL[0]: sep == ((void *)0) || str == ((void *)0) ||  *str == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 ) || *str == ( ( void * ) 0 )
  ORIGINAL[1]: csep == '\\0' || sep[1] != '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '\\0' || VAR2 [ 1 ] != '\\0'
  ORIGINAL[2]: csep == '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == '\\0'
  ORIGINAL[3]: sep[1] != '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ 1 ] != '\\0'
  ORIGINAL[4]: sep[1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ 1 ]
  ORIGINAL[5]: csep
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: sep
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477599
FRAGMENT_COUNT: 8
  ORIGINAL[0]: *__errno_location() == 34 && (val == - 9223372036854775807L - 1 || val == 9223372036854775807L) || val < minval || val > maxval
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 34 && ( VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L ) || VAR1 < VAR2 || VAR1 > VAR3
  ORIGINAL[1]: svn_error_createf(SVN_ERR_INCORRECT_PARAMS,((void *)0),\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( void * ) 0 ) , \
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: maxval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: SVN_ERR_INCORRECT_PARAMS
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: minval
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: maxval
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771776
FRAGMENT_COUNT: 4
  ORIGINAL[0]: find_char_backward((str -> data),str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ch
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771775
FRAGMENT_COUNT: 7
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> data[str -> len]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR1 -> VAR3 ]
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: len
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476894
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *size = minimum_size
  TYPE[0]: CALL
  TOKENIZED[0]: *size = VAR1
  ORIGINAL[1]: *size
  TYPE[1]: CALL
  TOKENIZED[1]: *size
  ORIGINAL[2]: minimum_size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: minimum_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: minimum_size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771808
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *(++e) = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: * ( ++e ) = '\\0'
  ORIGINAL[1]: *(++e)
  TYPE[1]: CALL
  TOKENIZED[1]: * ( ++e )
  ORIGINAL[2]: ++e
  TYPE[2]: CALL
  TOKENIZED[2]: ++e
  ORIGINAL[3]: chop_whitespace
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772128
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ui64toa_sep(number,seperator,buffer)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: number
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: seperator
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640368
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476745
FRAGMENT_COUNT: 5
  ORIGINAL[0]: getopt(argc, argv, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: argc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: argv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 3
  ORIGINAL[0]: _s_z_ = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: _s_z_
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771452
FRAGMENT_COUNT: 6
  ORIGINAL[0]: str -> len > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476956
FRAGMENT_COUNT: 5
  ORIGINAL[0]: len1 != len2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: memcmp(str1,str2,len1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: str1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: len1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477514
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *p) == 10
  TYPE[0]: CALL
  TOKENIZED[0]: ( *p ) == 10
  ORIGINAL[1]: *p
  TYPE[1]: CALL
  TOKENIZED[1]: *p
  ORIGINAL[2]: *p
  TYPE[2]: CALL
  TOKENIZED[2]: *p
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477284
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,(appendstr -> data),appendstr -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 -> VAR4 )
  ORIGINAL[1]: targetstr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: appendstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477124
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: nbytes
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477703
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: (apr_uint64_t )number
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: number
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: number
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477188
FRAGMENT_COUNT: 5
  ORIGINAL[0]: matless_untruism != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: toddy_stereomonoscope + 5
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + 5
  ORIGINAL[2]: toddy_stereomonoscope
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: miru_otocephaly
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: toddy_stereomonoscope
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771482
FRAGMENT_COUNT: 6
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: memcpy(mem,(str -> data),str -> len + 1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 -> VAR4 + 1 )
  ORIGINAL[2]: str -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> len + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 + 1
  ORIGINAL[4]: mem
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771200
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sscanf(stonesoup_envKey, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , \
  ORIGINAL[1]: (stonesoup_shmid = shmget(stonesoup_key, stonesoup_shmsz, 0666)) >= 0
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 = FUN1 ( VAR2 , VAR3 , 0666 ) ) >= 0
  ORIGINAL[2]: stonesoup_shmid = shmget(stonesoup_key, stonesoup_shmsz, 0666)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR2 , VAR3 , 0666 )
  ORIGINAL[3]: shmget(stonesoup_key, stonesoup_shmsz, 0666)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , 0666 )
  ORIGINAL[4]: stonesoup_shmid
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476925
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *const old_data = (membuf -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: *const VAR1 = ( VAR2 -> VAR3 )
  ORIGINAL[1]: membuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: old_data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: membuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old_data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771415
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476805
FRAGMENT_COUNT: 4
  ORIGINAL[0]: * ss_tc_root = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: * VAR1 = VAR2
  ORIGINAL[1]: * dirpath = NULL
  TYPE[1]: CALL
  TOKENIZED[1]: * VAR1 = VAR2
  ORIGINAL[2]: dirpath
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640364
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771741
FRAGMENT_COUNT: 5
  ORIGINAL[0]: svn_stringbuf_ncreate((original_string -> data),original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: original_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: original_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771249
FRAGMENT_COUNT: 6
  ORIGINAL[0]: minimum_size >  *size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > *size
  ORIGINAL[1]: membuf_create(data,size,new_size,pool)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pool
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i++
  TYPE[1]: CALL
  TOKENIZED[1]: i++
  ORIGINAL[2]: !(0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002))
  TYPE[2]: CALL
  TOKENIZED[2]: ! ( 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 ) )
  ORIGINAL[3]: 0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002)
  TYPE[3]: CALL
  TOKENIZED[3]: 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 )
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477577
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_err__temp
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: svn_err__temp
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: svn_err__temp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771369
FRAGMENT_COUNT: 3
  ORIGINAL[0]: string_first_non_whitespace(str -> data,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 68719477044
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: strbuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477565
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *__errno_location() == 34 && (val == - 9223372036854775807L - 1 || val == 9223372036854775807L) || val < 0 || ((apr_uint64_t )val) < minval || ((apr_uint64_t )val) > maxval
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 34 && ( VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L ) || VAR1 < 0 || ( ( VAR2 ) VAR1 ) < VAR3 || ( ( VAR2 ) VAR1 ) > VAR4
  ORIGINAL[1]: svn_error_createf(SVN_ERR_INCORRECT_PARAMS,((void *)0),\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( void * ) 0 ) , \
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: SVN_ERR_INCORRECT_PARAMS
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: minval
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: maxval
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771282
FRAGMENT_COUNT: 6
  ORIGINAL[0]: memset(_m_b_f_ -> data,0,_m_b_f_ -> size)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , 0 , VAR1 -> VAR3 )
  ORIGINAL[1]: _m_b_f_ -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: _m_b_f_ -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _m_b_f_
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: _m_b_f_
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477045
FRAGMENT_COUNT: 2
  ORIGINAL[0]: svn_stringbuf_create_ensure(0,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064772115
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i > 3
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 3
  ORIGINAL[1]: &buffer[i - 3]
  TYPE[1]: CALL
  TOKENIZED[1]: &buffer [ VAR1 - 3 ]
  ORIGINAL[2]: buffer[i - 3]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 - 3 ]
  ORIGINAL[3]: i - 3
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 3
  ORIGINAL[4]: buffer[i - 3]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 - 3 ]
  ORIGINAL[5]: buffer
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: buffer
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: buffer
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477023
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __builtin_va_start(ap,fmt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: ap
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fmt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477020
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *data = apr_pvsprintf(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: *data = FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: create_string(data,strlen(data),pool)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477287
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,cstr,strlen(cstr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[1]: targetstr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477775
FRAGMENT_COUNT: 5
  ORIGINAL[0]: resta < restb
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: pstr = stra
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: pstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stra
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pstr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

