# Tokenized code fragments for 153368-v1.0.0-bad
# Total center nodes processed: 25
# Total code fragments found: 150

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477241
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 8 == 1
  TYPE[0]: CALL
  TOKENIZED[0]: 8 == 1
  ORIGINAL[1]: ctx -> flags
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ctx -> iv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ctx -> num
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: ctx -> encrypt
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: flags
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ctx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477119
FRAGMENT_COUNT: 10
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: Camellia_cfb1_encrypt(in,out,((long )(1 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num,ctx -> encrypt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( 1 == 1 && ! ( VAR3 -> VAR4 & 0x2000 ) ?inl * 8 : VAR5 ) ) , ( & ( ( VAR6 * ) ( VAR3 -> VAR7 ) ) -> VAR8 ) , VAR3 -> VAR9 , &ctx -> VAR10 , VAR3 -> VAR11 )
  ORIGINAL[2]: (long )(1 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( 1 == 1 && ! ( VAR1 -> VAR2 & 0x2000 ) ?inl * 8 : VAR3 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ctx -> iv
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: &ctx -> VAR1
  ORIGINAL[6]: ctx -> encrypt
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: in
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: out
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: in
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477045
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl < bl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i <= inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= VAR2
  ORIGINAL[2]: inl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: inl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771736
FRAGMENT_COUNT: 8
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: 8 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl
  TYPE[1]: CALL
  TOKENIZED[1]: 8 == 1 && ! ( VAR1 -> VAR2 & 0x2000 ) ?inl * 8 : VAR3
  ORIGINAL[2]: 8 == 1 && !(ctx -> flags & 0x2000)
  TYPE[2]: CALL
  TOKENIZED[2]: 8 == 1 && ! ( VAR1 -> VAR2 & 0x2000 )
  ORIGINAL[3]: 8 == 1
  TYPE[3]: CALL
  TOKENIZED[3]: 8 == 1
  ORIGINAL[4]: !(ctx -> flags & 0x2000)
  TYPE[4]: CALL
  TOKENIZED[4]: ! ( VAR1 -> VAR2 & 0x2000 )
  ORIGINAL[5]: inl * 8
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 * 8
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: inl
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771562
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: out += ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[3]: inl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: out
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771403
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: sizeof(long ) * 8
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( long ) * 8

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 4
  ORIGINAL[0]: asymptotic_minuscular != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: miswriting_encoil(asymptotic_minuscular)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: asymptotic_minuscular
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> camellia_192_cbc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8 - 2
  ORIGINAL[2]: sizeof(long ) * 8
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) * 8
  ORIGINAL[3]: sizeof(long )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long )

CENTER_NODE: 68719477086
FRAGMENT_COUNT: 15
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: inl && inl >= chunk
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 && VAR1 >= VAR2
  ORIGINAL[3]: inl >= chunk
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= VAR2
  ORIGINAL[4]: inl < chunk
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < VAR2
  ORIGINAL[5]: chunk = inl
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = VAR2
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: inl
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: inl
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: inl
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: chunk
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: inl
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: inl
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: inl
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: inl
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064771302
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8 - 2
  ORIGINAL[2]: sizeof(long ) * 8
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) * 8
  ORIGINAL[3]: sizeof(long )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long )

CENTER_NODE: 30064771652
FRAGMENT_COUNT: 5
  ORIGINAL[0]: chunk = ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771439
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8 - 2
  ORIGINAL[2]: sizeof(long ) * 8
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) * 8
  ORIGINAL[3]: sizeof(long )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long )

CENTER_NODE: 30064771210
FRAGMENT_COUNT: 8
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: inl < chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: chunk = inl
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: inl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: inl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chunk
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: inl
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771796
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ret < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: ERR_put_error(6,159,157,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( 6 , 159 , 157 , \
  ORIGINAL[2]: ret
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771827
FRAGMENT_COUNT: 7
  ORIGINAL[0]: stonesoup_file_desc > -1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > -1
  ORIGINAL[1]: tracepoint(stonesoup_trace, variable_signed_integral, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: stonesoup_buffer[127]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 127 ]
  ORIGINAL[3]: &(stonesoup_buffer[127])
  TYPE[3]: CALL
  TOKENIZED[3]: & ( VAR1 [ 127 ] )
  ORIGINAL[4]: stonesoup_trace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: variable_signed_integral
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_oc_i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771345
FRAGMENT_COUNT: 11
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: Camellia_cfb128_encrypt(in,out,((long )(128 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num,ctx -> encrypt)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( 128 == 1 && ! ( VAR3 -> VAR4 & 0x2000 ) ?inl * 8 : VAR5 ) ) , ( & ( ( VAR6 * ) ( VAR3 -> VAR7 ) ) -> VAR8 ) , VAR3 -> VAR9 , &ctx -> VAR10 , VAR3 -> VAR11 )
  ORIGINAL[2]: (long )(128 == 1 && !(ctx -> flags & 0x2000)?inl * 8 : inl)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( 128 == 1 && ! ( VAR1 -> VAR2 & 0x2000 ) ?inl * 8 : VAR3 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[5]: ctx -> iv
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &ctx -> num
  TYPE[6]: CALL
  TOKENIZED[6]: &ctx -> VAR1
  ORIGINAL[7]: ctx -> encrypt
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: in
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: out
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: ctx
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771511
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: out += chunk
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: out
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: inl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476945
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl < bl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: inl -= bl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -= VAR2
  ORIGINAL[2]: i = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476764
FRAGMENT_COUNT: 6
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: size_filepath = strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: strlen(dirpath) + strlen(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[3]: size_filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size_filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771799
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ++stonesoup_global_variable
  TYPE[0]: CALL
  TOKENIZED[0]: ++stonesoup_global_variable
  ORIGINAL[1]: <global> stonesoup_global_variable
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: upmix_unsatiableness
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i <= inl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= VAR2
  ORIGINAL[1]: out + i
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: out
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477175
FRAGMENT_COUNT: 7
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: inl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: inl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: inl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771933
FRAGMENT_COUNT: 4
  ORIGINAL[0]: {(760), (1), (128 / 8), (16), ((0 | 0x3)), (camellia_init_key), (camellia_128_cfb1_cipher), (((void *)0)), ((sizeof(EVP_CAMELLIA_KEY ))), (EVP_CIPHER_set_asn1_iv), (EVP_CIPHER_get_asn1_iv), (((void *)0)), ((void *)0)}
  TYPE[0]: CALL
  TOKENIZED[0]: { ( 760 ) , ( 1 ) , ( 128 / 8 ) , ( 16 ) , ( ( 0 | 0x3 ) ) , ( VAR1 ) , ( VAR2 ) , ( ( ( void * ) 0 ) ) , ( ( sizeof ( VAR3 ) ) ) , ( VAR4 ) , ( VAR5 ) , ( ( ( void * ) 0 ) ) , ( ( void * ) 0 ) }
  ORIGINAL[1]: sizeof(EVP_CAMELLIA_KEY )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: EVP_CAMELLIA_KEY
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: EVP_CIPHER_set_asn1_iv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476875
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: (size_t )1
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) 1
  ORIGINAL[2]: sizeof(long )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long )
  ORIGINAL[3]: long
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: long

