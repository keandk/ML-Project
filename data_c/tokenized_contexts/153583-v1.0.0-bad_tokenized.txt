# Tokenized code fragments for 153583-v1.0.0-bad
# Total center nodes processed: 37
# Total code fragments found: 170

CENTER_NODE: 30064771537
FRAGMENT_COUNT: 3
  ORIGINAL[0]: cleanup_stream_hash()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: cleanup_fragment_hash()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: stream_cleanup_pdu_data()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 47244640304
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477044
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *key = (const fragment_key_t *)k
  TYPE[0]: CALL
  TOKENIZED[0]: *key = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const fragment_key_t *)k
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key -> stream
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key -> framenum
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: key -> offset
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476994
FRAGMENT_COUNT: 5
  ORIGINAL[0]: key . is_circuit = !0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = !0
  ORIGINAL[1]: key . is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: key . circ
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: circ
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771289
FRAGMENT_COUNT: 5
  ORIGINAL[0]: kabalevsky_greenbackism != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: coeternal_montessorian = ((char *)(malloc(getters_shifter + 1)))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( char * ) ( FUN1 ( VAR2 + 1 ) ) )
  ORIGINAL[2]: (char *)(malloc(getters_shifter + 1))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char * ) ( FUN1 ( VAR1 + 1 ) )
  ORIGINAL[3]: coeternal_montessorian
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: coeternal_montessorian
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 1
  ORIGINAL[0]: fragment_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )

CENTER_NODE: 68719477086
FRAGMENT_COUNT: 9
  ORIGINAL[0]: key -> offset = offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: val = (se_alloc(sizeof(stream_pdu_fragment_t )))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( sizeof ( VAR2 ) ) )
  ORIGINAL[2]: se_alloc(sizeof(stream_pdu_fragment_t ))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stream_pdu_fragment_t
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: val
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: val
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *key = (const stream_key_t *)k
  TYPE[0]: CALL
  TOKENIZED[0]: *key = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const stream_key_t *)k
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: k
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771519
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream = stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p2p_dir
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477115
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: conv
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771546
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash_lookup(stream,framenum,offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: framenum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477180
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (void )(frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: ( void ) ( frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: frag -> pdu
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: frag
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: frag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640308
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771228
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 8 ]

CENTER_NODE: 68719477035
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pdu_counter = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> pdu_counter
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 68719477168
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pdu -> fd_head != ((void *)0) && fit -> hf_reassembled_in != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != ( ( void * ) 0 ) && VAR3 -> VAR4 != ( ( void * ) 0 )
  ORIGINAL[1]: pdu -> fd_head
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu -> fd_head
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: fd_head
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pdu
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pdu
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476911
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: g_hash_table_destroy(stream_hash)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: stream_hash = ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: <global> stream_hash
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 68719476862
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *stonesoup_tainted_buff = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff = VAR1
  ORIGINAL[1]: *stonesoup_tainted_buff
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: NULL
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477068
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key . stream
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: stream
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771416
FRAGMENT_COUNT: 5
  ORIGINAL[0]: key -> circ . conv = conv
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 . VAR3 = VAR3
  ORIGINAL[1]: key -> circ . conv
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 . VAR3
  ORIGINAL[2]: key -> circ
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: conv
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: conv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477036
FRAGMENT_COUNT: 8
  ORIGINAL[0]: pdu = (se_alloc(sizeof(stream_pdu_t )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( FUN1 ( sizeof ( VAR2 ) ) )
  ORIGINAL[1]: se_alloc(sizeof(stream_pdu_t ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[2]: pdu
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream_pdu_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pdu
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pdu
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pdu
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pdu
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771472
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash = g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 6
  ORIGINAL[0]: key1 -> is_circuit
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key1 -> circ . conv == key2 -> circ . conv
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 . VAR3 == VAR4 -> VAR2 . VAR3
  ORIGINAL[2]: key1 -> circ . conv
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 . VAR3
  ORIGINAL[3]: key2 -> circ . conv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 . VAR3
  ORIGINAL[4]: key2 -> circ
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: conv
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771502
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream = stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640262
FRAGMENT_COUNT: 4
  ORIGINAL[0]: out_filename = optarg
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: break;
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: break ;
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771387
FRAGMENT_COUNT: 11
  ORIGINAL[0]: val -> key = key
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: val -> key
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: val
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: val
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: val
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: val
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771227
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c - 32
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 32
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476992
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash = g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771399
FRAGMENT_COUNT: 4
  ORIGINAL[0]: key = (se_alloc(sizeof(stream_key_t )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( FUN1 ( sizeof ( VAR2 ) ) )
  ORIGINAL[1]: se_alloc(sizeof(stream_key_t ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[2]: sizeof(stream_key_t )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771468
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: g_assertion_message_expr(((gchar *)0),\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( VAR1 * ) 0 ) , \
  ORIGINAL[2]: (gchar *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 * ) 0
  ORIGINAL[3]: (const char *)__func__
  TYPE[3]: CALL
  TOKENIZED[3]: ( const char * ) VAR1

CENTER_NODE: 68719476826
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: &st
  TYPE[1]: CALL
  TOKENIZED[1]: &st
  ORIGINAL[2]: st
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: dirpath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: st
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477113
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: circuit
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771662
FRAGMENT_COUNT: 8
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: abort()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )
  ORIGINAL[5]: except_throw(1,4,(ep_strdup_printf(\
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( 1 , 4 , ( FUN2 ( \
  ORIGINAL[6]: ep_strdup_printf(\
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( \
  ORIGINAL[7]: frag
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477052
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *key1 = (const fragment_key_t *)a
  TYPE[0]: CALL
  TOKENIZED[0]: *key1 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const fragment_key_t *)a
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key1 -> stream
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key1 -> framenum
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: key1 -> offset
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: key1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477178
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (void )(frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: ( void ) ( frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: frag -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: frag
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: frag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477139
FRAGMENT_COUNT: 9
  ORIGINAL[0]: fragment_add_seq_next(tvb,0,pinfo,pdu -> id,stream_fragment_table,stream_reassembled_table,tvb_reported_length(tvb),more_frags)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , VAR2 , VAR3 -> VAR4 , VAR5 , VAR6 , FUN2 ( VAR1 ) , VAR7 )
  ORIGINAL[1]: pdu -> id
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: tvb_reported_length(tvb)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pinfo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> stream_fragment_table
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> stream_reassembled_table
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: tvb
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: more_frags
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771380
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (stream_t *)(g_hash_table_lookup(stream_hash,(&key)))
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 * ) ( FUN1 ( VAR2 , ( &key ) ) )
  ORIGINAL[1]: g_hash_table_lookup(stream_hash,(&key))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( &key ) )

