# Tokenized code fragments for 153784-v1.0.0-bad
# Total center nodes processed: 144
# Total code fragments found: 443

CENTER_NODE: 68719477841
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok >= 0 && tok < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0 && VAR1 < ( 1 << 8 )
  ORIGINAL[1]: tok >= CSET
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= VAR2
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: CSET
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771232
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: (1 << 8) + 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[2]: 1 << 8
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << 8

CENTER_NODE: 47244640292
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640836
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480177
FRAGMENT_COUNT: 2
  ORIGINAL[0]: {(\
  TYPE[0]: CALL
  TOKENIZED[0]: { ( \
  ORIGINAL[1]: isblank
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640398
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773067
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: branch()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640390
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640295
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640756
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640979
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479722
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *cp
  TYPE[0]: CALL
  TOKENIZED[0]: *cp
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: (char *)cp
  TYPE[2]: CALL
  TOKENIZED[2]: ( char * ) VAR1
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640400
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773305
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: p . index == s -> elems[i] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2 == VAR3 -> VAR4 [ VAR5 ] . VAR2
  ORIGINAL[3]: s -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: nelem
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771774
FRAGMENT_COUNT: 4
  ORIGINAL[0]: gettext(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: lasttok = END
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: <global> lasttok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: END
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640311
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476913
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc == '_'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == '_'
  ORIGINAL[1]: iswalnum(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: wc
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477898
FRAGMENT_COUNT: 17
  ORIGINAL[0]: atom()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: tok == QMARK || tok == STAR || tok == PLUS || tok == REPMN
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[2]: tok == QMARK
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: tok == REPMN && (minrep || maxrep)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[4]: tok = lex()
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( )
  ORIGINAL[5]: tok == REPMN
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2
  ORIGINAL[6]: closure()
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( )
  ORIGINAL[7]: tok = lex()
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = FUN1 ( )
  ORIGINAL[8]: <global> tok
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: QMARK
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> tok
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> tok
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> tok
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> tok
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> tok
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> tok
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> tok
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1

CENTER_NODE: 68719476751
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ss_tc_root != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: size_dirpath = strlen(ss_tc_root) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: dirpath = (char*) malloc (size_dirpath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[3]: (char*) malloc (size_dirpath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dirpath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479857
FRAGMENT_COUNT: 3
  ORIGINAL[0]: mp -> left
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: left
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: mp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772868
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: dfa -> mbcsets[dfa -> nmbcsets - 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[2]: dfa -> nmbcsets - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 - 1
  ORIGINAL[3]: dfa -> nmbcsets
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640268
FRAGMENT_COUNT: 1
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640624
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476825
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064775855
FRAGMENT_COUNT: 5
  ORIGINAL[0]: rcp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: i = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: for (i = 1;lcp[i] != '\\0' && lcp[i] == rcp[i];++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 1 ; VAR2 [ VAR1 ] != '\\0' && VAR2 [ VAR1 ] == VAR3 [ VAR1 ] ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lcp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640563
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064775534
FRAGMENT_COUNT: 27
  ORIGINAL[0]: p[- 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ - 1 ]
  ORIGINAL[1]: s >= 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0
  ORIGINAL[2]: p[- 1] == eol
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ - 1 ] == VAR2
  ORIGINAL[3]: p[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 1 ]
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: p
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: p
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: p
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: p
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: p
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: p
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: p
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: p
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: p
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: p
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: p
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: p
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: eol
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477569
FRAGMENT_COUNT: 4
  ORIGINAL[0]: backslash && !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && ! ( VAR2 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: lasttok = ENDWORD
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: <global> lasttok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: ENDWORD
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640809
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < work_mbc -> nchars
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: for (i = 0;i < work_mbc -> nchars;i++)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )

CENTER_NODE: 47244640278
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < (1 << 8)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( 1 << 8 )
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: for (i = 0;i < (1 << 8);++i)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )

CENTER_NODE: 47244640441
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477999
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s -> alloc = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: s -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776382
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640883
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773502
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> tokens[s -> elems[j] . index] == BACKREF
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] == VAR7
  ORIGINAL[1]: d -> states[i] . backref = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 = 1
  ORIGINAL[2]: d -> states[i] . backref
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479727
FRAGMENT_COUNT: 8
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: cpp[i] = ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476866
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771339
FRAGMENT_COUNT: 5
  ORIGINAL[0]: setbit_c((( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)),c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN2 ( VAR1 ) ) , VAR3 )
  ORIGINAL[1]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)
  TYPE[1]: CALL
  TOKENIZED[1]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[2]: ( *__ctype_b_loc())[(int )b]
  TYPE[2]: CALL
  TOKENIZED[2]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[3]: (unsigned short )_ISupper
  TYPE[3]: CALL
  TOKENIZED[3]: ( unsigned short ) VAR1
  ORIGINAL[4]: _ISupper
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477889
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tokens
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640420
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773626
FRAGMENT_COUNT: 10
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: c[j] & ~(letters[j] | newline[j])
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] & ~ ( VAR3 [ VAR2 ] | VAR4 [ VAR2 ] )
  ORIGINAL[3]: c[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: ~(letters[j] | newline[j])
  TYPE[4]: CALL
  TOKENIZED[4]: ~ ( VAR1 [ VAR2 ] | VAR3 [ VAR2 ] )
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: c
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: c
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: j
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: <global> letters
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1

CENTER_NODE: 30064771343
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774885
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> newlines = (xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[2]: d -> newlines
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )

CENTER_NODE: 30064773100
FRAGMENT_COUNT: 33
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: src -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: new_n_alloc = src -> nelem + (!dst -> elems)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2 -> VAR3 + ( !dst -> VAR4 )
  ORIGINAL[4]: src -> nelem + (!dst -> elems)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 + ( !dst -> VAR3 )
  ORIGINAL[5]: src -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: !dst -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: !dst -> VAR1
  ORIGINAL[7]: dst -> elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: dst -> elems = (x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems))))
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) ) )
  ORIGINAL[9]: dst -> elems
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: x2nrealloc((dst -> elems),&new_n_alloc,sizeof(( *dst -> elems)))
  TYPE[10]: CALL
  TOKENIZED[10]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dst -> VAR2 ) ) )
  ORIGINAL[11]: dst -> elems
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: &new_n_alloc
  TYPE[12]: CALL
  TOKENIZED[12]: &new_n_alloc
  ORIGINAL[13]: sizeof(( *dst -> elems))
  TYPE[13]: CALL
  TOKENIZED[13]: sizeof ( ( *dst -> VAR1 ) )
  ORIGINAL[14]: *dst -> elems
  TYPE[14]: CALL
  TOKENIZED[14]: *dst -> VAR1
  ORIGINAL[15]: dst -> elems
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2
  ORIGINAL[16]: dst -> alloc = new_n_alloc
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2 = VAR3
  ORIGINAL[17]: dst -> alloc
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: nelem
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: elems
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: elems
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: elems
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: elems
  TYPE[22]: FIELD_IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: alloc
  TYPE[23]: FIELD_IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: new_n_alloc
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: src
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: dst
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: dst
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: dst
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: new_n_alloc
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: dst
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: dst
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: new_n_alloc
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1

CENTER_NODE: 47244640408
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640431
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640599
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771213
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775191
FRAGMENT_COUNT: 5
  ORIGINAL[0]: k <  *mbclen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < *mbclen
  ORIGINAL[1]: rs = transit_state_singlebyte(d,s2,( *pp)++,&s1)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , ( *pp ) ++ , &s1 )
  ORIGINAL[2]: transit_state_singlebyte(d,s2,( *pp)++,&s1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , ( *pp ) ++ , &s1 )
  ORIGINAL[3]: k
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: rs
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771182
FRAGMENT_COUNT: 3
  ORIGINAL[0]: QMARK=264
  TYPE[0]: CALL
  TOKENIZED[0]: QMARK=264
  ORIGINAL[1]: QMARK
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: STAR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719478063
FRAGMENT_COUNT: 7
  ORIGINAL[0]: m -> alloc <= s1 -> nelem + s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4 + VAR5 -> VAR4
  ORIGINAL[1]: m -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: m -> elems = (x2nrealloc((m -> elems),&new_n_alloc,sizeof(( *m -> elems))))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *m -> VAR2 ) ) ) )
  ORIGINAL[3]: m -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: m -> alloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: alloc
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: m
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064774385
FRAGMENT_COUNT: 20
  ORIGINAL[0]: d -> searchflag
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: &follows
  TYPE[1]: CALL
  TOKENIZED[1]: &follows
  ORIGINAL[2]: state_index(d,(&follows),separate_contexts ^ 7)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( &follows ) , VAR2 ^ 7 )
  ORIGINAL[3]: &follows
  TYPE[3]: CALL
  TOKENIZED[3]: &follows
  ORIGINAL[4]: &follows
  TYPE[4]: CALL
  TOKENIZED[4]: &follows
  ORIGINAL[5]: &follows
  TYPE[5]: CALL
  TOKENIZED[5]: &follows
  ORIGINAL[6]: &follows
  TYPE[6]: CALL
  TOKENIZED[6]: &follows
  ORIGINAL[7]: &follows
  TYPE[7]: CALL
  TOKENIZED[7]: &follows
  ORIGINAL[8]: &follows
  TYPE[8]: CALL
  TOKENIZED[8]: &follows
  ORIGINAL[9]: follows
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: separate_contexts
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: follows
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: follows
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: follows
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: follows
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: follows
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: follows
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: follows
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: follows
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: follows
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478038
FRAGMENT_COUNT: 6
  ORIGINAL[0]: lo < count && p . index == s -> elems[lo] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 . VAR4 == VAR5 -> VAR6 [ VAR1 ] . VAR4
  ORIGINAL[1]: i = count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: count
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771194
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 68719479026
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> trcount
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> trans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> realtrans
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> fails
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: sizeof(( *d -> fails)) == 1
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[7]: d -> tralloc
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: d -> tralloc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: tralloc
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640380
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773632
FRAGMENT_COUNT: 3
  ORIGINAL[0]: separate_contexts = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: separate_contexts
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640901
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774976
FRAGMENT_COUNT: 11
  ORIGINAL[0]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: wc == ((wchar_t )'\\0')
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: context & 2?pos . constraint >> 4 & 0xf : 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0
  ORIGINAL[4]: context & 2
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 & 2
  ORIGINAL[5]: pos . constraint >> 4 & 0xf
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2 >> 4 & 0xf
  ORIGINAL[6]: pos . constraint >> 4
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . VAR2 >> 4
  ORIGINAL[7]: pos . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . VAR2
  ORIGINAL[8]: constraint
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: context
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: pos
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719476808
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stonesoup_tainted_file != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: sizeof(char )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( char )
  ORIGINAL[2]: char
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: char

CENTER_NODE: 68719476854
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( int )
  ORIGINAL[1]: int
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: int

CENTER_NODE: 68719479764
FRAGMENT_COUNT: 13
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[j] != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[2]: istrstr(new,cpp[j]) == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] ) == ( ( void * ) 0 )
  ORIGINAL[3]: --i == j
  TYPE[3]: CALL
  TOKENIZED[3]: --i == VAR1
  ORIGINAL[4]: cpp = (xnrealloc(cpp,i + 2,sizeof(( *cpp))))
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = ( FUN1 ( VAR1 , VAR2 + 2 , sizeof ( ( *cpp ) ) ) )
  ORIGINAL[5]: xnrealloc(cpp,i + 2,sizeof(( *cpp)))
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 + 2 , sizeof ( ( *cpp ) ) )
  ORIGINAL[6]: break;
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: break ;
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: cpp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: cpp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: cpp
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: cpp
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: cpp
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640592
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640959
FRAGMENT_COUNT: 2
  ORIGINAL[0]: lmp -> left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: goto done;
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: goto VAR1 ;

CENTER_NODE: 47244640343
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776369
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476877
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640714
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640423
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479072
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER=2
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064776383
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064775660
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: !1
  TYPE[1]: CALL
  TOKENIZED[1]: !1
  ORIGINAL[2]: !using_utf8()
  TYPE[2]: CALL
  TOKENIZED[2]: !using_utf8 ( )
  ORIGINAL[3]: using_utf8()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )

CENTER_NODE: 47244640602
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479103
FRAGMENT_COUNT: 3
  ORIGINAL[0]: rval == TRANSIT_STATE_IN_PROGRESS
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: *next_state
  TYPE[1]: CALL
  TOKENIZED[1]: *next_state
  ORIGINAL[2]: next_state
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479580
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> multibyte_prop = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640812
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640544
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771223
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479264
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> tokens[pos . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: match_mb_charset(d,s,pos,idx)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pos
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771266
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: x2nrealloc((dfa -> charclasses),&new_n_alloc,sizeof(( *dfa -> charclasses)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) )
  ORIGINAL[2]: dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: sizeof(( *dfa -> charclasses))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *dfa -> VAR1 ) )
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: new_n_alloc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640355
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640364
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640626
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640710
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477879
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: 1 + ntoks1
  TYPE[1]: CALL
  TOKENIZED[1]: 1 + VAR1
  ORIGINAL[2]: ntoks1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ntoks1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ntoks1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771167
FRAGMENT_COUNT: 1
  ORIGINAL[0]: base_path[20]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 20 ]

CENTER_NODE: 68719477771
FRAGMENT_COUNT: 11
  ORIGINAL[0]: dfa -> nmultibyte_prop
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dfa -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> nmultibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[4]: dfa -> talloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: new_n_alloc = dfa -> tindex + 1 + (!dfa -> tokens)
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = VAR2 -> VAR3 + 1 + ( !dfa -> VAR4 )
  ORIGINAL[6]: dfa -> tindex
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: dfa -> tokens
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: dfa -> tokens
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: tokens
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1

CENTER_NODE: 68719478365
FRAGMENT_COUNT: 6
  ORIGINAL[0]: sizeof(( *nlastpos)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *nlastpos ) ) == 1
  ORIGINAL[1]: *nlastpos
  TYPE[1]: CALL
  TOKENIZED[1]: *nlastpos
  ORIGINAL[2]: d -> depth
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *nlastpos
  TYPE[3]: CALL
  TOKENIZED[3]: *nlastpos
  ORIGINAL[4]: nlastpos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: nlastpos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771197
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: b / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775754
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640313
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479625
FRAGMENT_COUNT: 17
  ORIGINAL[0]: *d
  TYPE[0]: CALL
  TOKENIZED[0]: *d
  ORIGINAL[1]: d -> charclasses
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> calloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> calloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> talloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> talloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> mb_cur_max > 1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 > 1
  ORIGINAL[8]: d -> mb_cur_max
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: d -> nmultibyte_prop = 1
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 = 1
  ORIGINAL[10]: d -> nmultibyte_prop
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: d -> multibyte_prop
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: d -> nmultibyte_prop
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: d -> nmultibyte_prop
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: multibyte_prop
  TYPE[14]: FIELD_IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 30064775898
FRAGMENT_COUNT: 3
  ORIGINAL[0]: left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: left
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640586
FRAGMENT_COUNT: 2
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: while (tok != RPAREN && tok != OR && tok >= 0)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: while ( VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0 )

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640353
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776367
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 68719476908
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum)
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 )
  ORIGINAL[1]: c == '_'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '_'
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775746
FRAGMENT_COUNT: 19
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: result = (xrealloc(old,oldsize + newsize + 1))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 , VAR3 + VAR4 + 1 ) )
  ORIGINAL[2]: xrealloc(old,oldsize + newsize + 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 + VAR3 + 1 )
  ORIGINAL[3]: oldsize + newsize + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + VAR2 + 1
  ORIGINAL[4]: oldsize + newsize
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 + VAR2
  ORIGINAL[5]: memcpy((result + oldsize),new,newsize + 1)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( ( VAR1 + VAR2 ) , VAR3 , VAR4 + 1 )
  ORIGINAL[6]: result + oldsize
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 + VAR2
  ORIGINAL[7]: newsize + 1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 + 1
  ORIGINAL[8]: newsize
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: old
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: result
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: old
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: oldsize
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: newsize
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: result
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: oldsize
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: new
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: newsize
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: result
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 47244640930
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640546
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478249
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index] != ANYCHAR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7
  ORIGINAL[2]: d -> tokens[s -> elems[i] . index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ]
  ORIGINAL[3]: ANYCHAR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479368
FRAGMENT_COUNT: 12
  ORIGINAL[0]: match_lens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: match_lens[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: nelem == 0 || maxlen == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0 || VAR2 == 0
  ORIGINAL[3]: transit_state_consume_1char(d,s,pp,match_lens,&mbclen,&follows)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , &mbclen , &follows )
  ORIGINAL[4]: match_lens[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: match_lens
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: match_lens
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: match_lens
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: mbclen
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: match_lens
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: match_lens
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719477974
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> nregexps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: addtok(OR)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: OR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775882
FRAGMENT_COUNT: 4
  ORIGINAL[0]: old == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: new == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: new
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479647
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfainit(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaparse(s,len,d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064774687
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (((1 & 1?( *d) . states[s] . constraint & 0xf : 0)) | ((1 & 2?( *d) . states[s] . constraint >> 4 & 0xf : 0)) | ((1 & 4?( *d) . states[s] . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( 1 & 1? ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf : 0 ) ) | ( ( 1 & 2? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 4 & 0xf : 0 ) ) | ( ( 1 & 4? ( *d ) . VAR1 [ VAR2 ] . VAR3 >> 8 & 0xf : 0 ) ) ) & VAR4 -> VAR1 [ VAR2 ] . VAR5
  ORIGINAL[1]: d -> success[s] |= 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] |= 1
  ORIGINAL[2]: d -> success[s]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: trans
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640872
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640633
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479691
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ndm = dm -> next
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3
  ORIGINAL[1]: dm -> next
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dm
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ndm
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ndm
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dm
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

