# Tokenized code fragments for 152077-v1.0.0-bad
# Total center nodes processed: 10
# Total code fragments found: 48

CENTER_NODE: 30064771219
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *((const Bitmapset *const *)key2)
  TYPE[0]: CALL
  TOKENIZED[0]: * ( ( const VAR1 *const * ) VAR2 )
  ORIGINAL[1]: (const Bitmapset *const *)key2
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 *const * ) VAR2
  ORIGINAL[2]: key2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771213
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *((const Bitmapset *const *)key)
  TYPE[0]: CALL
  TOKENIZED[0]: * ( ( const VAR1 *const * ) VAR2 )
  ORIGINAL[1]: (const Bitmapset *const *)key
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 *const * ) VAR2
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476833
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (Datum )(hash_any(((const unsigned char *)key),((int )keysize)))
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 ) ( FUN1 ( ( ( const unsigned char * ) VAR2 ) , ( ( int ) VAR3 ) ) )
  ORIGINAL[1]: uint32
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: Datum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476760
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: &st
  TYPE[1]: CALL
  TOKENIZED[1]: &st
  ORIGINAL[2]: st
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: dirpath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: st
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771163
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s_len < keysize - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 - 1
  ORIGINAL[1]: keysize - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: keysize - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: s_len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: keysize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476796
FRAGMENT_COUNT: 9
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: i < size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771200
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tridynamous_cereless != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: (char **)(((unsigned long )menthol_chiavetta) * tactions_pikemen * tactions_pikemen)
  TYPE[1]: CALL
  TOKENIZED[1]: ( char ** ) ( ( ( unsigned long ) VAR1 ) * VAR2 * VAR2 )
  ORIGINAL[2]: ((unsigned long )menthol_chiavetta) * tactions_pikemen * tactions_pikemen
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) VAR1 ) * VAR2 * VAR2
  ORIGINAL[3]: ((unsigned long )menthol_chiavetta) * tactions_pikemen
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) VAR1 ) * VAR2
  ORIGINAL[4]: tactions_pikemen
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771143
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 65 && c <= 90
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 65 && VAR1 <= 90
  ORIGINAL[2]: c >= 65
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= 65
  ORIGINAL[3]: c <= 90
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 <= 90
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476816
FRAGMENT_COUNT: 4
  ORIGINAL[0]: index < size_param
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: str[index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: index
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_str_list_index = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: stonesoup_str_list_index < stonesoup_num_files
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: ++stonesoup_str_list_index
  TYPE[2]: CALL
  TOKENIZED[2]: ++stonesoup_str_list_index
  ORIGINAL[3]: stonesoup_str_list[stonesoup_str_list_index] = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] = 0
  ORIGINAL[4]: for (stonesoup_str_list_index = 0;stonesoup_str_list_index < stonesoup_num_files;++stonesoup_str_list_index)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = 0 ; VAR1 < VAR2 ; ++stonesoup_str_list_index )

