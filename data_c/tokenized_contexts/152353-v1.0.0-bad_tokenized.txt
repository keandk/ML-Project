# Tokenized code fragments for 152353-v1.0.0-bad
# Total center nodes processed: 146
# Total code fragments found: 517

CENTER_NODE: 47244640701
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: j < ngrps
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: ++j
  TYPE[2]: CALL
  TOKENIZED[2]: ++j
  ORIGINAL[3]: for (j = 0;j < ngrps;++j)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 ; ++j )

CENTER_NODE: 30064773048
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: new_n_alloc = src -> nelem + (!dst -> elems)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 + ( !dst -> VAR4 )
  ORIGINAL[2]: src -> nelem + (!dst -> elems)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + ( !dst -> VAR3 )
  ORIGINAL[3]: src -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: !dst -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: !dst -> VAR1
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479676
FRAGMENT_COUNT: 8
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: cpp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640598
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640756
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640310
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773577
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (j = 0;j < s -> nelem;++j)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640563
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640609
FRAGMENT_COUNT: 3
  ORIGINAL[0]: j < s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: m -> elems[m -> nelem++] = s2 -> elems[j++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> nelem++ ] = VAR3 -> VAR2 [ j++ ]
  ORIGINAL[2]: while (j < s2 -> nelem)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: while ( VAR1 < VAR2 -> VAR3 )

CENTER_NODE: 47244640389
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772979
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < minrep
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: copytoks(tindex,ntokens)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: tindex
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ntokens
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: CAT
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477919
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok = lex()
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( )
  ORIGINAL[1]: depth = d -> depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR1
  ORIGINAL[2]: d -> depth
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: <global> depth
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640768
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640872
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773088
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s -> nelem = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ( *__ctype_b_loc())[(int )c]
  TYPE[0]: CALL
  TOKENIZED[0]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ]
  ORIGINAL[1]: (int )c
  TYPE[1]: CALL
  TOKENIZED[1]: ( int ) VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640441
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476812
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( int )
  ORIGINAL[1]: int
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: int

CENTER_NODE: 30064774949
FRAGMENT_COUNT: 28
  ORIGINAL[0]: wc == ((wchar_t )'\\0')
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[1]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: context = wchar_context(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[4]: wchar_context(wc)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[5]: CALL
  TOKENIZED[5]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[6]: (((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[6]: CALL
  TOKENIZED[6]: ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1
  ORIGINAL[7]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))
  TYPE[7]: CALL
  TOKENIZED[7]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) )
  ORIGINAL[8]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0))
  TYPE[8]: CALL
  TOKENIZED[8]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) )
  ORIGINAL[9]: context & 1?pos . constraint & 0xf : 0
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 & 1?pos . VAR2 & 0xf : 0
  ORIGINAL[10]: context & 1
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 & 1
  ORIGINAL[11]: context & 2?pos . constraint >> 4 & 0xf : 0
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0
  ORIGINAL[12]: context & 2
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 & 2
  ORIGINAL[13]: context & 4?pos . constraint >> 8 & 0xf : 0
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0
  ORIGINAL[14]: context & 4
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 & 4
  ORIGINAL[15]: d -> states[s] . context
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[16]: d -> states[s]
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[17]: d -> states
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: states
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: context
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: <global> syntax_bits
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1
  ORIGINAL[21]: context
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: wc
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: context
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: context
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: context
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: d
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: s
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1

CENTER_NODE: 30064775612
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: abort()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: ANYCHAR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773511
FRAGMENT_COUNT: 37
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET && d -> tokens[s -> elems[i] . index] < CSET
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < VAR10
  ORIGINAL[1]: visited[old . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 . VAR3 ]
  ORIGINAL[2]: old . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: --i
  TYPE[3]: CALL
  TOKENIZED[3]: --i
  ORIGINAL[4]: visited[old . index] = 1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 . VAR3 ] = 1
  ORIGINAL[5]: visited[old . index]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 . VAR3 ]
  ORIGINAL[6]: old . index
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . VAR2
  ORIGINAL[7]: d -> tokens[old . index]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[8]: d -> tokens
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: old . index
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 . VAR2
  ORIGINAL[10]: j = 0
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 = 0
  ORIGINAL[11]: j < d -> follows[old . index] . nelem
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 < VAR2 -> VAR3 [ VAR4 . VAR5 ] . VAR6
  ORIGINAL[12]: d -> follows[old . index] . nelem
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2 [ VAR3 . VAR4 ] . VAR5
  ORIGINAL[13]: d -> follows[old . index]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[14]: d -> follows
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: old . index
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 . VAR2
  ORIGINAL[16]: i = (- 1)
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 = ( - 1 )
  ORIGINAL[17]: - 1
  TYPE[17]: CALL
  TOKENIZED[17]: - 1
  ORIGINAL[18]: continue;
  TYPE[18]: CONTROL_STRUCTURE
  TOKENIZED[18]: continue ;
  ORIGINAL[19]: index
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: tokens
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: index
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: follows
  TYPE[22]: FIELD_IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: index
  TYPE[23]: FIELD_IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: nelem
  TYPE[24]: FIELD_IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: i
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: visited
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: i
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: visited
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: old
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: d
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: old
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: j
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: j
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: d
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: old
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: i
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1

CENTER_NODE: 47244640713
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775371
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ((char *)p) >= end
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( char * ) VAR1 ) >= VAR2
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 47244640835
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476998
FRAGMENT_COUNT: 10
  ORIGINAL[0]: c == '[' && syntax_bits & ((unsigned long )1) << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ' [ ' && VAR2 & ( ( unsigned long ) 1 ) << 1 << 1
  ORIGINAL[1]: str[128]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 128 ]
  ORIGINAL[2]: str[128]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 128 ]
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: str
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064774850
FRAGMENT_COUNT: 2
  ORIGINAL[0]: TRANSIT_STATE_END_BUFFER=2
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640397
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640973
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640762
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775885
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> right[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> right
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: mp -> is[0] = '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[4]: mp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476782
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BACKREF=257
  TYPE[0]: CALL
  TOKENIZED[0]: BACKREF=257
  ORIGINAL[1]: BEGLINE=258
  TYPE[1]: CALL
  TOKENIZED[1]: BEGLINE=258
  ORIGINAL[2]: BEGLINE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775758
FRAGMENT_COUNT: 10
  ORIGINAL[0]: cpp[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: --i == j
  TYPE[1]: CALL
  TOKENIZED[1]: --i == VAR1
  ORIGINAL[2]: cpp[j] = cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] = VAR1 [ VAR3 ]
  ORIGINAL[3]: cpp[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: cpp[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: cpp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064775207
FRAGMENT_COUNT: 17
  ORIGINAL[0]: nelem > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: match_lens = check_matching_with_multibyte_ops(d,s,( *pp - buf_begin))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR3 , ( *pp - VAR4 ) )
  ORIGINAL[2]: check_matching_with_multibyte_ops(d,s,( *pp - buf_begin))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , ( *pp - VAR3 ) )
  ORIGINAL[3]: *pp - buf_begin
  TYPE[3]: CALL
  TOKENIZED[3]: *pp - VAR1
  ORIGINAL[4]: *pp
  TYPE[4]: CALL
  TOKENIZED[4]: *pp
  ORIGINAL[5]: i = 0
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = 0
  ORIGINAL[6]: i < nelem
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 < VAR2
  ORIGINAL[7]: nelem
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: match_lens
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: pp
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: <global> buf_begin
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: i
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: i
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: nelem
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: nelem
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 47244640260
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data_size < buffer_size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: stonesoup_exit_flag = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719480101
FRAGMENT_COUNT: 5
  ORIGINAL[0]: strlen(guerison_peculiarities) < 1000 - strlen(stonesoup_command_str)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) < 1000 - FUN1 ( VAR2 )
  ORIGINAL[1]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: trace_point
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_trace
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: trace_point
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775815
FRAGMENT_COUNT: 7
  ORIGINAL[0]: len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: **p = enlist(cpp,lcp,len)
  TYPE[1]: CALL
  TOKENIZED[1]: **p = FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: enlist(cpp,lcp,len)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: lcp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640623
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 1
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0

CENTER_NODE: 47244640422
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640320
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640371
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640601
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 2
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 47244640354
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774755
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> fails
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *d -> fails
  TYPE[1]: CALL
  TOKENIZED[1]: *d -> VAR1
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: fails
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640407
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640632
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774900
FRAGMENT_COUNT: 28
  ORIGINAL[0]: wc == ((wchar_t )'\\0')
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[1]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[2]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: context = wchar_context(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[4]: wchar_context(wc)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[5]: CALL
  TOKENIZED[5]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[6]: (((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[6]: CALL
  TOKENIZED[6]: ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1
  ORIGINAL[7]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))
  TYPE[7]: CALL
  TOKENIZED[7]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) )
  ORIGINAL[8]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0))
  TYPE[8]: CALL
  TOKENIZED[8]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) )
  ORIGINAL[9]: context & 1?pos . constraint & 0xf : 0
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 & 1?pos . VAR2 & 0xf : 0
  ORIGINAL[10]: context & 1
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 & 1
  ORIGINAL[11]: context & 2?pos . constraint >> 4 & 0xf : 0
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0
  ORIGINAL[12]: context & 2
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 & 2
  ORIGINAL[13]: context & 4?pos . constraint >> 8 & 0xf : 0
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0
  ORIGINAL[14]: context & 4
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 & 4
  ORIGINAL[15]: d -> states[s] . context
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[16]: d -> states[s]
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[17]: d -> states
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: states
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: context
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: <global> syntax_bits
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1
  ORIGINAL[21]: context
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: wc
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: context
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: context
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: context
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: d
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: s
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1

CENTER_NODE: 30064773141
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i > lo
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2
  ORIGINAL[1]: s -> elems[i] = s -> elems[i - 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] = VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[2]: s -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: s -> elems[i - 1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[5]: s -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: i - 1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 - 1
  ORIGINAL[7]: s -> elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479889
FRAGMENT_COUNT: 33
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: rmp = --mp
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = --mp
  ORIGINAL[2]: lmp = --mp
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = --mp
  ORIGINAL[3]: --mp
  TYPE[3]: CALL
  TOKENIZED[3]: --mp
  ORIGINAL[4]: lmp -> is
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: lmp -> is
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: lmp -> left
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: lmp -> left
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: lmp -> left
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: lmp -> right
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: lmp -> right
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: lmp -> right
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: lmp -> right
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: lmp -> right
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: lmp -> in
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: lmp -> in
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2
  ORIGINAL[16]: lmp -> in
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: lmp
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: mp
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: lmp
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: lmp
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: lmp
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: lmp
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: lmp
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: lmp
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: lmp
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: lmp
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: lmp
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: lmp
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: lmp
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: lmp
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: lmp
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: lmp
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1

CENTER_NODE: 68719476830
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640352
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640882
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640264
FRAGMENT_COUNT: 2
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: if (getenv(\
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: if ( FUN1 ( \

CENTER_NODE: 30064775698
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640874
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775507
FRAGMENT_COUNT: 16
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: j < p -> nequivs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: p -> nequivs
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nequivs
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: j
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: p
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: p
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640430
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: (1 << 8) + 8 * sizeof(int ) - 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( 1 << 8 ) + 8 * sizeof ( int ) - 1
  ORIGINAL[3]: (1 << 8) + 8 * sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: ( 1 << 8 ) + 8 * sizeof ( int )
  ORIGINAL[4]: 8 * sizeof(int )
  TYPE[4]: CALL
  TOKENIZED[4]: 8 * sizeof ( int )

CENTER_NODE: 47244640755
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476804
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( int )
  ORIGINAL[1]: int
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: int

CENTER_NODE: 30064773005
FRAGMENT_COUNT: 3
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: closure()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: CAT
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640342
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640871
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640545
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640677
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774804
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) )
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> tralloc + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 + 1
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sizeof(( *d -> realtrans))
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064773792
FRAGMENT_COUNT: 15
  ORIGINAL[0]: pos[j]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: pos[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: pos[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: pos[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: j-- > 0
  TYPE[4]: CALL
  TOKENIZED[4]: j-- > 0
  ORIGINAL[5]: pos[j] = lastpos[j]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ] = VAR3 [ VAR2 ]
  ORIGINAL[6]: pos[j]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: lastpos[j]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 [ VAR2 ]
  ORIGINAL[8]: pos
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: pos
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: pos
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: pos
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: pos
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: j
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: lastpos
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064775560
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> tokens)) == 1?xmalloc(d -> talloc) : xnmalloc(d -> talloc,sizeof(( *d -> tokens)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *d -> tokens)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xnmalloc(d -> talloc,sizeof(( *d -> tokens)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[3]: d -> talloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: sizeof(( *d -> tokens))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *d -> VAR1 ) )

CENTER_NODE: 68719476778
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640294
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479605
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfaoptimize(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaanalyze(d,searchflag)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: searchflag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480110
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771244
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (i = 0;i < (1 << 8);++i)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719480065
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772904
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD || tok == LIMWORD
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9 || VAR1 == VAR10
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9
  ORIGINAL[2]: tok == LIMWORD
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: LIMWORD
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640379
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640363
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640440
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640591
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771138
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 68719477901
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: OR
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064776311
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064772837
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !using_utf8() && work_mbc -> cset != (- 1)
  TYPE[0]: CALL
  TOKENIZED[0]: !using_utf8 ( ) && VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[1]: !using_utf8()
  TYPE[1]: CALL
  TOKENIZED[1]: !using_utf8 ( )
  ORIGINAL[2]: work_mbc -> cset != (- 1)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[3]: work_mbc -> cset
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: argptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640709
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640625
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640924
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774574
FRAGMENT_COUNT: 11
  ORIGINAL[0]: 2 & 1?( *d) . states[s] . constraint & 0xf : 0
  TYPE[0]: CALL
  TOKENIZED[0]: 2 & 1? ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf : 0
  ORIGINAL[1]: 2 & 1
  TYPE[1]: CALL
  TOKENIZED[1]: 2 & 1
  ORIGINAL[2]: ( *d) . states[s] . constraint & 0xf
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf
  ORIGINAL[3]: ( *d) . states[s] . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[4]: ( *d) . states[s]
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[5]: ( *d) . states
  TYPE[5]: CALL
  TOKENIZED[5]: ( *d ) . VAR1
  ORIGINAL[6]: *d
  TYPE[6]: CALL
  TOKENIZED[6]: *d
  ORIGINAL[7]: states
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: constraint
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640543
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640836
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772771
FRAGMENT_COUNT: 18
  ORIGINAL[0]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> talloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> tindex + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1
  ORIGINAL[3]: dfa -> talloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: talloc
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> dfa
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> dfa
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> dfa
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> dfa
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> dfa
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> dfa
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> dfa
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1
  ORIGINAL[17]: <global> dfa
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: <global> VAR1

CENTER_NODE: 68719477837
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: ntokens
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640291
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771286
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775823
FRAGMENT_COUNT: 7
  ORIGINAL[0]: old == ((void *)0) || new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: old == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: new == ((void *)0)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775704
FRAGMENT_COUNT: 7
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: *cp
  TYPE[1]: CALL
  TOKENIZED[1]: *cp
  ORIGINAL[2]: strncmp(cp,lookfor,len) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: cp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772300
FRAGMENT_COUNT: 12
  ORIGINAL[0]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1) && laststart
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 ) && VAR2
  ORIGINAL[1]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1)
  TYPE[1]: CALL
  TOKENIZED[1]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 )
  ORIGINAL[2]: lasttok = STAR
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: laststart = 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = 0
  ORIGINAL[4]: __ctype_get_mb_cur_max() > 1
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ) > 1
  ORIGINAL[5]: __ctype_get_mb_cur_max()
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( )
  ORIGINAL[6]: goto normal_char;
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: goto VAR1 ;
  ORIGINAL[7]: backslash
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: <global> laststart
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> lasttok
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: STAR
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: <global> laststart
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1

CENTER_NODE: 30064774864
FRAGMENT_COUNT: 4
  ORIGINAL[0]: works < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: works = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: rval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: works
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775126
FRAGMENT_COUNT: 6
  ORIGINAL[0]: mblen_buf[ *pp - buf_begin] == 0?1 : mblen_buf[ *pp - buf_begin]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ *pp - VAR2 ] == 0?1 : VAR1 [ *pp - VAR2 ]
  ORIGINAL[1]: mblen_buf[ *pp - buf_begin] == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ *pp - VAR2 ] == 0
  ORIGINAL[2]: mblen_buf[ *pp - buf_begin]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ *pp - VAR2 ]
  ORIGINAL[3]: mblen_buf[ *pp - buf_begin]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ *pp - VAR2 ]
  ORIGINAL[4]: *pp - buf_begin
  TYPE[4]: CALL
  TOKENIZED[4]: *pp - VAR1
  ORIGINAL[5]: <global> mblen_buf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640419
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776328
FRAGMENT_COUNT: 4
  ORIGINAL[0]: {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: { { ( \
  ORIGINAL[1]: {(((void *)0)), (((void *)0)), (0)}
  TYPE[1]: CALL
  TOKENIZED[1]: { ( ( ( void * ) 0 ) ) , ( ( ( void * ) 0 ) ) , ( 0 ) }
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064773571
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[j] & ~(letters[j] | newline[j])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] & ~ ( VAR3 [ VAR2 ] | VAR4 [ VAR2 ] )
  ORIGINAL[2]: c[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: ~(letters[j] | newline[j])
  TYPE[3]: CALL
  TOKENIZED[3]: ~ ( VAR1 [ VAR2 ] | VAR3 [ VAR2 ] )
  ORIGINAL[4]: letters[j] | newline[j]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ] | VAR3 [ VAR2 ]

CENTER_NODE: 68719476819
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640302
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 47244640900
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479207
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *rarray
  TYPE[0]: CALL
  TOKENIZED[0]: *rarray
  ORIGINAL[1]: *rarray
  TYPE[1]: CALL
  TOKENIZED[1]: *rarray
  ORIGINAL[2]: d -> tokens[pos . index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[3]: rarray[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: rarray[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: rarray
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ANYCHAR
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: rarray
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719479660
FRAGMENT_COUNT: 7
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: result = (xrealloc(old,oldsize + newsize + 1))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 , VAR3 + VAR4 + 1 ) )
  ORIGINAL[2]: result + oldsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: result
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: result
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: oldsize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: result
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771206
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> charclasses = (x2nrealloc((dfa -> charclasses),&new_n_alloc,sizeof(( *dfa -> charclasses))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) ) )
  ORIGINAL[2]: dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: x2nrealloc((dfa -> charclasses),&new_n_alloc,sizeof(( *dfa -> charclasses)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *dfa -> VAR2 ) ) )
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 47244640332
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640811
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775630
FRAGMENT_COUNT: 20
  ORIGINAL[0]: i < (d -> sindex)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[1]: d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sindex
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: d
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: d
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: d
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: d
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: d
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776263
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 47244640573
FRAGMENT_COUNT: 1
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775847
FRAGMENT_COUNT: 5
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: both = (malloc(sizeof(( *both))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( sizeof ( ( *both ) ) ) )
  ORIGINAL[2]: malloc(sizeof(( *both)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( sizeof ( ( *both ) ) )
  ORIGINAL[3]: sizeof(( *both))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *both ) )
  ORIGINAL[4]: both
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773266
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[i] = s -> elems[i + 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] = VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[2]: s -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: s -> elems[i + 1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[5]: s -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: i + 1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 + 1

CENTER_NODE: 68719476808
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773374
FRAGMENT_COUNT: 11
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> states[i] . hash
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: d -> states[i] . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[i] . elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: d -> states[i] . context
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: d -> states[i] . backref
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[6]: d -> states[i] . constraint
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[7]: d -> states[i]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[8]: d -> states
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: constraint
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

