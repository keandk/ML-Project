# Tokenized code fragments for 153329-v1.0.0-bad
# Total center nodes processed: 72
# Total code fragments found: 256

CENTER_NODE: 30064772666
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 52 << 16 | 18 << 8
  TYPE[0]: CALL
  TOKENIZED[0]: 52 << 16 | 18 << 8
  ORIGINAL[1]: 52 << 16
  TYPE[1]: CALL
  TOKENIZED[1]: 52 << 16
  ORIGINAL[2]: 18 << 8
  TYPE[2]: CALL
  TOKENIZED[2]: 18 << 8

CENTER_NODE: 68719477289
FRAGMENT_COUNT: 8
  ORIGINAL[0]: ret == -((int )(('E' | 'O' << 8 | 'F' << 16) | ((unsigned int )32) << 24)) && link -> partial_buf
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - ( ( int ) ( ( 'E' | 'O' << 8 | 'F' << 16 ) | ( ( unsigned int ) 32 ) << 24 ) ) && VAR2 -> VAR3
  ORIGINAL[1]: link -> partial_buf = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[2]: link -> partial_buf
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ff_filter_frame_framed(link,pbuf)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[4]: link
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: link
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: link
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pbuf
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477380
FRAGMENT_COUNT: 6
  ORIGINAL[0]: !prev && ctx -> filter
  TYPE[0]: CALL
  TOKENIZED[0]: !prev && VAR1 -> VAR2
  ORIGINAL[1]: ctx -> filter
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ctx -> filter
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: filter
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ctx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477730
FRAGMENT_COUNT: 3
  ORIGINAL[0]: .category = AV_CLASS_CATEGORY_FILTER
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: category
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: AV_CLASS_CATEGORY_FILTER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771247
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 3 << 16 | 42 << 8
  TYPE[0]: CALL
  TOKENIZED[0]: 3 << 16 | 42 << 8
  ORIGINAL[1]: 3 << 16
  TYPE[1]: CALL
  TOKENIZED[1]: 3 << 16
  ORIGINAL[2]: 42 << 8
  TYPE[2]: CALL
  TOKENIZED[2]: 42 << 8

CENTER_NODE: 30064771547
FRAGMENT_COUNT: 5
  ORIGINAL[0]: src -> output_pads[srcpad] . type != dst -> input_pads[dstpad] . type
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 != VAR5 -> VAR6 [ VAR7 ] . VAR4
  ORIGINAL[1]: link -> dstpad = &dst -> input_pads[dstpad]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = &dst -> VAR3 [ VAR2 ]
  ORIGINAL[2]: link -> dstpad
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &dst -> input_pads[dstpad]
  TYPE[3]: CALL
  TOKENIZED[3]: &dst -> VAR1 [ VAR2 ]
  ORIGINAL[4]: link
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771415
FRAGMENT_COUNT: 3
  ORIGINAL[0]: \
  TYPE[0]: CALL
  TOKENIZED[0]: \
  ORIGINAL[1]: \
  TYPE[1]: CALL
  TOKENIZED[1]: \
  ORIGINAL[2]: sizeof(\
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( \

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477733
FRAGMENT_COUNT: 2
  ORIGINAL[0]: .child_class_next = filter_child_class_next
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: child_class_next
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771579
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !( *link)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( *link )
  ORIGINAL[1]: *link
  TYPE[1]: CALL
  TOKENIZED[1]: *link
  ORIGINAL[2]: ( *link) -> pool
  TYPE[2]: CALL
  TOKENIZED[2]: ( *link ) -> VAR1
  ORIGINAL[3]: ( *link) -> partial_buf
  TYPE[3]: CALL
  TOKENIZED[3]: ( *link ) -> VAR1
  ORIGINAL[4]: *link
  TYPE[4]: CALL
  TOKENIZED[4]: *link
  ORIGINAL[5]: partial_buf
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: link
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477732
FRAGMENT_COUNT: 2
  ORIGINAL[0]: .child_next = filter_child_next
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: child_next
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064772712
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (shmid = shmget(key, shmsz, IPC_CREAT | 0666)) < 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 | 0666 ) ) < 0
  ORIGINAL[1]: (char *) -1
  TYPE[1]: CALL
  TOKENIZED[1]: ( char * ) -1
  ORIGINAL[2]: -1
  TYPE[2]: CALL
  TOKENIZED[2]: -1

CENTER_NODE: 30064772422
FRAGMENT_COUNT: 2
  ORIGINAL[0]: av_log(((void *)0),48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , 48 , \
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 30064772426
FRAGMENT_COUNT: 2
  ORIGINAL[0]: av_log(((void *)0),48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , 48 , \
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477322
FRAGMENT_COUNT: 6
  ORIGINAL[0]: !strcmp(cmd,\
  TYPE[0]: CALL
  TOKENIZED[0]: !strcmp ( VAR1 , \
  ORIGINAL[1]: av_strlcatf(res,res_len,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: filter -> filter -> name
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR1 -> VAR2
  ORIGINAL[3]: filter -> name
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: res
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: res_len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477666
FRAGMENT_COUNT: 9
  ORIGINAL[0]: (link -> type) == AVMEDIA_TYPE_VIDEO
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) == VAR3
  ORIGINAL[1]: link -> type
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: strcmp(link -> dst -> filter -> name,\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 -> VAR3 -> VAR4 , \
  ORIGINAL[3]: (void )0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void ) 0
  ORIGINAL[4]: (void )0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void ) 0
  ORIGINAL[5]: link -> type
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: type
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: link
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: link
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640325
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772227
FRAGMENT_COUNT: 6
  ORIGINAL[0]: filter -> filter -> init_opaque
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR1 -> VAR2
  ORIGINAL[1]: filter -> filter -> init_opaque
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR1 -> VAR2
  ORIGINAL[2]: filter -> filter
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR1
  ORIGINAL[3]: filter
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: init_opaque
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filter
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771161
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *stonesoup_s != (char)0
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_s != ( char ) 0
  ORIGINAL[1]: (*stonesoup_tainted_buff)[stonesoup_s - stonesoup_shm] = *stonesoup_s
  TYPE[1]: CALL
  TOKENIZED[1]: ( *stonesoup_tainted_buff ) [ VAR1 - VAR2 ] = *stonesoup_s
  ORIGINAL[2]: (*stonesoup_tainted_buff)[stonesoup_s - stonesoup_shm]
  TYPE[2]: CALL
  TOKENIZED[2]: ( *stonesoup_tainted_buff ) [ VAR1 - VAR2 ]
  ORIGINAL[3]: *stonesoup_tainted_buff
  TYPE[3]: CALL
  TOKENIZED[3]: *stonesoup_tainted_buff
  ORIGINAL[4]: stonesoup_s - stonesoup_shm
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 - VAR2
  ORIGINAL[5]: *stonesoup_s
  TYPE[5]: CALL
  TOKENIZED[5]: *stonesoup_s
  ORIGINAL[6]: stonesoup_s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771583
FRAGMENT_COUNT: 5
  ORIGINAL[0]: link -> closed = closed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: link -> closed
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: closed
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: link
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: closed
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477303
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < link -> src -> nb_inputs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 -> VAR4
  ORIGINAL[1]: link -> src -> inputs[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[2]: link -> src -> inputs
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640405
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97
  ORIGINAL[1]: c <= 122
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= 122
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640274
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640299
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !link
  TYPE[0]: CALL
  TOKENIZED[0]: !link

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771184
FRAGMENT_COUNT: 3
  ORIGINAL[0]: buf[16]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 16 ]
  ORIGINAL[1]: buf[16]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 16 ]
  ORIGINAL[2]: buf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477061
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *count
  TYPE[0]: CALL
  TOKENIZED[0]: *count
  ORIGINAL[1]: sizeof(AVFilterLink *)
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 * )
  ORIGINAL[2]: *count
  TYPE[2]: CALL
  TOKENIZED[2]: *count
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640278
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771603
FRAGMENT_COUNT: 7
  ORIGINAL[0]: ret = avfilter_link(filt,filt_dstpad_idx,link -> dst,dstpad_idx)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 -> VAR5 , VAR6 )
  ORIGINAL[1]: avfilter_link(filt,filt_dstpad_idx,link -> dst,dstpad_idx)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 -> VAR4 , VAR5 )
  ORIGINAL[2]: link -> dst
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ret
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: filt
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filt_dstpad_idx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: dstpad_idx
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771422
FRAGMENT_COUNT: 3
  ORIGINAL[0]: av_freep((&c -> command))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( &c -> VAR1 ) )
  ORIGINAL[1]: &c -> command
  TYPE[1]: CALL
  TOKENIZED[1]: &c -> VAR1
  ORIGINAL[2]: filter
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771931
FRAGMENT_COUNT: 5
  ORIGINAL[0]: registered_avfilters[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: !strcmp(registered_avfilters[i] -> name,name)
  TYPE[1]: CALL
  TOKENIZED[1]: !strcmp ( VAR1 [ VAR2 ] -> VAR3 , VAR3 )
  ORIGINAL[2]: strcmp(registered_avfilters[i] -> name,name)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 [ VAR2 ] -> VAR3 , VAR3 )
  ORIGINAL[3]: registered_avfilters[i] -> name
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] -> VAR3
  ORIGINAL[4]: name
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477442
FRAGMENT_COUNT: 18
  ORIGINAL[0]: ret -> av_class
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: ret -> filter
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ret -> name
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ret -> priv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ret -> nb_inputs
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: ret -> input_pads
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: ret -> nb_inputs
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: ret -> inputs
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: ret -> nb_outputs
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: ret -> nb_outputs
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: ret -> output_pads
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: ret -> nb_outputs
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: !ret -> outputs
  TYPE[12]: CALL
  TOKENIZED[12]: !ret -> VAR1
  ORIGINAL[13]: ret -> outputs
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: *filter_ctx = ret
  TYPE[14]: CALL
  TOKENIZED[14]: *filter_ctx = VAR1
  ORIGINAL[15]: *filter_ctx
  TYPE[15]: CALL
  TOKENIZED[15]: *filter_ctx
  ORIGINAL[16]: ret
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: ret
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 30064772654
FRAGMENT_COUNT: 2
  ORIGINAL[0]: undeficiently_bundweed = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: undeficiently_bundweed
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771116
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477387
FRAGMENT_COUNT: 6
  ORIGINAL[0]: prev &&  *(filter_ptr = av_filter_next(filter_ptr))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && * ( VAR2 = FUN1 ( VAR2 ) )
  ORIGINAL[1]: ( *filter_ptr) -> priv_class == prev
  TYPE[1]: CALL
  TOKENIZED[1]: ( *filter_ptr ) -> VAR1 == VAR2
  ORIGINAL[2]: ( *filter_ptr) -> priv_class
  TYPE[2]: CALL
  TOKENIZED[2]: ( *filter_ptr ) -> VAR1
  ORIGINAL[3]: prev
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: prev
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: prev
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640280
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477513
FRAGMENT_COUNT: 3
  ORIGINAL[0]: pads[pad_idx]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: pads
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pad_idx
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640330
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476835
FRAGMENT_COUNT: 16
  ORIGINAL[0]: av_log(ctx,48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 48 , \
  ORIGINAL[1]: ref -> buf
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ref -> buf -> refcount
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: ff_get_ref_perms_string(buf,sizeof(buf),ref -> perms)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , sizeof ( VAR1 ) , VAR2 -> VAR3 )
  ORIGINAL[4]: ref -> data[0]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[5]: ref -> linesize[0]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[6]: ref -> linesize[1]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ 1 ]
  ORIGINAL[7]: ref -> linesize[2]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ 2 ]
  ORIGINAL[8]: ref -> linesize[3]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ 3 ]
  ORIGINAL[9]: ref -> pts
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: ref -> pos
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: ctx
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: ref
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: ctx
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: ctx
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: ctx
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 68719477368
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pads -> name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: count++
  TYPE[1]: CALL
  TOKENIZED[1]: count++
  ORIGINAL[2]: pads++
  TYPE[2]: CALL
  TOKENIZED[2]: pads++
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: count
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772552
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inharmony_btn > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *unresuscitative_beaverwood))))))))))))))))))))))))))))))))))))))))))))))))
  TYPE[1]: CALL
  TOKENIZED[1]: * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( *unresuscitative_beaverwood ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )
  ORIGINAL[2]: *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *unresuscitative_beaverwood)))))))))))))))))))))))))))))))))))))))))))))))
  TYPE[2]: CALL
  TOKENIZED[2]: * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( *unresuscitative_beaverwood ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )
  ORIGINAL[3]: *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *( *unresuscitative_beaverwood))))))))))))))))))))))))))))))))))))))))))))))
  TYPE[3]: CALL
  TOKENIZED[3]: * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( * ( *unresuscitative_beaverwood ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )

CENTER_NODE: 47244640279
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640324
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771820
FRAGMENT_COUNT: 2
  ORIGINAL[0]: av_log(((void *)0),48,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , 48 , \
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 30064772287
FRAGMENT_COUNT: 7
  ORIGINAL[0]: link -> dstpad
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: (dst -> min_perms & perms) != dst -> min_perms || dst -> rej_perms & perms
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 & VAR3 ) != VAR1 -> VAR2 || VAR1 -> VAR4 & VAR3
  ORIGINAL[2]: link -> dstpad -> rej_perms
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: link -> dstpad
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: dstpad
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: rej_perms
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: link
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477128
FRAGMENT_COUNT: 3
  ORIGINAL[0]: link -> channels
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: channels
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: link
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640282
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !(103 >= 100)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( 103 >= 100 )

CENTER_NODE: 30064771973
FRAGMENT_COUNT: 2
  ORIGINAL[0]: next_registered_avfilter_idx = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> next_registered_avfilter_idx
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 68719477645
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !pbuf
  TYPE[0]: CALL
  TOKENIZED[0]: !pbuf
  ORIGINAL[1]: !pbuf
  TYPE[1]: CALL
  TOKENIZED[1]: !pbuf
  ORIGINAL[2]: av_samples_copy(pbuf -> extended_data,(frame -> extended_data),pbuf -> audio -> nb_samples,inpos,nb_samples,nb_channels,(link -> format))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 -> VAR5 , VAR6 , VAR5 , VAR7 , ( VAR8 -> VAR9 ) )
  ORIGINAL[3]: inpos += nb_samples
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 += VAR2
  ORIGINAL[4]: inpos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: inpos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: inpos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: nb_samples
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771969
FRAGMENT_COUNT: 4
  ORIGINAL[0]: filter?++filter : &registered_avfilters[0]
  TYPE[0]: CALL
  TOKENIZED[0]: filter?++filter : &registered_avfilters [ 0 ]
  ORIGINAL[1]: &registered_avfilters[0]
  TYPE[1]: CALL
  TOKENIZED[1]: &registered_avfilters [ 0 ]
  ORIGINAL[2]: registered_avfilters[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: filter
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477516
FRAGMENT_COUNT: 3
  ORIGINAL[0]: pads[pad_idx]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: pads
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pad_idx
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771796
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (link -> type) == AVMEDIA_TYPE_VIDEO
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) == VAR3
  ORIGINAL[1]: buf[128]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 128 ]
  ORIGINAL[2]: buf[128]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 128 ]
  ORIGINAL[3]: buf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477320
FRAGMENT_COUNT: 8
  ORIGINAL[0]: link -> current_pts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: link -> time_base
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: link -> graph && link -> age_index >= 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 && VAR1 -> VAR3 >= 0
  ORIGINAL[3]: link -> graph
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: link -> age_index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: ff_avfilter_graph_update_heap(link -> graph,link)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 -> VAR2 , VAR1 )
  ORIGINAL[6]: link -> graph
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: link
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640290
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640404
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640329
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640406
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640407
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771951
FRAGMENT_COUNT: 7
  ORIGINAL[0]: filter -> inputs && filter -> inputs[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[1]: filter -> inputs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: filter -> inputs[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: filter -> inputs
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: inputs
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filter
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772193
FRAGMENT_COUNT: 6
  ORIGINAL[0]: &link -> in_channel_layouts
  TYPE[0]: CALL
  TOKENIZED[0]: &link -> VAR1
  ORIGINAL[1]: link -> in_channel_layouts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: link = filter -> outputs[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[3]: ff_channel_layouts_unref(&link -> in_channel_layouts)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( &link -> VAR1 )
  ORIGINAL[4]: &link -> in_channel_layouts
  TYPE[4]: CALL
  TOKENIZED[4]: &link -> VAR1
  ORIGINAL[5]: link -> in_channel_layouts
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2

CENTER_NODE: 47244640328
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477724
FRAGMENT_COUNT: 3
  ORIGINAL[0]: * stonesoup_printf_context = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: * VAR1 = VAR2
  ORIGINAL[1]: stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772241
FRAGMENT_COUNT: 5
  ORIGINAL[0]: link -> dst -> outputs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: link -> dst
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dst
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: outputs
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: link
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477728
FRAGMENT_COUNT: 2
  ORIGINAL[0]: .item_name = default_filter_name
  TYPE[0]: CALL
  TOKENIZED[0]: . VAR1 = VAR2
  ORIGINAL[1]: item_name
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 11
  ORIGINAL[0]: snprintf(buf,buf_size,\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: perms & 0x1?\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & 0x1?\
  ORIGINAL[2]: perms & 0x02?\
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & 0x02?\
  ORIGINAL[3]: perms & 0x02
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 & 0x02
  ORIGINAL[4]: perms & 0x04?\
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 & 0x04?\
  ORIGINAL[5]: perms & 0x08?\
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 & 0x08?\
  ORIGINAL[6]: perms & 0x10?\
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 & 0x10?\
  ORIGINAL[7]: perms & 0x20?\
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 & 0x20?\
  ORIGINAL[8]: buf
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: buf_size
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: perms
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771979
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *ctx = filter_ctx
  TYPE[0]: CALL
  TOKENIZED[0]: *ctx = VAR1
  ORIGINAL[1]: ctx
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: filter_ctx
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ctx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

