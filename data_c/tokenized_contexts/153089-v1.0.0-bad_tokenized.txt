# Tokenized code fragments for 153089-v1.0.0-bad
# Total center nodes processed: 78
# Total code fragments found: 328

CENTER_NODE: 68719476930
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *data = apr_pvsprintf(pool,fmt,ap)
  TYPE[0]: CALL
  TOKENIZED[0]: *data = FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: create_string(data,strlen(data),pool)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477270
FRAGMENT_COUNT: 6
  ORIGINAL[0]: old_count < new_count
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: delta = new_count - old_count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 - VAR3
  ORIGINAL[2]: new_count - old_count
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - VAR2
  ORIGINAL[3]: delta
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: delta
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477500
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *__errno_location() == 34 && (val == - 9223372036854775807L - 1 || val == 9223372036854775807L) || val < minval || val > maxval
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 34 && ( VAR1 == - 9223372036854775807L - 1 || VAR1 == 9223372036854775807L ) || VAR1 < VAR2 || VAR1 > VAR3
  ORIGINAL[1]: *n = val
  TYPE[1]: CALL
  TOKENIZED[1]: *n = VAR1
  ORIGINAL[2]: *n
  TYPE[2]: CALL
  TOKENIZED[2]: *n
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: val
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: val
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771318
FRAGMENT_COUNT: 11
  ORIGINAL[0]: memcpy((strbuf -> data),bytes,size)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR4 )
  ORIGINAL[1]: strbuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: strbuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: strbuf
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strbuf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: bytes
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: size
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: strbuf
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: strbuf
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: strbuf
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719476852
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *const _m_b_f_ = membuf
  TYPE[0]: CALL
  TOKENIZED[0]: *const VAR1 = VAR2
  ORIGINAL[1]: _m_b_f_ -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _m_b_f_
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _m_b_f_
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476921
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strlen(cstring)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: cstring
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477296
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_ncreate((original_string -> data),original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771380
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *mem = (void *)0
  TYPE[0]: CALL
  TOKENIZED[0]: *mem = ( void * ) 0
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: mem
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: minimum_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771326
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(str -> data,str -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477457
FRAGMENT_COUNT: 10
  ORIGINAL[0]: *__errno_location() == 34
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 34
  ORIGINAL[1]: val == - 9223372036854775807L - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == - 9223372036854775807L - 1
  ORIGINAL[2]: - 9223372036854775807L - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 9223372036854775807L - 1
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: val
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: val
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: val
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771129
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c - 32
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 32
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477470
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoui64(n,str,0,18446744073709551615UL,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 , 18446744073709551615UL , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771304
FRAGMENT_COUNT: 3
  ORIGINAL[0]: new_string -> data[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[1]: new_string -> data[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: new_string -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 47244640331
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 4
  ORIGINAL[0]: membuf_ensure(&membuf -> data,&membuf -> size,size,membuf -> pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 -> VAR4 )
  ORIGINAL[1]: &membuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: &membuf -> VAR1
  ORIGINAL[2]: membuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 1
  ORIGINAL[0]: apr_fnmatch(this_pattern,str,0) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 ) == 0

CENTER_NODE: 68719477553
FRAGMENT_COUNT: 7
  ORIGINAL[0]: number < 100
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 100
  ORIGINAL[1]: decimal_table[reduced % 100]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 % 100 ]
  ORIGINAL[2]: decimal_table[reduced % 100]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 % 100 ]
  ORIGINAL[3]: decimal_table[reduced]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: target
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> decimal_table
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: reduced
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771543
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,cstr,strlen(cstr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[1]: strlen(cstr)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771362
FRAGMENT_COUNT: 6
  ORIGINAL[0]: str -> len > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772058
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stringb . len = strlen(strb)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = FUN1 ( VAR3 )
  ORIGINAL[1]: stringb . len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: strlen(strb)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: strb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476888
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: new_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477297
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str1 -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771798
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *p) == 10
  TYPE[0]: CALL
  TOKENIZED[0]: ( *p ) == 10
  ORIGINAL[1]: ( *(p + 1)) == 13
  TYPE[1]: CALL
  TOKENIZED[1]: ( * ( VAR1 + 1 ) ) == 13
  ORIGINAL[2]: *(p + 1)
  TYPE[2]: CALL
  TOKENIZED[2]: * ( VAR1 + 1 )
  ORIGINAL[3]: p++
  TYPE[3]: CALL
  TOKENIZED[3]: p++
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476919
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: new_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_string -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data[size] = '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] = '\\0'
  ORIGINAL[4]: new_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476846
FRAGMENT_COUNT: 9
  ORIGINAL[0]: membuf -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: membuf -> size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: membuf -> pool
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf -> data && old_data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 && VAR3
  ORIGINAL[4]: membuf -> data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: membuf -> data
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: data
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: old_data
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: membuf
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476954
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: strbuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476797
FRAGMENT_COUNT: 5
  ORIGINAL[0]: minimum_size = minimum_size + (8 - 1) & (~(8 - 1))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR1 + ( 8 - 1 ) & ( ~ ( 8 - 1 ) )
  ORIGINAL[1]: minimum_size + (8 - 1) & (~(8 - 1))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + ( 8 - 1 ) & ( ~ ( 8 - 1 ) )
  ORIGINAL[2]: minimum_size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: minimum_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: minimum_size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477502
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoi64(n,str,- 9223372036854775807L - 1,9223372036854775807L,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , - 9223372036854775807L - 1 , 9223372036854775807L , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477376
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < list -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: *this_str = ((char **)(list -> elts))[i]
  TYPE[1]: CALL
  TOKENIZED[1]: *this_str = ( ( char ** ) ( VAR1 -> VAR2 ) ) [ VAR3 ]
  ORIGINAL[2]: strcmp(this_str,str)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: this_str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: this_str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771288
FRAGMENT_COUNT: 2
  ORIGINAL[0]: svn_stringbuf_create_ensure(0,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771356
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy((str -> data),value,amt + 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR4 + 1 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: amt + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: value
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477318
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771688
FRAGMENT_COUNT: 4
  ORIGINAL[0]: string_compare(str1 -> data,(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str2 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771281
FRAGMENT_COUNT: 4
  ORIGINAL[0]: string_first_non_whitespace(str -> data,str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772010
FRAGMENT_COUNT: 4
  ORIGINAL[0]: length = svn__ui64toa(buffer,number)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: svn__ui64toa(buffer,number)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: length
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477351
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *a = apr_array_make(pool,5,(sizeof(input)))
  TYPE[0]: CALL
  TOKENIZED[0]: *a = FUN1 ( VAR1 , 5 , ( sizeof ( VAR2 ) ) )
  ORIGINAL[1]: apr_array_make(pool,5,(sizeof(input)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 5 , ( sizeof ( VAR2 ) ) )
  ORIGINAL[2]: a
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: a
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476942
FRAGMENT_COUNT: 3
  ORIGINAL[0]: original_string -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: original_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771834
FRAGMENT_COUNT: 6
  ORIGINAL[0]: cmp || !a || !b
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 || !a || !b
  ORIGINAL[1]: cmp || !a
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 || !a
  ORIGINAL[2]: !a
  TYPE[2]: CALL
  TOKENIZED[2]: !a
  ORIGINAL[3]: !b
  TYPE[3]: CALL
  TOKENIZED[3]: !b
  ORIGINAL[4]: cmp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: b
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771265
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __builtin_va_start(ap,fmt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: ap
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fmt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771133
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 47244640335
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771325
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476998
FRAGMENT_COUNT: 10
  ORIGINAL[0]: size = strlen(data)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[1]: new_string = (apr_palloc(pool,sizeof(( *new_string))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 , sizeof ( ( *new_string ) ) ) )
  ORIGINAL[2]: apr_palloc(pool,sizeof(( *new_string)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , sizeof ( ( *new_string ) ) )
  ORIGINAL[3]: new_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pool
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_string
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: new_string
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: new_string
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: new_string
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771719
FRAGMENT_COUNT: 4
  ORIGINAL[0]: p[0] != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 0 ] != '\\0'
  ORIGINAL[1]: *((const char **)(apr_array_push(array)))
  TYPE[1]: CALL
  TOKENIZED[1]: * ( ( const char ** ) ( FUN1 ( VAR1 ) ) )
  ORIGINAL[2]: (const char **)(apr_array_push(array))
  TYPE[2]: CALL
  TOKENIZED[2]: ( const char ** ) ( FUN1 ( VAR1 ) )
  ORIGINAL[3]: apr_array_push(array)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771375
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> data[str -> len] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR1 -> VAR3 ] = '\\0'
  ORIGINAL[1]: str -> data[str -> len]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 ]
  ORIGINAL[2]: str -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 30064771408
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> blocksize > old_len + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 + 1
  ORIGINAL[1]: dest[old_len] = byte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = VAR3
  ORIGINAL[2]: dest[old_len]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: byte
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dest
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476855
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *const _m_b_f_ = membuf
  TYPE[0]: CALL
  TOKENIZED[0]: *const VAR1 = VAR2
  ORIGINAL[1]: _m_b_f_
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: membuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477301
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771882
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *n = ((unsigned int )val)
  TYPE[0]: CALL
  TOKENIZED[0]: *n = ( ( unsigned int ) VAR1 )
  ORIGINAL[1]: *n
  TYPE[1]: CALL
  TOKENIZED[1]: *n
  ORIGINAL[2]: (unsigned int )val
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned int ) VAR1

CENTER_NODE: 30064771678
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> data[str -> len] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR1 -> VAR3 ] = '\\0'
  ORIGINAL[1]: str -> data[str -> len]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 ]
  ORIGINAL[2]: str -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 68719477010
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __builtin_va_start(ap,fmt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: ap
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fmt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ap
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772005
FRAGMENT_COUNT: 3
  ORIGINAL[0]: number >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: svn__ui64toa(dest + 1,((apr_uint64_t )(0 - number))) + 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 + 1 , ( ( VAR2 ) ( 0 - VAR3 ) ) ) + 1
  ORIGINAL[2]: svn__ui64toa(dest + 1,((apr_uint64_t )(0 - number)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 + 1 , ( ( VAR2 ) ( 0 - VAR3 ) ) )

CENTER_NODE: 30064772039
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: buffer[0] = 45
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 0 ] = 45
  ORIGINAL[2]: buffer[0]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 0 ]
  ORIGINAL[3]: apr_uint64_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771211
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: !(0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002))
  TYPE[1]: CALL
  TOKENIZED[1]: ! ( 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 ) )
  ORIGINAL[2]: 0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002)
  TYPE[2]: CALL
  TOKENIZED[2]: 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 )
  ORIGINAL[3]: svn_ctype_table[(unsigned char )str[i]] & 0x0002
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002

CENTER_NODE: 68719477233
FRAGMENT_COUNT: 7
  ORIGINAL[0]: pos + count > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > VAR3 -> VAR4
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: count = str -> len - pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3 - VAR4
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: str -> data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: data
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771378
FRAGMENT_COUNT: 2
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771929
FRAGMENT_COUNT: 2
  ORIGINAL[0]: - 2147483647 - 1
  TYPE[0]: CALL
  TOKENIZED[0]: - 2147483647 - 1
  ORIGINAL[1]: - 2147483647
  TYPE[1]: CALL
  TOKENIZED[1]: - 2147483647

CENTER_NODE: 68719477401
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *str
  TYPE[0]: CALL
  TOKENIZED[0]: *str
  ORIGINAL[1]: next == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: *((char *)next) = '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: * ( ( char * ) VAR1 ) = '\\0'
  ORIGINAL[3]: *str
  TYPE[3]: CALL
  TOKENIZED[3]: *str
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771466
FRAGMENT_COUNT: 5
  ORIGINAL[0]: risibleness_carla != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: stonesoup_data = (struct stonesoup_struct*) malloc(sizeof(struct stonesoup_struct))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( struct stonesoup_struct* ) FUN1 ( sizeof ( struct VAR2 ) )
  ORIGINAL[2]: (struct stonesoup_struct*) malloc(sizeof(struct stonesoup_struct))
  TYPE[2]: CALL
  TOKENIZED[2]: ( struct stonesoup_struct* ) FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[3]: malloc(sizeof(struct stonesoup_struct))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[4]: stonesoup_data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476896
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: new_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476881
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: str[--i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ --i ]
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771572
FRAGMENT_COUNT: 6
  ORIGINAL[0]: bytes + count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: memcpy((str -> data + pos),bytes,count)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 + VAR3 ) , VAR4 , VAR5 )
  ORIGINAL[2]: str -> data + pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + VAR3
  ORIGINAL[3]: bytes
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771282
FRAGMENT_COUNT: 4
  ORIGINAL[0]: find_char_backward(str -> data,str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ch
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477183
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,(appendstr -> data),appendstr -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) , VAR2 -> VAR4 )
  ORIGINAL[1]: targetstr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: appendstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771106
FRAGMENT_COUNT: 4
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[2]: strlen(dirpath)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: dirpath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477018
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476829
FRAGMENT_COUNT: 6
  ORIGINAL[0]: membuf_create(&membuf -> data,&membuf -> size,size,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 )
  ORIGINAL[1]: membuf -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: membuf -> size
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf -> pool
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pool
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: membuf
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 1
  ORIGINAL[0]: len1 != len2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2

CENTER_NODE: 30064771820
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < strings -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: (const char **)(strings -> elts)
  TYPE[1]: CALL
  TOKENIZED[1]: ( const char ** ) ( VAR1 -> VAR2 )
  ORIGINAL[2]: strings -> elts
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: elts
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: strings
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strings
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477593
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ui64toa_sep(number,seperator,buffer)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: apr_pstrdup(pool,buffer)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: buffer
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 4
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: strbuf -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strbuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772083
FRAGMENT_COUNT: 12
  ORIGINAL[0]: stra < enda && strb < endb
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 < VAR4
  ORIGINAL[1]: ( *stra) == ( *strb)
  TYPE[1]: CALL
  TOKENIZED[1]: ( *stra ) == ( *strb )
  ORIGINAL[2]: *stra
  TYPE[2]: CALL
  TOKENIZED[2]: *stra
  ORIGINAL[3]: *strb
  TYPE[3]: CALL
  TOKENIZED[3]: *strb
  ORIGINAL[4]: strb
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strb
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: strb
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: strb
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: strb
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: strb
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: strb
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: strb
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771274
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare(str1 -> data,str2 -> data,str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR3 -> VAR2 , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str1 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str2 -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str1 -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: str2 -> len
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640339
FRAGMENT_COUNT: 0

