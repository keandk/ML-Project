# Tokenized code fragments for 153361-v1.0.0-bad
# Total center nodes processed: 142
# Total code fragments found: 413

CENTER_NODE: 30064773981
FRAGMENT_COUNT: 3
  ORIGINAL[0]: zeroset(matches)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: matches
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640435
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771250
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: wc == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: wc == '_' || iswalnum(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == '_' || FUN1 ( VAR1 )
  ORIGINAL[4]: wc == '_'
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == '_'
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775716
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476852
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: s2
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773195
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < s1 -> nelem && j < s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 && VAR4 < VAR5 -> VAR3
  ORIGINAL[1]: i < s1 -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: j < s2 -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < VAR2 -> VAR3
  ORIGINAL[3]: s2 -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773076
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: *dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: *dst -> VAR1
  ORIGINAL[3]: dst -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dst
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640586
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477869
FRAGMENT_COUNT: 6
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: dfa -> multibyte_prop[dfa -> tindex - 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[2]: dfa -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> multibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: multibyte_prop
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> dfa
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640557
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640932
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478293
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: context
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: context
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774593
FRAGMENT_COUNT: 18
  ORIGINAL[0]: ( *d) . states[s] . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: ( *d) . states[s] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: ( *d) . states[s] . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: 2 & 1
  TYPE[3]: CALL
  TOKENIZED[3]: 2 & 1
  ORIGINAL[4]: ( *d) . states[s] . constraint & 0xf
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ] . VAR3 & 0xf
  ORIGINAL[5]: ( *d) . states[s] . constraint
  TYPE[5]: CALL
  TOKENIZED[5]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[6]: ( *d) . states[s]
  TYPE[6]: CALL
  TOKENIZED[6]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[7]: ( *d) . states[s] . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[8]: ( *d) . states[s]
  TYPE[8]: CALL
  TOKENIZED[8]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[9]: ( *d) . states[s] . constraint
  TYPE[9]: CALL
  TOKENIZED[9]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[10]: ( *d) . states[s]
  TYPE[10]: CALL
  TOKENIZED[10]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[11]: ( *d) . states[s] . constraint
  TYPE[11]: CALL
  TOKENIZED[11]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[12]: ( *d) . states[s]
  TYPE[12]: CALL
  TOKENIZED[12]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[13]: ( *d) . states[s] . constraint
  TYPE[13]: CALL
  TOKENIZED[13]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[14]: ( *d) . states[s]
  TYPE[14]: CALL
  TOKENIZED[14]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[15]: ( *d) . states[s] . constraint
  TYPE[15]: CALL
  TOKENIZED[15]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[16]: ( *d) . states[s]
  TYPE[16]: CALL
  TOKENIZED[16]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[17]: constraint
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 68719476803
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BACKREF=257
  TYPE[0]: CALL
  TOKENIZED[0]: BACKREF=257
  ORIGINAL[1]: BEGLINE=258
  TYPE[1]: CALL
  TOKENIZED[1]: BEGLINE=258
  ORIGINAL[2]: BEGLINE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477901
FRAGMENT_COUNT: 6
  ORIGINAL[0]: tok == REPMN && (minrep || maxrep)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[1]: i < maxrep
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: <global> maxrep
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> maxrep
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> maxrep
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 30064773019
FRAGMENT_COUNT: 8
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN && tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: tok != OR
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != VAR2
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: RPAREN
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: OR
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640384
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 3
  ORIGINAL[0]: syntax_bits_set = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: <global> syntax_bits_set
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: <global> syntax_bits
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064775524
FRAGMENT_COUNT: 16
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: j < p -> nequivs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: p -> nequivs
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nequivs
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: j
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: p
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: p
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640708
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775601
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *d -> multibyte_prop)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[1]: d -> multibyte_prop
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(( *d -> multibyte_prop))
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[3]: *d -> multibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: d -> multibyte_prop
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640588
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640631
FRAGMENT_COUNT: 4
  ORIGINAL[0]: visited[old . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 . VAR3 ]
  ORIGINAL[1]: --i
  TYPE[1]: CALL
  TOKENIZED[1]: --i
  ORIGINAL[2]: continue;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: continue ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: stonesoup_trace
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_location
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> stonesoup_single_global_variable
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479139
FRAGMENT_COUNT: 4
  ORIGINAL[0]: wc < 1 << 8 && work_mbc -> cset != (- 1) && tstbit(((unsigned char )wc),d -> charclasses[work_mbc -> cset])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 1 << 8 && VAR2 -> VAR3 != ( - 1 ) && FUN1 ( ( ( unsigned char ) VAR1 ) , VAR4 -> VAR5 [ VAR2 -> VAR3 ] )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476846
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: s[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640392
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640830
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773825
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: nullable[- 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ - 1 ]
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1

CENTER_NODE: 30064775699
FRAGMENT_COUNT: 6
  ORIGINAL[0]: old == ((void *)0)?0 : strlen(old)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[1]: old == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: strlen(old)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640394
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775475
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ++ *count
  TYPE[0]: CALL
  TOKENIZED[0]: ++ *count
  ORIGINAL[1]: *count
  TYPE[1]: CALL
  TOKENIZED[1]: *count
  ORIGINAL[2]: count
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640305
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776384
FRAGMENT_COUNT: 16
  ORIGINAL[0]: prednames[] = {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ ] = { { ( \
  ORIGINAL[1]: {{(\
  TYPE[1]: CALL
  TOKENIZED[1]: { { ( \
  ORIGINAL[2]: {(\
  TYPE[2]: CALL
  TOKENIZED[2]: { ( \
  ORIGINAL[3]: {(\
  TYPE[3]: CALL
  TOKENIZED[3]: { ( \
  ORIGINAL[4]: {(\
  TYPE[4]: CALL
  TOKENIZED[4]: { ( \
  ORIGINAL[5]: {(\
  TYPE[5]: CALL
  TOKENIZED[5]: { ( \
  ORIGINAL[6]: {(\
  TYPE[6]: CALL
  TOKENIZED[6]: { ( \
  ORIGINAL[7]: {(\
  TYPE[7]: CALL
  TOKENIZED[7]: { ( \
  ORIGINAL[8]: {(\
  TYPE[8]: CALL
  TOKENIZED[8]: { ( \
  ORIGINAL[9]: {(\
  TYPE[9]: CALL
  TOKENIZED[9]: { ( \
  ORIGINAL[10]: {(\
  TYPE[10]: CALL
  TOKENIZED[10]: { ( \
  ORIGINAL[11]: {(\
  TYPE[11]: CALL
  TOKENIZED[11]: { ( \
  ORIGINAL[12]: {(\
  TYPE[12]: CALL
  TOKENIZED[12]: { ( \
  ORIGINAL[13]: {(\
  TYPE[13]: CALL
  TOKENIZED[13]: { ( \
  ORIGINAL[14]: {(((void *)0)), (((void *)0)), (0)}
  TYPE[14]: CALL
  TOKENIZED[14]: { ( ( ( void * ) 0 ) ) , ( ( ( void * ) 0 ) ) , ( 0 ) }
  ORIGINAL[15]: prednames
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775857
FRAGMENT_COUNT: 13
  ORIGINAL[0]: left == ((void *)0) || right == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: left == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: right == ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: both = (malloc(sizeof(( *both))))
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = ( FUN1 ( sizeof ( ( *both ) ) ) )
  ORIGINAL[5]: malloc(sizeof(( *both)))
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( sizeof ( ( *both ) ) )
  ORIGINAL[6]: sizeof(( *both))
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *both ) )
  ORIGINAL[7]: *both
  TYPE[7]: CALL
  TOKENIZED[7]: *both
  ORIGINAL[8]: both == ((void *)0)
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[9]: (void *)0
  TYPE[9]: CALL
  TOKENIZED[9]: ( void * ) 0
  ORIGINAL[10]: both
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: both
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: both
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 68719476840
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773617
FRAGMENT_COUNT: 7
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[2]: s -> elems[j] . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: s -> elems[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: s -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: constraint
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: j
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640618
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772892
FRAGMENT_COUNT: 21
  ORIGINAL[0]: 1 && tok == WCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2
  ORIGINAL[1]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[1]: CALL
  TOKENIZED[1]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[2]: 1 && tok == ANYCHAR
  TYPE[2]: CALL
  TOKENIZED[2]: 1 && VAR1 == VAR2
  ORIGINAL[3]: using_utf8()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: add_utf8_anychar()
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( )
  ORIGINAL[5]: tok = lex()
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = FUN1 ( )
  ORIGINAL[6]: lex()
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( )
  ORIGINAL[7]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD || tok == LIMWORD || tok == NOTLIMWORD
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9 || VAR1 == VAR10 || VAR1 == VAR11
  ORIGINAL[8]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD || tok == LIMWORD
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9 || VAR1 == VAR10
  ORIGINAL[9]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET || tok == ENDWORD
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8 || VAR1 == VAR9
  ORIGINAL[10]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR || tok == MBCSET
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7 || VAR1 == VAR8
  ORIGINAL[11]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD || tok == ANYCHAR
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6 || VAR1 == VAR7
  ORIGINAL[12]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6
  ORIGINAL[13]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[14]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[15]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3
  ORIGINAL[16]: tok >= 0 && tok < (1 << 8) || tok >= CSET
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2
  ORIGINAL[17]: tok >= 0 && tok < (1 << 8)
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 >= 0 && VAR1 < ( 1 << 8 )
  ORIGINAL[18]: tok >= 0
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 >= 0
  ORIGINAL[19]: <global> tok
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: <global> VAR1
  ORIGINAL[20]: <global> tok
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477792
FRAGMENT_COUNT: 5
  ORIGINAL[0]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0 || work_mbc -> ncoll_elems != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0 || VAR1 -> VAR8 != 0
  ORIGINAL[1]: addtok_mb(MBCSET,((dfa -> nmbcsets - 1 << 2) + 3))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( VAR2 -> VAR3 - 1 << 2 ) + 3 ) )
  ORIGINAL[2]: MBCSET
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: MBCSET
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 68719479276
FRAGMENT_COUNT: 6
  ORIGINAL[0]: match_lens == ((void *)0) && d -> states[s] . mbps . nelem != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) && VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 != 0
  ORIGINAL[1]: work_mbls = match_lens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: match_lens
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: work_mbls
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: match_lens
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: match_lens
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640981
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774865
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_DONE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479648
FRAGMENT_COUNT: 4
  ORIGINAL[0]: free((d -> follows))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640895
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771303
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640961
FRAGMENT_COUNT: 2
  ORIGINAL[0]: lmp -> left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: goto done;
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: goto VAR1 ;

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477968
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: elems
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640746
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479224
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: d -> states[s] . mbps . elems[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ]
  ORIGINAL[2]: d -> states[s] . mbps . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640672
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775855
FRAGMENT_COUNT: 12
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: new[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: ++i
  TYPE[3]: CALL
  TOKENIZED[3]: ++i
  ORIGINAL[4]: old == ((void *)0)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: break;
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: break ;
  ORIGINAL[7]: new
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: old
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: old
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640297
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640806
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479081
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inputwcs[idx]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: wc
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> inputwcs
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: idx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477764
FRAGMENT_COUNT: 11
  ORIGINAL[0]: depth > dfa -> depth
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR1
  ORIGINAL[1]: dfa -> depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: break;
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: break ;
  ORIGINAL[4]: break;
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: break ;
  ORIGINAL[5]: t
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> depth
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> depth
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> depth
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> dfa
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> depth
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1

CENTER_NODE: 68719477620
FRAGMENT_COUNT: 10
  ORIGINAL[0]: (!backslash || p != lim && ( *(p++)) == '\\\\') && p != lim && ( *(p++)) == '}'
  TYPE[0]: CALL
  TOKENIZED[0]: ( !backslash || VAR1 != VAR2 && ( * ( p++ ) ) == '\\\\' ) && VAR1 != VAR2 && ( * ( p++ ) ) == ' } '
  ORIGINAL[1]: 0 <= minrep
  TYPE[1]: CALL
  TOKENIZED[1]: 0 <= VAR1
  ORIGINAL[2]: <global> minrep
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> minrep
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> minrep
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> minrep
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> minrep
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> minrep
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> minrep
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> minrep
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1

CENTER_NODE: 30064775636
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfaoptimize(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640337
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773143
FRAGMENT_COUNT: 18
  ORIGINAL[0]: s -> alloc <= count + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 + 1
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: s -> elems = (x2nrealloc((s -> elems),&new_n_alloc,sizeof(( *s -> elems))))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *s -> VAR2 ) ) ) )
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: x2nrealloc((s -> elems),&new_n_alloc,sizeof(( *s -> elems)))
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *s -> VAR2 ) ) )
  ORIGINAL[5]: s -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: s -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: s -> elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: elems
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: s
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: s
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: s
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: s
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: s
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: s
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 47244640414
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640882
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cp = lookin
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: ( *cp) != '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: ( *cp ) != '\\0'
  ORIGINAL[2]: ++cp
  TYPE[2]: CALL
  TOKENIZED[2]: ++cp
  ORIGINAL[3]: for (cp = lookin;( *cp) != '\\0';++cp)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = VAR2 ; ( *cp ) != '\\0' ; ++cp )

CENTER_NODE: 47244640648
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771240
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640307
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640538
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771155
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 68719478170
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> states[i] . mbps . elems = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 = ( ( void * ) 0 )
  ORIGINAL[2]: j = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640402
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773027
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640750
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775905
FRAGMENT_COUNT: 3
  ORIGINAL[0]: mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> is[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> is
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 47244640596
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640704
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771275
FRAGMENT_COUNT: 8
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: wc == 0xffffffffu
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0xffffffffu
  ORIGINAL[2]: setbit(b,c)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: case_fold && iswalpha(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 && FUN1 ( VAR2 )
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: b
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: c
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> case_fold
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 30064776382
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064772939
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: 1 + nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: 1 + FUN1 ( VAR1 - 1 )
  ORIGINAL[2]: nsubtoks(tindex - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 - 1 )

CENTER_NODE: 47244640869
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775734
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: free(cpp[i])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 [ VAR2 ] )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771175
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: b / (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[3]: ~(1 << b % (8 * sizeof(int )))
  TYPE[3]: CALL
  TOKENIZED[3]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640266
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480162
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476862
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> calloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> cindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: dfa -> cindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: dfa -> charclasses
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: dfa -> calloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: cindex
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1

CENTER_NODE: 47244640620
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478082
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: p . index == s -> elems[i] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 == VAR3 -> VAR4 [ VAR5 ] . VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064776366
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775632
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> mb_cur_max = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = 1
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: mb_cur_max
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640327
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771185
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476766
FRAGMENT_COUNT: 6
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: size_filepath = strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[3]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476826
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064774880
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (t = d -> trans[works]) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 [ VAR4 ] ) != ( ( void * ) 0 )
  ORIGINAL[1]: works < 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < 0
  ORIGINAL[2]: works = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: rval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: works
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: works
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775838
FRAGMENT_COUNT: 4
  ORIGINAL[0]: p == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: cpp = p
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: cpp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640821
FRAGMENT_COUNT: 1
  ORIGINAL[0]: match_lens[i] > maxlen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] > VAR3

CENTER_NODE: 47244640540
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640366
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476824
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064774744
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> trcount = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: d -> trcount
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640866
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477305
FRAGMENT_COUNT: 23
  ORIGINAL[0]: *work_mbc
  TYPE[0]: CALL
  TOKENIZED[0]: *work_mbc
  ORIGINAL[1]: work_mbc -> ch_classes
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: work_mbc -> nch_classes
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: work_mbc -> equivs
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: work_mbc -> nequivs
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: work_mbc -> coll_elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: work_mbc -> ncoll_elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: __ctype_get_mb_cur_max() > 1
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( ) > 1
  ORIGINAL[8]: work_mbc -> nranges
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: work_mbc -> nranges
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: work_mbc -> range_sts
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: work_mbc -> nranges
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: work_mbc -> nranges
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: work_mbc -> range_ends
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: work_mbc -> chars
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: work_mbc -> nchars
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2
  ORIGINAL[16]: work_mbc -> chars
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: work_mbc -> nchars
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: nranges
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: work_mbc
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: work_mbc
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: range_ends_al
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: work_mbc
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1

CENTER_NODE: 30064775741
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0

CENTER_NODE: 68719476799
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064773044
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !syntax_bits_set
  TYPE[0]: CALL
  TOKENIZED[0]: !syntax_bits_set
  ORIGINAL[1]: dfaerror((gettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( FUN2 ( \
  ORIGINAL[2]: gettext(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \

CENTER_NODE: 30064774846
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> newlines = (xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[2]: d -> newlines
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )

CENTER_NODE: 30064776380
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

