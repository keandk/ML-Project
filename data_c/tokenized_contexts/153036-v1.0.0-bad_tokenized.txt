# Tokenized code fragments for 153036-v1.0.0-bad
# Total center nodes processed: 80
# Total code fragments found: 349

CENTER_NODE: 68719477295
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_cstring_split_append(a,input,sep_chars,chop_whitespace,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: chop_whitespace
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477361
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < strings -> nelts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: strings -> nelts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: strings -> elts
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nelts
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: strings
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477523
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i > 3
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 3
  ORIGINAL[1]: buffer[i - 3] = seperator
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 - 3 ] = VAR3
  ORIGINAL[2]: length++
  TYPE[2]: CALL
  TOKENIZED[2]: length++
  ORIGINAL[3]: length
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: length
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: length
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477685
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_buffer_stack[128] = {0}
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 128 ] = { 0 }
  ORIGINAL[1]: stonesoup_buffer_stack[128] = {0}
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 128 ] = { 0 }
  ORIGINAL[2]: {0}
  TYPE[2]: CALL
  TOKENIZED[2]: { 0 }
  ORIGINAL[3]: stonesoup_buffer_stack
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_buffer_stack
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476852
FRAGMENT_COUNT: 4
  ORIGINAL[0]: membuf_create(&membuf -> data,&membuf -> size,size,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &membuf -> VAR1 , &membuf -> VAR2 , VAR2 , VAR3 )
  ORIGINAL[1]: size
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771868
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *n = ((int )val)
  TYPE[0]: CALL
  TOKENIZED[0]: *n = ( ( int ) VAR1 )
  ORIGINAL[1]: *n
  TYPE[1]: CALL
  TOKENIZED[1]: *n
  ORIGINAL[2]: (int )val
  TYPE[2]: CALL
  TOKENIZED[2]: ( int ) VAR1

CENTER_NODE: 68719476877
FRAGMENT_COUNT: 4
  ORIGINAL[0]: _m_b_f_ -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: size
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: _m_b_f_
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _m_b_f_
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771885
FRAGMENT_COUNT: 4
  ORIGINAL[0]: number < 10
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 10
  ORIGINAL[1]: dest[2] = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 2 ] = 0
  ORIGINAL[2]: dest[2]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ 2 ]
  ORIGINAL[3]: dest
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771097
FRAGMENT_COUNT: 6
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stat(dirpath, &st) == -1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[2]: stat(dirpath, &st)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , &st )
  ORIGINAL[3]: &st
  TYPE[3]: CALL
  TOKENIZED[3]: &st
  ORIGINAL[4]: -1
  TYPE[4]: CALL
  TOKENIZED[4]: -1
  ORIGINAL[5]: dirpath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771793
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *__errno_location() == 22 || endptr == str || str[0] == '\\0' || ( *endptr) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) == 22 || VAR1 == VAR2 || VAR2 [ 0 ] == '\\0' || ( *endptr ) != '\\0'
  ORIGINAL[1]: svn_error_createf(SVN_ERR_INCORRECT_PARAMS,((void *)0),(dgettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( void * ) 0 ) , ( FUN2 ( \
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: dgettext(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: SVN_ERR_INCORRECT_PARAMS
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771344
FRAGMENT_COUNT: 4
  ORIGINAL[0]: blocksize - sizeof(( *new_string))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - sizeof ( ( *new_string ) )
  ORIGINAL[1]: sizeof(( *new_string))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *new_string ) )
  ORIGINAL[2]: *new_string
  TYPE[2]: CALL
  TOKENIZED[2]: *new_string
  ORIGINAL[3]: blocksize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771465
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ensure(str,total_len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: str
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: total_len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: start_address
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771591
FRAGMENT_COUNT: 3
  ORIGINAL[0]: string_first_non_whitespace((str -> data),str -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 30064771590
FRAGMENT_COUNT: 4
  ORIGINAL[0]: string_compare((str1 -> data),(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str2 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771422
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mem && mem != (str -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 != ( VAR2 -> VAR3 )
  ORIGINAL[1]: mem != (str -> data)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( VAR2 -> VAR3 )
  ORIGINAL[2]: str -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: mem
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: mem
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771390
FRAGMENT_COUNT: 8
  ORIGINAL[0]: memcpy((str -> data),value,amt + 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR3 , VAR4 + 1 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: amt + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: str
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: value
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640315
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < list -> nelts
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: for (i = 0;i < list -> nelts;i++)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )

CENTER_NODE: 30064771608
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 0
  ORIGINAL[1]: svn_ctype_table[(unsigned char )str -> data[str -> len - 1]]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ ( unsigned char ) VAR2 -> VAR3 [ VAR2 -> VAR4 - 1 ] ]
  ORIGINAL[2]: (unsigned char )str -> data[str -> len - 1]
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned char ) VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]
  ORIGINAL[3]: str -> data[str -> len - 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR1 -> VAR3 - 1 ]

CENTER_NODE: 30064771231
FRAGMENT_COUNT: 4
  ORIGINAL[0]: _s_z_ > _m_b_f_ -> size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: memset(_m_b_f_ -> data,0,_m_b_f_ -> size)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , 0 , VAR1 -> VAR3 )
  ORIGINAL[2]: _m_b_f_ -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: _m_b_f_ -> size
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 68719477501
FRAGMENT_COUNT: 3
  ORIGINAL[0]: number >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: svn__ui64toa(dest,((apr_uint64_t )number))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( VAR2 ) VAR3 ) )
  ORIGINAL[2]: dest
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771394
FRAGMENT_COUNT: 8
  ORIGINAL[0]: str -> len > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> data[0] = '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ 0 ] = '\\0'
  ORIGINAL[3]: str -> data[0]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[4]: str -> data
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: data
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477121
FRAGMENT_COUNT: 4
  ORIGINAL[0]: appendstr -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: targetstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: appendstr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640334
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771624
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare(str1 -> data,(str2 -> data),str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR2 ) , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str2 -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476975
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476900
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !(0 != (svn_ctype_table[(unsigned char )str[i]] & 0x0002))
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( 0 != ( VAR1 [ ( unsigned char ) VAR2 [ VAR3 ] ] & 0x0002 ) )
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771376
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_string -> blocksize = size + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3 + 1
  ORIGINAL[1]: new_string -> blocksize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size + 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771552
FRAGMENT_COUNT: 9
  ORIGINAL[0]: pos > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pos = str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: str -> len
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: len
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477549
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stringb . data = strb
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR3
  ORIGINAL[1]: stringb . data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: strb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477013
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771583
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_ncreate((original_string -> data),original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: original_string -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772029
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stra < enda && strb < endb
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 && VAR3 < VAR4
  ORIGINAL[1]: --endb
  TYPE[1]: CALL
  TOKENIZED[1]: --endb
  ORIGINAL[2]: endb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: enda
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771823
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *__errno_location() = 0
  TYPE[0]: CALL
  TOKENIZED[0]: *__errno_location ( ) = 0
  ORIGINAL[1]: *__errno_location()
  TYPE[1]: CALL
  TOKENIZED[1]: *__errno_location ( )
  ORIGINAL[2]: val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477348
FRAGMENT_COUNT: 8
  ORIGINAL[0]: ( *p) == 10
  TYPE[0]: CALL
  TOKENIZED[0]: ( *p ) == 10
  ORIGINAL[1]: *p
  TYPE[1]: CALL
  TOKENIZED[1]: *p
  ORIGINAL[2]: count++
  TYPE[2]: CALL
  TOKENIZED[2]: count++
  ORIGINAL[3]: p + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476817
FRAGMENT_COUNT: 10
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: stonesoup_tainted_file != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: *stonesoup_tainted_buff != 0
  TYPE[2]: CALL
  TOKENIZED[2]: *stonesoup_tainted_buff != 0
  ORIGINAL[3]: (*stonesoup_tainted_buff)[stonesoup_lsize] = '\\0'
  TYPE[3]: CALL
  TOKENIZED[3]: ( *stonesoup_tainted_buff ) [ VAR1 ] = '\\0'
  ORIGINAL[4]: stonesoup_tainted_file != 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 != 0
  ORIGINAL[5]: stonesoup_tainted_file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_tainted_file
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_tainted_file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_tainted_file
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: stonesoup_tainted_file
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771126
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stonesoup_printf_context != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context != stderr
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: <global> stonesoup_printf_context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> stonesoup_printf_context
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: stderr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477438
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoi64(n,str,- 9223372036854775807L - 1,9223372036854775807L,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , - 9223372036854775807L - 1 , 9223372036854775807L , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640338
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477011
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strlen(cstring)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: cstring
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771296
FRAGMENT_COUNT: 4
  ORIGINAL[0]: create_string(data,strlen(data),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(data)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640276
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476833
FRAGMENT_COUNT: 6
  ORIGINAL[0]: minimum_size >  *size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > *size
  ORIGINAL[1]: new_size =  *size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = *size
  ORIGINAL[2]: new_size == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: new_size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_size
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771972
FRAGMENT_COUNT: 3
  ORIGINAL[0]: apr_pstrdup(pool,buffer)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: buffer
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476979
FRAGMENT_COUNT: 2
  ORIGINAL[0]: svn_stringbuf_create_ensure(0,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( 0 , VAR1 )
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771355
FRAGMENT_COUNT: 4
  ORIGINAL[0]: strbuf -> len = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: strbuf -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strbuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771821
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *n = ((unsigned int )val)
  TYPE[0]: CALL
  TOKENIZED[0]: *n = ( ( unsigned int ) VAR1 )
  ORIGINAL[1]: *n
  TYPE[1]: CALL
  TOKENIZED[1]: *n
  ORIGINAL[2]: (unsigned int )val
  TYPE[2]: CALL
  TOKENIZED[2]: ( unsigned int ) VAR1
  ORIGINAL[3]: n
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476889
FRAGMENT_COUNT: 3
  ORIGINAL[0]: len1 != len2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: len1
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: len2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476936
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: new_string -> data = data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: new_string -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: new_string -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: len
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_string
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640330
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719476855
FRAGMENT_COUNT: 3
  ORIGINAL[0]: membuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: membuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772111
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TORBAY_ABORTS(preciosities_demophobe)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: floorboards_yugoslav((salten_homosassa)preciosities_demophobe)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 ) VAR2 )
  ORIGINAL[2]: (salten_homosassa)preciosities_demophobe
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2

CENTER_NODE: 68719477379
FRAGMENT_COUNT: 6
  ORIGINAL[0]: svn_ctype_casecmp(a,b)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: cmp || !a || !b
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 || !a || !b
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: a
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: b
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771310
FRAGMENT_COUNT: 5
  ORIGINAL[0]: string_compare(str1 -> data,str2 -> data,str1 -> len,str2 -> len)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR3 -> VAR2 , VAR1 -> VAR4 , VAR3 -> VAR4 )
  ORIGINAL[1]: str1 -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771222
FRAGMENT_COUNT: 10
  ORIGINAL[0]: &membuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: &membuf -> VAR1
  ORIGINAL[1]: membuf -> data && old_data && old_data != (membuf -> data)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && VAR3 && VAR3 != ( VAR1 -> VAR2 )
  ORIGINAL[2]: membuf -> data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: membuf -> data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: memcpy(membuf -> data,old_data,old_size)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 -> VAR2 , VAR3 , VAR4 )
  ORIGINAL[5]: membuf -> data
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: data
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: membuf
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: old_data
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: old_size
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719476912
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: pool
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: new_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476909
FRAGMENT_COUNT: 3
  ORIGINAL[0]: i != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771172
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ~(8 - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ~ ( 8 - 1 )
  ORIGINAL[1]: 8 - 1
  TYPE[1]: CALL
  TOKENIZED[1]: 8 - 1

CENTER_NODE: 68719477331
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !( *token)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( *token )
  ORIGINAL[1]: *token
  TYPE[1]: CALL
  TOKENIZED[1]: *token
  ORIGINAL[2]: strchr(token,csep)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: token
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: token
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: next
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: token
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: csep
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: token
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: token
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477124
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_stringbuf_appendbytes(targetstr,cstr,strlen(cstr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , FUN2 ( VAR2 ) )
  ORIGINAL[1]: targetstr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: cstr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: cstr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477407
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_cstring_strtoui64(n,str,0,18446744073709551615UL,10)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 0 , 18446744073709551615UL , 10 )
  ORIGINAL[1]: n
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771412
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476965
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771289
FRAGMENT_COUNT: 4
  ORIGINAL[0]: svn_string_ncreate(cstring,strlen(cstring),pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , FUN2 ( VAR1 ) , VAR2 )
  ORIGINAL[1]: strlen(cstring)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: cstring
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pool
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771666
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (i = 0;i < list -> nelts;i++)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; i++ )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476973
FRAGMENT_COUNT: 3
  ORIGINAL[0]: str -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771516
FRAGMENT_COUNT: 9
  ORIGINAL[0]: pos > str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: str -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: str -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: len
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: str
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: str
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: str
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477139
FRAGMENT_COUNT: 5
  ORIGINAL[0]: bytes + count > (str -> data) && bytes < (str -> data + str -> blocksize)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 + VAR2 > ( VAR3 -> VAR4 ) && VAR1 < ( VAR3 -> VAR4 + VAR3 -> VAR5 )
  ORIGINAL[1]: svn_stringbuf_insert(str,pos,temp,count)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[2]: count
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477276
FRAGMENT_COUNT: 12
  ORIGINAL[0]: *e = p + (strlen(p) - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: *e = VAR1 + ( FUN1 ( VAR1 ) - 1 )
  ORIGINAL[1]: e >= p && 0 != (svn_ctype_table[(unsigned char )( *e)] & 0x0002)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= VAR2 && 0 != ( VAR3 [ ( unsigned char ) ( *e ) ] & 0x0002 )
  ORIGINAL[2]: e >= p
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= VAR2
  ORIGINAL[3]: *e
  TYPE[3]: CALL
  TOKENIZED[3]: *e
  ORIGINAL[4]: e--
  TYPE[4]: CALL
  TOKENIZED[4]: e--
  ORIGINAL[5]: chop_whitespace
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: e
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: e
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: e
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: e
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: e
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719477044
FRAGMENT_COUNT: 4
  ORIGINAL[0]: str -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476948
FRAGMENT_COUNT: 4
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: strbuf -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: len
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: strbuf
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476978
FRAGMENT_COUNT: 3
  ORIGINAL[0]: strbuf -> data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: strbuf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771438
FRAGMENT_COUNT: 5
  ORIGINAL[0]: str -> blocksize > old_len + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > VAR3 + 1
  ORIGINAL[1]: str -> len = old_len + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3 + 1
  ORIGINAL[2]: str -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: old_len + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: old_len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476968
FRAGMENT_COUNT: 3
  ORIGINAL[0]: svn_string_ncreate(original_string -> data,original_string -> len,pool)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: original_string -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pool
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771382
FRAGMENT_COUNT: 3
  ORIGINAL[0]: __builtin_va_end(ap)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: ap
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771407
FRAGMENT_COUNT: 2
  ORIGINAL[0]: str -> data[str -> len] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR1 -> VAR3 ] = '\\0'
  ORIGINAL[1]: str -> data[str -> len]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> VAR3 ]

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771620
FRAGMENT_COUNT: 5
  ORIGINAL[0]: find_char_backward((str -> data),str -> len,ch)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) , VAR1 -> VAR3 , VAR4 )
  ORIGINAL[1]: str -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: str
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *new_string
  TYPE[0]: CALL
  TOKENIZED[0]: *new_string
  ORIGINAL[1]: new_string -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_string -> len = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = 0
  ORIGINAL[3]: new_string -> len
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: new_string
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new_string
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477537
FRAGMENT_COUNT: 5
  ORIGINAL[0]: number < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: ui64toa_sep(((apr_uint64_t )(-number)),seperator,&buffer[1])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( VAR1 ) ( -number ) ) , VAR2 , &buffer [ 1 ] )
  ORIGINAL[2]: (apr_uint64_t )(-number)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) ( -number )
  ORIGINAL[3]: seperator
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: buffer
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771298
FRAGMENT_COUNT: 4
  ORIGINAL[0]: __builtin_va_start(ap,fmt)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: ap
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fmt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

