# Tokenized code fragments for 152726-v1.0.0-bad
# Total center nodes processed: 24
# Total code fragments found: 178

CENTER_NODE: 30064771158
FRAGMENT_COUNT: 5
  ORIGINAL[0]: conversation -> options & 0x02
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 & 0x02
  ORIGINAL[1]: new_conversation_from_template = conversation_new(conversation -> setup_frame,(&conversation -> key_ptr -> addr1),(&conversation -> key_ptr -> addr2),conversation -> key_ptr -> ptype,conversation -> key_ptr -> port1,port2,options)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 -> VAR3 , ( &conversation -> VAR4 -> VAR5 ) , ( &conversation -> VAR4 -> VAR6 ) , VAR2 -> VAR4 -> VAR7 , VAR2 -> VAR4 -> VAR8 , VAR9 , VAR10 )
  ORIGINAL[2]: conversation_new(conversation -> setup_frame,(&conversation -> key_ptr -> addr1),(&conversation -> key_ptr -> addr2),conversation -> key_ptr -> ptype,conversation -> key_ptr -> port1,port2,options)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , ( &conversation -> VAR3 -> VAR4 ) , ( &conversation -> VAR3 -> VAR5 ) , VAR1 -> VAR3 -> VAR6 , VAR1 -> VAR3 -> VAR7 , VAR8 , VAR9 )
  ORIGINAL[3]: new_conversation_from_template
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new_conversation_from_template
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771671
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation_hashtable_no_addr2_or_port2 = g_hash_table_new(conversation_hash_no_addr2_or_port2,conversation_match_no_addr2_or_port2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(conversation_hash_no_addr2_or_port2,conversation_match_no_addr2_or_port2)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> conversation_hashtable_no_addr2_or_port2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771115
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476977
FRAGMENT_COUNT: 8
  ORIGINAL[0]: v1 -> ptype
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: v1 -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ((&v1 -> addr1) -> type) == ((&v2 -> addr1) -> type)
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( &v1 -> VAR1 ) -> VAR2 ) == ( ( &v2 -> VAR1 ) -> VAR2 )
  ORIGINAL[3]: v1 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: addr1
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: v1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: v1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771375
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_data = ((&key -> addr1) -> data)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( &key -> VAR2 ) -> VAR3 )
  ORIGINAL[1]: (&key -> addr1) -> data
  TYPE[1]: CALL
  TOKENIZED[1]: ( &key -> VAR1 ) -> VAR2
  ORIGINAL[2]: ADD_ADDRESS_TO_HASH_data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_index
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477024
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: ADD_ADDRESS_TO_HASH_index
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771676
FRAGMENT_COUNT: 25
  ORIGINAL[0]: g_hash_table_lookup(hashtable,(conv -> key_ptr))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( VAR2 -> VAR3 ) )
  ORIGINAL[1]: conv -> key_ptr
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: conv -> key_ptr
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: conv -> key_ptr
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: key_ptr
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashtable
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: conv
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: conv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: conv
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: conv
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: conv
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: conv
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: conv
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: conv
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: conv
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: conv
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: conv
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: conv
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: conv
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: conv
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: conv
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: conv
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: conv
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: conv
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: conv
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1

CENTER_NODE: 30064772147
FRAGMENT_COUNT: 5
  ORIGINAL[0]: item = g_slist_find_custom(conv -> data_list,((gpointer *)(&temp)),p_compare)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 -> VAR3 , ( ( VAR4 * ) ( &temp ) ) , VAR5 )
  ORIGINAL[1]: g_slist_find_custom(conv -> data_list,((gpointer *)(&temp)),p_compare)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , ( ( VAR3 * ) ( &temp ) ) , VAR4 )
  ORIGINAL[2]: conv -> data_list
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (gpointer *)(&temp)
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 * ) ( &temp )
  ORIGINAL[4]: item
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772132
FRAGMENT_COUNT: 4
  ORIGINAL[0]: p1 -> proto = proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: p1 -> proto
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: proto
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772075
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !(options & 0x02)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & 0x02 )
  ORIGINAL[1]: conversation != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: conversation
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771594
FRAGMENT_COUNT: 10
  ORIGINAL[0]: (v1 -> ptype) != (v2 -> ptype)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) != ( VAR3 -> VAR2 )
  ORIGINAL[1]: v1 -> port1 == v2 -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[2]: v1 -> port1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: v2 -> port1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: port1
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: v2
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: v2
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: v2
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: v2
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v2
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771204
FRAGMENT_COUNT: 9
  ORIGINAL[0]: hash_val += key -> port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 += VAR2 -> VAR3
  ORIGINAL[1]: key -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: port1
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hash_val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477482
FRAGMENT_COUNT: 7
  ORIGINAL[0]: *ap = (const conv_proto_data *)a
  TYPE[0]: CALL
  TOKENIZED[0]: *ap = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const conv_proto_data *)a
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: ap -> proto
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ap -> proto
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ap
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ap
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ap
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771306
FRAGMENT_COUNT: 19
  ORIGINAL[0]: v1 -> port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: v1 -> port2 == v2 -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == VAR3 -> VAR4
  ORIGINAL[2]: v1 -> port1 == v2 -> port2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == VAR3 -> VAR4
  ORIGINAL[3]: v1 -> port1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: v2 -> port2
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: port1
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: v1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: v1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: v2
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: v1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: v1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: v1
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: v1
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: v1
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: v1
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: v1
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: v1
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: v1
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 30064772263
FRAGMENT_COUNT: 9
  ORIGINAL[0]: dbhost != 0 && dbport != 0 && dbuser != 0 && dbpassword != 0 && dbdatabase != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0 && VAR2 != 0 && VAR3 != 0 && VAR4 != 0 && VAR5 != 0
  ORIGINAL[1]: snprintf(dbconn_str,150,\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 150 , \
  ORIGINAL[2]: dbconn_str
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: dbdatabase
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dbhost
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dbuser
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: dbpassword
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dbport
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: conn
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771401
FRAGMENT_COUNT: 14
  ORIGINAL[0]: (v1 -> ptype) != (v2 -> ptype)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) != ( VAR3 -> VAR2 )
  ORIGINAL[1]: v1 -> port1 == v2 -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[2]: v1 -> port1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: v2 -> port1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: port1
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: v1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: v1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: v2
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: v1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: v1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: v1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: v1
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: v1
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: v1
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 68719477513
FRAGMENT_COUNT: 4
  ORIGINAL[0]: conv -> data_list
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data_list
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: item
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640301
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ((void *)0) == conv -> next
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( void * ) 0 ) == VAR1 -> VAR2
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 68719477549
FRAGMENT_COUNT: 11
  ORIGINAL[0]: (conv = find_conversation(pinfo -> fd -> num,(&pinfo -> src),(&pinfo -> dst),pinfo -> ptype,pinfo -> srcport,pinfo -> destport,0)) == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 -> VAR3 -> VAR4 , ( &pinfo -> VAR5 ) , ( &pinfo -> VAR6 ) , VAR2 -> VAR7 , VAR2 -> VAR8 , VAR2 -> VAR9 , 0 ) ) == ( ( void * ) 0 )
  ORIGINAL[1]: pinfo -> src
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pinfo -> dst
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pinfo -> ptype
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pinfo -> srcport
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: pinfo -> destport
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &pinfo -> src
  TYPE[6]: CALL
  TOKENIZED[6]: &pinfo -> VAR1
  ORIGINAL[7]: pinfo -> src
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: pinfo -> dst
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: dst
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: pinfo
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719476952
FRAGMENT_COUNT: 7
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: hash_val += ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2 [ VAR3 ]
  ORIGINAL[2]: ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: hash_val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hash_val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ADD_ADDRESS_TO_HASH_data
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hash_val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064772176
FRAGMENT_COUNT: 5
  ORIGINAL[0]: conversation -> dissector_handle = handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: conversation -> dissector_handle
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dissector_handle
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conversation
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: handle
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771994
FRAGMENT_COUNT: 6
  ORIGINAL[0]: chain_head -> latest_found = match
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: chain_head -> latest_found
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: latest_found
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: match
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chain_head
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: match
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477527
FRAGMENT_COUNT: 4
  ORIGINAL[0]: find_conversation(pinfo -> fd -> num,addr_a,addr_b,ptype,port_a,port_b,0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 -> VAR3 , VAR4 , VAR5 , VAR6 , VAR7 , VAR8 , 0 )
  ORIGINAL[1]: addr_b
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: ptype
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: port_a
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771631
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conv -> data_list = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[1]: conv -> data_list
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0

