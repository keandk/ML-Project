# Tokenized code fragments for 152594-v1.0.0-bad
# Total center nodes processed: 44
# Total code fragments found: 181

CENTER_NODE: 47244640377
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771992
FRAGMENT_COUNT: 4
  ORIGINAL[0]: status -> curEntry == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: ++curBucket
  TYPE[1]: CALL
  TOKENIZED[1]: ++curBucket
  ORIGINAL[2]: curBucket
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: status
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476782
FRAGMENT_COUNT: 3
  ORIGINAL[0]: keysize - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - 1
  ORIGINAL[1]: key2
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: keysize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476826
FRAGMENT_COUNT: 6
  ORIGINAL[0]: hashp -> tabname
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: flags & 0x010
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & 0x010
  ORIGINAL[2]: hashp -> hash
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hash
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772220
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (((intptr_t )_vstart) & sizeof(long ) - 1) == 0 && (_len & sizeof(long ) - 1) == 0 && _val == 0 && _len <= 1024 && 1024 != 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( VAR1 ) VAR2 ) & sizeof ( long ) - 1 ) == 0 && ( VAR3 & sizeof ( long ) - 1 ) == 0 && VAR4 == 0 && VAR3 <= 1024 && 1024 != 0
  ORIGINAL[1]: *_start = (long *)_vstart
  TYPE[1]: CALL
  TOKENIZED[1]: *_start = ( long * ) VAR1
  ORIGINAL[2]: (long *)_vstart
  TYPE[2]: CALL
  TOKENIZED[2]: ( long * ) VAR1
  ORIGINAL[3]: _start
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _stop
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477294
FRAGMENT_COUNT: 4
  ORIGINAL[0]: hashp -> isshared
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hashp -> tabname
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: tabname
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476772
FRAGMENT_COUNT: 6
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: *stonesoup_server = mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_server = FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: stonesoup_server
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: NULL
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_server
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477086
FRAGMENT_COUNT: 5
  ORIGINAL[0]: hash_search_with_hash_value(hashp,keyPtr,((hashp -> hash)(keyPtr,hashp -> keysize)),action,foundPtr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , ( ( VAR1 -> VAR3 ) ( VAR2 , VAR1 -> VAR4 ) ) , VAR5 , VAR6 )
  ORIGINAL[1]: hashp
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: keyPtr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: keyPtr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771612
FRAGMENT_COUNT: 9
  ORIGINAL[0]: hashp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: hash_stats(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: MemoryContextDelete(hashp -> hcxt)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[4]: hashp -> hcxt
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: hcxt
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hashp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hashp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: hashp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640333
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771598
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (num_entries - 1) / 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 - 1 ) / 1
  ORIGINAL[1]: num_entries - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: num_entries
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476741
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mg_vprintf_data((struct mg_connection*) stonesoup_printf_context, format, argptr)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( struct mg_connection* ) VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: va_end(argptr)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: argptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: argptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640371
FRAGMENT_COUNT: 1
  ORIGINAL[0]: p != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )

CENTER_NODE: 30064772399
FRAGMENT_COUNT: 35
  ORIGINAL[0]: huntingburg_churchton != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: strlen(echium_bands) < 1000 - strlen(stonesoup_command_str)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) < 1000 - FUN1 ( VAR2 )
  ORIGINAL[2]: strlen(echium_bands)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: 1000 - strlen(stonesoup_command_str)
  TYPE[3]: CALL
  TOKENIZED[3]: 1000 - FUN1 ( VAR1 )
  ORIGINAL[4]: tracepoint(stonesoup_trace, variable_buffer, \
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[5]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[6]: snprintf(stonesoup_command_buffer, 1000, \
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( VAR1 , 1000 , \
  ORIGINAL[7]: tracepoint(stonesoup_trace, variable_buffer, \
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[8]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[9]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[10]: stonesoup_fpipe = popen(stonesoup_command_buffer,\
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[11]: popen(stonesoup_command_buffer,\
  TYPE[11]: CALL
  TOKENIZED[11]: FUN1 ( VAR1 , \
  ORIGINAL[12]: stonesoup_fpipe != 0
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 != 0
  ORIGINAL[13]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[13]: CALL
  TOKENIZED[13]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[14]: stonesoup_trace
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: variable_buffer
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: echium_bands
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: stonesoup_trace
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: trace_point
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: stonesoup_command_buffer
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: stonesoup_command_str
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: echium_bands
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: stonesoup_trace
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: variable_buffer
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: stonesoup_command_buffer
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: stonesoup_trace
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: trace_point
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: stonesoup_trace
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: trace_point
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: stonesoup_fpipe
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: stonesoup_command_buffer
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: stonesoup_fpipe
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: stonesoup_trace
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: trace_point
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: stonesoup_trace
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1

CENTER_NODE: 30064772285
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !firstElement
  TYPE[0]: CALL
  TOKENIZED[0]: !firstElement
  ORIGINAL[1]: firstElement -> link = hctlv -> freeList
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3 -> VAR4
  ORIGINAL[2]: firstElement -> link
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hctlv -> freeList
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: freeList
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hctlv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hctlv
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hctlv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064772300
FRAGMENT_COUNT: 3
  ORIGINAL[0]: hashp -> isshared
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: elog_start(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: <global> __func__
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064772424
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ++stonesoup_global_variable
  TYPE[0]: CALL
  TOKENIZED[0]: ++stonesoup_global_variable
  ORIGINAL[1]: <global> stonesoup_global_variable
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: interglyph_disburdenment
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771085
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_tainted_buff = (char*) malloc(buffer_size * sizeof(char))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[1]: (char*) malloc(buffer_size * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[2]: malloc(buffer_size * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: stonesoup_tainted_buff
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771897
FRAGMENT_COUNT: 5
  ORIGINAL[0]: newElement != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: !element_alloc(hashp,hctlv -> nelem_alloc)
  TYPE[1]: CALL
  TOKENIZED[1]: !element_alloc ( VAR1 , VAR2 -> VAR3 )
  ORIGINAL[2]: element_alloc(hashp,hctlv -> nelem_alloc)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 -> VAR3 )
  ORIGINAL[3]: hctlv -> nelem_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772429
FRAGMENT_COUNT: 1
  ORIGINAL[0]: *seq_scan_tables[100]
  TYPE[0]: CALL
  TOKENIZED[0]: *seq_scan_tables [ 100 ]

CENTER_NODE: 47244640385
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640302
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771630
FRAGMENT_COUNT: 6
  ORIGINAL[0]: bucket > hctl -> max_bucket
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: hctl -> max_bucket
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: max_bucket
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: bucket
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hctl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hctl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772313
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 1L << my_log2(num)
  TYPE[0]: CALL
  TOKENIZED[0]: 1L << FUN1 ( VAR1 )
  ORIGINAL[1]: my_log2(num)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: num
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477168
FRAGMENT_COUNT: 6
  ORIGINAL[0]: currBucket -> hashvalue
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: currBucket != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[2]: currBucket -> link
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (char *)currBucket
  TYPE[3]: CALL
  TOKENIZED[3]: ( char * ) VAR1
  ORIGINAL[4]: currBucket
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: currBucket
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772325
FRAGMENT_COUNT: 5
  ORIGINAL[0]: seq_scan_tables[num_seq_scans] = hashp
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] = VAR3
  ORIGINAL[1]: seq_scan_tables[num_seq_scans]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: <global> seq_scan_tables
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> num_seq_scans
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771611
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (info -> dsize) * sizeof(HASHSEGMENT )
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) * sizeof ( VAR3 )
  ORIGINAL[1]: info -> dsize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(HASHSEGMENT )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: HASHSEGMENT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771913
FRAGMENT_COUNT: 5
  ORIGINAL[0]: hashp -> hctl -> nentries
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: hashp -> hctl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hctl
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: nentries
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477036
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(HASHBUCKET )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: HASHBUCKET
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719477356
FRAGMENT_COUNT: 7
  ORIGINAL[0]: currElement != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: currElement -> link
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: currElement -> hashvalue
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hashvalue
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: currElement
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hctl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: currElement
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476959
FRAGMENT_COUNT: 5
  ORIGINAL[0]: elementSize = ((((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))) + (((intptr_t )entrysize) + (8 - 1) & ~((intptr_t )(8 - 1))))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( ( ( VAR2 ) ( sizeof ( VAR3 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) ) + ( ( ( VAR2 ) VAR4 ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) ) )
  ORIGINAL[1]: (((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))) + (((intptr_t )entrysize) + (8 - 1) & ~((intptr_t )(8 - 1)))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) ) ) + ( ( ( VAR1 ) VAR3 ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) ) )
  ORIGINAL[2]: elementSize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: intptr_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: elementSize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477494
FRAGMENT_COUNT: 5
  ORIGINAL[0]: num > 9223372036854775807L / 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 9223372036854775807L / 2
  ORIGINAL[1]: num = 9223372036854775807L / 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 9223372036854775807L / 2
  ORIGINAL[2]: 9223372036854775807L / 2
  TYPE[2]: CALL
  TOKENIZED[2]: 9223372036854775807L / 2
  ORIGINAL[3]: num
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: num
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640359
FRAGMENT_COUNT: 1
  ORIGINAL[0]: !status -> hashp -> frozen
  TYPE[0]: CALL
  TOKENIZED[0]: !status -> VAR1 -> VAR2

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771921
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !hashp -> frozen
  TYPE[0]: CALL
  TOKENIZED[0]: !hashp -> VAR1
  ORIGINAL[1]: hashp -> frozen
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: register_seq_scan(hashp)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771619
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: hashp -> keysize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: keysize
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: keyPtr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772318
FRAGMENT_COUNT: 2
  ORIGINAL[0]: 1 << my_log2(num)
  TYPE[0]: CALL
  TOKENIZED[0]: 1 << FUN1 ( VAR1 )
  ORIGINAL[1]: my_log2(num)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )

CENTER_NODE: 68719476994
FRAGMENT_COUNT: 5
  ORIGINAL[0]: hashp -> hctl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: nsegs > hctl -> dsize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 > VAR2 -> VAR3
  ORIGINAL[2]: hashp -> dir
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dir
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640342
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 4
  ORIGINAL[0]: hctl -> sshift = 8
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 8
  ORIGINAL[1]: hctl -> sshift
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sshift
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hctl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

