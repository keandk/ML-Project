# Tokenized code fragments for 153501-v1.0.0-bad
# Total center nodes processed: 25
# Total code fragments found: 170

CENTER_NODE: 30064771142
FRAGMENT_COUNT: 5
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: stonesoup_tainted_file = fopen(stonesoup_tainted_file_name,\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(stonesoup_tainted_file_name,\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: stonesoup_tainted_file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_tainted_file_name
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771175
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8 - 2
  ORIGINAL[2]: sizeof(long ) * 8
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) * 8
  ORIGINAL[3]: sizeof(long )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long )

CENTER_NODE: 68719476875
FRAGMENT_COUNT: 5
  ORIGINAL[0]: bl = (ctx -> cipher -> block_size)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( VAR2 -> VAR3 -> VAR4 )
  ORIGINAL[1]: ctx -> cipher -> block_size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: bl
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ctx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: bl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771637
FRAGMENT_COUNT: 25
  ORIGINAL[0]: inl < bl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: i <= inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= VAR2
  ORIGINAL[2]: i += bl
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += VAR2
  ORIGINAL[3]: Camellia_ecb_encrypt(in + i,out + i,(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> encrypt)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 + VAR2 , VAR3 + VAR2 , ( & ( ( VAR4 * ) ( VAR5 -> VAR6 ) ) -> VAR7 ) , VAR5 -> VAR8 )
  ORIGINAL[4]: in + i
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 + VAR2
  ORIGINAL[5]: out + i
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 + VAR2
  ORIGINAL[6]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[6]: CALL
  TOKENIZED[6]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[7]: ((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[7]: CALL
  TOKENIZED[7]: ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[8]: (EVP_CAMELLIA_KEY *)(ctx -> cipher_data)
  TYPE[8]: CALL
  TOKENIZED[8]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[9]: ctx -> cipher_data
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: ctx -> encrypt
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: for (i = 0;i <= inl;i += bl)
  TYPE[11]: CONTROL_STRUCTURE
  TOKENIZED[11]: for ( VAR1 = 0 ; VAR1 <= VAR2 ; VAR1 += VAR3 )
  ORIGINAL[12]: cipher_data
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: ks
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: encrypt
  TYPE[14]: FIELD_IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: inl
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: i
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: bl
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: in
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: i
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: out
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: i
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: ctx
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: ctx
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1

CENTER_NODE: 30064771827
FRAGMENT_COUNT: 9
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: (EVP_CAMELLIA_KEY *)(ctx -> cipher_data)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: cipher_data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ctx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ctx
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ctx
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ctx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ctx
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771168
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476945
FRAGMENT_COUNT: 15
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: inl && inl >= chunk
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 && VAR1 >= VAR2
  ORIGINAL[3]: inl >= chunk
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= VAR2
  ORIGINAL[4]: inl < chunk
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < VAR2
  ORIGINAL[5]: chunk = inl
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = VAR2
  ORIGINAL[6]: inl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: inl
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: inl
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: inl
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: chunk
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: inl
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: inl
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: inl
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: inl
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064771345
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: (size_t )1
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) 1
  ORIGINAL[3]: sizeof(long ) * 8 - 2
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8 - 2
  ORIGINAL[4]: sizeof(long ) * 8
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( long ) * 8

CENTER_NODE: 30064771736
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: (size_t )1
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) 1
  ORIGINAL[2]: sizeof(long ) * 8 - 2
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) * 8 - 2
  ORIGINAL[3]: sizeof(long ) * 8
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long ) * 8

CENTER_NODE: 30064771933
FRAGMENT_COUNT: 4
  ORIGINAL[0]: anthracoid_geoscopic > 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 0
  ORIGINAL[1]: strlen(unfixable_hotspur) + 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 ) + 1
  ORIGINAL[2]: strlen(unfixable_hotspur)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: unfixable_hotspur
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 8
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: ctx -> flags
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ctx -> iv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ctx -> num
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: ctx -> encrypt
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: cipher_data
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ctx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771302
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8 - 2
  ORIGINAL[2]: sizeof(long ) * 8
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) * 8
  ORIGINAL[3]: sizeof(long )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long )

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 9
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: Camellia_ofb128_encrypt(in,out,((long )(((size_t )1) << sizeof(long ) * 8 - 2)),(&((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks),ctx -> iv,&ctx -> num)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , ( ( long ) ( ( ( VAR3 ) 1 ) << sizeof ( long ) * 8 - 2 ) ) , ( & ( ( VAR4 * ) ( VAR5 -> VAR6 ) ) -> VAR7 ) , VAR5 -> VAR8 , &ctx -> VAR9 )
  ORIGINAL[2]: (long )(((size_t )1) << sizeof(long ) * 8 - 2)
  TYPE[2]: CALL
  TOKENIZED[2]: ( long ) ( ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2 )
  ORIGINAL[3]: &((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[3]: CALL
  TOKENIZED[3]: & ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[4]: ctx -> iv
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: &ctx -> VAR1
  ORIGINAL[6]: ctx -> num
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: in
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: out
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477241
FRAGMENT_COUNT: 9
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: ctx -> flags
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ctx -> iv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &ctx -> num
  TYPE[4]: CALL
  TOKENIZED[4]: &ctx -> VAR1
  ORIGINAL[5]: ctx -> num
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: ctx -> encrypt
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: encrypt
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ctx
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771652
FRAGMENT_COUNT: 4
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: sizeof(long ) * 8
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( long ) * 8
  ORIGINAL[2]: sizeof(long )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long )
  ORIGINAL[3]: long
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: long

CENTER_NODE: 68719477175
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 1 == 1
  TYPE[0]: CALL
  TOKENIZED[0]: 1 == 1
  ORIGINAL[1]: ctx -> flags
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ctx -> cipher_data
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: ctx -> iv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ctx -> num
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: ctx -> encrypt
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: flags
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ctx
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476764
FRAGMENT_COUNT: 6
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: size_filepath = strlen(dirpath) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: strlen(dirpath) + strlen(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[3]: size_filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: size_filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771578
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl >= ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[1]: in += ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += ( ( VAR2 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[2]: ((size_t )1) << sizeof(long ) * 8 - 2
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( VAR1 ) 1 ) << sizeof ( long ) * 8 - 2
  ORIGINAL[3]: (size_t )1
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 ) 1
  ORIGINAL[4]: sizeof(long ) * 8 - 2
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( long ) * 8 - 2
  ORIGINAL[5]: in
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771403
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i <= inl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= VAR2
  ORIGINAL[1]: i += bl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: for (i = 0;i <= inl;i += bl)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 <= VAR2 ; VAR1 += VAR3 )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: bl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771861
FRAGMENT_COUNT: 5
  ORIGINAL[0]: inl && inl >= chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 >= VAR2
  ORIGINAL[1]: ((EVP_CAMELLIA_KEY *)(ctx -> cipher_data)) -> ks
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 * ) ( VAR2 -> VAR3 ) ) -> VAR4
  ORIGINAL[2]: (EVP_CAMELLIA_KEY *)(ctx -> cipher_data)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 * ) ( VAR2 -> VAR3 )
  ORIGINAL[3]: ctx -> cipher_data
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: ks
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477318
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: chunk
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: inl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chunk
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477161
FRAGMENT_COUNT: 3
  ORIGINAL[0]: &camellia_256_ofb
  TYPE[0]: CALL
  TOKENIZED[0]: &camellia_256_ofb
  ORIGINAL[1]: <global> camellia_256_ofb
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: camellia_256_ofb
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477345
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ctx -> key_len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key_len
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ctx
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771511
FRAGMENT_COUNT: 5
  ORIGINAL[0]: bluffly_bluegums != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: tallboy_unpocket = &marquardt_myographer
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = &marquardt_myographer
  ORIGINAL[2]: &marquardt_myographer
  TYPE[2]: CALL
  TOKENIZED[2]: &marquardt_myographer
  ORIGINAL[3]: tallboy_unpocket
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ensuant_daguerreotyping
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477119
FRAGMENT_COUNT: 6
  ORIGINAL[0]: inl < chunk
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: chunk = inl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: chunk
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: chunk
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chunk
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: inl
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

