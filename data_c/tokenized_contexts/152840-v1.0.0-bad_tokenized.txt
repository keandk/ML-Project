# Tokenized code fragments for 152840-v1.0.0-bad
# Total center nodes processed: 39
# Total code fragments found: 208

CENTER_NODE: 47244640404
FRAGMENT_COUNT: 1
  ORIGINAL[0]: num > 9223372036854775807L / 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 9223372036854775807L / 2

CENTER_NODE: 68719477017
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *hctl = hashp -> hctl
  TYPE[0]: CALL
  TOKENIZED[0]: *hctl = VAR1 -> VAR2
  ORIGINAL[1]: hctl -> num_partitions
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: num_partitions
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hctl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hctl
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771624
FRAGMENT_COUNT: 4
  ORIGINAL[0]: elementSize = (((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))) + (((intptr_t )entrysize) + (8 - 1) & ~((intptr_t )(8 - 1)))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( ( VAR2 ) ( sizeof ( VAR3 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) ) + ( ( ( VAR2 ) VAR4 ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) )
  ORIGINAL[1]: (((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))) + (((intptr_t )entrysize) + (8 - 1) & ~((intptr_t )(8 - 1)))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) ) ) + ( ( ( VAR1 ) VAR3 ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) ) )
  ORIGINAL[2]: elementSize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: size
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477483
FRAGMENT_COUNT: 13
  ORIGINAL[0]: hctl -> nsegs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hctl -> dsize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hctl -> nsegs
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hctl -> max_bucket
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: hctl -> low_mask
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: hctl -> high_mask
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: hctl -> high_mask
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: hctl -> low_mask
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: currElement != ((void *)0)
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[9]: calc_bucket(hctl,currElement -> hashvalue)
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( VAR1 , VAR2 -> VAR3 )
  ORIGINAL[10]: hctl
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: hctl
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: currElement
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 16
  ORIGINAL[0]: flags & 0x100
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 0x100
  ORIGINAL[1]: hashp -> alloc = info -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3 -> VAR2
  ORIGINAL[2]: hashp -> alloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: info -> alloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: alloc
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: info
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: info
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: info
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: info
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: info
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: info
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: info
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: info
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: info
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: info
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: info
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1

CENTER_NODE: 47244640272
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640302
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772526
FRAGMENT_COUNT: 1
  ORIGINAL[0]: *seq_scan_tables[100]
  TYPE[0]: CALL
  TOKENIZED[0]: *seq_scan_tables [ 100 ]

CENTER_NODE: 68719476825
FRAGMENT_COUNT: 3
  ORIGINAL[0]: keysize - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - 1
  ORIGINAL[1]: key2
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: keysize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640391
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772057
FRAGMENT_COUNT: 7
  ORIGINAL[0]: status -> hashp = hashp
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: status -> hashp
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hashp
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: status
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: status
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: status
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771661
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (info -> dsize) * sizeof(HASHSEGMENT )
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) * sizeof ( VAR3 )
  ORIGINAL[1]: info -> dsize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(HASHSEGMENT )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: dsize
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: info
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: HASHSEGMENT
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772029
FRAGMENT_COUNT: 30
  ORIGINAL[0]: newElement != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: hctlv -> num_partitions != 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 != 0
  ORIGINAL[3]: hctlv -> num_partitions
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: !element_alloc(hashp,hctlv -> nelem_alloc)
  TYPE[4]: CALL
  TOKENIZED[4]: !element_alloc ( VAR1 , VAR2 -> VAR3 )
  ORIGINAL[5]: element_alloc(hashp,hctlv -> nelem_alloc)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 -> VAR3 )
  ORIGINAL[6]: hctlv -> nelem_alloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: hctlv -> freeList = newElement -> link
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 = VAR3 -> VAR4
  ORIGINAL[8]: hctlv -> freeList
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: newElement -> link
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: hctlv -> nentries++
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> nentries++
  ORIGINAL[11]: hctlv -> nentries
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: hctlv -> num_partitions != 0
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2 != 0
  ORIGINAL[13]: hctlv -> num_partitions
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: break;
  TYPE[14]: CONTROL_STRUCTURE
  TOKENIZED[14]: break ;
  ORIGINAL[15]: num_partitions
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: nelem_alloc
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: freeList
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: link
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: nentries
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: num_partitions
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: newElement
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: hctlv
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: hashp
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: hctlv
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: hctlv
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: newElement
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: hctlv
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: hctlv
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: newElement
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1

CENTER_NODE: 68719477565
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (((intptr_t )_vstart) & sizeof(long ) - 1) == 0 && (_len & sizeof(long ) - 1) == 0 && _val == 0 && _len <= 1024 && 1024 != 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( VAR1 ) VAR2 ) & sizeof ( long ) - 1 ) == 0 && ( VAR3 & sizeof ( long ) - 1 ) == 0 && VAR4 == 0 && VAR3 <= 1024 && 1024 != 0
  ORIGINAL[1]: (long *)_vstart
  TYPE[1]: CALL
  TOKENIZED[1]: ( long * ) VAR1
  ORIGINAL[2]: _vstart
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _vstart
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771689
FRAGMENT_COUNT: 3
  ORIGINAL[0]: *uteropexy_byliny[10] = {0}
  TYPE[0]: CALL
  TOKENIZED[0]: *uteropexy_byliny [ 10 ] = { 0 }
  ORIGINAL[1]: {0}
  TYPE[1]: CALL
  TOKENIZED[1]: { 0 }
  ORIGINAL[2]: uteropexy_byliny
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772269
FRAGMENT_COUNT: 8
  ORIGINAL[0]: hashp -> hctl -> max_dsize != (- 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3 != ( - 1 )
  ORIGINAL[1]: hashp -> hctl -> max_dsize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: hashp -> hctl -> dsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: hashp -> hctl -> dsize
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[4]: hashp -> hctl
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: hctl
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: dsize
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hashp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771096
FRAGMENT_COUNT: 9
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stat(dirpath, &st) == -1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[2]: stat(dirpath, &st)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , &st )
  ORIGINAL[3]: -1
  TYPE[3]: CALL
  TOKENIZED[3]: -1
  ORIGINAL[4]: retval = mkdir(dirpath, 0700)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[5]: mkdir(dirpath, 0700)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[6]: retval
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dirpath
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: retval
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064772438
FRAGMENT_COUNT: 15
  ORIGINAL[0]: hashp -> isshared
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: elog_start(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: elog_finish(22,\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( 22 , \
  ORIGINAL[3]: hashp -> tabname
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elog_start(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \
  ORIGINAL[5]: elog_finish(21,\
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( 21 , \
  ORIGINAL[6]: hashp -> tabname
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: isshared
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: tabname
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: tabname
  TYPE[9]: FIELD_IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: hashp
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: <global> __func__
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: hashp
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: <global> __func__
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: hashp
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 2
  ORIGINAL[0]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 )
  ORIGINAL[1]: 8 - 1
  TYPE[1]: CALL
  TOKENIZED[1]: 8 - 1

CENTER_NODE: 30064772163
FRAGMENT_COUNT: 8
  ORIGINAL[0]: hashp -> tabname
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: !hashp -> frozen && has_seq_scans(hashp)
  TYPE[1]: CALL
  TOKENIZED[1]: !hashp -> VAR1 && FUN1 ( VAR2 )
  ORIGINAL[2]: elog_finish(20,\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( 20 , \
  ORIGINAL[3]: hashp -> tabname
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: tabname
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hashp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hashp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640358
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640386
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771645
FRAGMENT_COUNT: 4
  ORIGINAL[0]: nBuckets = next_pow2_long((num_entries - 1) / 1 + 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( ( VAR2 - 1 ) / 1 + 1 )
  ORIGINAL[1]: next_pow2_long((num_entries - 1) / 1 + 1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 - 1 ) / 1 + 1 )
  ORIGINAL[2]: nBuckets
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: nSegments
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772454
FRAGMENT_COUNT: 2
  ORIGINAL[0]: 1L << my_log2(num)
  TYPE[0]: CALL
  TOKENIZED[0]: 1L << FUN1 ( VAR1 )
  ORIGINAL[1]: my_log2(num)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )

CENTER_NODE: 47244640356
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064772151
FRAGMENT_COUNT: 3
  ORIGINAL[0]: !status -> hashp -> frozen
  TYPE[0]: CALL
  TOKENIZED[0]: !status -> VAR1 -> VAR2
  ORIGINAL[1]: deregister_seq_scan(status -> hashp)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[2]: status -> hashp
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 30064771670
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: hashp -> keysize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: keysize
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: keyPtr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640347
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771778
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: hashp -> hash
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hash
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: keyPtr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772506
FRAGMENT_COUNT: 10
  ORIGINAL[0]: i >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 0
  ORIGINAL[1]: i--
  TYPE[1]: CALL
  TOKENIZED[1]: i--
  ORIGINAL[2]: seq_scan_level[i] >= nestDepth
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] >= VAR3
  ORIGINAL[3]: seq_scan_level[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: for (i = num_seq_scans - 1;i >= 0;i--)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = VAR2 - 1 ; VAR1 >= 0 ; i-- )
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> seq_scan_level
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: nestDepth
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771439
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (((intptr_t )_vstart) & sizeof(long ) - 1) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( ( VAR1 ) VAR2 ) & sizeof ( long ) - 1 ) == 0
  ORIGINAL[1]: _len & sizeof(long ) - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 & sizeof ( long ) - 1
  ORIGINAL[2]: sizeof(long ) - 1
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( long ) - 1
  ORIGINAL[3]: sizeof(long )
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( long )
  ORIGINAL[4]: _len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477111
FRAGMENT_COUNT: 6
  ORIGINAL[0]: hashp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: hash_stats(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: hashp -> hcxt
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477371
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (curElem = status -> curEntry) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 ) != ( ( void * ) 0 )
  ORIGINAL[1]: curBucket = status -> curBucket
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR1
  ORIGINAL[2]: status -> curBucket
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: curBucket
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: status
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: curBucket
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477632
FRAGMENT_COUNT: 5
  ORIGINAL[0]: num > (2147483647 / 2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > ( 2147483647 / 2 )
  ORIGINAL[1]: num = (2147483647 / 2)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( 2147483647 / 2 )
  ORIGINAL[2]: 2147483647 / 2
  TYPE[2]: CALL
  TOKENIZED[2]: 2147483647 / 2
  ORIGINAL[3]: num
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: num
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772419
FRAGMENT_COUNT: 8
  ORIGINAL[0]: hctlv -> num_partitions != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != 0
  ORIGINAL[1]: tas(&hctlv -> mutex)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &hctlv -> VAR1 )
  ORIGINAL[2]: &hctlv -> mutex
  TYPE[2]: CALL
  TOKENIZED[2]: &hctlv -> VAR1
  ORIGINAL[3]: s_lock(&hctlv -> mutex,\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( &hctlv -> VAR1 , \
  ORIGINAL[4]: &hctlv -> mutex
  TYPE[4]: CALL
  TOKENIZED[4]: &hctlv -> VAR1
  ORIGINAL[5]: hctlv -> mutex
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: mutex
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hctlv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064772054
FRAGMENT_COUNT: 3
  ORIGINAL[0]: hashp -> hctl -> nentries
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: hashp -> hctl
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nentries
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771835
FRAGMENT_COUNT: 7
  ORIGINAL[0]: currBucket -> hashvalue == hashvalue
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR2
  ORIGINAL[1]: match((((char *)currBucket) + (((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1)))),keyPtr,keysize)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( ( char * ) VAR1 ) + ( ( ( VAR2 ) ( sizeof ( VAR3 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) ) ) , VAR4 , VAR5 )
  ORIGINAL[2]: ((char *)currBucket) + (((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1)))
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( char * ) VAR1 ) + ( ( ( VAR2 ) ( sizeof ( VAR3 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) )
  ORIGINAL[3]: (char *)currBucket
  TYPE[3]: CALL
  TOKENIZED[3]: ( char * ) VAR1
  ORIGINAL[4]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) )
  ORIGINAL[5]: keyPtr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: keysize
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

