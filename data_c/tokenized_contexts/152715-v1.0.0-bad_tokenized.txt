# Tokenized code fragments for 152715-v1.0.0-bad
# Total center nodes processed: 34
# Total code fragments found: 146

CENTER_NODE: 68719476835
FRAGMENT_COUNT: 7
  ORIGINAL[0]: key1 -> p2p_dir
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key1 -> is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key1 -> is_circuit
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key1 -> circ
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: circ
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771358
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (guint )(key -> framenum)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 ) ( VAR2 -> VAR3 )
  ORIGINAL[1]: key -> framenum
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: framenum
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771276
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash = g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719476976
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> fragment_hash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064771392
FRAGMENT_COUNT: 4
  ORIGINAL[0]: key . offset = offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: key . offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477091
FRAGMENT_COUNT: 9
  ORIGINAL[0]: frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: (void )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void ) 0
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: getenv(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: frag -> len
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: frag
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: frag
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476939
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key -> p2p_dir = p2p_dir
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: key -> p2p_dir
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key -> p2p_dir = p2p_dir
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: key -> p2p_dir
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771450
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: conv
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771116
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476924
FRAGMENT_COUNT: 4
  ORIGINAL[0]: val -> key = key
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: val -> key
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771336
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pdu_counter = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> pdu_counter
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 68719477013
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771199
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: g_hash_table_destroy(stream_hash)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> stream_hash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064771583
FRAGMENT_COUNT: 3
  ORIGINAL[0]: frag -> pdu -> pdu_number
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: frag -> pdu
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu_number
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477026
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: circuit
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477083
FRAGMENT_COUNT: 10
  ORIGINAL[0]: !frag -> final_fragment
  TYPE[0]: CALL
  TOKENIZED[0]: !frag -> VAR1
  ORIGINAL[1]: process_reassembled_data(tvb,offset,pinfo,name,pdu -> fd_head,fit,update_col_infop,tree)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 , VAR5 -> VAR6 , VAR7 , VAR8 , VAR9 )
  ORIGINAL[2]: pdu -> fd_head
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pinfo
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: name
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: fit
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: update_col_infop
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: tree
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477034
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash_lookup(stream,framenum,offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: framenum
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 10
  ORIGINAL[0]: strlen(acrawl_bibliomanianism) < 1000 - strlen(stonesoup_command_str)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) < 1000 - FUN1 ( VAR2 )
  ORIGINAL[1]: stonesoup_fpipe != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: fgets(stonesoup_buffer,100,stonesoup_fpipe) != 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , 100 , VAR2 ) != 0
  ORIGINAL[3]: fgets(stonesoup_buffer,100,stonesoup_fpipe)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , 100 , VAR2 )
  ORIGINAL[4]: pclose(stonesoup_fpipe)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: stonesoup_fpipe
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_buffer
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_fpipe
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_fpipe
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: stonesoup_trace
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640285
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771293
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key . p2p_dir = p2p_dir
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: key . p2p_dir
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771385
FRAGMENT_COUNT: 5
  ORIGINAL[0]: fragment_hash == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: g_assertion_message_expr(((gchar *)0),\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( VAR1 * ) 0 ) , \
  ORIGINAL[2]: (gchar *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 * ) 0
  ORIGINAL[3]: (const char *)__func__
  TYPE[3]: CALL
  TOKENIZED[3]: ( const char * ) VAR1
  ORIGINAL[4]: <global> __func__
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064771373
FRAGMENT_COUNT: 5
  ORIGINAL[0]: key1 -> stream == key2 -> stream && key1 -> framenum == key2 -> framenum && key1 -> offset == key2 -> offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2 && VAR1 -> VAR4 == VAR3 -> VAR4 && VAR1 -> VAR5 == VAR3 -> VAR5
  ORIGINAL[1]: key1 -> stream == key2 -> stream && key1 -> framenum == key2 -> framenum
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == VAR3 -> VAR2 && VAR1 -> VAR4 == VAR3 -> VAR4
  ORIGINAL[2]: key1 -> offset == key2 -> offset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[3]: key1 -> offset
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: key2 -> offset
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2

CENTER_NODE: 30064771572
FRAGMENT_COUNT: 6
  ORIGINAL[0]: frag -> pdu -> fd_head
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: frag -> pdu
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: fd_head
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: frag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: frag
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771280
FRAGMENT_COUNT: 4
  ORIGINAL[0]: key . circ . circuit = circuit
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 = VAR3
  ORIGINAL[1]: key . circ . circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 . VAR3
  ORIGINAL[2]: circuit
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771161
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *stonesoup_tainted_buff != 0
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff != 0
  ORIGINAL[1]: (*stonesoup_tainted_buff)[stonesoup_lsize] = '\\0'
  TYPE[1]: CALL
  TOKENIZED[1]: ( *stonesoup_tainted_buff ) [ VAR1 ] = '\\0'
  ORIGINAL[2]: (*stonesoup_tainted_buff)[stonesoup_lsize]
  TYPE[2]: CALL
  TOKENIZED[2]: ( *stonesoup_tainted_buff ) [ VAR1 ]
  ORIGINAL[3]: *stonesoup_tainted_buff
  TYPE[3]: CALL
  TOKENIZED[3]: *stonesoup_tainted_buff
  ORIGINAL[4]: stonesoup_lsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771437
FRAGMENT_COUNT: 9
  ORIGINAL[0]: stream == ((void *)0)?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) ? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: stream == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: (void )0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void ) 0
  ORIGINAL[4]: getenv(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \
  ORIGINAL[5]: getenv(\
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( \
  ORIGINAL[6]: getenv(\
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( \
  ORIGINAL[7]: (void *)0
  TYPE[7]: CALL
  TOKENIZED[7]: ( void * ) 0
  ORIGINAL[8]: stream
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771453
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cleanup_fragment_hash()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: stream_cleanup_pdu_data()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )

CENTER_NODE: 68719476981
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash = g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719477001
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(stream_pdu_fragment_t )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: val
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream_pdu_fragment_t
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771171
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (guint )((unsigned long )key -> circ . circuit)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 ) ( ( unsigned long ) VAR2 -> VAR3 . VAR4 )
  ORIGINAL[1]: (unsigned long )key -> circ . circuit
  TYPE[1]: CALL
  TOKENIZED[1]: ( unsigned long ) VAR1 -> VAR2 . VAR3
  ORIGINAL[2]: key -> circ . circuit
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 . VAR3

CENTER_NODE: 68719476951
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(stream_pdu_t )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: pdu
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream_pdu_t
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477061
FRAGMENT_COUNT: 5
  ORIGINAL[0]: frag_data = fragment_hash_insert(stream,framenum,offset,tvb_reported_length(tvb))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 , FUN2 ( VAR5 ) )
  ORIGINAL[1]: frag_data -> pdu
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: frag_data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: frag_data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

