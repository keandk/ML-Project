# Tokenized code fragments for 153758-v1.0.0-bad
# Total center nodes processed: 35
# Total code fragments found: 149

CENTER_NODE: 68719477049
FRAGMENT_COUNT: 9
  ORIGINAL[0]: frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: (void )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void ) 0
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: getenv(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: frag -> pdu
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: frag
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: frag
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771382
FRAGMENT_COUNT: 4
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: except_throw(1,4,(ep_strdup_printf(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( 1 , 4 , ( FUN2 ( \
  ORIGINAL[3]: ep_strdup_printf(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 11
  ORIGINAL[0]: key1 -> p2p_dir != key2 -> p2p_dir
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != VAR3 -> VAR2
  ORIGINAL[1]: key1 -> p2p_dir
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key2 -> p2p_dir
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: p2p_dir
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key2
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: key1
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: key1
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771334
FRAGMENT_COUNT: 7
  ORIGINAL[0]: fragment_hash == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: g_assertion_message_expr(((gchar *)0),\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( ( VAR1 * ) 0 ) , \
  ORIGINAL[3]: (gchar *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 * ) 0
  ORIGINAL[4]: (const char *)__func__
  TYPE[4]: CALL
  TOKENIZED[4]: ( const char * ) VAR1
  ORIGINAL[5]: <global> fragment_hash
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> __func__
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1

CENTER_NODE: 30064771330
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771358
FRAGMENT_COUNT: 6
  ORIGINAL[0]: key -> offset = offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: key -> offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: offset
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: offset
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stonesoup_tainted_file != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: *stonesoup_tainted_buff = ((char *)(malloc(sizeof(char ) * (stonesoup_lsize + 1))))
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff = ( ( char * ) ( FUN1 ( sizeof ( char ) * ( VAR1 + 1 ) ) ) )
  ORIGINAL[2]: *stonesoup_tainted_buff
  TYPE[2]: CALL
  TOKENIZED[2]: *stonesoup_tainted_buff
  ORIGINAL[3]: (char *)(malloc(sizeof(char ) * (stonesoup_lsize + 1)))
  TYPE[3]: CALL
  TOKENIZED[3]: ( char * ) ( FUN1 ( sizeof ( char ) * ( VAR1 + 1 ) ) )
  ORIGINAL[4]: stonesoup_tainted_buff
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key . offset = offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: key . offset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: offset
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476896
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(stream_key_t )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: key
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream_key_t
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771514
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (void )(frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: ( void ) ( frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: frag?((void )0) : ((getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[2]: frag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771463
FRAGMENT_COUNT: 6
  ORIGINAL[0]: fd_head != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: pdu -> fd_head = fd_head
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: pdu -> fd_head
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: fd_head
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pdu
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: fd_head
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771483
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: except_throw(1,4,(ep_strdup_printf(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( 1 , 4 , ( FUN2 ( \
  ORIGINAL[2]: ep_strdup_printf(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \

CENTER_NODE: 30064771314
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *key1 = (const fragment_key_t *)a
  TYPE[0]: CALL
  TOKENIZED[0]: *key1 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const fragment_key_t *)a
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477097
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stonesoup_ss_i < strlen(saiff_shorer)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < FUN1 ( VAR2 )
  ORIGINAL[1]: tracepoint(stonesoup_trace, variable_signed_integral, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[2]: (int)saiff_shorer[stonesoup_ss_i]
  TYPE[2]: CALL
  TOKENIZED[2]: ( int ) VAR1 [ VAR2 ]
  ORIGINAL[3]: &(saiff_shorer[stonesoup_ss_i])
  TYPE[3]: CALL
  TOKENIZED[3]: & ( VAR1 [ VAR2 ] )
  ORIGINAL[4]: stonesoup_trace
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: variable_signed_integral
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771270
FRAGMENT_COUNT: 8
  ORIGINAL[0]: key -> is_circuit = !0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = !0
  ORIGINAL[1]: key -> is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: !0
  TYPE[2]: CALL
  TOKENIZED[2]: !0
  ORIGINAL[3]: is_circuit
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 4
  ORIGINAL[0]: pdu -> id = pdu_counter++
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = pdu_counter++
  ORIGINAL[1]: pdu -> id
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu_counter++
  TYPE[2]: CALL
  TOKENIZED[2]: pdu_counter++
  ORIGINAL[3]: pdu
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 1
  ORIGINAL[0]: stream_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )

CENTER_NODE: 68719477045
FRAGMENT_COUNT: 9
  ORIGINAL[0]: frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: (void )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void ) 0
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: getenv(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \
  ORIGINAL[5]: (void *)0
  TYPE[5]: CALL
  TOKENIZED[5]: ( void * ) 0
  ORIGINAL[6]: frag -> len
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: frag
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: frag
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771340
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash = g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719476845
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *epitrope_regioide = 0
  TYPE[0]: CALL
  TOKENIZED[0]: *epitrope_regioide = 0
  ORIGINAL[1]: &quickwork_poker
  TYPE[1]: CALL
  TOKENIZED[1]: &quickwork_poker
  ORIGINAL[2]: <global> quickwork_poker
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: quickwork_poker
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476884
FRAGMENT_COUNT: 5
  ORIGINAL[0]: g_hash_table_insert(stream_hash,key,val)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: key
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771406
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cleanup_fragment_hash()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: stream_cleanup_pdu_data()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )

CENTER_NODE: 68719476860
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash = g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719476903
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pdu_counter = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> pdu_counter
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771173
FRAGMENT_COUNT: 6
  ORIGINAL[0]: key -> circ . circuit
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 . VAR3
  ORIGINAL[1]: key -> circ
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: circ
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: circuit
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771402
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: circuit
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640279
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476983
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: conv
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771396
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064771414
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash_lookup(stream,framenum,offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: framenum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: offset
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771305
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ((guint )((unsigned long )(key -> stream))) + ((guint )(key -> framenum)) + ((guint )(key -> offset))
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( VAR1 ) ( ( unsigned long ) ( VAR2 -> VAR3 ) ) ) + ( ( VAR1 ) ( VAR2 -> VAR4 ) ) + ( ( VAR1 ) ( VAR2 -> VAR5 ) )
  ORIGINAL[1]: ((guint )((unsigned long )(key -> stream))) + ((guint )(key -> framenum))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) ( ( unsigned long ) ( VAR2 -> VAR3 ) ) ) + ( ( VAR1 ) ( VAR2 -> VAR4 ) )
  ORIGINAL[2]: (guint )(key -> offset)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) ( VAR2 -> VAR3 )

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key . is_circuit
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: is_circuit
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771101
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stat(dirpath, &st) == -1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[1]: retval = mkdir(dirpath, 0700)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[2]: mkdir(dirpath, 0700)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[3]: retval
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771243
FRAGMENT_COUNT: 4
  ORIGINAL[0]: key . circ . conv = conv
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 . VAR3 = VAR3
  ORIGINAL[1]: key . circ . conv
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 . VAR3
  ORIGINAL[2]: conv
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

