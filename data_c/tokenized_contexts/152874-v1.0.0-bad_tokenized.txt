# Tokenized code fragments for 152874-v1.0.0-bad
# Total center nodes processed: 33
# Total code fragments found: 159

CENTER_NODE: 30064771228
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 68719477085
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771561
FRAGMENT_COUNT: 18
  ORIGINAL[0]: state -> compression == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: state -> have
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> compression == 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == 1
  ORIGINAL[3]: state -> compression
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: raw_read(state,state -> out,state -> size,&state -> have) == - 1
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , &state -> VAR4 ) == - 1
  ORIGINAL[5]: raw_read(state,state -> out,state -> size,&state -> have)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , &state -> VAR4 )
  ORIGINAL[6]: state -> out
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: state -> size
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: &state -> have
  TYPE[8]: CALL
  TOKENIZED[8]: &state -> VAR1
  ORIGINAL[9]: state -> have
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: - 1
  TYPE[10]: CALL
  TOKENIZED[10]: - 1
  ORIGINAL[11]: out
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: size
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: have
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: state
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: state
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: state
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: state
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 68719477017
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> fast_seek = seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: stream -> fast_seek
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: seek
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771109
FRAGMENT_COUNT: 5
  ORIGINAL[0]: retval == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: filepath = (char*) malloc (size_filepath * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[2]: (char*) malloc (size_filepath * sizeof(char))
  TYPE[2]: CALL
  TOKENIZED[2]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[3]: malloc (size_filepath * sizeof(char))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476849
FRAGMENT_COUNT: 8
  ORIGINAL[0]: ret <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: *have < count
  TYPE[1]: CALL
  TOKENIZED[1]: *have < VAR1
  ORIGINAL[2]: ret < 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < 0
  ORIGINAL[3]: break;
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: break ;
  ORIGINAL[4]: ret
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ret
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ret
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ret
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771651
FRAGMENT_COUNT: 7
  ORIGINAL[0]: buf == ((void *)0) || len < 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 < 1
  ORIGINAL[1]: buf == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: len < 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < 1
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: file -> err
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: err
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: file
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477194
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> err
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: err
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 9
  ORIGINAL[0]: state -> fast_seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: fast_seek_header(state,state -> raw_pos - (state -> avail_in) - (state -> have),state -> pos,1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR1 -> VAR2 - ( VAR1 -> VAR3 ) - ( VAR1 -> VAR4 ) , VAR1 -> VAR5 , 1 )
  ORIGINAL[2]: state -> pos
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: state -> pos
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: pos
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: state
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771460
FRAGMENT_COUNT: 5
  ORIGINAL[0]: fd = open(path,0 | 0,0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 )
  ORIGINAL[1]: open(path,0 | 0,0)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 0 | 0 , 0 )
  ORIGINAL[2]: 0 | 0
  TYPE[2]: CALL
  TOKENIZED[2]: 0 | 0
  ORIGINAL[3]: fd
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: path
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477088
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> raw_pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: raw_pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771592
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> is_compressed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: is_compressed
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c >= 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97
  ORIGINAL[1]: c <= 122
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <= 122
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771747
FRAGMENT_COUNT: 3
  ORIGINAL[0]: open(path,0 | 0,0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 | 0 , 0 )
  ORIGINAL[1]: 0 | 0
  TYPE[1]: CALL
  TOKENIZED[1]: 0 | 0
  ORIGINAL[2]: path
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771229
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 30064771226
FRAGMENT_COUNT: 7
  ORIGINAL[0]: raw_read(state,state -> in,state -> size,((unsigned int *)(&state -> avail_in))) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , ( ( unsigned int * ) ( &state -> VAR4 ) ) ) == - 1
  ORIGINAL[1]: state -> next_in = state -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[2]: state -> next_in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: state -> in
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: next_in
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771727
FRAGMENT_COUNT: 5
  ORIGINAL[0]: fh -> err != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != 0
  ORIGINAL[1]: fh -> err_info == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: fh -> err_info
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0

CENTER_NODE: 30064771535
FRAGMENT_COUNT: 4
  ORIGINAL[0]: lseek(file -> fd,off,0) == (- 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR3 , 0 ) == ( - 1 )
  ORIGINAL[1]: fast_seek_reset(file)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: file
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477082
FRAGMENT_COUNT: 3
  ORIGINAL[0]: file_seek(file,delta,1,err)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 1 , VAR3 )
  ORIGINAL[1]: file
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: delta
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 3
  ORIGINAL[0]: state -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: have
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: state
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476945
FRAGMENT_COUNT: 4
  ORIGINAL[0]: state -> eof
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: state -> avail_in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: avail_in
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: state
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771742
FRAGMENT_COUNT: 5
  ORIGINAL[0]: file -> fd = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = - 1
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: fd
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: file
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476882
FRAGMENT_COUNT: 6
  ORIGINAL[0]: pos > item -> out
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: item -> out
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: smallest = item
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: item
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: smallest
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: item
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771638
FRAGMENT_COUNT: 4
  ORIGINAL[0]: file -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> have--
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> have--
  ORIGINAL[2]: file -> have
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 1
  ORIGINAL[0]: (shmid = shmget(key, shmsz, IPC_CREAT | 0666)) < 0
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , VAR3 , VAR4 | 0666 ) ) < 0

CENTER_NODE: 68719477118
FRAGMENT_COUNT: 6
  ORIGINAL[0]: file -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: len -= n
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -= VAR2
  ORIGINAL[2]: n
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: n
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: n
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476964
FRAGMENT_COUNT: 4
  ORIGINAL[0]: want = 4096
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 4096
  ORIGINAL[1]: &nothingness_declaratives
  TYPE[1]: CALL
  TOKENIZED[1]: &nothingness_declaratives
  ORIGINAL[2]: <global> nothingness_declaratives
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: nothingness_declaratives
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771768
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fd != - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: fd
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477188
FRAGMENT_COUNT: 6
  ORIGINAL[0]: file -> eof && file -> avail_in == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0
  ORIGINAL[1]: file -> eof
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file -> avail_in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file -> have
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: have
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771581
FRAGMENT_COUNT: 7
  ORIGINAL[0]: fstat(stream -> fd,statb) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR3 ) == - 1
  ORIGINAL[1]: fstat(stream -> fd,statb)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , VAR3 )
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: err != ((void *)0)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: - 1
  TYPE[5]: CALL
  TOKENIZED[5]: - 1
  ORIGINAL[6]: err
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476798
FRAGMENT_COUNT: 5
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: stonesoup_envKey != NULL
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: stonesoup_envKey
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_envKey
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476895
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !item || item -> out < out_pos
  TYPE[0]: CALL
  TOKENIZED[0]: !item || VAR1 -> VAR2 < VAR3
  ORIGINAL[1]: *val = (struct fast_seek_point *)(g_malloc_n(1,sizeof(struct fast_seek_point )))
  TYPE[1]: CALL
  TOKENIZED[1]: *val = ( struct VAR1 * ) ( FUN1 ( 1 , sizeof ( struct VAR1 ) ) )
  ORIGINAL[2]: (struct fast_seek_point *)(g_malloc_n(1,sizeof(struct fast_seek_point )))
  TYPE[2]: CALL
  TOKENIZED[2]: ( struct VAR1 * ) ( FUN1 ( 1 , sizeof ( struct VAR1 ) ) )
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: val
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: val
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

