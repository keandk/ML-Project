# Tokenized code fragments for 153787-v1.0.0-bad
# Total center nodes processed: 42
# Total code fragments found: 168

CENTER_NODE: 30064771976
FRAGMENT_COUNT: 4
  ORIGINAL[0]: status -> hashp = hashp
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: status -> hashp
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hashp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: status
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 5
  ORIGINAL[0]: c >= 97
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640335
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640379
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640303
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477140
FRAGMENT_COUNT: 4
  ORIGINAL[0]: hashp -> hash
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hash
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: keyPtr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hashp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771096
FRAGMENT_COUNT: 9
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stat(dirpath, &st) == -1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[2]: stat(dirpath, &st)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , &st )
  ORIGINAL[3]: -1
  TYPE[3]: CALL
  TOKENIZED[3]: -1
  ORIGINAL[4]: retval = mkdir(dirpath, 0700)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[5]: mkdir(dirpath, 0700)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[6]: retval
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dirpath
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: retval
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064772506
FRAGMENT_COUNT: 8
  ORIGINAL[0]: stonesoup_data.buff_pointer
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: strlen( stonesoup_data.buff_pointer)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 . VAR2 )
  ORIGINAL[2]: stonesoup_data.buff_pointer
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: buff_pointer
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_data
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_data
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_data
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_data
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477528
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: tmpElement -> link
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: prevElement = tmpElement
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: tmpElement
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: prevElement
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tmpElement
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: tmpElement
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: tmpElement
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477111
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(HASHHDR )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: HASHHDR
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771486
FRAGMENT_COUNT: 4
  ORIGINAL[0]: hctl -> sshift = 8
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 8
  ORIGINAL[1]: hctl -> sshift
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sshift
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hctl
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771171
FRAGMENT_COUNT: 1
  ORIGINAL[0]: buffer[64]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 64 ]

CENTER_NODE: 30064772359
FRAGMENT_COUNT: 3
  ORIGINAL[0]: hashp -> isshared
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: elog_start(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: <global> __func__
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771624
FRAGMENT_COUNT: 4
  ORIGINAL[0]: elementAllocCnt = (choose_nelem_alloc(entrysize))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( FUN1 ( VAR2 ) )
  ORIGINAL[1]: choose_nelem_alloc(entrysize)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: elementAllocCnt
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: entrysize
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477295
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (curElem = status -> curEntry) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 ) != ( ( void * ) 0 )
  ORIGINAL[1]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 )
  ORIGINAL[2]: (intptr_t )(8 - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) ( 8 - 1 )
  ORIGINAL[3]: intptr_t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640346
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772416
FRAGMENT_COUNT: 2
  ORIGINAL[0]: i < num_seq_scans
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: (bool )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) 0

CENTER_NODE: 30064771956
FRAGMENT_COUNT: 10
  ORIGINAL[0]: &hctlv -> mutex
  TYPE[0]: CALL
  TOKENIZED[0]: &hctlv -> VAR1
  ORIGINAL[1]: hctlv -> mutex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: &hctlv -> mutex
  TYPE[2]: CALL
  TOKENIZED[2]: &hctlv -> VAR1
  ORIGINAL[3]: hctlv -> mutex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: hctlv -> num_partitions != 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 != 0
  ORIGINAL[5]: (volatile slock_t *)(&hctlv -> mutex)
  TYPE[5]: CALL
  TOKENIZED[5]: ( volatile VAR1 * ) ( &hctlv -> VAR2 )
  ORIGINAL[6]: &hctlv -> mutex
  TYPE[6]: CALL
  TOKENIZED[6]: &hctlv -> VAR1
  ORIGINAL[7]: hctlv -> mutex
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: &hctlv -> mutex
  TYPE[8]: CALL
  TOKENIZED[8]: &hctlv -> VAR1
  ORIGINAL[9]: hctlv -> mutex
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2

CENTER_NODE: 30064771488
FRAGMENT_COUNT: 5
  ORIGINAL[0]: elementSize = ((((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))) + (((intptr_t )entrysize) + (8 - 1) & ~((intptr_t )(8 - 1))))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( ( ( VAR2 ) ( sizeof ( VAR3 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) ) + ( ( ( VAR2 ) VAR4 ) + ( 8 - 1 ) & ~ ( ( VAR2 ) ( 8 - 1 ) ) ) )
  ORIGINAL[1]: (((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))) + (((intptr_t )entrysize) + (8 - 1) & ~((intptr_t )(8 - 1)))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) ) ) + ( ( ( VAR1 ) VAR3 ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) ) )
  ORIGINAL[2]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) )
  ORIGINAL[3]: ((intptr_t )entrysize) + (8 - 1) & ~((intptr_t )(8 - 1))
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( VAR1 ) VAR2 ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) )
  ORIGINAL[4]: elementSize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477698
FRAGMENT_COUNT: 4
  ORIGINAL[0]: CurrentDynaHashCxt = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( void * ) 0 )
  ORIGINAL[1]: functioned_wickiups = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: <global> functioned_wickiups
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: functioned_wickiups
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640387
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771661
FRAGMENT_COUNT: 7
  ORIGINAL[0]: nDirEntries < nSegments
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: nDirEntries <<= 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 <<= 1
  ORIGINAL[2]: while (nDirEntries < nSegments)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: while ( VAR1 < VAR2 )
  ORIGINAL[3]: nDirEntries
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: nSegments
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: nDirEntries
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: nDirEntries
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477558
FRAGMENT_COUNT: 4
  ORIGINAL[0]: my_log2(num)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: num
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: num
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: num
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772526
FRAGMENT_COUNT: 1
  ORIGINAL[0]: *seq_scan_tables[100]
  TYPE[0]: CALL
  TOKENIZED[0]: *seq_scan_tables [ 100 ]

CENTER_NODE: 30064771557
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !hashp -> dir
  TYPE[0]: CALL
  TOKENIZED[0]: !hashp -> VAR1
  ORIGINAL[1]: hashp -> dir = ((HASHSEGMENT *)((hashp -> alloc)((hctl -> dsize) * sizeof(HASHSEGMENT ))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( VAR3 * ) ( ( VAR1 -> VAR4 ) ( ( VAR5 -> VAR6 ) * sizeof ( VAR3 ) ) ) )
  ORIGINAL[2]: hashp -> dir
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (HASHSEGMENT *)((hashp -> alloc)((hctl -> dsize) * sizeof(HASHSEGMENT )))
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 * ) ( ( VAR2 -> VAR3 ) ( ( VAR4 -> VAR5 ) * sizeof ( VAR1 ) ) )
  ORIGINAL[4]: (hashp -> alloc)((hctl -> dsize) * sizeof(HASHSEGMENT ))
  TYPE[4]: CALL
  TOKENIZED[4]: ( VAR1 -> VAR2 ) ( ( VAR3 -> VAR4 ) * sizeof ( VAR5 ) )

CENTER_NODE: 68719477344
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !status -> hashp -> frozen
  TYPE[0]: CALL
  TOKENIZED[0]: !status -> VAR1 -> VAR2
  ORIGINAL[1]: status -> hashp
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hashp
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: status
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772206
FRAGMENT_COUNT: 5
  ORIGINAL[0]: p != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: *_vstart = (void *)(((char *)p) + old_dirsize)
  TYPE[1]: CALL
  TOKENIZED[1]: *_vstart = ( void * ) ( ( ( char * ) VAR1 ) + VAR2 )
  ORIGINAL[2]: (void *)(((char *)p) + old_dirsize)
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) ( ( ( char * ) VAR1 ) + VAR2 )
  ORIGINAL[3]: _vstart
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 5
  ORIGINAL[0]: hashp -> hash == string_hash
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3
  ORIGINAL[1]: hashp -> keycopy = memcpy
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3
  ORIGINAL[2]: hashp -> keycopy
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: memcpy
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: flags
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477116
FRAGMENT_COUNT: 6
  ORIGINAL[0]: hashp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: hash_stats(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: hashp -> hcxt
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: hcxt
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hashp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477279
FRAGMENT_COUNT: 3
  ORIGINAL[0]: hashp -> hctl
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hctl
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: hashp
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772083
FRAGMENT_COUNT: 8
  ORIGINAL[0]: hashp -> tabname
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: !hashp -> frozen && has_seq_scans(hashp)
  TYPE[1]: CALL
  TOKENIZED[1]: !hashp -> VAR1 && FUN1 ( VAR2 )
  ORIGINAL[2]: elog_finish(20,\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( 20 , \
  ORIGINAL[3]: hashp -> tabname
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: tabname
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: hashp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hashp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hashp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771835
FRAGMENT_COUNT: 7
  ORIGINAL[0]: currBucket != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1) & ~((intptr_t )(8 - 1))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 ) & ~ ( ( VAR1 ) ( 8 - 1 ) )
  ORIGINAL[2]: ((intptr_t )(sizeof(HASHELEMENT ))) + (8 - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( VAR1 ) ( sizeof ( VAR2 ) ) ) + ( 8 - 1 )
  ORIGINAL[3]: (intptr_t )(sizeof(HASHELEMENT ))
  TYPE[3]: CALL
  TOKENIZED[3]: ( VAR1 ) ( sizeof ( VAR2 ) )
  ORIGINAL[4]: 8 - 1
  TYPE[4]: CALL
  TOKENIZED[4]: 8 - 1
  ORIGINAL[5]: ~((intptr_t )(8 - 1))
  TYPE[5]: CALL
  TOKENIZED[5]: ~ ( ( VAR1 ) ( 8 - 1 ) )
  ORIGINAL[6]: intptr_t
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477555
FRAGMENT_COUNT: 2
  ORIGINAL[0]: my_log2(num)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: num
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772365
FRAGMENT_COUNT: 7
  ORIGINAL[0]: num > 9223372036854775807L / 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 9223372036854775807L / 2
  ORIGINAL[1]: 9223372036854775807L / 2
  TYPE[1]: CALL
  TOKENIZED[1]: 9223372036854775807L / 2
  ORIGINAL[2]: num = 9223372036854775807L / 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 9223372036854775807L / 2
  ORIGINAL[3]: 9223372036854775807L / 2
  TYPE[3]: CALL
  TOKENIZED[3]: 9223372036854775807L / 2
  ORIGINAL[4]: num
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: num
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477371
FRAGMENT_COUNT: 8
  ORIGINAL[0]: hctl -> max_bucket
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: hctl -> nsegs
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hctl -> dsize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: !(hashp -> dir[new_segnum] = seg_alloc(hashp))
  TYPE[3]: CALL
  TOKENIZED[3]: ! ( VAR1 -> VAR2 [ VAR3 ] = FUN1 ( VAR1 ) )
  ORIGINAL[4]: hctl -> nsegs
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nsegs
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: hctl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: hctl
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 5
  ORIGINAL[0]: strncmp(key1,key2,keysize - 1)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 - 1 )
  ORIGINAL[1]: keysize - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 1
  ORIGINAL[2]: key1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: keysize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477483
FRAGMENT_COUNT: 6
  ORIGINAL[0]: !segp
  TYPE[0]: CALL
  TOKENIZED[0]: !segp
  ORIGINAL[1]: (intptr_t )_vstart
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 ) VAR2
  ORIGINAL[2]: _vstart
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: _vstart
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: _vstart
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: _vstart
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771673
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (hashp -> hash)(keyPtr,hashp -> keysize)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 ) ( VAR3 , VAR1 -> VAR4 )
  ORIGINAL[1]: hashp -> hash
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hashp -> keysize
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: keyPtr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

