# Tokenized code fragments for 153139-v1.0.0-bad
# Total center nodes processed: 142
# Total code fragments found: 519

CENTER_NODE: 47244640833
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771306
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640675
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640832
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640437
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640976
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477361
FRAGMENT_COUNT: 29
  ORIGINAL[0]: !lexleft
  TYPE[0]: CALL
  TOKENIZED[0]: !lexleft
  ORIGINAL[1]: mbrtowc(&_wc,lexptr,lexleft,&mbs)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &_wc , VAR1 , VAR2 , &mbs )
  ORIGINAL[2]: &_wc
  TYPE[2]: CALL
  TOKENIZED[2]: &_wc
  ORIGINAL[3]: &mbs
  TYPE[3]: CALL
  TOKENIZED[3]: &mbs
  ORIGINAL[4]: <global> lexptr
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> lexptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> lexptr
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> lexptr
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> lexptr
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> lexptr
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> lexptr
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> lexptr
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> lexptr
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> lexptr
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> lexptr
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> lexptr
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> lexptr
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1
  ORIGINAL[17]: <global> lexptr
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: <global> VAR1
  ORIGINAL[18]: <global> lexptr
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: <global> VAR1
  ORIGINAL[19]: <global> lexptr
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: <global> VAR1
  ORIGINAL[20]: <global> lexptr
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1
  ORIGINAL[21]: <global> lexptr
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: <global> VAR1
  ORIGINAL[22]: <global> lexptr
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: <global> VAR1
  ORIGINAL[23]: <global> lexptr
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: <global> VAR1
  ORIGINAL[24]: <global> lexptr
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: <global> VAR1
  ORIGINAL[25]: <global> lexptr
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: <global> VAR1
  ORIGINAL[26]: <global> lexleft
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: <global> VAR1
  ORIGINAL[27]: <global> lexptr
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: <global> VAR1
  ORIGINAL[28]: <global> lexptr
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: <global> VAR1

CENTER_NODE: 47244640436
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476818
FRAGMENT_COUNT: 3
  ORIGINAL[0]: WCHAR=274
  TYPE[0]: CALL
  TOKENIZED[0]: WCHAR=274
  ORIGINAL[1]: CSET=275
  TYPE[1]: CALL
  TOKENIZED[1]: CSET=275
  ORIGINAL[2]: CSET
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640290
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640754
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775130
FRAGMENT_COUNT: 9
  ORIGINAL[0]: d -> tokens[pos . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: rarray[i] = match_anychar(d,s,pos,idx)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[2]: rarray[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: match_anychar(d,s,pos,idx)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[4]: rarray
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: rarray
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: rarray
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719479620
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfaparse(s,len,d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: s
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640587
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478301
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (s -> elems[j] . constraint >> 2 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[1]: separate_contexts |= 4
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 4
  ORIGINAL[2]: separate_contexts
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: separate_contexts
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: separate_contexts
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: separate_contexts
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477922
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: branch()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: addtok(OR)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: OR
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719478136
FRAGMENT_COUNT: 9
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> sindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> salloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> sindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> states
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> salloc
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: sindex
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476836
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640306
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771201
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: s[i] = ~s[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[2]: s[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: ~s[i]
  TYPE[3]: CALL
  TOKENIZED[3]: ~s [ VAR1 ]
  ORIGINAL[4]: s[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]

CENTER_NODE: 68719476838
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: charclass
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775733
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: for (i = 0;cpp[i] != ((void *)0);++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR2 [ VAR1 ] != ( ( void * ) 0 ) ; ++i )
  ORIGINAL[3]: cpp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775521
FRAGMENT_COUNT: 15
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: free((p -> range_ends))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[2]: p -> range_ends
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: range_ends
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: p
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: p
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: p
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: p
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: p
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: p
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1

CENTER_NODE: 30064775465
FRAGMENT_COUNT: 11
  ORIGINAL[0]: d -> fails[s]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: d -> mb_cur_max > 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 > 1
  ORIGINAL[2]: d -> fails[s]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: fails
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640621
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480147
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775707
FRAGMENT_COUNT: 19
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: result = (xrealloc(old,oldsize + newsize + 1))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 , VAR3 + VAR4 + 1 ) )
  ORIGINAL[2]: xrealloc(old,oldsize + newsize + 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 + VAR3 + 1 )
  ORIGINAL[3]: oldsize + newsize + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + VAR2 + 1
  ORIGINAL[4]: oldsize + newsize
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 + VAR2
  ORIGINAL[5]: memcpy((result + oldsize),new,newsize + 1)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( ( VAR1 + VAR2 ) , VAR3 , VAR4 + 1 )
  ORIGINAL[6]: result + oldsize
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 + VAR2
  ORIGINAL[7]: newsize + 1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 + 1
  ORIGINAL[8]: newsize
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: old
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: result
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: old
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: oldsize
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: newsize
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: result
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: oldsize
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: new
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: newsize
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: result
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 30064776358
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064772764
FRAGMENT_COUNT: 29
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: dfa -> nmultibyte_prop <= dfa -> tindex + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[2]: dfa -> nmultibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> tindex + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 + 1
  ORIGINAL[4]: dfa -> nmultibyte_prop
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nmultibyte_prop
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> dfa
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> dfa
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> dfa
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> dfa
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> dfa
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> dfa
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1
  ORIGINAL[14]: <global> dfa
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: <global> dfa
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> dfa
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1
  ORIGINAL[17]: <global> dfa
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: <global> VAR1
  ORIGINAL[18]: <global> dfa
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: <global> VAR1
  ORIGINAL[19]: <global> dfa
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: <global> VAR1
  ORIGINAL[20]: <global> dfa
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1
  ORIGINAL[21]: <global> dfa
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: <global> VAR1
  ORIGINAL[22]: <global> dfa
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: <global> VAR1
  ORIGINAL[23]: <global> dfa
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: <global> VAR1
  ORIGINAL[24]: <global> dfa
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: <global> VAR1
  ORIGINAL[25]: <global> dfa
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: <global> VAR1
  ORIGINAL[26]: <global> dfa
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: <global> VAR1
  ORIGINAL[27]: <global> dfa
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: <global> VAR1
  ORIGINAL[28]: <global> dfa
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: <global> VAR1

CENTER_NODE: 47244640651
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640328
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774900
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mbclen = (mblen_buf[idx] == 0?1 : mblen_buf[idx])
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( VAR2 [ VAR3 ] == 0?1 : VAR2 [ VAR3 ] )
  ORIGINAL[1]: mblen_buf[idx] == 0?1 : mblen_buf[idx]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] == 0?1 : VAR1 [ VAR2 ]
  ORIGINAL[2]: mblen_buf[idx] == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] == 0
  ORIGINAL[3]: mblen_buf[idx]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: mbclen
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640267
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 2
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 30064773742
FRAGMENT_COUNT: 13
  ORIGINAL[0]: d -> follows
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *d -> follows
  TYPE[1]: CALL
  TOKENIZED[1]: *d -> VAR1
  ORIGINAL[2]: *d -> follows
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1
  ORIGINAL[3]: j < nlastpos[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 < VAR2 [ - 1 ]
  ORIGINAL[4]: d -> follows[pos[j] . index]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 [ VAR4 ] . VAR5 ]
  ORIGINAL[5]: d -> follows[pos[j] . index]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 [ VAR4 ] . VAR5 ]
  ORIGINAL[6]: d -> follows
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> follows[pos[j] . index]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR3 [ VAR4 ] . VAR5 ]
  ORIGINAL[8]: d -> follows[pos[j] . index]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 [ VAR3 [ VAR4 ] . VAR5 ]
  ORIGINAL[9]: d -> follows[i]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[10]: follows
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: pos
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: break;
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: break ;
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640393
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774635
FRAGMENT_COUNT: 6
  ORIGINAL[0]: 1 & 2
  TYPE[0]: CALL
  TOKENIZED[0]: 1 & 2
  ORIGINAL[1]: ( *d) . states[s]
  TYPE[1]: CALL
  TOKENIZED[1]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[2]: ( *d) . states
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1
  ORIGINAL[3]: *d
  TYPE[3]: CALL
  TOKENIZED[3]: *d
  ORIGINAL[4]: states
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477925
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa = d
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: lexptr = s
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: <global> lexptr
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640287
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640308
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640375
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476797
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064773484
FRAGMENT_COUNT: 31
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET && d -> tokens[s -> elems[i] . index] < CSET
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < VAR10
  ORIGINAL[2]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9
  ORIGINAL[3]: d -> tokens[s -> elems[i] . index] < CSET
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < VAR7
  ORIGINAL[4]: old = s -> elems[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[5]: s -> elems[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: s -> elems
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: p . constraint = old . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . VAR2 = VAR3 . VAR2
  ORIGINAL[8]: p . constraint
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 . VAR2
  ORIGINAL[9]: old . constraint
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 . VAR2
  ORIGINAL[10]: delete(s -> elems[i],s)
  TYPE[10]: CALL
  TOKENIZED[10]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] , VAR1 )
  ORIGINAL[11]: s -> elems[i]
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[12]: s -> elems
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: visited[old . index]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 [ VAR2 . VAR3 ]
  ORIGINAL[14]: old . index
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 . VAR2
  ORIGINAL[15]: elems
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: constraint
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: constraint
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: elems
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: index
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: i
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: old
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: s
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: i
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: p
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: old
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: s
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: i
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: s
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: visited
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: old
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640316
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064775851
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: old = enlist(old,new[i],strlen(new[i]))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[2]: enlist(old,new[i],strlen(new[i]))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[3]: new[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: strlen(new[i])
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 [ VAR2 ] )
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: old
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479802
FRAGMENT_COUNT: 8
  ORIGINAL[0]: left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: right == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: right[rnum]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: right[rnum]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: right
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: right
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: right
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640868
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640403
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476771
FRAGMENT_COUNT: 6
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: sprintf(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: filepath
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: filepath
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dirpath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: filepath
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640747
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775716
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640870
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640338
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776083
FRAGMENT_COUNT: 11
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: lmp -> left[i] != '\\0' && lmp -> left[i] == rmp -> left[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] != '\\0' && VAR1 -> VAR2 [ VAR3 ] == VAR4 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: lmp -> left[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: lmp -> left
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: lmp -> left[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: lmp -> left[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[6]: lmp -> left
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: left
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: lmp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: lmp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773191
FRAGMENT_COUNT: 22
  ORIGINAL[0]: m -> nelem = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: m -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: m -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: m -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: m -> nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: m -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: m -> nelem
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: m -> nelem
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: nelem
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: m
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: m
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: m
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: m
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: m
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: m
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: m
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: m
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: m
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: m
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: m
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: m
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: m
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1

CENTER_NODE: 47244640499
FRAGMENT_COUNT: 1
  ORIGINAL[0]: minrep < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640298
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771268
FRAGMENT_COUNT: 13
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: sbit[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: setbit(i,letters)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: setbit(i,newline)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[4]: break;
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: break ;
  ORIGINAL[5]: break;
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: break ;
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> sbit
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> letters
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: <global> newline
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1

CENTER_NODE: 68719476867
FRAGMENT_COUNT: 8
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> calloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> cindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: dfa -> charclasses
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &new_n_alloc
  TYPE[4]: CALL
  TOKENIZED[4]: &new_n_alloc
  ORIGINAL[5]: dfa -> charclasses
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: charclasses
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 47244640643
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: ++j
  TYPE[2]: CALL
  TOKENIZED[2]: ++j
  ORIGINAL[3]: for (j = 0;j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++j)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++j )

CENTER_NODE: 30064771239
FRAGMENT_COUNT: 6
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: c == eolbyte
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: c == 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == 0
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> eolbyte
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: c
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772874
FRAGMENT_COUNT: 10
  ORIGINAL[0]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0 || work_mbc -> ncoll_elems != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0 || VAR1 -> VAR8 != 0
  ORIGINAL[1]: work_mbc -> cset
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: work_mbc -> cset != (- 1)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[3]: work_mbc -> cset
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1
  ORIGINAL[5]: work_mbc -> cset
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: cset
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: work_mbc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: work_mbc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640752
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476824
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640878
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640896
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b % (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719479728
FRAGMENT_COUNT: 9
  ORIGINAL[0]: istrstr(new,cpp[j]) == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 [ VAR3 ] ) == ( ( void * ) 0 )
  ORIGINAL[1]: free(cpp[j])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 [ VAR2 ] )
  ORIGINAL[2]: --i
  TYPE[2]: CALL
  TOKENIZED[2]: --i
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640927
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773110
FRAGMENT_COUNT: 22
  ORIGINAL[0]: lo < hi
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: mid = lo + hi >> 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 + VAR3 >> 1
  ORIGINAL[2]: lo + hi >> 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2 >> 1
  ORIGINAL[3]: lo + hi
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + VAR2
  ORIGINAL[4]: s -> elems[mid] . index > p . index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 . VAR4
  ORIGINAL[5]: s -> elems[mid] . index
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[6]: s -> elems[mid]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[7]: s -> elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: p . index
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 . VAR2
  ORIGINAL[9]: while (lo < hi)
  TYPE[9]: CONTROL_STRUCTURE
  TOKENIZED[9]: while ( VAR1 < VAR2 )
  ORIGINAL[10]: elems
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: index
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: index
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: lo
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: hi
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: mid
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: lo
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: hi
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: s
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: mid
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: p
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: lo
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1

CENTER_NODE: 47244640426
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773019
FRAGMENT_COUNT: 8
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN && tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: tok != OR
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != VAR2
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: RPAREN
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: OR
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640807
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479124
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[1]: pos . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: pos . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: pos . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: d -> multibyte_prop
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: pos . index
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2
  ORIGINAL[6]: index
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: pos
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064775810
FRAGMENT_COUNT: 4
  ORIGINAL[0]: ( *lcp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *lcp ) != '\\0'
  ORIGINAL[1]: len = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: len
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: rcp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772948
FRAGMENT_COUNT: 5
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: nsubtoks(tindex - 1 - ntoks1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 - 1 - VAR2 )
  ORIGINAL[2]: tindex - 1 - ntoks1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1 - VAR2
  ORIGINAL[3]: tindex - 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - 1
  ORIGINAL[4]: ntoks1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640867
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640348
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640395
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640589
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476848
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772894
FRAGMENT_COUNT: 5
  ORIGINAL[0]: 1 && tok == ANYCHAR
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2
  ORIGINAL[1]: tok == ANYCHAR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: tok == ANYCHAR
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: ANYCHAR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477903
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < maxrep
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: copytoks(tindex,ntokens)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: addtok(QMARK)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: QMARK
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: QMARK
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: QMARK
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479832
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> left[0] = mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = VAR1 -> VAR4 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: in
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640628
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477970
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: s -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: alloc
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640709
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771251
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: (wchar_t )eolbyte
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: wc == 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == 0
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064776370
FRAGMENT_COUNT: 3
  ORIGINAL[0]: {{(\
  TYPE[0]: CALL
  TOKENIZED[0]: { { ( \
  ORIGINAL[1]: {(\
  TYPE[1]: CALL
  TOKENIZED[1]: { ( \
  ORIGINAL[2]: isalnum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640317
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640816
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < d -> states[s] . mbps . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: for (i = 0;i < d -> states[s] . mbps . nelem;i++)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 ; i++ )

CENTER_NODE: 68719479637
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> states[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: d -> states
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719478090
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: s -> elems[i] = s -> elems[i + 1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] = VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640415
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771155
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640359
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640541
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774896
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *next_state = works
  TYPE[0]: CALL
  TOKENIZED[0]: *next_state = VAR1
  ORIGINAL[1]: *next_state
  TYPE[1]: CALL
  TOKENIZED[1]: *next_state
  ORIGINAL[2]: next_state
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: works
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640871
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640558
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771132
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c - 32
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 - 32
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640385
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478817
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < ngrps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: possible_contexts = charclass_context(labels[i])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 [ VAR3 ] )
  ORIGINAL[2]: separate_contexts = state_separate_contexts((&follows))
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( ( &follows ) )
  ORIGINAL[3]: state_separate_contexts((&follows))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( &follows ) )
  ORIGINAL[4]: separate_contexts
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: follows
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: separate_contexts
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640594
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640597
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479016
FRAGMENT_COUNT: 8
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_state >= d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: tralloc
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_state
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719477855
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < ntokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ntokens
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719479689
FRAGMENT_COUNT: 7
  ORIGINAL[0]: cp = lookin
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: *cp
  TYPE[1]: CALL
  TOKENIZED[1]: *cp
  ORIGINAL[2]: ++cp
  TYPE[2]: CALL
  TOKENIZED[2]: ++cp
  ORIGINAL[3]: strncmp(cp,lookfor,len) == 0
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[4]: cp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: cp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640418
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771163
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )

CENTER_NODE: 30064774865
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_DONE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640705
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640619
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775566
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> talloc = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 1
  ORIGINAL[1]: d -> talloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064774772
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> fails
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *d -> fails
  TYPE[1]: CALL
  TOKENIZED[1]: *d -> VAR1
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: fails
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064776345
FRAGMENT_COUNT: 3
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )
  ORIGINAL[2]: struct dfa
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: struct VAR1

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773062
FRAGMENT_COUNT: 14
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: src -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: alloc
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dst
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: src
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: dst
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dst
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: dst
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: dst
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: dst
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: dst
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: dst
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: dst
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640345
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775260
FRAGMENT_COUNT: 9
  ORIGINAL[0]: nelem == 0 || maxlen == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 == 0
  ORIGINAL[1]: &follows
  TYPE[1]: CALL
  TOKENIZED[1]: &follows
  ORIGINAL[2]: state_index(d,(&follows),wchar_context(wc))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( &follows ) , FUN2 ( VAR2 ) )
  ORIGINAL[3]: &follows
  TYPE[3]: CALL
  TOKENIZED[3]: &follows
  ORIGINAL[4]: &follows
  TYPE[4]: CALL
  TOKENIZED[4]: &follows
  ORIGINAL[5]: follows
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: wc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: follows
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: follows
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064776360
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640539
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640761
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640649
FRAGMENT_COUNT: 0

