# Tokenized code fragments for 152165-v1.0.0-bad
# Total center nodes processed: 145
# Total code fragments found: 466

CENTER_NODE: 47244640950
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640563
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480206
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640856
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640606
FRAGMENT_COUNT: 2
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: while (tok == OR)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: while ( VAR1 == VAR2 )

CENTER_NODE: 68719479637
FRAGMENT_COUNT: 13
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: p -> chars
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: p -> ch_classes
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: p -> range_sts
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: p -> range_ends
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: j < p -> nequivs
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 < VAR2 -> VAR3
  ORIGINAL[6]: p -> nequivs
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: p -> equivs
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: p -> ncoll_elems
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: p -> coll_elems
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: equivs
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: p
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 30064772923
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && t == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 == VAR2
  ORIGINAL[1]: __ctype_get_mb_cur_max() > 1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ) > 1
  ORIGINAL[2]: t == MBCSET
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: t
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: MBCSET
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771209
FRAGMENT_COUNT: 11
  ORIGINAL[0]: src[i] != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != '\\0'
  ORIGINAL[1]: src[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: src[i] == ';'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] == ' ; '
  ORIGINAL[3]: src[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: i == 0 || src[i-1] != '\\\\'
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[5]: i == 0 || src[i-1] != '\\\\'
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[6]: src[i] == '&'
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ] == '&'
  ORIGINAL[7]: i == 0 || src[i-1] != '\\\\'
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[8]: while (src[i] != '\\0')
  TYPE[8]: CONTROL_STRUCTURE
  TOKENIZED[8]: while ( VAR1 [ VAR2 ] != '\\0' )
  ORIGINAL[9]: src
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719479683
FRAGMENT_COUNT: 2
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: MBCSET
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 68719478298
FRAGMENT_COUNT: 17
  ORIGINAL[0]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET && d -> tokens[s -> elems[i] . index] < CSET
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < VAR10
  ORIGINAL[1]: old = s -> elems[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[2]: s -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: old . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 . VAR2
  ORIGINAL[4]: old . index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: old . index
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2
  ORIGINAL[6]: old . index
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . VAR2
  ORIGINAL[7]: old . index
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . VAR2
  ORIGINAL[8]: old . index
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 . VAR2
  ORIGINAL[9]: old
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: old
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: old
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: old
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: old
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: old
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: old
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 68719480236
FRAGMENT_COUNT: 9
  ORIGINAL[0]: (key = strtol(optarg, NULL, 10)) < 1000
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , VAR3 , 10 ) ) < 1000
  ORIGINAL[1]: fprintf(stderr, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: errors++
  TYPE[2]: CALL
  TOKENIZED[2]: errors++
  ORIGINAL[3]: errors
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: errors
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: errors
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: errors
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: errors
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: errors
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640926
FRAGMENT_COUNT: 4
  ORIGINAL[0]: lcp[i] != '\\0' && lcp[i] == rcp[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != '\\0' && VAR1 [ VAR2 ] == VAR3 [ VAR2 ]
  ORIGINAL[1]: for (i = 1;lcp[i] != '\\0' && lcp[i] == rcp[i];++i)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 1 ; VAR2 [ VAR1 ] != '\\0' && VAR2 [ VAR1 ] == VAR3 [ VAR1 ] ; ++i )
  ORIGINAL[2]: continue;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: continue ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773969
FRAGMENT_COUNT: 13
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: firstpos -> constraint = lastpos -> constraint = 0x777
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR3 -> VAR2 = 0x777
  ORIGINAL[2]: firstpos -> constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: lastpos -> constraint = 0x777
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 = 0x777
  ORIGINAL[4]: constraint
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: firstpos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: firstpos
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: firstpos
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: firstpos
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: firstpos
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: firstpos
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: lastpos
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: firstpos
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776131
FRAGMENT_COUNT: 5
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: !\
  TYPE[1]: CALL
  TOKENIZED[1]: !\
  ORIGINAL[2]: !\
  TYPE[2]: CALL
  TOKENIZED[2]: !\
  ORIGINAL[3]: (void )0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void ) 0
  ORIGINAL[4]: __assert_fail(\
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( \

CENTER_NODE: 47244640894
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476995
FRAGMENT_COUNT: 6
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: utf8 == - 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == - 1
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: utf8
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: utf8
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640785
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773285
FRAGMENT_COUNT: 6
  ORIGINAL[0]: m -> alloc <= s1 -> nelem + s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4 + VAR5 -> VAR4
  ORIGINAL[1]: x2nrealloc((m -> elems),&new_n_alloc,sizeof(( *m -> elems)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) , &new_n_alloc , sizeof ( ( *m -> VAR2 ) ) )
  ORIGINAL[2]: m -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &new_n_alloc
  TYPE[3]: CALL
  TOKENIZED[3]: &new_n_alloc
  ORIGINAL[4]: sizeof(( *m -> elems))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *m -> VAR1 ) )
  ORIGINAL[5]: *m -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: *m -> VAR1

CENTER_NODE: 30064772919
FRAGMENT_COUNT: 6
  ORIGINAL[0]: depth > dfa -> depth
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR1
  ORIGINAL[1]: dfa -> depth = depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = VAR2
  ORIGINAL[2]: dfa -> depth
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: depth
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> depth
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772269
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ((unsigned long )1) << 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( unsigned long ) 1 ) << 1
  ORIGINAL[1]: (unsigned long )1
  TYPE[1]: CALL
  TOKENIZED[1]: ( unsigned long ) 1
  ORIGINAL[2]: backslash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773211
FRAGMENT_COUNT: 5
  ORIGINAL[0]: lo < hi
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: mid = lo + hi >> 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 + VAR3 >> 1
  ORIGINAL[2]: lo + hi >> 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2 >> 1
  ORIGINAL[3]: mid
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771369
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sbit[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: setbit(i,letters)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> letters
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064775793
FRAGMENT_COUNT: 10
  ORIGINAL[0]: ndm = dm -> next
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3
  ORIGINAL[1]: dm -> next
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: next
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: dm
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: dm
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: dm
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ndm
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dm
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: dm
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: dm
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640369
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640891
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640314
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640675
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775361
FRAGMENT_COUNT: 4
  ORIGINAL[0]: nelem == 0 || maxlen == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 == 0
  ORIGINAL[1]: state_index(d,(&follows),wchar_context(wc))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( &follows ) , FUN2 ( VAR2 ) )
  ORIGINAL[2]: wchar_context(wc)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: wc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775943
FRAGMENT_COUNT: 4
  ORIGINAL[0]: old == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: new == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: new
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771411
FRAGMENT_COUNT: 11
  ORIGINAL[0]: prednames[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: prednames[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: strcmp(str,prednames[i] . name) == 0
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 [ VAR3 ] . VAR4 ) == 0
  ORIGINAL[4]: strcmp(str,prednames[i] . name)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 [ VAR3 ] . VAR4 )
  ORIGINAL[5]: break;
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: break ;
  ORIGINAL[6]: name
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> prednames
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: i
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: <global> prednames
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1

CENTER_NODE: 30064771096
FRAGMENT_COUNT: 9
  ORIGINAL[0]: dirpath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stat(dirpath, &st) == -1
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , &st ) == -1
  ORIGINAL[2]: stat(dirpath, &st)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , &st )
  ORIGINAL[3]: -1
  TYPE[3]: CALL
  TOKENIZED[3]: -1
  ORIGINAL[4]: retval = mkdir(dirpath, 0700)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR2 , 0700 )
  ORIGINAL[5]: mkdir(dirpath, 0700)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , 0700 )
  ORIGINAL[6]: retval
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: dirpath
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: retval
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640340
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640450
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640784
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771281
FRAGMENT_COUNT: 4
  ORIGINAL[0]: 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: b % (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[2]: 8 * sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: 8 * sizeof ( int )
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773080
FRAGMENT_COUNT: 36
  ORIGINAL[0]: tok == QMARK || tok == STAR || tok == PLUS || tok == REPMN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[1]: tok == REPMN && (minrep || maxrep)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[2]: tok == REPMN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: minrep || maxrep
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 || VAR2
  ORIGINAL[4]: ntokens = nsubtoks(dfa -> tindex)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR2 -> VAR3 )
  ORIGINAL[5]: nsubtoks(dfa -> tindex)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[6]: dfa -> tindex
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tindex = dfa -> tindex - ntokens
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = VAR2 -> VAR1 - VAR3
  ORIGINAL[8]: dfa -> tindex - ntokens
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2 - VAR3
  ORIGINAL[9]: dfa -> tindex
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: maxrep < 0
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 < 0
  ORIGINAL[11]: minrep == 0
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 == 0
  ORIGINAL[12]: i = 1
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 = 1
  ORIGINAL[13]: i < minrep
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 < VAR2
  ORIGINAL[14]: i < maxrep
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 < VAR2
  ORIGINAL[15]: tok = lex()
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 = FUN1 ( )
  ORIGINAL[16]: lex()
  TYPE[16]: CALL
  TOKENIZED[16]: FUN1 ( )
  ORIGINAL[17]: tok == REPMN
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 == VAR2
  ORIGINAL[18]: tindex
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: tindex
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: <global> tok
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1
  ORIGINAL[21]: ntokens
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: <global> dfa
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: <global> VAR1
  ORIGINAL[23]: tindex
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: <global> dfa
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: <global> VAR1
  ORIGINAL[25]: ntokens
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: <global> maxrep
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: <global> VAR1
  ORIGINAL[27]: <global> minrep
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: <global> VAR1
  ORIGINAL[28]: i
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: i
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: <global> minrep
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: <global> VAR1
  ORIGINAL[31]: i
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: <global> maxrep
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: <global> VAR1
  ORIGINAL[33]: <global> tok
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: <global> VAR1
  ORIGINAL[34]: <global> tok
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: <global> VAR1
  ORIGINAL[35]: REPMN
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1

CENTER_NODE: 68719479162
FRAGMENT_COUNT: 4
  ORIGINAL[0]: context & 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 1
  ORIGINAL[1]: pos . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: constraint
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pos
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640831
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477928
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: tindex + i
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064775815
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775804
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new == ((void *)0)?0 : strlen(new)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) ?0 : FUN1 ( VAR1 )
  ORIGINAL[1]: new == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: strlen(new)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: new
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640791
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640611
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773039
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: 1 + nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: 1 + FUN1 ( VAR1 - 1 )
  ORIGINAL[2]: nsubtoks(tindex - 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 - 1 )

CENTER_NODE: 30064773157
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> nregexps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: addtok(OR)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: nregexps
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640892
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640895
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479762
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *cp
  TYPE[0]: CALL
  TOKENIZED[0]: *cp
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: (char *)cp
  TYPE[2]: CALL
  TOKENIZED[2]: ( char * ) VAR1
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: cp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775166
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < work_mbc -> ncoll_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: strncpy(buffer,((const char *)buf_begin) + idx,op_len)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( const char * ) VAR2 ) + VAR3 , VAR4 )
  ORIGINAL[2]: ((const char *)buf_begin) + idx
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( const char * ) VAR1 ) + VAR2
  ORIGINAL[3]: (const char *)buf_begin
  TYPE[3]: CALL
  TOKENIZED[3]: ( const char * ) VAR1
  ORIGINAL[4]: idx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: op_len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640618
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773699
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: (s -> elems[j] . constraint >> 2 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[2]: s -> elems[j] . constraint >> 2 & 0x111
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2 & 0x111
  ORIGINAL[3]: s -> elems[j] . constraint >> 2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 2
  ORIGINAL[4]: s -> elems[j] . constraint & 0x111
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479687
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfainit(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaparse(s,len,d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640352
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775257
FRAGMENT_COUNT: 4
  ORIGINAL[0]: copy((&d -> states[s1] . elems),pps)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( &d -> VAR1 [ VAR2 ] . VAR3 ) , VAR4 )
  ORIGINAL[1]: &d -> states[s1] . elems
  TYPE[1]: CALL
  TOKENIZED[1]: &d -> VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: pps
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: match_lens
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640341
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773187
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dst -> nelem = src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3 -> VAR2
  ORIGINAL[1]: dst -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: src -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2

CENTER_NODE: 47244640621
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774639
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: free(d -> fails[i])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] )
  ORIGINAL[2]: d -> fails[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> fails[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: d -> fails
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479071
FRAGMENT_COUNT: 12
  ORIGINAL[0]: d -> trcount
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> trans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> fails
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> tralloc
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> success
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: sizeof(( *d -> success)) == 1
  TYPE[7]: CALL
  TOKENIZED[7]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[8]: d -> tralloc
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: d -> tralloc
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: tralloc
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 47244640565
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640857
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064771255
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064773373
FRAGMENT_COUNT: 12
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: --s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: --s -> VAR1
  ORIGINAL[3]: s -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: i < s -> nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 < VAR2 -> VAR3
  ORIGINAL[5]: s -> nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: nelem
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: nelem
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 68719480199
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(struct dfa )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( struct VAR1 )
  ORIGINAL[1]: struct dfa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: struct VAR1

CENTER_NODE: 47244640652
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640330
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640409
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640920
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640677
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776439
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640311
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476903
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476947
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (unsigned short )_ISalnum
  TYPE[0]: CALL
  TOKENIZED[0]: ( unsigned short ) VAR1
  ORIGINAL[1]: _ISalnum
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640460
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640374
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640902
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771131
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *stonesoup_tainted_buff = NULL
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff = VAR1
  ORIGINAL[1]: *stonesoup_tainted_buff
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff
  ORIGINAL[2]: stonesoup_tainted_buff
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: NULL
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stonesoup_tainted_buff
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_tainted_buff
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775837
FRAGMENT_COUNT: 8
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: cpp[i] = ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[3]: cpp[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: cpp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064775196
FRAGMENT_COUNT: 3
  ORIGINAL[0]: rarray = ((sizeof(( *rarray)) == 1?xmalloc(d -> states[s] . mbps . nelem) : xnmalloc(d -> states[s] . mbps . nelem,sizeof(( *rarray)))))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( ( sizeof ( ( *rarray ) ) == 1?xmalloc ( VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 ) : FUN1 ( VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 , sizeof ( ( *rarray ) ) ) ) )
  ORIGINAL[1]: sizeof(( *rarray)) == 1?xmalloc(d -> states[s] . mbps . nelem) : xnmalloc(d -> states[s] . mbps . nelem,sizeof(( *rarray)))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *rarray ) ) == 1?xmalloc ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 ) : FUN1 ( VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 , sizeof ( ( *rarray ) ) )
  ORIGINAL[2]: rarray
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771199
FRAGMENT_COUNT: 3
  ORIGINAL[0]: src+=3
  TYPE[0]: CALL
  TOKENIZED[0]: src+=3
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: src
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719479112
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER=2
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480200
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640383
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476914
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: s[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: s[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640855
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775691
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: d -> multibyte_prop = ((sizeof(( *d -> multibyte_prop)) == 1?xmalloc(d -> nmultibyte_prop) : xnmalloc(d -> nmultibyte_prop,sizeof(( *d -> multibyte_prop)))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( sizeof ( ( *d -> VAR2 ) ) == 1?xmalloc ( VAR1 -> VAR3 ) : FUN1 ( VAR1 -> VAR3 , sizeof ( ( *d -> VAR2 ) ) ) ) )
  ORIGINAL[2]: d -> multibyte_prop
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *d -> multibyte_prop)) == 1?xmalloc(d -> nmultibyte_prop) : xnmalloc(d -> nmultibyte_prop,sizeof(( *d -> multibyte_prop)))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[4]: sizeof(( *d -> multibyte_prop)) == 1
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[5]: xmalloc(d -> nmultibyte_prop)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[6]: xnmalloc(d -> nmultibyte_prop,sizeof(( *d -> multibyte_prop)))
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( VAR1 -> VAR2 , sizeof ( ( *d -> VAR3 ) ) )

CENTER_NODE: 30064773119
FRAGMENT_COUNT: 8
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN && tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: tok != OR
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != VAR2
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: RPAREN
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: OR
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640782
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640775
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776003
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> right
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: right
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771246
FRAGMENT_COUNT: 3
  ORIGINAL[0]: REPMN=267
  TYPE[0]: CALL
  TOKENIZED[0]: REPMN=267
  ORIGINAL[1]: REPMN
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: CAT
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640778
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479581
FRAGMENT_COUNT: 36
  ORIGINAL[0]: d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> trans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> states
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> trans
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> fails
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> success
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: d -> states
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: d -> mb_cur_max
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: d -> mb_cur_max > 1
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 > 1
  ORIGINAL[10]: d -> mb_cur_max
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: transit_state(d,s,&p)
  TYPE[11]: CALL
  TOKENIZED[11]: FUN1 ( VAR1 , VAR2 , &p )
  ORIGINAL[12]: d -> trans
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: d -> fails
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: d -> mb_cur_max
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: d -> mb_cur_max
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2
  ORIGINAL[16]: d -> trans
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: d -> newlines
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: d
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: d
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: d
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: d
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: d
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: d
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: d
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: d
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: d
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: s
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: d
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: s
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: d
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: d
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: d
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: d
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: d
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: d
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1

CENTER_NODE: 30064774917
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> realtrans = (xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[2]: d -> realtrans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnrealloc((d -> realtrans),(d -> tralloc + 1),sizeof(( *d -> realtrans)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 + 1 ) , sizeof ( ( *d -> VAR2 ) ) )

CENTER_NODE: 47244640776
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479134
FRAGMENT_COUNT: 5
  ORIGINAL[0]: works < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: d -> fails[works]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: works
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: works
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640777
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640733
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640291
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640427
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771286
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640391
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640439
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476865
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 68719477295
FRAGMENT_COUNT: 7
  ORIGINAL[0]: cur_mb_len <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: c1 = (to_uchar( *(lexptr++)))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( * ( lexptr++ ) ) )
  ORIGINAL[2]: to_uchar( *(lexptr++))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( * ( lexptr++ ) )
  ORIGINAL[3]: wc1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> lexptr
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: c1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775845
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (new = icpyalloc(new)) == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 = FUN1 ( VAR1 ) ) == ( ( void * ) 0 )
  ORIGINAL[2]: new = icpyalloc(new)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR1 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640643
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640419
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640461
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640783
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640789
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478259
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !d -> states[i] . first_end
  TYPE[0]: CALL
  TOKENIZED[0]: !d -> VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: s -> elems[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640676
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640362
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771351
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: (wchar_t )eolbyte
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: wc == 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == 0
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640645
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773202
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s -> alloc = size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: s -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: size
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719478612
FRAGMENT_COUNT: 8
  ORIGINAL[0]: d -> tokens[pos . index] >= 0 && d -> tokens[pos . index] < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ] >= 0 && VAR1 -> VAR2 [ VAR3 . VAR4 ] < ( 1 << 8 )
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> nleaves
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> nleaves
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> nleaves
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> nleaves
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: tokens
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771265
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] |= 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] |= 1 << VAR2 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: 1 << b % (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 68719476993
FRAGMENT_COUNT: 5
  ORIGINAL[0]: setbit_c((( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)),c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN2 ( VAR1 ) ) , VAR3 )
  ORIGINAL[1]: setbit(((*__ctype_b_loc())[(int)b] & ((short unsigned)_ISupper) ? tolower(b) : toupper(b)), c)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( short unsigned ) VAR2 ) ? FUN2 ( VAR1 ) : FUN3 ( VAR1 ) ) , VAR3 )
  ORIGINAL[2]: ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISupper)?tolower(b) : toupper(b)
  TYPE[2]: CALL
  TOKENIZED[2]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) ?tolower ( VAR1 ) : FUN1 ( VAR1 )
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640697
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773670
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tstbit(eolbyte,c)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: context |= 4
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 |= 4
  ORIGINAL[2]: context
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640332
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640699
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> charclasses[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640613
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640729
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640788
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640999
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640582
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640698
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640790
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771304
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(charclass )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476888
FRAGMENT_COUNT: 5
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773031
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: dfaerror((gettext(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( FUN2 ( \
  ORIGINAL[2]: gettext(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( \
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775959
FRAGMENT_COUNT: 3
  ORIGINAL[0]: left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: left
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

