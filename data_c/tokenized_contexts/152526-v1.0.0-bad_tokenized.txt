# Tokenized code fragments for 152526-v1.0.0-bad
# Total center nodes processed: 29
# Total code fragments found: 209

CENTER_NODE: 68719476835
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr2) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_index++
  TYPE[1]: CALL
  TOKENIZED[1]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[2]: hash_val += ADD_ADDRESS_TO_HASH_data[ADD_ADDRESS_TO_HASH_index]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 += VAR2 [ VAR3 ]
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_index
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772227
FRAGMENT_COUNT: 10
  ORIGINAL[0]: strlen(palindrome_colonizer) < 1000 - strlen(stonesoup_command_str)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) < 1000 - FUN1 ( VAR2 )
  ORIGINAL[1]: stonesoup_fpipe != 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != 0
  ORIGINAL[2]: fgets(stonesoup_buffer,100,stonesoup_fpipe) != 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , 100 , VAR2 ) != 0
  ORIGINAL[3]: fgets(stonesoup_buffer,100,stonesoup_fpipe)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , 100 , VAR2 )
  ORIGINAL[4]: pclose(stonesoup_fpipe)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: stonesoup_fpipe
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_buffer
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_fpipe
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_fpipe
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: stonesoup_trace
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 68719477536
FRAGMENT_COUNT: 5
  ORIGINAL[0]: cytoma_dextrans != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: besnuff_lehi(ontologies_nepenthes)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: ontologies_nepenthes
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: besnuff_lehi
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ontologies_nepenthes
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771114
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: mg_destroy_server(&stonesoup_server)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( &stonesoup_server )
  ORIGINAL[2]: &stonesoup_server
  TYPE[2]: CALL
  TOKENIZED[2]: &stonesoup_server

CENTER_NODE: 30064771674
FRAGMENT_COUNT: 8
  ORIGINAL[0]: conv -> setup_frame >= chain_tail -> setup_frame
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 >= VAR3 -> VAR2
  ORIGINAL[1]: conv -> setup_frame > cur -> setup_frame && cur -> next
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 > VAR3 -> VAR2 && VAR3 -> VAR4
  ORIGINAL[2]: conv -> setup_frame > cur -> setup_frame
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 > VAR3 -> VAR2
  ORIGINAL[3]: conv -> setup_frame
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: cur -> setup_frame
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: cur -> next
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: next
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cur
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771470
FRAGMENT_COUNT: 23
  ORIGINAL[0]: v1 -> port1 == v2 -> port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[1]: &v1 -> addr1
  TYPE[1]: CALL
  TOKENIZED[1]: &v1 -> VAR1
  ORIGINAL[2]: v1 -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: &v1 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: &v1 -> VAR1
  ORIGINAL[4]: v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: &v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: &v1 -> VAR1
  ORIGINAL[6]: v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: &v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: &v1 -> VAR1
  ORIGINAL[8]: v1 -> addr1
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: &v1 -> addr1
  TYPE[9]: CALL
  TOKENIZED[9]: &v1 -> VAR1
  ORIGINAL[10]: v1 -> addr1
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: addr1
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: v1
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: v1
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: v1
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: v1
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: v1
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: v1
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: v1
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: v1
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: v1
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: v1
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: v1
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1

CENTER_NODE: 30064771116
FRAGMENT_COUNT: 18
  ORIGINAL[0]: conversation -> options & 0x08 && (conversation -> key_ptr -> ptype) != PT_UDP
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 & 0x08 && ( VAR1 -> VAR3 -> VAR4 ) != VAR5
  ORIGINAL[1]: conversation -> options & 0x08
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 & 0x08
  ORIGINAL[2]: (conversation -> key_ptr -> ptype) != PT_UDP
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 -> VAR2 -> VAR3 ) != VAR4
  ORIGINAL[3]: options = conversation -> options & (~(0x08 | 0x01 | 0x02))
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2 -> VAR1 & ( ~ ( 0x08 | 0x01 | 0x02 ) )
  ORIGINAL[4]: conversation -> options & (~(0x08 | 0x01 | 0x02))
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 & ( ~ ( 0x08 | 0x01 | 0x02 ) )
  ORIGINAL[5]: conversation -> options
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: ~(0x08 | 0x01 | 0x02)
  TYPE[6]: CALL
  TOKENIZED[6]: ~ ( 0x08 | 0x01 | 0x02 )
  ORIGINAL[7]: 0x08 | 0x01 | 0x02
  TYPE[7]: CALL
  TOKENIZED[7]: 0x08 | 0x01 | 0x02
  ORIGINAL[8]: 0x08 | 0x01
  TYPE[8]: CALL
  TOKENIZED[8]: 0x08 | 0x01
  ORIGINAL[9]: conversation -> options & 0x01 && conversation -> options & 0x02
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 & 0x01 && VAR1 -> VAR2 & 0x02
  ORIGINAL[10]: conversation -> options & 0x01
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 & 0x01
  ORIGINAL[11]: conversation -> options
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: options
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: options
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: options
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: conversation
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: conversation
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: conversation
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 68719476749
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stonesoup_tainted_buff = (char*) malloc(buffer_size * sizeof(char))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[1]: (char*) malloc(buffer_size * sizeof(char))
  TYPE[1]: CALL
  TOKENIZED[1]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[2]: stonesoup_tainted_buff
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_tainted_buff
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477250
FRAGMENT_COUNT: 7
  ORIGINAL[0]: chain_head && chain_head -> setup_frame <= frame_num
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && VAR1 -> VAR2 <= VAR3
  ORIGINAL[1]: chain_head -> setup_frame
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: match = chain_head
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: chain_head -> last
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: last
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chain_head
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chain_head
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477013
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *conv = (conversation_t *)value
  TYPE[0]: CALL
  TOKENIZED[0]: *conv = ( VAR1 * ) VAR2
  ORIGINAL[1]: (conversation_t *)value
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 * ) VAR2
  ORIGINAL[2]: conv -> data_list
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: conv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: conv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772145
FRAGMENT_COUNT: 5
  ORIGINAL[0]: conversation -> dissector_handle = handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: conversation -> dissector_handle
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dissector_handle
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conversation
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: handle
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772098
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *p1 = (se_alloc(sizeof(conv_proto_data )))
  TYPE[0]: CALL
  TOKENIZED[0]: *p1 = ( FUN1 ( sizeof ( VAR1 ) ) )
  ORIGINAL[1]: se_alloc(sizeof(conv_proto_data ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[2]: p1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772165
FRAGMENT_COUNT: 7
  ORIGINAL[0]: find_conversation(pinfo -> fd -> num,(&pinfo -> src),(&pinfo -> dst),pinfo -> ptype,pinfo -> srcport,pinfo -> destport,0)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 -> VAR3 , ( &pinfo -> VAR4 ) , ( &pinfo -> VAR5 ) , VAR1 -> VAR6 , VAR1 -> VAR7 , VAR1 -> VAR8 , 0 )
  ORIGINAL[1]: pinfo -> fd -> num
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[2]: pinfo -> fd
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: pinfo -> fd -> num
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[4]: pinfo -> fd
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: num
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: pinfo
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771793
FRAGMENT_COUNT: 4
  ORIGINAL[0]: SE_COPY_ADDRESS_data = (se_alloc((addr2 -> len)))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( FUN1 ( ( VAR2 -> VAR3 ) ) )
  ORIGINAL[1]: se_alloc((addr2 -> len))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[2]: SE_COPY_ADDRESS_data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: SE_COPY_ADDRESS_data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477486
FRAGMENT_COUNT: 8
  ORIGINAL[0]: conv -> data_list
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: item -> data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: item -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: data
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: item
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: item
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: item
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: item
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476894
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *key = (const conversation_key *)v
  TYPE[0]: CALL
  TOKENIZED[0]: *key = ( const VAR1 * ) VAR2
  ORIGINAL[1]: hash_val = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: hash_val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: hash_val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hash_val
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771556
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *v2 = (const conversation_key *)w
  TYPE[0]: CALL
  TOKENIZED[0]: *v2 = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const conversation_key *)w
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: v2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: w
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 23
  ORIGINAL[0]: v1 -> port1 == v2 -> port1 && v1 -> port2 == v2 -> port2 && (((&v1 -> addr1) -> type) == ((&v2 -> addr1) -> type) && (((&v1 -> addr1) -> type) == AT_NONE || (&v1 -> addr1) -> len == (&v2 -> addr1) -> len && memcmp((&v1 -> addr1) -> data,(&v2 -> addr1) -> data,((&v1 -> addr1) -> len)) == 0))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2 && VAR1 -> VAR4 == VAR3 -> VAR4 && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == ( ( &v2 -> VAR5 ) -> VAR6 ) && ( ( ( &v1 -> VAR5 ) -> VAR6 ) == VAR7 || ( &v1 -> VAR5 ) -> VAR8 == ( &v2 -> VAR5 ) -> VAR8 && FUN1 ( ( &v1 -> VAR5 ) -> VAR9 , ( &v2 -> VAR5 ) -> VAR9 , ( ( &v1 -> VAR5 ) -> VAR8 ) ) == 0 ) )
  ORIGINAL[1]: (&v1 -> addr2) -> type
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[2]: &v1 -> addr2
  TYPE[2]: CALL
  TOKENIZED[2]: &v1 -> VAR1
  ORIGINAL[3]: v1 -> addr2
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &v1 -> addr2
  TYPE[4]: CALL
  TOKENIZED[4]: &v1 -> VAR1
  ORIGINAL[5]: v1 -> addr2
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &v1 -> addr2
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: v1 -> addr2
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: &v1 -> addr2
  TYPE[8]: CALL
  TOKENIZED[8]: &v1 -> VAR1
  ORIGINAL[9]: v1 -> addr2
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: &v1 -> addr2
  TYPE[10]: CALL
  TOKENIZED[10]: &v1 -> VAR1
  ORIGINAL[11]: v1 -> addr2
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: &v1 -> addr2
  TYPE[12]: CALL
  TOKENIZED[12]: &v1 -> VAR1
  ORIGINAL[13]: v1 -> addr2
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: &v1 -> addr2
  TYPE[14]: CALL
  TOKENIZED[14]: &v1 -> VAR1
  ORIGINAL[15]: v1 -> addr2
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2
  ORIGINAL[16]: &v1 -> addr2
  TYPE[16]: CALL
  TOKENIZED[16]: &v1 -> VAR1
  ORIGINAL[17]: v1 -> addr2
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: &v1 -> addr2
  TYPE[18]: CALL
  TOKENIZED[18]: &v1 -> VAR1
  ORIGINAL[19]: v1 -> addr2
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2
  ORIGINAL[20]: &v1 -> addr2
  TYPE[20]: CALL
  TOKENIZED[20]: &v1 -> VAR1
  ORIGINAL[21]: v1 -> addr2
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 -> VAR2
  ORIGINAL[22]: type
  TYPE[22]: FIELD_IDENTIFIER
  TOKENIZED[22]: VAR1

CENTER_NODE: 68719477502
FRAGMENT_COUNT: 6
  ORIGINAL[0]: conversation -> dissector_handle == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: call_dissector_only(conversation -> dissector_handle,tvb,pinfo,tree)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , VAR3 , VAR4 , VAR5 )
  ORIGINAL[2]: conversation -> dissector_handle
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tvb
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pinfo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: tree
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771640
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation_hashtable_no_addr2_or_port2 = g_hash_table_new(conversation_hash_no_addr2_or_port2,conversation_match_no_addr2_or_port2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(conversation_hash_no_addr2_or_port2,conversation_match_no_addr2_or_port2)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> conversation_hashtable_no_addr2_or_port2
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477107
FRAGMENT_COUNT: 14
  ORIGINAL[0]: conv == chain_head
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: prev = chain_head
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: cur != conv && cur -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2 && VAR1 -> VAR3
  ORIGINAL[3]: cur != conv
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != VAR2
  ORIGINAL[4]: cur -> next
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: cur = cur -> next
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 = VAR1 -> VAR2
  ORIGINAL[6]: cur -> next
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: cur
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: cur
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: conv
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: cur
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: cur
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: cur
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: cur
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 68719477452
FRAGMENT_COUNT: 8
  ORIGINAL[0]: *ap = (const conv_proto_data *)a
  TYPE[0]: CALL
  TOKENIZED[0]: *ap = ( const VAR1 * ) VAR2
  ORIGINAL[1]: *bp = (const conv_proto_data *)b
  TYPE[1]: CALL
  TOKENIZED[1]: *bp = ( const VAR1 * ) VAR2
  ORIGINAL[2]: (const conv_proto_data *)b
  TYPE[2]: CALL
  TOKENIZED[2]: ( const VAR1 * ) VAR2
  ORIGINAL[3]: bp -> proto
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: bp -> proto
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: bp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: bp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: bp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476951
FRAGMENT_COUNT: 3
  ORIGINAL[0]: hash_val
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1
  ORIGINAL[1]: hash_val
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: hash_val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771547
FRAGMENT_COUNT: 9
  ORIGINAL[0]: &key -> addr1
  TYPE[0]: CALL
  TOKENIZED[0]: &key -> VAR1
  ORIGINAL[1]: key -> addr1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[3]: &key -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: &key -> VAR1
  ORIGINAL[4]: key -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: addr1
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771422
FRAGMENT_COUNT: 8
  ORIGINAL[0]: (&v1 -> addr1) -> len == (&v2 -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[1]: (&v1 -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[2]: memcmp((&v1 -> addr1) -> data,(&v2 -> addr1) -> data,((&v1 -> addr1) -> len))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( &v1 -> VAR1 ) -> VAR2 , ( &v2 -> VAR1 ) -> VAR2 , ( ( &v1 -> VAR1 ) -> VAR3 ) )
  ORIGINAL[3]: (&v1 -> addr1) -> data
  TYPE[3]: CALL
  TOKENIZED[3]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[4]: (&v2 -> addr1) -> data
  TYPE[4]: CALL
  TOKENIZED[4]: ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[5]: (&v1 -> addr1) -> len
  TYPE[5]: CALL
  TOKENIZED[5]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[6]: &v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: len
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064772114
FRAGMENT_COUNT: 3
  ORIGINAL[0]: temp . proto_data = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = ( ( void * ) 0 )
  ORIGINAL[1]: temp . proto_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0

