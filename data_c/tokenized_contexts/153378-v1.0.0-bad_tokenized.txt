# Tokenized code fragments for 153378-v1.0.0-bad
# Total center nodes processed: 33
# Total code fragments found: 139

CENTER_NODE: 68719476979
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: conv
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476869
FRAGMENT_COUNT: 4
  ORIGINAL[0]: g_hash_table_lookup(stream_hash,(&key))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , ( &key ) )
  ORIGINAL[1]: &key
  TYPE[1]: CALL
  TOKENIZED[1]: &key
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771134
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (unsigned long )key -> circ . circuit
  TYPE[0]: CALL
  TOKENIZED[0]: ( unsigned long ) VAR1 -> VAR2 . VAR3
  ORIGINAL[1]: key -> circ . circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 . VAR3
  ORIGINAL[2]: key -> circ
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: circuit
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771301
FRAGMENT_COUNT: 9
  ORIGINAL[0]: key1 -> stream == key2 -> stream
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2
  ORIGINAL[1]: key1 -> stream
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key2 -> stream
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: stream
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: key1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key2
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: key1
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: key1
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771236
FRAGMENT_COUNT: 3
  ORIGINAL[0]: val -> pdu_counter = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: val -> pdu_counter
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771384
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cleanup_stream_hash()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: cleanup_fragment_hash()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )

CENTER_NODE: 30064771281
FRAGMENT_COUNT: 7
  ORIGINAL[0]: pdu -> id = pdu_counter++
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = pdu_counter++
  ORIGINAL[1]: pdu -> id
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pdu_counter++
  TYPE[2]: CALL
  TOKENIZED[2]: pdu_counter++
  ORIGINAL[3]: id
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pdu
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> pdu_counter
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: pdu
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771317
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: g_assertion_message_expr(((gchar *)0),\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( ( VAR1 * ) 0 ) , \
  ORIGINAL[2]: (gchar *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 * ) 0
  ORIGINAL[3]: (const char *)__func__
  TYPE[3]: CALL
  TOKENIZED[3]: ( const char * ) VAR1

CENTER_NODE: 30064771082
FRAGMENT_COUNT: 22
  ORIGINAL[0]: ss_tc_root != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: size_dirpath = strlen(ss_tc_root) + strlen(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 ) + FUN1 ( \
  ORIGINAL[2]: strlen(ss_tc_root) + strlen(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[3]: strlen(ss_tc_root) + strlen(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 ) + FUN1 ( \
  ORIGINAL[4]: strlen(ss_tc_root)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: strlen(\
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( \
  ORIGINAL[6]: dirpath = (char*) malloc (size_dirpath * sizeof(char))
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 = ( char* ) FUN1 ( VAR2 * sizeof ( char ) )
  ORIGINAL[7]: (char*) malloc (size_dirpath * sizeof(char))
  TYPE[7]: CALL
  TOKENIZED[7]: ( char* ) FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[8]: malloc (size_dirpath * sizeof(char))
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( VAR1 * sizeof ( char ) )
  ORIGINAL[9]: size_dirpath * sizeof(char)
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 * sizeof ( char )
  ORIGINAL[10]: sizeof(char)
  TYPE[10]: CALL
  TOKENIZED[10]: sizeof ( char )
  ORIGINAL[11]: dirpath != NULL
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 != VAR2
  ORIGINAL[12]: ss_tc_root
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: NULL
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: size_dirpath
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: ss_tc_root
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: dirpath
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: size_dirpath
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: char
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: char
  ORIGINAL[19]: dirpath
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: NULL
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: <global> stonesoup_printf_context
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: <global> VAR1

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 1
  ORIGINAL[0]: empididae_choledography > 1000
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 1000

CENTER_NODE: 30064771471
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !frag -> final_fragment
  TYPE[0]: CALL
  TOKENIZED[0]: !frag -> VAR1
  ORIGINAL[1]: pdu -> fd_head != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 != ( ( void * ) 0 )
  ORIGINAL[2]: pdu -> fd_head
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064771496
FRAGMENT_COUNT: 3
  ORIGINAL[0]: frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: (void )0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void ) 0
  ORIGINAL[2]: frag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771261
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key -> is_circuit = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: key -> is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771212
FRAGMENT_COUNT: 3
  ORIGINAL[0]: key . is_circuit = !0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = !0
  ORIGINAL[1]: key . is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: !0
  TYPE[2]: CALL
  TOKENIZED[2]: !0

CENTER_NODE: 30064771393
FRAGMENT_COUNT: 3
  ORIGINAL[0]: reassembled_table_init(&stream_reassembled_table)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( &stream_reassembled_table )
  ORIGINAL[1]: &stream_reassembled_table
  TYPE[1]: CALL
  TOKENIZED[1]: &stream_reassembled_table
  ORIGINAL[2]: <global> stream_reassembled_table
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771361
FRAGMENT_COUNT: 3
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: abort()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )

CENTER_NODE: 68719476813
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: g_hash_table_destroy(stream_hash)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: stream_hash = ((void *)0)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = ( ( void * ) 0 )
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: <global> stream_hash
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064771209
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash = g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(stream_hash_func,stream_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> stream_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719476977
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream_hash_lookup_circ(circuit,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: circuit
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: p2p_dir
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476807
FRAGMENT_COUNT: 7
  ORIGINAL[0]: key1 -> p2p_dir
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: key1 -> is_circuit
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: key1 -> is_circuit
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: key1 -> circ
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: circ
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key1
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key1
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476931
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash = g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: g_hash_table_new(fragment_hash_func,fragment_compare_func)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> fragment_hash
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064771507
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (void )(frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: ( void ) ( frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: frag?((void )0) : ((getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[2]: (void )0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void ) 0
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: frag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476969
FRAGMENT_COUNT: 5
  ORIGINAL[0]: stream_hash_lookup_conv(conv,p2p_dir)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: conv
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: p2p_dir
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: conv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771484
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (void )(frag?((void )0) : ((getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: ( void ) ( frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[1]: frag?((void )0) : ((getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: frag? ( ( void ) 0 ) : ( ( FUN1 ( \
  ORIGINAL[2]: (void )0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void ) 0
  ORIGINAL[3]: getenv(\
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( \
  ORIGINAL[4]: frag
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771339
FRAGMENT_COUNT: 4
  ORIGINAL[0]: val = (se_alloc(sizeof(stream_pdu_fragment_t )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = ( FUN1 ( sizeof ( VAR2 ) ) )
  ORIGINAL[1]: se_alloc(sizeof(stream_pdu_fragment_t ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( sizeof ( VAR1 ) )
  ORIGINAL[2]: val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476899
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pdu_counter = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> pdu_counter
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 30064771257
FRAGMENT_COUNT: 2
  ORIGINAL[0]: new_stream(key)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: key
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640277
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476982
FRAGMENT_COUNT: 3
  ORIGINAL[0]: fragment_hash_lookup(stream,framenum,offset)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[1]: stream
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: framenum
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719476911
FRAGMENT_COUNT: 4
  ORIGINAL[0]: key -> stream
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: stream
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476938
FRAGMENT_COUNT: 6
  ORIGINAL[0]: key . offset = offset
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: val = (g_hash_table_lookup(fragment_hash,(&key)))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( FUN1 ( VAR2 , ( &key ) ) )
  ORIGINAL[2]: g_hash_table_lookup(fragment_hash,(&key))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( &key ) )
  ORIGINAL[3]: val
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> fragment_hash
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: val
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771313
FRAGMENT_COUNT: 4
  ORIGINAL[0]: fragment_hash != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: fragment_hash = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: <global> fragment_hash
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

