# Tokenized code fragments for 152338-v1.0.0-bad
# Total center nodes processed: 148
# Total code fragments found: 449

CENTER_NODE: 30064773085
FRAGMENT_COUNT: 10
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: __ctype_get_mb_cur_max()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: cur_mb_len = 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = 0
  ORIGINAL[3]: memset((&mbs),0,sizeof(mbs))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( &mbs ) , 0 , sizeof ( VAR1 ) )
  ORIGINAL[4]: &mbs
  TYPE[4]: CALL
  TOKENIZED[4]: &mbs
  ORIGINAL[5]: sizeof(mbs)
  TYPE[5]: CALL
  TOKENIZED[5]: sizeof ( VAR1 )
  ORIGINAL[6]: <global> cur_mb_len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> mbs
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> mbs
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> syntax_bits_set
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1

CENTER_NODE: 30064775787
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: cpp[i] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = ( ( void * ) 0 )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 47244640854
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775764
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771235
FRAGMENT_COUNT: 3
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772865
FRAGMENT_COUNT: 8
  ORIGINAL[0]: depth > dfa -> depth
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR1
  ORIGINAL[1]: dfa -> depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> depth = depth
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 = VAR2
  ORIGINAL[3]: dfa -> depth
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: depth
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> depth
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> dfa
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> depth
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 68719476861
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(charclass )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( VAR1 )
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: charclass
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640563
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771101
FRAGMENT_COUNT: 13
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: getenv(\
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( \
  ORIGINAL[2]: strcmp(getenv(\
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( FUN2 ( \
  ORIGINAL[3]: *stonesoup_server = mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[3]: CALL
  TOKENIZED[3]: *stonesoup_server = FUN1 ( VAR1 , VAR2 )
  ORIGINAL[4]: mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[5]: mg_set_option(stonesoup_server, \
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , \
  ORIGINAL[6]: mg_destroy_server(&stonesoup_server)
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( &stonesoup_server )
  ORIGINAL[7]: &stonesoup_server
  TYPE[7]: CALL
  TOKENIZED[7]: &stonesoup_server
  ORIGINAL[8]: if (getenv(\
  TYPE[8]: CONTROL_STRUCTURE
  TOKENIZED[8]: if ( FUN1 ( \
  ORIGINAL[9]: stonesoup_server
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: NULL
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: stonesoup_server
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: stonesoup_server
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640609
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774853
FRAGMENT_COUNT: 14
  ORIGINAL[0]: d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tralloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: sizeof(( *d -> newlines)) == 1
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[3]: d -> tralloc
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: xnmalloc((d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( ( VAR1 -> VAR2 ) , sizeof ( ( *d -> VAR3 ) ) )
  ORIGINAL[5]: d -> tralloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: sizeof(( *d -> newlines))
  TYPE[6]: CALL
  TOKENIZED[6]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[7]: tralloc
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: d
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640389
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640286
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: s[i] = ~s[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[4]: for (i = 0;i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++i)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++i )

CENTER_NODE: 47244640674
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477883
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> tindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: tokens
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640309
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478001
FRAGMENT_COUNT: 5
  ORIGINAL[0]: lo = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: hi = count
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: hi
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: count
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: hi
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771181
FRAGMENT_COUNT: 7
  ORIGINAL[0]: i == 0 || src[i-1] != '\\\\'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[1]: i == 0 || src[i-1] != '\\\\'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[2]: src[i] == '&'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] == '&'
  ORIGINAL[3]: i == 0 || src[i-1] != '\\\\'
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == 0 || VAR2 [ i-1 ] != '\\\\'
  ORIGINAL[4]: i++
  TYPE[4]: CALL
  TOKENIZED[4]: i++
  ORIGINAL[5]: src
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771996
FRAGMENT_COUNT: 7
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: work_mbc -> cset = ((equal(ccl,zeroclass)?(- 1) : charclass_index(ccl)))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( FUN1 ( VAR3 , VAR4 ) ? ( - 1 ) : FUN2 ( VAR3 ) ) )
  ORIGINAL[2]: work_mbc -> cset
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: equal(ccl,zeroclass)?(- 1) : charclass_index(ccl)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 ) ? ( - 1 ) : FUN2 ( VAR1 )
  ORIGINAL[4]: cset
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: work_mbc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: ccl
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640437
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776388
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640675
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775876
FRAGMENT_COUNT: 6
  ORIGINAL[0]: rcp != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: rcp = strchr((rcp + 1),( *lcp))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( ( VAR1 + 1 ) , ( *lcp ) )
  ORIGINAL[2]: strchr((rcp + 1),( *lcp))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 + 1 ) , ( *lcp ) )
  ORIGINAL[3]: rcp + 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 + 1
  ORIGINAL[4]: *lcp
  TYPE[4]: CALL
  TOKENIZED[4]: *lcp
  ORIGINAL[5]: rcp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640700
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064775355
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *pp - p1 < maxlen
  TYPE[0]: CALL
  TOKENIZED[0]: *pp - VAR1 < VAR2
  ORIGINAL[1]: s1 = state_index(d,(&follows),wchar_context(wc))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , ( &follows ) , FUN2 ( VAR3 ) )
  ORIGINAL[2]: state_index(d,(&follows),wchar_context(wc))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( &follows ) , FUN2 ( VAR2 ) )
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775115
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < work_mbc -> ncoll_elems
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: strncpy(buffer,((const char *)buf_begin) + idx,op_len)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , ( ( const char * ) VAR2 ) + VAR3 , VAR4 )
  ORIGINAL[2]: ((const char *)buf_begin) + idx
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( const char * ) VAR1 ) + VAR2
  ORIGINAL[3]: (const char *)buf_begin
  TYPE[3]: CALL
  TOKENIZED[3]: ( const char * ) VAR1
  ORIGINAL[4]: idx
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: op_len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479119
FRAGMENT_COUNT: 4
  ORIGINAL[0]: context & 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & 1
  ORIGINAL[1]: pos . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: constraint
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: pos
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640786
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640397
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640696
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640671
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771358
FRAGMENT_COUNT: 6
  ORIGINAL[0]: prednames[i] . name
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: prednames[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: strcmp(str,prednames[i] . name) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] . VAR4 ) == 0
  ORIGINAL[3]: name
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> prednames
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064772151
FRAGMENT_COUNT: 8
  ORIGINAL[0]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: lexleft > 1 && lexptr[0] == '\\\\' && lexptr[1] == '|'
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 > 1 && VAR2 [ 0 ] == '\\\\' && VAR2 [ 1 ] == '|'
  ORIGINAL[2]: lexleft > 1 && lexptr[0] == '\\\\'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 > 1 && VAR2 [ 0 ] == '\\\\'
  ORIGINAL[3]: lexleft > 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 > 1
  ORIGINAL[4]: lexptr[0] == '\\\\'
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ 0 ] == '\\\\'
  ORIGINAL[5]: lexptr[1] == '|'
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ 1 ] == '|'
  ORIGINAL[6]: lexptr[1]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ 1 ]
  ORIGINAL[7]: <global> lexptr
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 47244640773
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476826
FRAGMENT_COUNT: 3
  ORIGINAL[0]: BACKREF=257
  TYPE[0]: CALL
  TOKENIZED[0]: BACKREF=257
  ORIGINAL[1]: BEGLINE=258
  TYPE[1]: CALL
  TOKENIZED[1]: BEGLINE=258
  ORIGINAL[2]: BEGLINE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775895
FRAGMENT_COUNT: 20
  ORIGINAL[0]: old == ((void *)0) || new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) || VAR2 == ( ( void * ) 0 )
  ORIGINAL[1]: new[i] != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[2]: new[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: old = enlist(old,new[i],strlen(new[i]))
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[5]: enlist(old,new[i],strlen(new[i]))
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[6]: new[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: strlen(new[i])
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( VAR1 [ VAR2 ] )
  ORIGINAL[8]: new[i]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 [ VAR2 ]
  ORIGINAL[9]: old == ((void *)0)
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[10]: (void *)0
  TYPE[10]: CALL
  TOKENIZED[10]: ( void * ) 0
  ORIGINAL[11]: for (i = 0;new[i] != ((void *)0);++i)
  TYPE[11]: CONTROL_STRUCTURE
  TOKENIZED[11]: for ( VAR1 = 0 ; VAR2 [ VAR1 ] != ( ( void * ) 0 ) ; ++i )
  ORIGINAL[12]: old
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: old
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: new
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: i
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: new
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: i
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: old
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: old
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: VAR1

CENTER_NODE: 47244640289
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479702
FRAGMENT_COUNT: 7
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: oldsize + newsize
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 + VAR2
  ORIGINAL[2]: oldsize
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: old
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: oldsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: newsize
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: oldsize
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640320
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640611
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476953
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: utf8
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719480129
FRAGMENT_COUNT: 6
  ORIGINAL[0]: isValid(physicalness_punalua) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 ) == 1
  ORIGINAL[1]: strlen(physicalness_punalua)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: physicalness_punalua
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_parsed_input
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: physicalness_punalua
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: physicalness_punalua
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640350
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640407
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640892
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775950
FRAGMENT_COUNT: 5
  ORIGINAL[0]: mp -> left[0] = mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = VAR1 -> VAR4 [ 0 ] = '\\0'
  ORIGINAL[1]: mp -> left[0]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[2]: mp -> right[0] = mp -> is[0] = '\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ 0 ] = VAR1 -> VAR3 [ 0 ] = '\\0'
  ORIGINAL[3]: mp -> right[0]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[4]: mp -> is[0] = '\\0'
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ 0 ] = '\\0'

CENTER_NODE: 47244640893
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479633
FRAGMENT_COUNT: 4
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640372
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478174
FRAGMENT_COUNT: 10
  ORIGINAL[0]: i < d -> sindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> salloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> sindex
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> sindex
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> states
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> salloc
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: d -> states[i] . hash = hash
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ] . VAR4 = VAR4
  ORIGINAL[7]: d -> states
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: states
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640731
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640425
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640641
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476901
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c == eolbyte
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: <global> eolbyte
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 68719476737
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: format
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064773260
FRAGMENT_COUNT: 4
  ORIGINAL[0]: s1 -> elems[i] . index > s2 -> elems[j] . index
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 -> VAR2 [ VAR6 ] . VAR4
  ORIGINAL[1]: s1 -> elems[i++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ i++ ]
  ORIGINAL[2]: i++
  TYPE[2]: CALL
  TOKENIZED[2]: i++
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640415
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772993
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: nsubtoks(tindex - 1)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 - 1 )
  ORIGINAL[2]: tindex - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - 1
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771082
FRAGMENT_COUNT: 10
  ORIGINAL[0]: ev == MG_REQUEST
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: strcmp(ifmatch_header, \
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , \
  ORIGINAL[2]: strcmp(ifmatch_header, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: stonesoup_printf_context = conn
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 = VAR2
  ORIGINAL[4]: stonesoup_handle_taint(stonesoup_tainted_buff)
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 )
  ORIGINAL[5]: if (strcmp(ifmatch_header, \
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: if ( FUN1 ( VAR1 , \
  ORIGINAL[6]: <global> stonesoup_printf_context
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: conn
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_tainted_buff
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: MG_TRUE
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064775594
FRAGMENT_COUNT: 2
  ORIGINAL[0]: d -> nmbcsets = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: d -> nmbcsets
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 47244640889
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773330
FRAGMENT_COUNT: 8
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[i] = s -> elems[i + 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] = VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[2]: s -> elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: s -> elems[i + 1]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 + 1 ]
  ORIGINAL[5]: s -> elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476845
FRAGMENT_COUNT: 5
  ORIGINAL[0]: b / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: b
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640829
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640330
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773932
FRAGMENT_COUNT: 12
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> tokens[i] < (1 << 8) || d -> tokens[i] == BACKREF || d -> tokens[i] == ANYCHAR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] < ( 1 << 8 ) || VAR1 -> VAR2 [ VAR3 ] == VAR4 || VAR1 -> VAR2 [ VAR3 ] == VAR5
  ORIGINAL[2]: d -> tokens[i] < (1 << 8) || d -> tokens[i] == BACKREF
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] < ( 1 << 8 ) || VAR1 -> VAR2 [ VAR3 ] == VAR4
  ORIGINAL[3]: d -> tokens[i] < (1 << 8)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] < ( 1 << 8 )
  ORIGINAL[4]: d -> tokens[i] == BACKREF
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] == VAR4
  ORIGINAL[5]: d -> tokens[i] == ANYCHAR
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] == VAR4
  ORIGINAL[6]: d -> tokens[i]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[7]: d -> tokens
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: tokens
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: ANYCHAR
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064774895
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> newlines = (xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[2]: d -> newlines
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnrealloc((d -> newlines),(d -> tralloc),sizeof(( *d -> newlines)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )

CENTER_NODE: 68719479657
FRAGMENT_COUNT: 9
  ORIGINAL[0]: d -> charclasses
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> mb_cur_max
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: i < (d -> sindex)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[4]: d -> sindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: sindex
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064773069
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok != RPAREN && tok != OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[1]: tok != RPAREN
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2
  ORIGINAL[2]: tok != OR
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640727
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476822
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064775924
FRAGMENT_COUNT: 10
  ORIGINAL[0]: both == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: left[lnum] != ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[2]: left[lnum]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: right[rnum] != ((void *)0)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[5]: left[lnum]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: left
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: left
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: lnum
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: left
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064771148
FRAGMENT_COUNT: 3
  ORIGINAL[0]: src+=3
  TYPE[0]: CALL
  TOKENIZED[0]: src+=3
  ORIGINAL[1]: src
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: src
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775769
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: *cp
  TYPE[1]: CALL
  TOKENIZED[1]: *cp
  ORIGINAL[2]: strncmp(cp,lookfor,len) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[3]: strncmp(cp,lookfor,len)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: for (cp = lookin;( *cp) != '\\0';++cp)
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: for ( VAR1 = VAR2 ; ( *cp ) != '\\0' ; ++cp )
  ORIGINAL[6]: cp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: lookfor
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: len
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640650
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640991
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477988
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dst -> alloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: dst -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: memcpy((dst -> elems),(src -> elems),sizeof(dst -> elems[0]) * src -> nelem)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR3 -> VAR2 ) , sizeof ( VAR1 -> VAR2 [ 0 ] ) * VAR3 -> VAR4 )
  ORIGINAL[3]: dst -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: dst -> nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nelem
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: dst
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479495
FRAGMENT_COUNT: 12
  ORIGINAL[0]: trans[s]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: s = transit_state(d,s,&p)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , VAR1 , &p )
  ORIGINAL[2]: trans = d -> trans
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR1
  ORIGINAL[3]: d -> trans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: trans[s]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: trans[s1]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: trans
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: backref
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: trans
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: trans
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: trans
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064774768
FRAGMENT_COUNT: 4
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> trans[oldalloc] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] = ( ( void * ) 0 )
  ORIGINAL[2]: d -> trans[oldalloc]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 47244640360
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640855
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064775179
FRAGMENT_COUNT: 9
  ORIGINAL[0]: d -> tokens[pos . index]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[1]: rarray[i] = match_anychar(d,s,pos,idx)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR3 , VAR4 , VAR5 , VAR6 )
  ORIGINAL[2]: rarray[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: match_anychar(d,s,pos,idx)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 , VAR4 )
  ORIGINAL[4]: rarray
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: rarray
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: rarray
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064775684
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfamust(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640782
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640775
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640440
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478271
FRAGMENT_COUNT: 7
  ORIGINAL[0]: p . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: d -> tokens[old . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[2]: p . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: constraint
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: BEGLINE
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640370
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776233
FRAGMENT_COUNT: 9
  ORIGINAL[0]: lmp -> is[0] != '\\0' && rmp -> is[0] != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ] != '\\0' && VAR3 -> VAR2 [ 0 ] != '\\0'
  ORIGINAL[1]: lmp -> is = icatalloc(lmp -> is,(rmp -> is))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR2 ) )
  ORIGINAL[2]: lmp -> is
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: icatalloc(lmp -> is,(rmp -> is))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 , ( VAR3 -> VAR2 ) )
  ORIGINAL[4]: lmp -> is
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: is
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: lmp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: lmp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: lmp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640774
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640780
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640918
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771314
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < (1 << 8)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( 1 << 8 )
  ORIGINAL[1]: sbit[i] = char_context(i)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = FUN1 ( VAR2 )
  ORIGINAL[2]: sbit[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: char_context(i)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: <global> sbit
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064776386
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064775241
FRAGMENT_COUNT: 7
  ORIGINAL[0]: work_mbls[i] ==  *mbclen
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == *mbclen
  ORIGINAL[1]: j < d -> follows[d -> states[s] . mbps . elems[i] . index] . nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[2]: d -> states[s] . mbps . elems[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ]
  ORIGINAL[3]: d -> states[s] . mbps . elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[4]: d -> states[s] . mbps
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640580
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640776
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640459
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476873
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640890
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640942
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640328
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640695
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640672
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771270
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa -> calloc <= dfa -> cindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> cindex + 1 + (!dfa -> charclasses)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 + 1 + ( !dfa -> VAR3 )
  ORIGINAL[2]: !dfa -> charclasses
  TYPE[2]: CALL
  TOKENIZED[2]: !dfa -> VAR1
  ORIGINAL[3]: dfa -> charclasses
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640381
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640853
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476854
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c[b / (8 * sizeof(int ))]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640795
FRAGMENT_COUNT: 2
  ORIGINAL[0]: works < 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 47244640616
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640787
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775655
FRAGMENT_COUNT: 12
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: d -> mbcsets = ((sizeof(( *d -> mbcsets)) == 1?xmalloc(d -> mbcsets_alloc) : xnmalloc(d -> mbcsets_alloc,sizeof(( *d -> mbcsets)))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( ( sizeof ( ( *d -> VAR2 ) ) == 1?xmalloc ( VAR1 -> VAR3 ) : FUN1 ( VAR1 -> VAR3 , sizeof ( ( *d -> VAR2 ) ) ) ) )
  ORIGINAL[2]: d -> mbcsets
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *d -> mbcsets)) == 1?xmalloc(d -> mbcsets_alloc) : xnmalloc(d -> mbcsets_alloc,sizeof(( *d -> mbcsets)))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[4]: d -> mbcsets
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: d -> mbcsets
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: mbcsets
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064773045
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < minrep
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: copytoks(tindex,ntokens)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: tindex
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ntokens
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: CAT
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719480109
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771300
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == ((wchar_t )eolbyte)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[2]: (wchar_t )eolbyte
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) VAR2
  ORIGINAL[3]: wc == 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == 0
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640367
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640673
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479068
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_DONE=1
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_DONE=1
  ORIGINAL[2]: TRANSIT_STATE_DONE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640643
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771204
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 47244640338
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640619
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640781
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640783
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640789
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640339
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480108
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(struct dfa )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( struct VAR1 )
  ORIGINAL[1]: struct dfa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: struct VAR1

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064772956
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[2]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3
  ORIGINAL[3]: tok >= 0 && tok < (1 << 8) || tok >= CSET
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2
  ORIGINAL[4]: tok == BACKREF
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: tok == BEGLINE
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: BEGLINE
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640448
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640676
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640900
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640458
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773150
FRAGMENT_COUNT: 6
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[1]: *s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: *s -> VAR1
  ORIGINAL[2]: *s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: *s -> VAR1
  ORIGINAL[3]: s -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477946
FRAGMENT_COUNT: 5
  ORIGINAL[0]: tok == OR
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: lex()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1

CENTER_NODE: 30064773638
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ~(letters[j] | newline[j])
  TYPE[1]: CALL
  TOKENIZED[1]: ~ ( VAR1 [ VAR2 ] | VAR3 [ VAR2 ] )
  ORIGINAL[2]: letters[j] | newline[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] | VAR3 [ VAR2 ]
  ORIGINAL[3]: letters[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: newline[j]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 47244640561
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640697
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773645
FRAGMENT_COUNT: 9
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719479759
FRAGMENT_COUNT: 8
  ORIGINAL[0]: --i == j
  TYPE[0]: CALL
  TOKENIZED[0]: --i == VAR1
  ORIGINAL[1]: cpp[j] = cpp[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] = VAR1 [ VAR3 ]
  ORIGINAL[2]: cpp[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: cpp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: i
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 68719476941
FRAGMENT_COUNT: 6
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: setbit(b,c)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: b
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: b
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: b
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640788
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772901
FRAGMENT_COUNT: 9
  ORIGINAL[0]: work_mbc -> invert
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: !using_utf8() && work_mbc -> cset != (- 1)
  TYPE[1]: CALL
  TOKENIZED[1]: !using_utf8 ( ) && VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[2]: !using_utf8()
  TYPE[2]: CALL
  TOKENIZED[2]: !using_utf8 ( )
  ORIGINAL[3]: using_utf8()
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( )
  ORIGINAL[4]: work_mbc -> cset != (- 1)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 != ( - 1 )
  ORIGINAL[5]: work_mbc -> cset
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: - 1
  TYPE[6]: CALL
  TOKENIZED[6]: - 1
  ORIGINAL[7]: cset
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: work_mbc
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719476851
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( int )
  ORIGINAL[1]: int
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: int

CENTER_NODE: 47244640417
FRAGMENT_COUNT: 0

