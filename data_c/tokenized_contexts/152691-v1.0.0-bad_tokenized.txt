# Tokenized code fragments for 152691-v1.0.0-bad
# Total center nodes processed: 34
# Total code fragments found: 299

CENTER_NODE: 68719476948
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> fast_seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: fast_seek
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771492
FRAGMENT_COUNT: 4
  ORIGINAL[0]: file_seek(file,delta,1,err)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , 1 , VAR3 )
  ORIGINAL[1]: file
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: delta
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: err
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771323
FRAGMENT_COUNT: 72
  ORIGINAL[0]: fd == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: state == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: state -> fast_seek_cur = ((void *)0)
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[5]: state -> fast_seek_cur
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: (void *)0
  TYPE[6]: CALL
  TOKENIZED[6]: ( void * ) 0
  ORIGINAL[7]: state -> fast_seek = ((void *)0)
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[8]: state -> fast_seek
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: (void *)0
  TYPE[9]: CALL
  TOKENIZED[9]: ( void * ) 0
  ORIGINAL[10]: state -> fd = fd
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 = VAR2
  ORIGINAL[11]: state -> fd
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: state -> is_compressed = 0
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2 = 0
  ORIGINAL[13]: state -> is_compressed
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2
  ORIGINAL[14]: state -> start = lseek(state -> fd,0,1)
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2 = FUN1 ( VAR1 -> VAR3 , 0 , 1 )
  ORIGINAL[15]: state -> start
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2
  ORIGINAL[16]: lseek(state -> fd,0,1)
  TYPE[16]: CALL
  TOKENIZED[16]: FUN1 ( VAR1 -> VAR2 , 0 , 1 )
  ORIGINAL[17]: state -> fd
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2
  ORIGINAL[18]: state -> start == (- 1)
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2 == ( - 1 )
  ORIGINAL[19]: state -> start
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2
  ORIGINAL[20]: - 1
  TYPE[20]: CALL
  TOKENIZED[20]: - 1
  ORIGINAL[21]: state -> raw_pos = state -> start
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[22]: state -> raw_pos
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 -> VAR2
  ORIGINAL[23]: state -> start
  TYPE[23]: CALL
  TOKENIZED[23]: VAR1 -> VAR2
  ORIGINAL[24]: gz_reset(state)
  TYPE[24]: CALL
  TOKENIZED[24]: FUN1 ( VAR1 )
  ORIGINAL[25]: state -> in = ((unsigned char *)(g_try_malloc(want)))
  TYPE[25]: CALL
  TOKENIZED[25]: VAR1 -> VAR2 = ( ( unsigned char * ) ( FUN1 ( VAR3 ) ) )
  ORIGINAL[26]: state -> in
  TYPE[26]: CALL
  TOKENIZED[26]: VAR1 -> VAR2
  ORIGINAL[27]: (unsigned char *)(g_try_malloc(want))
  TYPE[27]: CALL
  TOKENIZED[27]: ( unsigned char * ) ( FUN1 ( VAR1 ) )
  ORIGINAL[28]: g_try_malloc(want)
  TYPE[28]: CALL
  TOKENIZED[28]: FUN1 ( VAR1 )
  ORIGINAL[29]: state -> out = ((unsigned char *)(g_try_malloc((want << 1))))
  TYPE[29]: CALL
  TOKENIZED[29]: VAR1 -> VAR2 = ( ( unsigned char * ) ( FUN1 ( ( VAR3 << 1 ) ) ) )
  ORIGINAL[30]: state -> out
  TYPE[30]: CALL
  TOKENIZED[30]: VAR1 -> VAR2
  ORIGINAL[31]: (unsigned char *)(g_try_malloc((want << 1)))
  TYPE[31]: CALL
  TOKENIZED[31]: ( unsigned char * ) ( FUN1 ( ( VAR1 << 1 ) ) )
  ORIGINAL[32]: g_try_malloc((want << 1))
  TYPE[32]: CALL
  TOKENIZED[32]: FUN1 ( ( VAR1 << 1 ) )
  ORIGINAL[33]: want << 1
  TYPE[33]: CALL
  TOKENIZED[33]: VAR1 << 1
  ORIGINAL[34]: state -> size = want
  TYPE[34]: CALL
  TOKENIZED[34]: VAR1 -> VAR2 = VAR3
  ORIGINAL[35]: state -> size
  TYPE[35]: CALL
  TOKENIZED[35]: VAR1 -> VAR2
  ORIGINAL[36]: state -> in == ((void *)0) || state -> out == ((void *)0)
  TYPE[36]: CALL
  TOKENIZED[36]: VAR1 -> VAR2 == ( ( void * ) 0 ) || VAR1 -> VAR3 == ( ( void * ) 0 )
  ORIGINAL[37]: state -> in == ((void *)0)
  TYPE[37]: CALL
  TOKENIZED[37]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[38]: state -> in
  TYPE[38]: CALL
  TOKENIZED[38]: VAR1 -> VAR2
  ORIGINAL[39]: (void *)0
  TYPE[39]: CALL
  TOKENIZED[39]: ( void * ) 0
  ORIGINAL[40]: fast_seek_cur
  TYPE[40]: FIELD_IDENTIFIER
  TOKENIZED[40]: VAR1
  ORIGINAL[41]: fast_seek
  TYPE[41]: FIELD_IDENTIFIER
  TOKENIZED[41]: VAR1
  ORIGINAL[42]: fd
  TYPE[42]: FIELD_IDENTIFIER
  TOKENIZED[42]: VAR1
  ORIGINAL[43]: is_compressed
  TYPE[43]: FIELD_IDENTIFIER
  TOKENIZED[43]: VAR1
  ORIGINAL[44]: start
  TYPE[44]: FIELD_IDENTIFIER
  TOKENIZED[44]: VAR1
  ORIGINAL[45]: fd
  TYPE[45]: FIELD_IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: start
  TYPE[46]: FIELD_IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: raw_pos
  TYPE[47]: FIELD_IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: start
  TYPE[48]: FIELD_IDENTIFIER
  TOKENIZED[48]: VAR1
  ORIGINAL[49]: in
  TYPE[49]: FIELD_IDENTIFIER
  TOKENIZED[49]: VAR1
  ORIGINAL[50]: out
  TYPE[50]: FIELD_IDENTIFIER
  TOKENIZED[50]: VAR1
  ORIGINAL[51]: size
  TYPE[51]: FIELD_IDENTIFIER
  TOKENIZED[51]: VAR1
  ORIGINAL[52]: in
  TYPE[52]: FIELD_IDENTIFIER
  TOKENIZED[52]: VAR1
  ORIGINAL[53]: state
  TYPE[53]: IDENTIFIER
  TOKENIZED[53]: VAR1
  ORIGINAL[54]: state
  TYPE[54]: IDENTIFIER
  TOKENIZED[54]: VAR1
  ORIGINAL[55]: state
  TYPE[55]: IDENTIFIER
  TOKENIZED[55]: VAR1
  ORIGINAL[56]: state
  TYPE[56]: IDENTIFIER
  TOKENIZED[56]: VAR1
  ORIGINAL[57]: fd
  TYPE[57]: IDENTIFIER
  TOKENIZED[57]: VAR1
  ORIGINAL[58]: state
  TYPE[58]: IDENTIFIER
  TOKENIZED[58]: VAR1
  ORIGINAL[59]: state
  TYPE[59]: IDENTIFIER
  TOKENIZED[59]: VAR1
  ORIGINAL[60]: state
  TYPE[60]: IDENTIFIER
  TOKENIZED[60]: VAR1
  ORIGINAL[61]: state
  TYPE[61]: IDENTIFIER
  TOKENIZED[61]: VAR1
  ORIGINAL[62]: state
  TYPE[62]: IDENTIFIER
  TOKENIZED[62]: VAR1
  ORIGINAL[63]: state
  TYPE[63]: IDENTIFIER
  TOKENIZED[63]: VAR1
  ORIGINAL[64]: state
  TYPE[64]: IDENTIFIER
  TOKENIZED[64]: VAR1
  ORIGINAL[65]: state
  TYPE[65]: IDENTIFIER
  TOKENIZED[65]: VAR1
  ORIGINAL[66]: want
  TYPE[66]: IDENTIFIER
  TOKENIZED[66]: VAR1
  ORIGINAL[67]: state
  TYPE[67]: IDENTIFIER
  TOKENIZED[67]: VAR1
  ORIGINAL[68]: want
  TYPE[68]: IDENTIFIER
  TOKENIZED[68]: VAR1
  ORIGINAL[69]: state
  TYPE[69]: IDENTIFIER
  TOKENIZED[69]: VAR1
  ORIGINAL[70]: want
  TYPE[70]: IDENTIFIER
  TOKENIZED[70]: VAR1
  ORIGINAL[71]: state
  TYPE[71]: IDENTIFIER
  TOKENIZED[71]: VAR1

CENTER_NODE: 47244640260
FRAGMENT_COUNT: 4
  ORIGINAL[0]: data_size < buffer_size
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: stonesoup_exit_flag = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: break;
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: break ;
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064771612
FRAGMENT_COUNT: 5
  ORIGINAL[0]: eol != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: n = ((unsigned int )(eol - file -> next)) + 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( unsigned int ) ( VAR2 - VAR3 -> VAR4 ) ) + 1
  ORIGINAL[2]: ((unsigned int )(eol - file -> next)) + 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( unsigned int ) ( VAR1 - VAR2 -> VAR3 ) ) + 1
  ORIGINAL[3]: (unsigned int )(eol - file -> next)
  TYPE[3]: CALL
  TOKENIZED[3]: ( unsigned int ) ( VAR1 - VAR2 -> VAR3 )
  ORIGINAL[4]: n
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477020
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> raw_pos
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: raw_pos
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771380
FRAGMENT_COUNT: 3
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1
  ORIGINAL[1]: fd = open(path,0 | 0,0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 )
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1

CENTER_NODE: 30064771644
FRAGMENT_COUNT: 9
  ORIGINAL[0]: fh -> err != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 != 0
  ORIGINAL[1]: fh -> err_info == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: fh -> err_info
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0
  ORIGINAL[4]: fh -> err_info
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: err_info
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: fh
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: fh
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: fh
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064771632
FRAGMENT_COUNT: 8
  ORIGINAL[0]: file -> eof && file -> avail_in == 0 && file -> have == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0 && VAR1 -> VAR4 == 0
  ORIGINAL[1]: file -> eof && file -> avail_in == 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 && VAR1 -> VAR3 == 0
  ORIGINAL[2]: file -> eof
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file -> avail_in == 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 == 0
  ORIGINAL[4]: file -> have == 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 == 0
  ORIGINAL[5]: file -> have
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: have
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771275
FRAGMENT_COUNT: 9
  ORIGINAL[0]: state -> have
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: state -> have
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> have -= n
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -= VAR3
  ORIGINAL[3]: state -> have
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: have
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: state
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: n
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: state
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477136
FRAGMENT_COUNT: 4
  ORIGINAL[0]: file -> fd
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: fd
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: fd
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771444
FRAGMENT_COUNT: 50
  ORIGINAL[0]: offset < 0 && file -> next
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < 0 && VAR2 -> VAR3
  ORIGINAL[1]: -offset <= had
  TYPE[1]: CALL
  TOKENIZED[1]: -offset <= VAR1
  ORIGINAL[2]: lseek(file -> fd,off,0) == (- 1)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 , VAR3 , 0 ) == ( - 1 )
  ORIGINAL[3]: lseek(file -> fd,off,0)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 -> VAR2 , VAR3 , 0 )
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1
  ORIGINAL[5]: *err =  *__errno_location()
  TYPE[5]: CALL
  TOKENIZED[5]: *err = *__errno_location ( )
  ORIGINAL[6]: *err
  TYPE[6]: CALL
  TOKENIZED[6]: *err
  ORIGINAL[7]: *__errno_location()
  TYPE[7]: CALL
  TOKENIZED[7]: *__errno_location ( )
  ORIGINAL[8]: __errno_location()
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( )
  ORIGINAL[9]: - 1
  TYPE[9]: CALL
  TOKENIZED[9]: - 1
  ORIGINAL[10]: fast_seek_reset(file)
  TYPE[10]: CALL
  TOKENIZED[10]: FUN1 ( VAR1 )
  ORIGINAL[11]: file -> raw_pos = off
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 = VAR3
  ORIGINAL[12]: file -> raw_pos
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: file -> have = 0
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 = 0
  ORIGINAL[14]: file -> have
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: file -> eof = 0
  TYPE[15]: CALL
  TOKENIZED[15]: VAR1 -> VAR2 = 0
  ORIGINAL[16]: file -> eof
  TYPE[16]: CALL
  TOKENIZED[16]: VAR1 -> VAR2
  ORIGINAL[17]: file -> seek = 0
  TYPE[17]: CALL
  TOKENIZED[17]: VAR1 -> VAR2 = 0
  ORIGINAL[18]: file -> seek
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 -> VAR2
  ORIGINAL[19]: file -> err = 0
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 -> VAR2 = 0
  ORIGINAL[20]: file -> err
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 -> VAR2
  ORIGINAL[21]: file -> err_info = ((void *)0)
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 -> VAR2 = ( ( void * ) 0 )
  ORIGINAL[22]: file -> err_info
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 -> VAR2
  ORIGINAL[23]: (void *)0
  TYPE[23]: CALL
  TOKENIZED[23]: ( void * ) 0
  ORIGINAL[24]: file -> avail_in = 0
  TYPE[24]: CALL
  TOKENIZED[24]: VAR1 -> VAR2 = 0
  ORIGINAL[25]: file -> avail_in
  TYPE[25]: CALL
  TOKENIZED[25]: VAR1 -> VAR2
  ORIGINAL[26]: file -> compression = here -> compression
  TYPE[26]: CALL
  TOKENIZED[26]: VAR1 -> VAR2 = VAR3 -> VAR2
  ORIGINAL[27]: file -> compression
  TYPE[27]: CALL
  TOKENIZED[27]: VAR1 -> VAR2
  ORIGINAL[28]: here -> compression
  TYPE[28]: CALL
  TOKENIZED[28]: VAR1 -> VAR2
  ORIGINAL[29]: raw_pos
  TYPE[29]: FIELD_IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: have
  TYPE[30]: FIELD_IDENTIFIER
  TOKENIZED[30]: VAR1
  ORIGINAL[31]: eof
  TYPE[31]: FIELD_IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: seek
  TYPE[32]: FIELD_IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: err
  TYPE[33]: FIELD_IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: err_info
  TYPE[34]: FIELD_IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: avail_in
  TYPE[35]: FIELD_IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: compression
  TYPE[36]: FIELD_IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: compression
  TYPE[37]: FIELD_IDENTIFIER
  TOKENIZED[37]: VAR1
  ORIGINAL[38]: err
  TYPE[38]: IDENTIFIER
  TOKENIZED[38]: VAR1
  ORIGINAL[39]: file
  TYPE[39]: IDENTIFIER
  TOKENIZED[39]: VAR1
  ORIGINAL[40]: file
  TYPE[40]: IDENTIFIER
  TOKENIZED[40]: VAR1
  ORIGINAL[41]: off
  TYPE[41]: IDENTIFIER
  TOKENIZED[41]: VAR1
  ORIGINAL[42]: file
  TYPE[42]: IDENTIFIER
  TOKENIZED[42]: VAR1
  ORIGINAL[43]: file
  TYPE[43]: IDENTIFIER
  TOKENIZED[43]: VAR1
  ORIGINAL[44]: file
  TYPE[44]: IDENTIFIER
  TOKENIZED[44]: VAR1
  ORIGINAL[45]: file
  TYPE[45]: IDENTIFIER
  TOKENIZED[45]: VAR1
  ORIGINAL[46]: file
  TYPE[46]: IDENTIFIER
  TOKENIZED[46]: VAR1
  ORIGINAL[47]: file
  TYPE[47]: IDENTIFIER
  TOKENIZED[47]: VAR1
  ORIGINAL[48]: file
  TYPE[48]: IDENTIFIER
  TOKENIZED[48]: VAR1
  ORIGINAL[49]: here
  TYPE[49]: IDENTIFIER
  TOKENIZED[49]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 30
  ORIGINAL[0]: state -> avail_in == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: state -> avail_in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fill_in_buffer(state) == - 1
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 ) == - 1
  ORIGINAL[3]: fill_in_buffer(state)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: - 1
  TYPE[4]: CALL
  TOKENIZED[4]: - 1
  ORIGINAL[5]: state -> fast_seek
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: state -> raw = state -> pos
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[7]: state -> raw
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: state -> pos
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: state -> next = state -> out
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 = VAR1 -> VAR3
  ORIGINAL[10]: state -> next
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2
  ORIGINAL[11]: state -> out
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: state -> avail_in
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2
  ORIGINAL[13]: state -> compression = 1
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 = 1
  ORIGINAL[14]: state -> compression
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: fast_seek
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: raw
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: pos
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: next
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: out
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: avail_in
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: compression
  TYPE[21]: FIELD_IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: state
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: state
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: state
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: state
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: state
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: state
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: state
  TYPE[28]: IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: state
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 2
  ORIGINAL[0]: pos > item -> out
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > VAR2 -> VAR3
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 68719477025
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stream -> is_compressed
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: is_compressed
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: stream
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477046
FRAGMENT_COUNT: 12
  ORIGINAL[0]: file -> seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: file -> skip
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: file -> next
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: file -> have
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: file -> err
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: file -> eof
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: file -> avail_in
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: file -> pos
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: eof
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: file
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: file
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: file
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1

CENTER_NODE: 30064771173
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 47244640308
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477133
FRAGMENT_COUNT: 4
  ORIGINAL[0]: (fd = open(path,0 | 0,0)) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = FUN1 ( VAR2 , 0 | 0 , 0 ) ) == - 1
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fd
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771291
FRAGMENT_COUNT: 3
  ORIGINAL[0]: state -> have = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: state -> have
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771206
FRAGMENT_COUNT: 5
  ORIGINAL[0]: file -> fast_seek -> len != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3 != 0
  ORIGINAL[1]: item = ((struct fast_seek_point *)file -> fast_seek -> pdata[file -> fast_seek -> len - 1])
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = ( ( struct VAR2 * ) VAR3 -> VAR4 -> VAR5 [ VAR3 -> VAR4 -> VAR6 - 1 ] )
  ORIGINAL[2]: (struct fast_seek_point *)file -> fast_seek -> pdata[file -> fast_seek -> len - 1]
  TYPE[2]: CALL
  TOKENIZED[2]: ( struct VAR1 * ) VAR2 -> VAR3 -> VAR4 [ VAR2 -> VAR3 -> VAR5 - 1 ]
  ORIGINAL[3]: item
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: item
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771554
FRAGMENT_COUNT: 2
  ORIGINAL[0]: file -> err
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1

CENTER_NODE: 68719476812
FRAGMENT_COUNT: 5
  ORIGINAL[0]: state -> eof == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: state -> eof
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> avail_in
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: avail_in
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: state
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771499
FRAGMENT_COUNT: 7
  ORIGINAL[0]: fstat(stream -> fd,statb) == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 , VAR3 ) == - 1
  ORIGINAL[1]: fstat(stream -> fd,statb)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 , VAR3 )
  ORIGINAL[2]: - 1
  TYPE[2]: CALL
  TOKENIZED[2]: - 1
  ORIGINAL[3]: err != ((void *)0)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: - 1
  TYPE[5]: CALL
  TOKENIZED[5]: - 1
  ORIGINAL[6]: err
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771651
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stream -> err = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = 0
  ORIGINAL[1]: stream -> err
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: err
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: stream
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stream
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477148
FRAGMENT_COUNT: 3
  ORIGINAL[0]: stonesoup_exit_flag = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: <global> stonesoup_exit_flag
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: stonesoup_exit_flag
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771658
FRAGMENT_COUNT: 5
  ORIGINAL[0]: close(file -> fd)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: file -> fd
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: fd
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: file
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: file
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771479
FRAGMENT_COUNT: 18
  ORIGINAL[0]: state -> compression == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == 0
  ORIGINAL[1]: state -> have
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: state -> compression == 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 == 1
  ORIGINAL[3]: state -> compression
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: raw_read(state,state -> out,state -> size,&state -> have) == - 1
  TYPE[4]: CALL
  TOKENIZED[4]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , &state -> VAR4 ) == - 1
  ORIGINAL[5]: raw_read(state,state -> out,state -> size,&state -> have)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR1 -> VAR2 , VAR1 -> VAR3 , &state -> VAR4 )
  ORIGINAL[6]: state -> out
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: state -> size
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: &state -> have
  TYPE[8]: CALL
  TOKENIZED[8]: &state -> VAR1
  ORIGINAL[9]: state -> have
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: - 1
  TYPE[10]: CALL
  TOKENIZED[10]: - 1
  ORIGINAL[11]: out
  TYPE[11]: FIELD_IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: size
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: have
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: state
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: state
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: state
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: state
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1

CENTER_NODE: 68719476736
FRAGMENT_COUNT: 4
  ORIGINAL[0]: va_start(argptr, format)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[1]: argptr
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: format
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: argptr
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477019
FRAGMENT_COUNT: 4
  ORIGINAL[0]: stream -> seek
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: stream -> skip
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: skip
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stream
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 1
  ORIGINAL[0]: window[32768]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 32768 ]

CENTER_NODE: 68719476804
FRAGMENT_COUNT: 8
  ORIGINAL[0]: state -> fd
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: state -> raw_pos
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ret < 0
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 < 0
  ORIGINAL[3]: state -> err =  *__errno_location()
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 = *__errno_location ( )
  ORIGINAL[4]: state -> err
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: state -> err_info
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: err_info
  TYPE[6]: FIELD_IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: state
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

