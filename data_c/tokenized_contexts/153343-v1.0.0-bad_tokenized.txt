# Tokenized code fragments for 153343-v1.0.0-bad
# Total center nodes processed: 145
# Total code fragments found: 474

CENTER_NODE: 68719479239
FRAGMENT_COUNT: 5
  ORIGINAL[0]: work_mbc -> range_sts[i] <= wc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] <= VAR4
  ORIGINAL[1]: work_mbc -> range_ends[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: work_mbc -> range_ends
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478004
FRAGMENT_COUNT: 6
  ORIGINAL[0]: src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: src -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dst -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: src -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: src
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640442
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479663
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfainit(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: dfaparse(s,len,d)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: len
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775674
FRAGMENT_COUNT: 5
  ORIGINAL[0]: !1 || !using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: !1 || !using_utf8 ( )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: for (i = 0;i < d -> tindex;++i)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++i )
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640773
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640304
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477770
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dfa -> nmultibyte_prop <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: new_n_alloc = dfa -> tindex + 1 + (!dfa -> multibyte_prop)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3 + 1 + ( !dfa -> VAR4 )
  ORIGINAL[2]: dfa -> tindex + 1 + (!dfa -> multibyte_prop)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 + 1 + ( !dfa -> VAR3 )
  ORIGINAL[3]: new_n_alloc
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: new_n_alloc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: new_n_alloc
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719478275
FRAGMENT_COUNT: 8
  ORIGINAL[0]: s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: d -> tokens[s -> elems[i] . index] >= (1 << 8) && d -> tokens[s -> elems[i] . index] != BACKREF && d -> tokens[s -> elems[i] . index] != ANYCHAR && d -> tokens[s -> elems[i] . index] != MBCSET && d -> tokens[s -> elems[i] . index] < CSET
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] >= ( 1 << 8 ) && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR7 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR8 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] != VAR9 && VAR1 -> VAR2 [ VAR3 -> VAR4 [ VAR5 ] . VAR6 ] < VAR10
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640659
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476893
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s1
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s2
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477024
FRAGMENT_COUNT: 14
  ORIGINAL[0]: cur_mb_len <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: lexptr += cur_mb_len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 += VAR2
  ORIGINAL[2]: lexleft -= cur_mb_len
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -= VAR2
  ORIGINAL[3]: <global> lexleft
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> lexleft
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> lexleft
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> cur_mb_len
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> lexleft
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> lexleft
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> lexleft
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> lexleft
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> lexleft
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> lexleft
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1
  ORIGINAL[13]: <global> lexleft
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: <global> VAR1

CENTER_NODE: 47244640766
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640660
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640934
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640681
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479268
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < d -> states[s] . mbps . nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6
  ORIGINAL[1]: d -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: pos . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: index
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: pos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[3]: 1 << b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 30064771167
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tracepoint(stonesoup_trace, trace_location, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[1]: stonesoup_trace
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: trace_location
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: modulus_param_str
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640296
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640876
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479718
FRAGMENT_COUNT: 4
  ORIGINAL[0]: newsize == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == 0
  ORIGINAL[1]: old
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: old
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: old
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640873
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776171
FRAGMENT_COUNT: 8
  ORIGINAL[0]: t = d -> tokens[ri]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3 [ VAR4 ]
  ORIGINAL[1]: mp == &musts[1]?((void )0) : __assert_fail(\
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == &musts [ 1 ] ? ( ( void ) 0 ) : FUN1 ( \
  ORIGINAL[2]: mp == &musts[1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == &musts [ 1 ]
  ORIGINAL[3]: &musts[1]
  TYPE[3]: CALL
  TOKENIZED[3]: &musts [ 1 ]
  ORIGINAL[4]: (void )0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void ) 0
  ORIGINAL[5]: __assert_fail(\
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( \
  ORIGINAL[6]: mp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> __PRETTY_FUNCTION__
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 30064771215
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 8 * sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: 8 * sizeof ( int )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 47244640273
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640753
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640595
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640421
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480171
FRAGMENT_COUNT: 2
  ORIGINAL[0]: {(\
  TYPE[0]: CALL
  TOKENIZED[0]: { ( \
  ORIGINAL[1]: isdigit
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064771175
FRAGMENT_COUNT: 9
  ORIGINAL[0]: len > 10
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 > 10
  ORIGINAL[1]: *modulus_function = stonesoup_modulus_function1
  TYPE[1]: CALL
  TOKENIZED[1]: *modulus_function = VAR1
  ORIGINAL[2]: *modulus_function
  TYPE[2]: CALL
  TOKENIZED[2]: *modulus_function
  ORIGINAL[3]: tracepoint(stonesoup_trace, trace_point, \
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , \
  ORIGINAL[4]: len
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: modulus_function
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_trace
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: trace_point
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: len
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640838
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640356
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640634
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771261
FRAGMENT_COUNT: 11
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: equal(s,dfa -> charclasses[i])
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[4]: dfa -> charclasses[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: cindex
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771322
FRAGMENT_COUNT: 13
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: __ctype_get_mb_cur_max()
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( )
  ORIGINAL[2]: wc = btowc(b)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[3]: btowc(b)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: wc == 0xffffffffu
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == 0xffffffffu
  ORIGINAL[5]: setbit(b,c)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[6]: case_fold && ( *__ctype_b_loc())[(int )b] & ((unsigned short )_ISalpha)
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 && ( *__ctype_b_loc ( ) ) [ ( int ) VAR2 ] & ( ( unsigned short ) VAR3 )
  ORIGINAL[7]: wc
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: b
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: wc
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: b
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: c
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: <global> case_fold
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1

CENTER_NODE: 47244640680
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774916
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_IN_PROGRESS=0
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_IN_PROGRESS=0
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: TRANSIT_STATE_DONE
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771312
FRAGMENT_COUNT: 4
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: for (i = 0;i < (1 << 8);++i)
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: for ( VAR1 = 0 ; VAR1 < ( 1 << 8 ) ; ++i )
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640354
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771306
FRAGMENT_COUNT: 6
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0
  ORIGINAL[1]: wc == '_' || iswalnum(wc)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == '_' || FUN1 ( VAR1 )
  ORIGINAL[2]: wc == '_'
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == '_'
  ORIGINAL[3]: iswalnum(wc)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: wc
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: wc
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640443
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640839
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 47244640293
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771238
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: charclass
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477888
FRAGMENT_COUNT: 2
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: STAR
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 30064772748
FRAGMENT_COUNT: 26
  ORIGINAL[0]: !backslash || syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[0]: CALL
  TOKENIZED[0]: !backslash || VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[1]: !backslash
  TYPE[1]: CALL
  TOKENIZED[1]: !backslash
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[4]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[5]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[5]: CALL
  TOKENIZED[5]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[6]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[6]: CALL
  TOKENIZED[6]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[7]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[7]: CALL
  TOKENIZED[7]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[8]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[8]: CALL
  TOKENIZED[8]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[9]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[9]: CALL
  TOKENIZED[9]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[10]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[10]: CALL
  TOKENIZED[10]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[11]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[11]: CALL
  TOKENIZED[11]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[12]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[12]: CALL
  TOKENIZED[12]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[13]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[13]: CALL
  TOKENIZED[13]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[14]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[14]: CALL
  TOKENIZED[14]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[15]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[15]: CALL
  TOKENIZED[15]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[16]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[16]: CALL
  TOKENIZED[16]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[17]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1
  TYPE[17]: CALL
  TOKENIZED[17]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1
  ORIGINAL[18]: ((unsigned long )1) << 1 << 1 << 1 << 1
  TYPE[18]: CALL
  TOKENIZED[18]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1
  ORIGINAL[19]: ((unsigned long )1) << 1 << 1 << 1
  TYPE[19]: CALL
  TOKENIZED[19]: ( ( unsigned long ) 1 ) << 1 << 1 << 1
  ORIGINAL[20]: ((unsigned long )1) << 1 << 1
  TYPE[20]: CALL
  TOKENIZED[20]: ( ( unsigned long ) 1 ) << 1 << 1
  ORIGINAL[21]: ((unsigned long )1) << 1
  TYPE[21]: CALL
  TOKENIZED[21]: ( ( unsigned long ) 1 ) << 1
  ORIGINAL[22]: (unsigned long )1
  TYPE[22]: CALL
  TOKENIZED[22]: ( unsigned long ) 1
  ORIGINAL[23]: c
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: backslash
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: <global> syntax_bits
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: <global> VAR1

CENTER_NODE: 47244640902
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640715
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776382
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 30064773380
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> states[i] . elems . elems[j] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4 [ VAR5 ] . VAR6
  ORIGINAL[2]: d -> states[i] . elems . elems[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4 [ VAR5 ]
  ORIGINAL[3]: d -> states[i] . elems . elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4
  ORIGINAL[4]: constraint
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064774837
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> success
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: *d -> success
  TYPE[1]: CALL
  TOKENIZED[1]: *d -> VAR1
  ORIGINAL[2]: d -> success
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: *d -> success
  TYPE[3]: CALL
  TOKENIZED[3]: *d -> VAR1
  ORIGINAL[4]: success
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064773074
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: addtok(CAT)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> tok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: CAT
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640322
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 30064774693
FRAGMENT_COUNT: 14
  ORIGINAL[0]: ( *d) . states[s] . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[1]: ( *d) . states[s] . constraint
  TYPE[1]: CALL
  TOKENIZED[1]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[2]: ( *d) . states[s] . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: ( *d) . states[s] . constraint
  TYPE[3]: CALL
  TOKENIZED[3]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[4]: ( *d) . states[s] . constraint
  TYPE[4]: CALL
  TOKENIZED[4]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[5]: ( *d) . states[s] . constraint
  TYPE[5]: CALL
  TOKENIZED[5]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[6]: ( *d) . states[s] . constraint
  TYPE[6]: CALL
  TOKENIZED[6]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[7]: ( *d) . states[s] . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[8]: 1 & 4
  TYPE[8]: CALL
  TOKENIZED[8]: 1 & 4
  ORIGINAL[9]: ( *d) . states[s] . constraint
  TYPE[9]: CALL
  TOKENIZED[9]: ( *d ) . VAR1 [ VAR2 ] . VAR3
  ORIGINAL[10]: ( *d) . states[s]
  TYPE[10]: CALL
  TOKENIZED[10]: ( *d ) . VAR1 [ VAR2 ]
  ORIGINAL[11]: ( *d) . states
  TYPE[11]: CALL
  TOKENIZED[11]: ( *d ) . VAR1
  ORIGINAL[12]: constraint
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: s
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640323
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479067
FRAGMENT_COUNT: 7
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> realtrans
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> tralloc
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> trans
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: d -> realtrans
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: realtrans
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640314
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773002
FRAGMENT_COUNT: 17
  ORIGINAL[0]: i < ntokens
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: ++i
  TYPE[1]: CALL
  TOKENIZED[1]: ++i
  ORIGINAL[2]: addtok(dfa -> tokens[tindex + i])
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 [ VAR3 + VAR4 ] )
  ORIGINAL[3]: dfa -> tokens[tindex + i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[4]: dfa -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: tindex + i
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 + VAR2
  ORIGINAL[6]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[6]: CALL
  TOKENIZED[6]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[7]: __ctype_get_mb_cur_max() > 1
  TYPE[7]: CALL
  TOKENIZED[7]: FUN1 ( ) > 1
  ORIGINAL[8]: __ctype_get_mb_cur_max()
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( )
  ORIGINAL[9]: for (i = 0;i < ntokens;++i)
  TYPE[9]: CONTROL_STRUCTURE
  TOKENIZED[9]: for ( VAR1 = 0 ; VAR1 < VAR2 ; ++i )
  ORIGINAL[10]: tokens
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: ntokens
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: i
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: <global> dfa
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: <global> VAR1
  ORIGINAL[15]: tindex
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: i
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1

CENTER_NODE: 47244640344
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480159
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sizeof(struct dfa )
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( struct VAR1 )
  ORIGINAL[1]: struct dfa
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: struct VAR1

CENTER_NODE: 47244640365
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640600
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773166
FRAGMENT_COUNT: 7
  ORIGINAL[0]: lo < hi
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: s -> elems[mid] . index > p . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 > VAR5 . VAR4
  ORIGINAL[2]: s -> elems[mid] . index
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: s -> elems[mid]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: p . index
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: index
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719479616
FRAGMENT_COUNT: 14
  ORIGINAL[0]: i < d -> nmbcsets
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: p -> chars
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: p -> ch_classes
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: p -> range_sts
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: p -> range_ends
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: p -> nequivs
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: p -> equivs
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: j < p -> ncoll_elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 < VAR2 -> VAR3
  ORIGINAL[8]: p -> ncoll_elems
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: p -> coll_elems
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2
  ORIGINAL[10]: ncoll_elems
  TYPE[10]: FIELD_IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: p
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: j
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: p
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 30064771115
FRAGMENT_COUNT: 5
  ORIGINAL[0]: filepath != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: stonesoup_printf_context = fopen(filepath, \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 , \
  ORIGINAL[2]: fopen(filepath, \
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , \
  ORIGINAL[3]: <global> stonesoup_printf_context
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: filepath
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640813
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640401
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479866
FRAGMENT_COUNT: 6
  ORIGINAL[0]: temp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: both = addlists(both,temp)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: addlists(both,temp)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[3]: both
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: both
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: both
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479414
FRAGMENT_COUNT: 4
  ORIGINAL[0]: match_lens[i] ==  *pp - p1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] == *pp - VAR3
  ORIGINAL[1]: j = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: j
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: j
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771204
FRAGMENT_COUNT: 3
  ORIGINAL[0]: WCHAR=274
  TYPE[0]: CALL
  TOKENIZED[0]: WCHAR=274
  ORIGINAL[1]: WCHAR
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: CSET
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775500
FRAGMENT_COUNT: 4
  ORIGINAL[0]: d -> mb_cur_max > 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 > 1
  ORIGINAL[1]: free(mblen_buf)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 )
  ORIGINAL[2]: <global> mblen_buf
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: <global> inputwcs
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 30064775634
FRAGMENT_COUNT: 7
  ORIGINAL[0]: d -> mb_cur_max = (__ctype_get_mb_cur_max())
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = ( FUN1 ( ) )
  ORIGINAL[1]: d -> mb_cur_max
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: __ctype_get_mb_cur_max()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: d -> mb_cur_max
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: mb_cur_max
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640759
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640545
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640270
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: s[i] = ~s[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ] = ~s [ VAR2 ]
  ORIGINAL[4]: for (i = 0;i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ));++i)
  TYPE[4]: CONTROL_STRUCTURE
  TOKENIZED[4]: for ( VAR1 = 0 ; VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) ) ; ++i )

CENTER_NODE: 47244640760
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476841
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 47244640877
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640391
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640560
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 68719479791
FRAGMENT_COUNT: 5
  ORIGINAL[0]: left == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: right == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[2]: (void *)0
  TYPE[2]: CALL
  TOKENIZED[2]: ( void * ) 0
  ORIGINAL[3]: right
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: right
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064775702
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < (d -> sindex)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( VAR2 -> VAR3 )
  ORIGINAL[1]: d -> states[i] . elems . elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4
  ORIGINAL[2]: d -> states[i] . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[3]: d -> states[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640565
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 30064771206
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064773323
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640409
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640373
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774354
FRAGMENT_COUNT: 14
  ORIGINAL[0]: j == ngrps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: grps[ngrps] . elems = ((sizeof(( *grps[ngrps] . elems)) == 1?xmalloc(d -> nleaves) : xnmalloc(d -> nleaves,sizeof(( *grps[ngrps] . elems)))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] . VAR3 = ( ( sizeof ( ( *grps [ VAR2 ] . VAR3 ) ) == 1?xmalloc ( VAR4 -> VAR5 ) : FUN1 ( VAR4 -> VAR5 , sizeof ( ( *grps [ VAR2 ] . VAR3 ) ) ) ) )
  ORIGINAL[2]: grps[ngrps] . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[3]: grps[ngrps]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: sizeof(( *grps[ngrps] . elems)) == 1?xmalloc(d -> nleaves) : xnmalloc(d -> nleaves,sizeof(( *grps[ngrps] . elems)))
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( ( *grps [ VAR1 ] . VAR2 ) ) == 1?xmalloc ( VAR3 -> VAR4 ) : FUN1 ( VAR3 -> VAR4 , sizeof ( ( *grps [ VAR1 ] . VAR2 ) ) )
  ORIGINAL[5]: grps[ngrps] . elems
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[6]: grps[ngrps]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 [ VAR2 ]
  ORIGINAL[7]: grps[ngrps] . elems
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[8]: grps[ngrps]
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 [ VAR2 ]
  ORIGINAL[9]: grps[ngrps]
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 [ VAR2 ]
  ORIGINAL[10]: grps[ngrps] . elems
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 [ VAR2 ] . VAR3
  ORIGINAL[11]: grps[ngrps]
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 [ VAR2 ]
  ORIGINAL[12]: elems
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: grps
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 68719479317
FRAGMENT_COUNT: 8
  ORIGINAL[0]: match_lens == ((void *)0) && d -> states[s] . mbps . nelem != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 ) && VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 != 0
  ORIGINAL[1]: work_mbls = match_lens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: work_mbls[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: work_mbls
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: match_lens
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: work_mbls
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: work_mbls
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: work_mbls
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771159
FRAGMENT_COUNT: 9
  ORIGINAL[0]: *stonesoup_tainted_buff != 0
  TYPE[0]: CALL
  TOKENIZED[0]: *stonesoup_tainted_buff != 0
  ORIGINAL[1]: *stonesoup_tainted_buff
  TYPE[1]: CALL
  TOKENIZED[1]: *stonesoup_tainted_buff
  ORIGINAL[2]: fread(*stonesoup_tainted_buff,1,stonesoup_lsize,stonesoup_tainted_file)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( *stonesoup_tainted_buff , 1 , VAR1 , VAR2 )
  ORIGINAL[3]: *stonesoup_tainted_buff
  TYPE[3]: CALL
  TOKENIZED[3]: *stonesoup_tainted_buff
  ORIGINAL[4]: *stonesoup_tainted_buff
  TYPE[4]: CALL
  TOKENIZED[4]: *stonesoup_tainted_buff
  ORIGINAL[5]: stonesoup_tainted_buff
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_lsize
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: stonesoup_tainted_file
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: stonesoup_tainted_buff
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 47244640547
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640424
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775766
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773147
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *s -> elems
  TYPE[0]: CALL
  TOKENIZED[0]: *s -> VAR1
  ORIGINAL[1]: s -> elems
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: elems
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: s
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719478075
FRAGMENT_COUNT: 7
  ORIGINAL[0]: m -> alloc <= s1 -> nelem + s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4 + VAR5 -> VAR4
  ORIGINAL[1]: m -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: new_n_alloc = s1 -> nelem + s2 -> nelem + (!m -> elems)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2 -> VAR3 + VAR4 -> VAR3 + ( !m -> VAR5 )
  ORIGINAL[3]: m -> elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: m -> elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: elems
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: m
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064771221
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] |= 1 << b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] |= 1 << VAR2 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: 1 << b % (8 * sizeof(int ))
  TYPE[2]: CALL
  TOKENIZED[2]: 1 << VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[3]: b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 68719478315
FRAGMENT_COUNT: 4
  ORIGINAL[0]: context = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: tstbit(eolbyte,c)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: <global> eolbyte
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640874
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477968
FRAGMENT_COUNT: 10
  ORIGINAL[0]: dfa = d
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2
  ORIGINAL[1]: d -> depth
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> nregexps
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: d -> nregexps
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: <global> dfa
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478453
FRAGMENT_COUNT: 19
  ORIGINAL[0]: j < nlastpos[- 2]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 [ - 2 ]
  ORIGINAL[1]: merge((&tmp),(&d -> follows[pos[j] . index]),&merged)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( &tmp ) , ( &d -> VAR1 [ VAR2 [ VAR3 ] . VAR4 ] ) , &merged )
  ORIGINAL[2]: &merged
  TYPE[2]: CALL
  TOKENIZED[2]: &merged
  ORIGINAL[3]: &merged
  TYPE[3]: CALL
  TOKENIZED[3]: &merged
  ORIGINAL[4]: merged . elems
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 . VAR2
  ORIGINAL[5]: merged
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: merged
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: merged
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: merged
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: merged
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: merged
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: merged
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: merged
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: merged
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: merged
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: merged
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: merged
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: merged
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: merged
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640351
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640381
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772956
FRAGMENT_COUNT: 8
  ORIGINAL[0]: 1 && tok == ANYCHAR && using_utf8()
  TYPE[0]: CALL
  TOKENIZED[0]: 1 && VAR1 == VAR2 && FUN1 ( )
  ORIGINAL[1]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE || tok == BEGWORD
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5 || VAR1 == VAR6
  ORIGINAL[2]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE || tok == ENDLINE
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4 || VAR1 == VAR5
  ORIGINAL[3]: tok >= 0 && tok < (1 << 8) || tok >= CSET || tok == BACKREF || tok == BEGLINE
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 >= 0 && VAR1 < ( 1 << 8 ) || VAR1 >= VAR2 || VAR1 == VAR3 || VAR1 == VAR4
  ORIGINAL[4]: tok == ENDLINE
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 == VAR2
  ORIGINAL[5]: tok == BEGWORD
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 == VAR2
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: BEGWORD
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 30064771357
FRAGMENT_COUNT: 3
  ORIGINAL[0]: utf8 == - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 68719477945
FRAGMENT_COUNT: 6
  ORIGINAL[0]: i < maxrep
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: copytoks(tindex,ntokens)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: tindex
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tindex
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ntokens
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640767
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773658
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: s -> elems[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[2]: s -> elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: elems
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479740
FRAGMENT_COUNT: 7
  ORIGINAL[0]: cpp == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: i = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640334
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640603
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640983
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640711
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775958
FRAGMENT_COUNT: 2
  ORIGINAL[0]: freelist(mp -> in)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[1]: mp -> in
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2

CENTER_NODE: 68719479842
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: new[i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: new
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640625
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771171
FRAGMENT_COUNT: 2
  ORIGINAL[0]: modulus_param_str[1] % 2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 ] % 2
  ORIGINAL[1]: modulus_param_str[1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ 1 ]

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479776
FRAGMENT_COUNT: 9
  ORIGINAL[0]: cpp[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: cpp[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: --i == j
  TYPE[2]: CALL
  TOKENIZED[2]: --i == VAR1
  ORIGINAL[3]: cpp[j]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: cpp[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 [ VAR2 ]
  ORIGINAL[5]: cpp[i]
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 [ VAR2 ]
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: cpp
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719480166
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 68719477963
FRAGMENT_COUNT: 6
  ORIGINAL[0]: branch()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: tok == OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: addtok(OR)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: OR
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: <global> tok
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1

CENTER_NODE: 68719476922
FRAGMENT_COUNT: 5
  ORIGINAL[0]: (int )c
  TYPE[0]: CALL
  TOKENIZED[0]: ( int ) VAR1
  ORIGINAL[1]: c
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: c
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: c
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640432
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640627
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479099
FRAGMENT_COUNT: 6
  ORIGINAL[0]: (t = d -> trans[works]) != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: ( VAR1 = VAR2 -> VAR3 [ VAR4 ] ) != ( ( void * ) 0 )
  ORIGINAL[1]: t[ *p]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ *p ]
  ORIGINAL[2]: t
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: works
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: t
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719476879
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: charclass
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064774997
FRAGMENT_COUNT: 8
  ORIGINAL[0]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: wc == ((wchar_t )'\\0')
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: (((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[3]: CALL
  TOKENIZED[3]: ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1
  ORIGINAL[4]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) )
  ORIGINAL[5]: d -> states[s] . context
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[6]: d -> states[s]
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[7]: context
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640772
FRAGMENT_COUNT: 0

CENTER_NODE: 68719480160
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640884
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775771
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: *cp
  TYPE[1]: CALL
  TOKENIZED[1]: *cp
  ORIGINAL[2]: strncmp(cp,lookfor,len) == 0
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[3]: strncmp(cp,lookfor,len)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[4]: (void *)0
  TYPE[4]: CALL
  TOKENIZED[4]: ( void * ) 0
  ORIGINAL[5]: for (cp = lookin;( *cp) != '\\0';++cp)
  TYPE[5]: CONTROL_STRUCTURE
  TOKENIZED[5]: for ( VAR1 = VAR2 ; ( *cp ) != '\\0' ; ++cp )
  ORIGINAL[6]: cp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: lookfor
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: len
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

