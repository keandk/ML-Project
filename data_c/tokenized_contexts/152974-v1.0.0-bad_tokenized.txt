# Tokenized code fragments for 152974-v1.0.0-bad
# Total center nodes processed: 30
# Total code fragments found: 181

CENTER_NODE: 68719476763
FRAGMENT_COUNT: 6
  ORIGINAL[0]: strcmp(ifmatch_header, \
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , \
  ORIGINAL[1]: data_size < buffer_size
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: stonesoup_printf_context = conn
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = VAR2
  ORIGINAL[3]: break;
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: break ;
  ORIGINAL[4]: <global> stonesoup_printf_context
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: conn
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771511
FRAGMENT_COUNT: 19
  ORIGINAL[0]: ((&v1 -> addr2) -> type) == ((&v2 -> addr2) -> type)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( &v1 -> VAR1 ) -> VAR2 ) == ( ( &v2 -> VAR1 ) -> VAR2 )
  ORIGINAL[1]: ((&v1 -> addr2) -> type) == AT_NONE || (&v1 -> addr2) -> len == (&v2 -> addr2) -> len && memcmp((&v1 -> addr2) -> data,(&v2 -> addr2) -> data,((&v1 -> addr2) -> len)) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( &v1 -> VAR1 ) -> VAR2 ) == VAR3 || ( &v1 -> VAR1 ) -> VAR4 == ( &v2 -> VAR1 ) -> VAR4 && FUN1 ( ( &v1 -> VAR1 ) -> VAR5 , ( &v2 -> VAR1 ) -> VAR5 , ( ( &v1 -> VAR1 ) -> VAR4 ) ) == 0
  ORIGINAL[2]: ((&v1 -> addr2) -> type) == AT_NONE
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( &v1 -> VAR1 ) -> VAR2 ) == VAR3
  ORIGINAL[3]: (&v1 -> addr2) -> type
  TYPE[3]: CALL
  TOKENIZED[3]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[4]: (&v1 -> addr2) -> len == (&v2 -> addr2) -> len && memcmp((&v1 -> addr2) -> data,(&v2 -> addr2) -> data,((&v1 -> addr2) -> len)) == 0
  TYPE[4]: CALL
  TOKENIZED[4]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2 && FUN1 ( ( &v1 -> VAR1 ) -> VAR3 , ( &v2 -> VAR1 ) -> VAR3 , ( ( &v1 -> VAR1 ) -> VAR2 ) ) == 0
  ORIGINAL[5]: (&v1 -> addr2) -> len == (&v2 -> addr2) -> len
  TYPE[5]: CALL
  TOKENIZED[5]: ( &v1 -> VAR1 ) -> VAR2 == ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[6]: (&v1 -> addr2) -> len
  TYPE[6]: CALL
  TOKENIZED[6]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[7]: &v1 -> addr2
  TYPE[7]: CALL
  TOKENIZED[7]: &v1 -> VAR1
  ORIGINAL[8]: v1 -> addr2
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: (&v2 -> addr2) -> len
  TYPE[9]: CALL
  TOKENIZED[9]: ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[10]: &v2 -> addr2
  TYPE[10]: CALL
  TOKENIZED[10]: &v2 -> VAR1
  ORIGINAL[11]: v2 -> addr2
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2
  ORIGINAL[12]: addr2
  TYPE[12]: FIELD_IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: len
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: addr2
  TYPE[14]: FIELD_IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: len
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: AT_NONE
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: v1
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: v2
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 30064771118
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c >= 97 && c <= 122
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= 97 && VAR1 <= 122
  ORIGINAL[1]: c >= 97
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 >= 97
  ORIGINAL[2]: c <= 122
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 <= 122
  ORIGINAL[3]: c
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771142
FRAGMENT_COUNT: 7
  ORIGINAL[0]: conversation -> key_ptr -> ptype
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[1]: conversation -> options & 0x01 && conversation -> options & 0x02
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 & 0x01 && VAR1 -> VAR2 & 0x02
  ORIGINAL[2]: conversation -> key_ptr -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 -> VAR3
  ORIGINAL[3]: conversation -> key_ptr
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: key_ptr
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: addr1
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: conversation
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477485
FRAGMENT_COUNT: 4
  ORIGINAL[0]: conv -> data_list
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: data_list
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: item
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477511
FRAGMENT_COUNT: 6
  ORIGINAL[0]: *conv = ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: *conv = ( ( void * ) 0 )
  ORIGINAL[1]: conv = find_conversation(pinfo -> fd -> num,(&pinfo -> src),(&pinfo -> dst),pinfo -> ptype,pinfo -> srcport,pinfo -> destport,0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR2 -> VAR3 -> VAR4 , ( &pinfo -> VAR5 ) , ( &pinfo -> VAR6 ) , VAR2 -> VAR7 , VAR2 -> VAR8 , VAR2 -> VAR9 , 0 )
  ORIGINAL[2]: find_conversation(pinfo -> fd -> num,(&pinfo -> src),(&pinfo -> dst),pinfo -> ptype,pinfo -> srcport,pinfo -> destport,0)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 -> VAR3 , ( &pinfo -> VAR4 ) , ( &pinfo -> VAR5 ) , VAR1 -> VAR6 , VAR1 -> VAR7 , VAR1 -> VAR8 , 0 )
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: pinfo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: conv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064771375
FRAGMENT_COUNT: 5
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_index++
  TYPE[1]: CALL
  TOKENIZED[1]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[2]: for (ADD_ADDRESS_TO_HASH_index = 0;ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len;ADD_ADDRESS_TO_HASH_index++)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: for ( VAR1 = 0 ; VAR1 < ( &key -> VAR2 ) -> VAR3 ; ADD_ADDRESS_TO_HASH_index++ )
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_index
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477467
FRAGMENT_COUNT: 3
  ORIGINAL[0]: p1 -> proto_data = proto_data
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR2
  ORIGINAL[1]: p1 -> proto_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: proto_data
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771430
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *key = (const conversation_key *)v
  TYPE[0]: CALL
  TOKENIZED[0]: *key = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const conversation_key *)v
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: key
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: v
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719477019
FRAGMENT_COUNT: 5
  ORIGINAL[0]: *conv = (conversation_t *)value
  TYPE[0]: CALL
  TOKENIZED[0]: *conv = ( VAR1 * ) VAR2
  ORIGINAL[1]: conv -> data_list
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: data_list
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conv
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: conv
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064772216
FRAGMENT_COUNT: 6
  ORIGINAL[0]: stonesoup_buffer != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2
  ORIGINAL[1]: strncpy(stonesoup_source, gamasid_dimity, sizeof(stonesoup_source))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR1 ) )
  ORIGINAL[2]: sizeof(stonesoup_source)
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: stonesoup_source
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: gamasid_dimity
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_source
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719477042
FRAGMENT_COUNT: 3
  ORIGINAL[0]: conversation_hashtable_no_addr2_or_port2 = g_hash_table_new(conversation_hash_no_addr2_or_port2,conversation_match_no_addr2_or_port2)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = FUN1 ( VAR2 , VAR3 )
  ORIGINAL[1]: new_index = 0
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 0
  ORIGINAL[2]: <global> new_index
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064772064
FRAGMENT_COUNT: 7
  ORIGINAL[0]: !(conversation -> options & 0x08)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 -> VAR2 & 0x08 )
  ORIGINAL[1]: !(conversation -> options & 0x01)
  TYPE[1]: CALL
  TOKENIZED[1]: ! ( VAR1 -> VAR2 & 0x01 )
  ORIGINAL[2]: conversation -> options & 0x01
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 & 0x01
  ORIGINAL[3]: conversation_set_addr2(conversation,addr_b)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[4]: conversation
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: addr_b
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: conversation
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719476738
FRAGMENT_COUNT: 2
  ORIGINAL[0]: (struct mg_connection*) stonesoup_printf_context
  TYPE[0]: CALL
  TOKENIZED[0]: ( struct mg_connection* ) VAR1
  ORIGINAL[1]: <global> stonesoup_printf_context
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 30064771194
FRAGMENT_COUNT: 4
  ORIGINAL[0]: hash_val += key -> port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 += VAR2 -> VAR3
  ORIGINAL[1]: key -> port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: hash_val
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_data
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771660
FRAGMENT_COUNT: 11
  ORIGINAL[0]: ((void *)0) == chain_head
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( void * ) 0 ) == VAR1
  ORIGINAL[1]: chain_tail = chain_head -> last
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 -> VAR3
  ORIGINAL[2]: chain_head -> last
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: last
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: chain_head
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: chain_tail
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: chain_head
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: chain_head
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: chain_head
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: chain_head
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: chain_head
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640265
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 68719476773
FRAGMENT_COUNT: 5
  ORIGINAL[0]: getenv(\
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( \
  ORIGINAL[1]: mg_create_server(NULL, stonesoup_ev_handler)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 )
  ORIGINAL[2]: NULL
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: stonesoup_server
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: NULL
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771403
FRAGMENT_COUNT: 9
  ORIGINAL[0]: v1 -> port1 == v2 -> port1 && v1 -> port2 == v2 -> port2
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 == VAR3 -> VAR2 && VAR1 -> VAR4 == VAR3 -> VAR4
  ORIGINAL[1]: (&v2 -> addr1) -> type
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v2 -> VAR1 ) -> VAR2
  ORIGINAL[2]: &v2 -> addr1
  TYPE[2]: CALL
  TOKENIZED[2]: &v2 -> VAR1
  ORIGINAL[3]: v2 -> addr1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: &v2 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: &v2 -> VAR1
  ORIGINAL[5]: v2 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: &v2 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &v2 -> VAR1
  ORIGINAL[7]: v2 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2
  ORIGINAL[8]: type
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064772091
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *ap = (const conv_proto_data *)a
  TYPE[0]: CALL
  TOKENIZED[0]: *ap = ( const VAR1 * ) VAR2
  ORIGINAL[1]: (const conv_proto_data *)a
  TYPE[1]: CALL
  TOKENIZED[1]: ( const VAR1 * ) VAR2
  ORIGINAL[2]: ap
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: bp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 68719476991
FRAGMENT_COUNT: 9
  ORIGINAL[0]: ADD_ADDRESS_TO_HASH_index = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: ADD_ADDRESS_TO_HASH_index < (&key -> addr1) -> len
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < ( &key -> VAR2 ) -> VAR3
  ORIGINAL[2]: (&key -> addr1) -> len
  TYPE[2]: CALL
  TOKENIZED[2]: ( &key -> VAR1 ) -> VAR2
  ORIGINAL[3]: ADD_ADDRESS_TO_HASH_index++
  TYPE[3]: CALL
  TOKENIZED[3]: ADD_ADDRESS_TO_HASH_index++
  ORIGINAL[4]: ADD_ADDRESS_TO_HASH_index
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: ADD_ADDRESS_TO_HASH_index
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: ADD_ADDRESS_TO_HASH_index
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: ADD_ADDRESS_TO_HASH_index
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 68719477119
FRAGMENT_COUNT: 11
  ORIGINAL[0]: conv -> key_ptr
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: conv == chain_head
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2
  ORIGINAL[2]: cur != conv
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: conv -> next
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: conv -> next
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: conv
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cur
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: conv
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: conv
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: conv
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: conv
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 30064771341
FRAGMENT_COUNT: 10
  ORIGINAL[0]: ((&v1 -> addr1) -> type) == ((&v2 -> addr2) -> type)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( &v1 -> VAR1 ) -> VAR2 ) == ( ( &v2 -> VAR3 ) -> VAR2 )
  ORIGINAL[1]: (&v1 -> addr1) -> type
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[2]: ((&v1 -> addr1) -> type) == AT_NONE
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( &v1 -> VAR1 ) -> VAR2 ) == VAR3
  ORIGINAL[3]: (&v1 -> addr1) -> type
  TYPE[3]: CALL
  TOKENIZED[3]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[4]: &v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: &v1 -> VAR1
  ORIGINAL[5]: &v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: &v1 -> VAR1
  ORIGINAL[6]: &v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: &v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: &v1 -> VAR1
  ORIGINAL[8]: type
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: AT_NONE
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064772149
FRAGMENT_COUNT: 5
  ORIGINAL[0]: conversation -> dissector_handle = handle
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 = VAR3
  ORIGINAL[1]: conversation -> dissector_handle
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dissector_handle
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: conversation
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: handle
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064771578
FRAGMENT_COUNT: 10
  ORIGINAL[0]: ((&v1 -> addr1) -> type) == ((&v2 -> addr1) -> type)
  TYPE[0]: CALL
  TOKENIZED[0]: ( ( &v1 -> VAR1 ) -> VAR2 ) == ( ( &v2 -> VAR1 ) -> VAR2 )
  ORIGINAL[1]: (&v1 -> addr1) -> type
  TYPE[1]: CALL
  TOKENIZED[1]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[2]: ((&v1 -> addr1) -> type) == AT_NONE
  TYPE[2]: CALL
  TOKENIZED[2]: ( ( &v1 -> VAR1 ) -> VAR2 ) == VAR3
  ORIGINAL[3]: (&v1 -> addr1) -> type
  TYPE[3]: CALL
  TOKENIZED[3]: ( &v1 -> VAR1 ) -> VAR2
  ORIGINAL[4]: &v1 -> addr1
  TYPE[4]: CALL
  TOKENIZED[4]: &v1 -> VAR1
  ORIGINAL[5]: &v1 -> addr1
  TYPE[5]: CALL
  TOKENIZED[5]: &v1 -> VAR1
  ORIGINAL[6]: &v1 -> addr1
  TYPE[6]: CALL
  TOKENIZED[6]: &v1 -> VAR1
  ORIGINAL[7]: &v1 -> addr1
  TYPE[7]: CALL
  TOKENIZED[7]: &v1 -> VAR1
  ORIGINAL[8]: type
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: AT_NONE
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 30064772158
FRAGMENT_COUNT: 4
  ORIGINAL[0]: conversation != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != ( ( void * ) 0 )
  ORIGINAL[1]: conversation -> dissector_handle == ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 == ( ( void * ) 0 )
  ORIGINAL[2]: conversation -> dissector_handle
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 47244640258
FRAGMENT_COUNT: 1
  ORIGINAL[0]: while (1)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: while ( 1 )

CENTER_NODE: 30064771933
FRAGMENT_COUNT: 7
  ORIGINAL[0]: key . port1 = port1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2 = VAR2
  ORIGINAL[1]: key . port1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: port1
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: key
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: port1
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: key
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: key
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 68719477529
FRAGMENT_COUNT: 5
  ORIGINAL[0]: emblemist_stours != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: tuberculiferous_pollaiuolo = emblemist_stours
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: tuberculiferous_pollaiuolo
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: emblemist_stours
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: tuberculiferous_pollaiuolo
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719477476
FRAGMENT_COUNT: 4
  ORIGINAL[0]: temp . proto
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: temp . proto_data
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2
  ORIGINAL[2]: &temp
  TYPE[2]: CALL
  TOKENIZED[2]: &temp
  ORIGINAL[3]: temp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

