# Tokenized code fragments for 153735-v1.0.0-bad
# Total center nodes processed: 142
# Total code fragments found: 451

CENTER_NODE: 30064776350
FRAGMENT_COUNT: 2
  ORIGINAL[0]: xmalloc(sizeof(struct dfa ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( sizeof ( struct VAR1 ) )
  ORIGINAL[1]: sizeof(struct dfa )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( struct VAR1 )

CENTER_NODE: 47244640399
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640256
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ss_tc_root != NULL
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2

CENTER_NODE: 47244640271
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640763
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772837
FRAGMENT_COUNT: 7
  ORIGINAL[0]: dfa -> talloc <= dfa -> tindex + 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR1 -> VAR3 + 1
  ORIGINAL[1]: dfa -> tokens
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: dfa -> tokens
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: sizeof(( *dfa -> tokens))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *dfa -> VAR1 ) )
  ORIGINAL[4]: *dfa -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: *dfa -> VAR1
  ORIGINAL[5]: dfa -> tokens
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 -> VAR2
  ORIGINAL[6]: dfa -> tokens
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2

CENTER_NODE: 30064773058
FRAGMENT_COUNT: 2
  ORIGINAL[0]: branch()
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( )
  ORIGINAL[1]: <global> tok
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1

CENTER_NODE: 47244640762
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775307
FRAGMENT_COUNT: 28
  ORIGINAL[0]: i < nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2
  ORIGINAL[1]: match_lens[i] ==  *pp - p1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ] == *pp - VAR3
  ORIGINAL[2]: match_lens[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: *pp - p1
  TYPE[3]: CALL
  TOKENIZED[3]: *pp - VAR1
  ORIGINAL[4]: j = 0
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 = 0
  ORIGINAL[5]: j < d -> follows[d -> states[s1] . mbps . elems[i] . index] . nelem
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 < VAR2 -> VAR3 [ VAR2 -> VAR4 [ VAR5 ] . VAR6 . VAR7 [ VAR8 ] . VAR9 ] . VAR10
  ORIGINAL[6]: d -> follows[d -> states[s1] . mbps . elems[i] . index] . nelem
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ] . VAR9
  ORIGINAL[7]: d -> follows[d -> states[s1] . mbps . elems[i] . index]
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 -> VAR2 [ VAR1 -> VAR3 [ VAR4 ] . VAR5 . VAR6 [ VAR7 ] . VAR8 ]
  ORIGINAL[8]: d -> follows
  TYPE[8]: CALL
  TOKENIZED[8]: VAR1 -> VAR2
  ORIGINAL[9]: d -> states[s1] . mbps . elems[i] . index
  TYPE[9]: CALL
  TOKENIZED[9]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ] . VAR7
  ORIGINAL[10]: d -> states[s1] . mbps . elems[i]
  TYPE[10]: CALL
  TOKENIZED[10]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5 [ VAR6 ]
  ORIGINAL[11]: d -> states[s1] . mbps . elems
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR5
  ORIGINAL[12]: d -> states[s1] . mbps
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[13]: d -> states[s1]
  TYPE[13]: CALL
  TOKENIZED[13]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[14]: d -> states
  TYPE[14]: CALL
  TOKENIZED[14]: VAR1 -> VAR2
  ORIGINAL[15]: follows
  TYPE[15]: FIELD_IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: states
  TYPE[16]: FIELD_IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: mbps
  TYPE[17]: FIELD_IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: elems
  TYPE[18]: FIELD_IDENTIFIER
  TOKENIZED[18]: VAR1
  ORIGINAL[19]: index
  TYPE[19]: FIELD_IDENTIFIER
  TOKENIZED[19]: VAR1
  ORIGINAL[20]: nelem
  TYPE[20]: FIELD_IDENTIFIER
  TOKENIZED[20]: VAR1
  ORIGINAL[21]: i
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: VAR1
  ORIGINAL[22]: j
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: VAR1
  ORIGINAL[23]: j
  TYPE[23]: IDENTIFIER
  TOKENIZED[23]: VAR1
  ORIGINAL[24]: d
  TYPE[24]: IDENTIFIER
  TOKENIZED[24]: VAR1
  ORIGINAL[25]: d
  TYPE[25]: IDENTIFIER
  TOKENIZED[25]: VAR1
  ORIGINAL[26]: s1
  TYPE[26]: IDENTIFIER
  TOKENIZED[26]: VAR1
  ORIGINAL[27]: i
  TYPE[27]: IDENTIFIER
  TOKENIZED[27]: VAR1

CENTER_NODE: 30064776366
FRAGMENT_COUNT: 2
  ORIGINAL[0]: cur_mb_len = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: cur_mb_len
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1

CENTER_NODE: 47244640291
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775207
FRAGMENT_COUNT: 8
  ORIGINAL[0]: *pp
  TYPE[0]: CALL
  TOKENIZED[0]: *pp
  ORIGINAL[1]: *pp
  TYPE[1]: CALL
  TOKENIZED[1]: *pp
  ORIGINAL[2]: *pp
  TYPE[2]: CALL
  TOKENIZED[2]: *pp
  ORIGINAL[3]: match_lens == ((void *)0) && d -> states[s] . mbps . nelem != 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 == ( ( void * ) 0 ) && VAR2 -> VAR3 [ VAR4 ] . VAR5 . VAR6 != 0
  ORIGINAL[4]: *pp - buf_begin
  TYPE[4]: CALL
  TOKENIZED[4]: *pp - VAR1
  ORIGINAL[5]: *pp
  TYPE[5]: CALL
  TOKENIZED[5]: *pp
  ORIGINAL[6]: pp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> buf_begin
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1

CENTER_NODE: 30064775815
FRAGMENT_COUNT: 7
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: xnrealloc(cpp,i + 2,sizeof(( *cpp)))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 + 2 , sizeof ( ( *cpp ) ) )
  ORIGINAL[2]: i + 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + 2
  ORIGINAL[3]: sizeof(( *cpp))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *cpp ) )
  ORIGINAL[4]: cpp
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: i
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: cpp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640598
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640591
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640312
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640625
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640653
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640354
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640871
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774804
FRAGMENT_COUNT: 3
  ORIGINAL[0]: sizeof(( *d -> fails)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[1]: sizeof(( *d -> fails))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) )
  ORIGINAL[2]: *d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: *d -> VAR1

CENTER_NODE: 47244640294
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479842
FRAGMENT_COUNT: 7
  ORIGINAL[0]: right[rnum] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: right[rnum]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 ]
  ORIGINAL[2]: left[lnum]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: right[rnum]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ VAR2 ]
  ORIGINAL[4]: right
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: right
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: rnum
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640835
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773097
FRAGMENT_COUNT: 10
  ORIGINAL[0]: dst -> alloc <= src -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 <= VAR3 -> VAR4
  ORIGINAL[1]: dst -> alloc
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: src -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: src -> nelem
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2
  ORIGINAL[4]: src -> nelem
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nelem
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: src
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: src
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: src
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: src
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1

CENTER_NODE: 47244640656
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640771
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771206
FRAGMENT_COUNT: 3
  ORIGINAL[0]: b % (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 % ( 8 * sizeof ( int ) )
  ORIGINAL[1]: 8 * sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: 8 * sizeof ( int )
  ORIGINAL[2]: sizeof(int )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( int )

CENTER_NODE: 47244640701
FRAGMENT_COUNT: 4
  ORIGINAL[0]: j = 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 0
  ORIGINAL[1]: j < ngrps
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 < VAR2
  ORIGINAL[2]: ++j
  TYPE[2]: CALL
  TOKENIZED[2]: ++j
  ORIGINAL[3]: for (j = 0;j < ngrps;++j)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 ; ++j )

CENTER_NODE: 30064773005
FRAGMENT_COUNT: 5
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1 && dfa -> tokens[tindex + i] == MBCSET
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1 && VAR1 -> VAR2 [ VAR3 + VAR4 ] == VAR5
  ORIGINAL[1]: dfa -> multibyte_prop[tindex + i]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 + VAR4 ]
  ORIGINAL[2]: tindex + i
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2
  ORIGINAL[3]: tindex
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640756
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640874
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776365
FRAGMENT_COUNT: 2
  ORIGINAL[0]: sbit[1 << 8]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 1 << 8 ]
  ORIGINAL[1]: 1 << 8
  TYPE[1]: CALL
  TOKENIZED[1]: 1 << 8

CENTER_NODE: 47244640310
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640371
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640770
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771174
FRAGMENT_COUNT: 3
  ORIGINAL[0]: ENDWORD=261
  TYPE[0]: CALL
  TOKENIZED[0]: ENDWORD=261
  ORIGINAL[1]: ENDWORD
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: LIMWORD
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064771221
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memset(s,0,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , 0 , sizeof ( VAR2 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: s
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: charclass
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640678
FRAGMENT_COUNT: 0

CENTER_NODE: 30064774758
FRAGMENT_COUNT: 4
  ORIGINAL[0]: oldalloc < d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> fails[oldalloc++] = ((void *)0)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ oldalloc++ ] = ( ( void * ) 0 )
  ORIGINAL[2]: d -> fails[oldalloc++]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ oldalloc++ ]
  ORIGINAL[3]: (void *)0
  TYPE[3]: CALL
  TOKENIZED[3]: ( void * ) 0

CENTER_NODE: 30064773649
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: (s -> elems[j] . constraint >> 1 & 0x111) != (s -> elems[j] . constraint & 0x111)
  TYPE[1]: CALL
  TOKENIZED[1]: ( VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111 ) != ( VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111 )
  ORIGINAL[2]: s -> elems[j] . constraint >> 1 & 0x111
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 >> 1 & 0x111
  ORIGINAL[3]: s -> elems[j] . constraint & 0x111
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4 & 0x111
  ORIGINAL[4]: s -> elems[j] . constraint
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ] . VAR4

CENTER_NODE: 47244640320
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719478104
FRAGMENT_COUNT: 5
  ORIGINAL[0]: s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: p . index == s -> elems[i] . index
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 . VAR2 == VAR3 -> VAR4 [ VAR5 ] . VAR2
  ORIGINAL[2]: nelem
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: i
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640419
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772979
FRAGMENT_COUNT: 4
  ORIGINAL[0]: dfa -> tokens[tindex - 1]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 - 1 ]
  ORIGINAL[1]: 1 + ntoks1 + nsubtoks(tindex - 1 - ntoks1)
  TYPE[1]: CALL
  TOKENIZED[1]: 1 + VAR1 + FUN1 ( VAR2 - 1 - VAR1 )
  ORIGINAL[2]: 1 + ntoks1
  TYPE[2]: CALL
  TOKENIZED[2]: 1 + VAR1
  ORIGINAL[3]: nsubtoks(tindex - 1 - ntoks1)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 - 1 - VAR2 )

CENTER_NODE: 47244640389
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640593
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775749
FRAGMENT_COUNT: 3
  ORIGINAL[0]: icatalloc(((void *)0),string)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( ( void * ) 0 ) , VAR1 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640713
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771230
FRAGMENT_COUNT: 5
  ORIGINAL[0]: i < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[1]: CALL
  TOKENIZED[1]: ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[2]: (1 << 8) + 8 * sizeof(int ) - 1
  TYPE[2]: CALL
  TOKENIZED[2]: ( 1 << 8 ) + 8 * sizeof ( int ) - 1
  ORIGINAL[3]: 8 * sizeof(int )
  TYPE[3]: CALL
  TOKENIZED[3]: 8 * sizeof ( int )
  ORIGINAL[4]: sizeof(int )
  TYPE[4]: CALL
  TOKENIZED[4]: sizeof ( int )

CENTER_NODE: 47244640275
FRAGMENT_COUNT: 1
  ORIGINAL[0]: wc == ((wchar_t )eolbyte) || wc == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 ) || VAR1 == 0

CENTER_NODE: 47244640609
FRAGMENT_COUNT: 3
  ORIGINAL[0]: j < s2 -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: m -> elems[m -> nelem++] = s2 -> elems[j++]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR1 -> nelem++ ] = VAR3 -> VAR2 [ j++ ]
  ORIGINAL[2]: while (j < s2 -> nelem)
  TYPE[2]: CONTROL_STRUCTURE
  TOKENIZED[2]: while ( VAR1 < VAR2 -> VAR3 )

CENTER_NODE: 47244640758
FRAGMENT_COUNT: 0

CENTER_NODE: 30064776352
FRAGMENT_COUNT: 3
  ORIGINAL[0]: d -> musts
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2
  ORIGINAL[1]: musts
  TYPE[1]: FIELD_IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064772300
FRAGMENT_COUNT: 4
  ORIGINAL[0]: backslash && !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 && ! ( VAR2 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: lasttok = LIMWORD
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2
  ORIGINAL[2]: <global> lasttok
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1
  ORIGINAL[3]: LIMWORD
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640563
FRAGMENT_COUNT: 1
  ORIGINAL[0]: else
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: else

CENTER_NODE: 47244640765
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640302
FRAGMENT_COUNT: 0

CENTER_NODE: 68719478274
FRAGMENT_COUNT: 7
  ORIGINAL[0]: p . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 . VAR2
  ORIGINAL[1]: d -> tokens[old . index]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 . VAR4 ]
  ORIGINAL[2]: p . constraint
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 . VAR2
  ORIGINAL[3]: constraint
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: BEGWORD
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: p
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: p
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775937
FRAGMENT_COUNT: 4
  ORIGINAL[0]: mp -> right[0]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ 0 ]
  ORIGINAL[1]: mp -> right
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: right
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: mp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640632
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771275
FRAGMENT_COUNT: 3
  ORIGINAL[0]: c == eolbyte || c == 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2 || VAR1 == 0
  ORIGINAL[1]: 1 && (( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum) || c == '_')
  TYPE[1]: CALL
  TOKENIZED[1]: 1 && ( ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) || VAR1 == '_' )
  ORIGINAL[2]: ( *__ctype_b_loc())[(int )c] & ((unsigned short )_ISalnum) || c == '_'
  TYPE[2]: CALL
  TOKENIZED[2]: ( *__ctype_b_loc ( ) ) [ ( int ) VAR1 ] & ( ( unsigned short ) VAR2 ) || VAR1 == '_'

CENTER_NODE: 47244640657
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771244
FRAGMENT_COUNT: 11
  ORIGINAL[0]: i < dfa -> cindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: dfa -> cindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: equal(s,dfa -> charclasses[i])
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 , VAR2 -> VAR3 [ VAR4 ] )
  ORIGINAL[4]: dfa -> charclasses[i]
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[5]: cindex
  TYPE[5]: FIELD_IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: i
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: <global> dfa
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 68719478302
FRAGMENT_COUNT: 6
  ORIGINAL[0]: j < ((1 << 8) + 8 * sizeof(int ) - 1) / (8 * sizeof(int ))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < ( ( 1 << 8 ) + 8 * sizeof ( int ) - 1 ) / ( 8 * sizeof ( int ) )
  ORIGINAL[1]: ++j
  TYPE[1]: CALL
  TOKENIZED[1]: ++j
  ORIGINAL[2]: c[j] & ~(letters[j] | newline[j])
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ] & ~ ( VAR3 [ VAR2 ] | VAR4 [ VAR2 ] )
  ORIGINAL[3]: context |= 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 |= 1
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 30064775768
FRAGMENT_COUNT: 4
  ORIGINAL[0]: cpp[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: free(cpp[i])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 [ VAR2 ] )
  ORIGINAL[2]: cpp[i]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 [ VAR2 ]
  ORIGINAL[3]: cpp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 47244640768
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775704
FRAGMENT_COUNT: 13
  ORIGINAL[0]: free((d -> follows))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ( VAR1 -> VAR2 ) )
  ORIGINAL[1]: d -> follows
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: follows
  TYPE[2]: FIELD_IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: d
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: d
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: d
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: d
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: d
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 30064771291
FRAGMENT_COUNT: 3
  ORIGINAL[0]: syntax_bits_set = 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = 1
  ORIGINAL[1]: <global> syntax_bits_set
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: <global> VAR1
  ORIGINAL[2]: <global> syntax_bits
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: <global> VAR1

CENTER_NODE: 30064775025
FRAGMENT_COUNT: 11
  ORIGINAL[0]: !(syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1)
  TYPE[0]: CALL
  TOKENIZED[0]: ! ( VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 )
  ORIGINAL[1]: wc == ((wchar_t )'\\0')
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[2]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[3]: context & 4?pos . constraint >> 8 & 0xf : 0
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0
  ORIGINAL[4]: context & 4
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 & 4
  ORIGINAL[5]: pos . constraint >> 8 & 0xf
  TYPE[5]: CALL
  TOKENIZED[5]: VAR1 . VAR2 >> 8 & 0xf
  ORIGINAL[6]: pos . constraint >> 8
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 . VAR2 >> 8
  ORIGINAL[7]: pos . constraint
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 . VAR2
  ORIGINAL[8]: constraint
  TYPE[8]: FIELD_IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: context
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: pos
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1

CENTER_NODE: 47244640363
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640352
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640882
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771238
FRAGMENT_COUNT: 5
  ORIGINAL[0]: memcmp(s1,s2,sizeof(charclass )) == 0
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) ) == 0
  ORIGINAL[1]: memcmp(s1,s2,sizeof(charclass ))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[2]: sizeof(charclass )
  TYPE[2]: CALL
  TOKENIZED[2]: sizeof ( VAR1 )
  ORIGINAL[3]: s1
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: s2
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 68719476998
FRAGMENT_COUNT: 13
  ORIGINAL[0]: cur_mb_len <= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 <= 0
  ORIGINAL[1]: cur_mb_len = 1
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = 1
  ORIGINAL[2]: --lexleft
  TYPE[2]: CALL
  TOKENIZED[2]: --lexleft
  ORIGINAL[3]: <global> lexleft
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: <global> lexleft
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: <global> lexleft
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: <global> VAR1
  ORIGINAL[6]: <global> lexleft
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: <global> lexleft
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: <global> VAR1
  ORIGINAL[8]: <global> lexleft
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: <global> VAR1
  ORIGINAL[9]: <global> lexleft
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: <global> VAR1
  ORIGINAL[10]: <global> lexleft
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: <global> VAR1
  ORIGINAL[11]: <global> lexleft
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: <global> VAR1
  ORIGINAL[12]: <global> lexleft
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: <global> VAR1

CENTER_NODE: 47244640321
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640654
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773053
FRAGMENT_COUNT: 8
  ORIGINAL[0]: tok != RPAREN && tok != OR && tok >= 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != VAR2 && VAR1 != VAR3 && VAR1 >= 0
  ORIGINAL[1]: tok != RPAREN && tok != OR
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 != VAR2 && VAR1 != VAR3
  ORIGINAL[2]: tok != RPAREN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 != VAR2
  ORIGINAL[3]: tok != OR
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 != VAR2
  ORIGINAL[4]: <global> tok
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: <global> VAR1
  ORIGINAL[5]: RPAREN
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: <global> tok
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: <global> VAR1
  ORIGINAL[7]: OR
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1

CENTER_NODE: 47244640875
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640927
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479860
FRAGMENT_COUNT: 4
  ORIGINAL[0]: *trickful_tusker = 0
  TYPE[0]: CALL
  TOKENIZED[0]: *trickful_tusker = 0
  ORIGINAL[1]: empty_string[] = \
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ ] = \
  ORIGINAL[2]: empty_string
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: empty_string
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064771189
FRAGMENT_COUNT: 1
  ORIGINAL[0]: utf8_anychar_classes[5]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ 5 ]

CENTER_NODE: 30064773039
FRAGMENT_COUNT: 23
  ORIGINAL[0]: tok == REPMN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok == REPMN && (minrep || maxrep)
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == VAR2 && ( VAR3 || VAR4 )
  ORIGINAL[2]: tok == REPMN
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 == VAR2
  ORIGINAL[3]: dfa -> tindex -= nsubtoks(dfa -> tindex)
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 -= FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[4]: dfa -> tindex
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: nsubtoks(dfa -> tindex)
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[6]: dfa -> tindex
  TYPE[6]: CALL
  TOKENIZED[6]: VAR1 -> VAR2
  ORIGINAL[7]: tok = lex()
  TYPE[7]: CALL
  TOKENIZED[7]: VAR1 = FUN1 ( )
  ORIGINAL[8]: lex()
  TYPE[8]: CALL
  TOKENIZED[8]: FUN1 ( )
  ORIGINAL[9]: closure()
  TYPE[9]: CALL
  TOKENIZED[9]: FUN1 ( )
  ORIGINAL[10]: addtok(tok)
  TYPE[10]: CALL
  TOKENIZED[10]: FUN1 ( VAR1 )
  ORIGINAL[11]: tok = lex()
  TYPE[11]: CALL
  TOKENIZED[11]: VAR1 = FUN1 ( )
  ORIGINAL[12]: lex()
  TYPE[12]: CALL
  TOKENIZED[12]: FUN1 ( )
  ORIGINAL[13]: tindex
  TYPE[13]: FIELD_IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: tindex
  TYPE[14]: FIELD_IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: <global> tok
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: <global> VAR1
  ORIGINAL[16]: <global> tok
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: <global> VAR1
  ORIGINAL[17]: REPMN
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: <global> dfa
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: <global> VAR1
  ORIGINAL[19]: <global> dfa
  TYPE[19]: IDENTIFIER
  TOKENIZED[19]: <global> VAR1
  ORIGINAL[20]: <global> tok
  TYPE[20]: IDENTIFIER
  TOKENIZED[20]: <global> VAR1
  ORIGINAL[21]: <global> tok
  TYPE[21]: IDENTIFIER
  TOKENIZED[21]: <global> VAR1
  ORIGINAL[22]: <global> tok
  TYPE[22]: IDENTIFIER
  TOKENIZED[22]: <global> VAR1

CENTER_NODE: 47244640872
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640836
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640837
FRAGMENT_COUNT: 1
  ORIGINAL[0]: for (;;)
  TYPE[0]: CONTROL_STRUCTURE
  TOKENIZED[0]: for ( ; ; )

CENTER_NODE: 68719479074
FRAGMENT_COUNT: 4
  ORIGINAL[0]: rval == TRANSIT_STATE_IN_PROGRESS
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: TRANSIT_STATE_IN_PROGRESS
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: rval
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: TRANSIT_STATE_IN_PROGRESS
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775371
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *mblen_buf)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *mblen_buf ) ) == 1
  ORIGINAL[1]: xmalloc((end - begin + 2))
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( ( VAR1 - VAR2 + 2 ) )
  ORIGINAL[2]: end - begin + 2
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 - VAR2 + 2
  ORIGINAL[3]: end - begin
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 - VAR2

CENTER_NODE: 30064774864
FRAGMENT_COUNT: 4
  ORIGINAL[0]: new_state >= d -> tralloc
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 >= VAR2 -> VAR3
  ORIGINAL[1]: d -> fails = (xnrealloc((d -> fails),(d -> tralloc),sizeof(( *d -> fails))))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 = ( FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) ) )
  ORIGINAL[2]: d -> fails
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: xnrealloc((d -> fails),(d -> tralloc),sizeof(( *d -> fails)))
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( ( VAR1 -> VAR2 ) , ( VAR1 -> VAR3 ) , sizeof ( ( *d -> VAR2 ) ) )

CENTER_NODE: 30064775661
FRAGMENT_COUNT: 14
  ORIGINAL[0]: i < d -> tindex
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: d -> tindex
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: ++i
  TYPE[2]: CALL
  TOKENIZED[2]: ++i
  ORIGINAL[3]: d -> tokens[i]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[4]: d -> tokens
  TYPE[4]: CALL
  TOKENIZED[4]: VAR1 -> VAR2
  ORIGINAL[5]: abort()
  TYPE[5]: CALL
  TOKENIZED[5]: FUN1 ( )
  ORIGINAL[6]: break;
  TYPE[6]: CONTROL_STRUCTURE
  TOKENIZED[6]: break ;
  ORIGINAL[7]: tindex
  TYPE[7]: FIELD_IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: i
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: d
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: i
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: i
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: ANYCHAR
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: MBCSET
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1

CENTER_NODE: 47244640751
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640342
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771194
FRAGMENT_COUNT: 3
  ORIGINAL[0]: 8 * sizeof(int )
  TYPE[0]: CALL
  TOKENIZED[0]: 8 * sizeof ( int )
  ORIGINAL[1]: sizeof(int )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( int )
  ORIGINAL[2]: int
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: int

CENTER_NODE: 47244640764
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640655
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640658
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640332
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640281
FRAGMENT_COUNT: 2
  ORIGINAL[0]: __ctype_get_mb_cur_max() > 1
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( ) > 1
  ORIGINAL[1]: else
  TYPE[1]: CONTROL_STRUCTURE
  TOKENIZED[1]: else

CENTER_NODE: 68719479642
FRAGMENT_COUNT: 3
  ORIGINAL[0]: dfainit(d)
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 )
  ORIGINAL[1]: d
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: d
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 47244640709
FRAGMENT_COUNT: 0

CENTER_NODE: 68719479817
FRAGMENT_COUNT: 6
  ORIGINAL[0]: new[i] != ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ] != ( ( void * ) 0 )
  ORIGINAL[1]: old = enlist(old,new[i],strlen(new[i]))
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[2]: enlist(old,new[i],strlen(new[i]))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 [ VAR3 ] , FUN2 ( VAR2 [ VAR3 ] ) )
  ORIGINAL[3]: old
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: old
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: old
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 68719479068
FRAGMENT_COUNT: 3
  ORIGINAL[0]: TRANSIT_STATE_DONE=1
  TYPE[0]: CALL
  TOKENIZED[0]: TRANSIT_STATE_DONE=1
  ORIGINAL[1]: TRANSIT_STATE_END_BUFFER=2
  TYPE[1]: CALL
  TOKENIZED[1]: TRANSIT_STATE_END_BUFFER=2
  ORIGINAL[2]: TRANSIT_STATE_END_BUFFER
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064773141
FRAGMENT_COUNT: 19
  ORIGINAL[0]: count = s -> nelem
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = VAR2 -> VAR3
  ORIGINAL[1]: s -> nelem
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: s -> nelem
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nelem
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: count
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: s
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: s
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: s
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: s
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: s
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: s
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: s
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: s
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1
  ORIGINAL[13]: s
  TYPE[13]: IDENTIFIER
  TOKENIZED[13]: VAR1
  ORIGINAL[14]: s
  TYPE[14]: IDENTIFIER
  TOKENIZED[14]: VAR1
  ORIGINAL[15]: s
  TYPE[15]: IDENTIFIER
  TOKENIZED[15]: VAR1
  ORIGINAL[16]: s
  TYPE[16]: IDENTIFIER
  TOKENIZED[16]: VAR1
  ORIGINAL[17]: s
  TYPE[17]: IDENTIFIER
  TOKENIZED[17]: VAR1
  ORIGINAL[18]: s
  TYPE[18]: IDENTIFIER
  TOKENIZED[18]: VAR1

CENTER_NODE: 30064774949
FRAGMENT_COUNT: 38
  ORIGINAL[0]: wc == ((wchar_t )eolbyte)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( VAR2 ) VAR3 )
  ORIGINAL[1]: wc == ((wchar_t )'\\0')
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 == ( ( VAR2 ) '\\0' )
  ORIGINAL[2]: (wchar_t )'\\0'
  TYPE[2]: CALL
  TOKENIZED[2]: ( VAR1 ) '\\0'
  ORIGINAL[3]: syntax_bits & ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 & ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[4]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[4]: CALL
  TOKENIZED[4]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[5]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1 << 1
  TYPE[5]: CALL
  TOKENIZED[5]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1 << 1
  ORIGINAL[6]: ((unsigned long )1) << 1 << 1 << 1 << 1 << 1
  TYPE[6]: CALL
  TOKENIZED[6]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1 << 1
  ORIGINAL[7]: ((unsigned long )1) << 1 << 1 << 1 << 1
  TYPE[7]: CALL
  TOKENIZED[7]: ( ( unsigned long ) 1 ) << 1 << 1 << 1 << 1
  ORIGINAL[8]: ((unsigned long )1) << 1 << 1 << 1
  TYPE[8]: CALL
  TOKENIZED[8]: ( ( unsigned long ) 1 ) << 1 << 1 << 1
  ORIGINAL[9]: ((unsigned long )1) << 1 << 1
  TYPE[9]: CALL
  TOKENIZED[9]: ( ( unsigned long ) 1 ) << 1 << 1
  ORIGINAL[10]: ((unsigned long )1) << 1
  TYPE[10]: CALL
  TOKENIZED[10]: ( ( unsigned long ) 1 ) << 1
  ORIGINAL[11]: (unsigned long )1
  TYPE[11]: CALL
  TOKENIZED[11]: ( unsigned long ) 1
  ORIGINAL[12]: context = wchar_context(wc)
  TYPE[12]: CALL
  TOKENIZED[12]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[13]: wchar_context(wc)
  TYPE[13]: CALL
  TOKENIZED[13]: FUN1 ( VAR1 )
  ORIGINAL[14]: !((((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context)
  TYPE[14]: CALL
  TOKENIZED[14]: ! ( ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1 )
  ORIGINAL[15]: (((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))) & d -> states[s] . context
  TYPE[15]: CALL
  TOKENIZED[15]: ( ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) ) ) & VAR3 -> VAR4 [ VAR5 ] . VAR1
  ORIGINAL[16]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0)) | ((context & 4?pos . constraint >> 8 & 0xf : 0))
  TYPE[16]: CALL
  TOKENIZED[16]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) ) | ( ( VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0 ) )
  ORIGINAL[17]: ((context & 1?pos . constraint & 0xf : 0)) | ((context & 2?pos . constraint >> 4 & 0xf : 0))
  TYPE[17]: CALL
  TOKENIZED[17]: ( ( VAR1 & 1?pos . VAR2 & 0xf : 0 ) ) | ( ( VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0 ) )
  ORIGINAL[18]: context & 1?pos . constraint & 0xf : 0
  TYPE[18]: CALL
  TOKENIZED[18]: VAR1 & 1?pos . VAR2 & 0xf : 0
  ORIGINAL[19]: context & 1
  TYPE[19]: CALL
  TOKENIZED[19]: VAR1 & 1
  ORIGINAL[20]: context & 2?pos . constraint >> 4 & 0xf : 0
  TYPE[20]: CALL
  TOKENIZED[20]: VAR1 & 2?pos . VAR2 >> 4 & 0xf : 0
  ORIGINAL[21]: context & 2
  TYPE[21]: CALL
  TOKENIZED[21]: VAR1 & 2
  ORIGINAL[22]: context & 4?pos . constraint >> 8 & 0xf : 0
  TYPE[22]: CALL
  TOKENIZED[22]: VAR1 & 4?pos . VAR2 >> 8 & 0xf : 0
  ORIGINAL[23]: context & 4
  TYPE[23]: CALL
  TOKENIZED[23]: VAR1 & 4
  ORIGINAL[24]: d -> states[s] . context
  TYPE[24]: CALL
  TOKENIZED[24]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[25]: d -> states[s]
  TYPE[25]: CALL
  TOKENIZED[25]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[26]: d -> states
  TYPE[26]: CALL
  TOKENIZED[26]: VAR1 -> VAR2
  ORIGINAL[27]: states
  TYPE[27]: FIELD_IDENTIFIER
  TOKENIZED[27]: VAR1
  ORIGINAL[28]: context
  TYPE[28]: FIELD_IDENTIFIER
  TOKENIZED[28]: VAR1
  ORIGINAL[29]: wc
  TYPE[29]: IDENTIFIER
  TOKENIZED[29]: VAR1
  ORIGINAL[30]: <global> syntax_bits
  TYPE[30]: IDENTIFIER
  TOKENIZED[30]: <global> VAR1
  ORIGINAL[31]: context
  TYPE[31]: IDENTIFIER
  TOKENIZED[31]: VAR1
  ORIGINAL[32]: wc
  TYPE[32]: IDENTIFIER
  TOKENIZED[32]: VAR1
  ORIGINAL[33]: context
  TYPE[33]: IDENTIFIER
  TOKENIZED[33]: VAR1
  ORIGINAL[34]: context
  TYPE[34]: IDENTIFIER
  TOKENIZED[34]: VAR1
  ORIGINAL[35]: context
  TYPE[35]: IDENTIFIER
  TOKENIZED[35]: VAR1
  ORIGINAL[36]: d
  TYPE[36]: IDENTIFIER
  TOKENIZED[36]: VAR1
  ORIGINAL[37]: s
  TYPE[37]: IDENTIFIER
  TOKENIZED[37]: VAR1

CENTER_NODE: 47244640601
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640397
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640769
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771213
FRAGMENT_COUNT: 4
  ORIGINAL[0]: c[b / (8 * sizeof(int ))] &= ~(1 << b % (8 * sizeof(int )))
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ] &= ~ ( 1 << VAR2 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[1]: c[b / (8 * sizeof(int ))]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 [ VAR2 / ( 8 * sizeof ( int ) ) ]
  ORIGINAL[2]: ~(1 << b % (8 * sizeof(int )))
  TYPE[2]: CALL
  TOKENIZED[2]: ~ ( 1 << VAR1 % ( 8 * sizeof ( int ) ) )
  ORIGINAL[3]: 1 << b % (8 * sizeof(int ))
  TYPE[3]: CALL
  TOKENIZED[3]: 1 << VAR1 % ( 8 * sizeof ( int ) )

CENTER_NODE: 30064773374
FRAGMENT_COUNT: 6
  ORIGINAL[0]: s -> elems[j] . constraint != d -> states[i] . elems . elems[j] . constraint
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ] . VAR4 != VAR5 -> VAR6 [ VAR7 ] . VAR2 . VAR2 [ VAR3 ] . VAR4
  ORIGINAL[1]: d -> states[i] . elems . elems[j]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4 [ VAR5 ]
  ORIGINAL[2]: d -> states[i] . elems . elems
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ] . VAR4 . VAR4
  ORIGINAL[3]: d -> states[i] . elems
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2 [ VAR3 ] . VAR4
  ORIGINAL[4]: elems
  TYPE[4]: FIELD_IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: j
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640757
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640422
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640755
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640900
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640407
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640543
FRAGMENT_COUNT: 0

CENTER_NODE: 30064772904
FRAGMENT_COUNT: 4
  ORIGINAL[0]: work_mbc -> invert || !using_utf8() && work_mbc -> cset != (- 1) || work_mbc -> nchars != 0 || work_mbc -> nch_classes != 0 || work_mbc -> nranges != 0 || work_mbc -> nequivs != 0 || work_mbc -> ncoll_elems != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 || !using_utf8 ( ) && VAR1 -> VAR3 != ( - 1 ) || VAR1 -> VAR4 != 0 || VAR1 -> VAR5 != 0 || VAR1 -> VAR6 != 0 || VAR1 -> VAR7 != 0 || VAR1 -> VAR8 != 0
  ORIGINAL[1]: dfa -> nmbcsets - 1 << 2
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2 - 1 << 2
  ORIGINAL[2]: dfa -> nmbcsets - 1
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 - 1
  ORIGINAL[3]: dfa -> nmbcsets
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640545
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773132
FRAGMENT_COUNT: 5
  ORIGINAL[0]: sizeof(( *s -> elems)) == 1?xmalloc(size) : xnmalloc(size,sizeof(( *s -> elems)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *s -> VAR1 ) ) == 1?xmalloc ( VAR2 ) : FUN1 ( VAR2 , sizeof ( ( *s -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *s -> elems)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *s -> VAR1 ) ) == 1
  ORIGINAL[2]: xnmalloc(size,sizeof(( *s -> elems)))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , sizeof ( ( *s -> VAR2 ) ) )
  ORIGINAL[3]: sizeof(( *s -> elems))
  TYPE[3]: CALL
  TOKENIZED[3]: sizeof ( ( *s -> VAR1 ) )
  ORIGINAL[4]: size
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 30064773792
FRAGMENT_COUNT: 6
  ORIGINAL[0]: d -> tokens[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[1]: pos = lastpos + nlastpos[- 1]
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = VAR2 + VAR3 [ - 1 ]
  ORIGINAL[2]: lastpos + nlastpos[- 1]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 + VAR2 [ - 1 ]
  ORIGINAL[3]: nlastpos[- 1]
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 [ - 1 ]
  ORIGINAL[4]: pos
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: lastpos
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640440
FRAGMENT_COUNT: 0

CENTER_NODE: 30064775146
FRAGMENT_COUNT: 7
  ORIGINAL[0]: sizeof(( *rarray)) == 1
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *rarray ) ) == 1
  ORIGINAL[1]: sizeof(( *rarray))
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *rarray ) )
  ORIGINAL[2]: *rarray
  TYPE[2]: CALL
  TOKENIZED[2]: *rarray
  ORIGINAL[3]: rarray
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: rarray
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: rarray
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: rarray
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 30064775630
FRAGMENT_COUNT: 4
  ORIGINAL[0]: sizeof(( *d -> multibyte_prop)) == 1?xmalloc(d -> nmultibyte_prop) : xnmalloc(d -> nmultibyte_prop,sizeof(( *d -> multibyte_prop)))
  TYPE[0]: CALL
  TOKENIZED[0]: sizeof ( ( *d -> VAR1 ) ) == 1?xmalloc ( VAR2 -> VAR3 ) : FUN1 ( VAR2 -> VAR3 , sizeof ( ( *d -> VAR1 ) ) )
  ORIGINAL[1]: sizeof(( *d -> multibyte_prop)) == 1
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( ( *d -> VAR1 ) ) == 1
  ORIGINAL[2]: xmalloc(d -> nmultibyte_prop)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 -> VAR2 )
  ORIGINAL[3]: d -> nmultibyte_prop
  TYPE[3]: CALL
  TOKENIZED[3]: VAR1 -> VAR2

CENTER_NODE: 47244640430
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640677
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476804
FRAGMENT_COUNT: 7
  ORIGINAL[0]: stonesoup_tainted_file != 0
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 != 0
  ORIGINAL[1]: fseek(stonesoup_tainted_file,0L,2)
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , 0L , 2 )
  ORIGINAL[2]: stonesoup_lsize = ftell(stonesoup_tainted_file)
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 = FUN1 ( VAR2 )
  ORIGINAL[3]: ftell(stonesoup_tainted_file)
  TYPE[3]: CALL
  TOKENIZED[3]: FUN1 ( VAR1 )
  ORIGINAL[4]: stonesoup_lsize
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: stonesoup_tainted_file
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: stonesoup_lsize
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1

CENTER_NODE: 47244640623
FRAGMENT_COUNT: 0

CENTER_NODE: 30064771218
FRAGMENT_COUNT: 4
  ORIGINAL[0]: memcpy(dst,src,sizeof(charclass ))
  TYPE[0]: CALL
  TOKENIZED[0]: FUN1 ( VAR1 , VAR2 , sizeof ( VAR3 ) )
  ORIGINAL[1]: sizeof(charclass )
  TYPE[1]: CALL
  TOKENIZED[1]: sizeof ( VAR1 )
  ORIGINAL[2]: dst
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: src
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064772963
FRAGMENT_COUNT: 4
  ORIGINAL[0]: tok == LPAREN
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == VAR2
  ORIGINAL[1]: tok = lex()
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 = FUN1 ( )
  ORIGINAL[2]: regexp()
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( )
  ORIGINAL[3]: <global> tok
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1

CENTER_NODE: 68719476950
FRAGMENT_COUNT: 4
  ORIGINAL[0]: utf8 = - 1
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 = - 1
  ORIGINAL[1]: - 1
  TYPE[1]: CALL
  TOKENIZED[1]: - 1
  ORIGINAL[2]: utf8
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: utf8
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1

CENTER_NODE: 30064775847
FRAGMENT_COUNT: 13
  ORIGINAL[0]: ( *lcp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *lcp ) != '\\0'
  ORIGINAL[1]: *lcp
  TYPE[1]: CALL
  TOKENIZED[1]: *lcp
  ORIGINAL[2]: strchr(right,( *lcp))
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , ( *lcp ) )
  ORIGINAL[3]: *lcp
  TYPE[3]: CALL
  TOKENIZED[3]: *lcp
  ORIGINAL[4]: *lcp
  TYPE[4]: CALL
  TOKENIZED[4]: *lcp
  ORIGINAL[5]: lcp
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: lcp
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: right
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: lcp
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1
  ORIGINAL[9]: lcp
  TYPE[9]: IDENTIFIER
  TOKENIZED[9]: VAR1
  ORIGINAL[10]: lcp
  TYPE[10]: IDENTIFIER
  TOKENIZED[10]: VAR1
  ORIGINAL[11]: lcp
  TYPE[11]: IDENTIFIER
  TOKENIZED[11]: VAR1
  ORIGINAL[12]: lcp
  TYPE[12]: IDENTIFIER
  TOKENIZED[12]: VAR1

CENTER_NODE: 47244640379
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476821
FRAGMENT_COUNT: 1
  ORIGINAL[0]: ch
  TYPE[0]: IDENTIFIER
  TOKENIZED[0]: VAR1

CENTER_NODE: 30064775560
FRAGMENT_COUNT: 5
  ORIGINAL[0]: j < p -> nequivs
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 < VAR2 -> VAR3
  ORIGINAL[1]: free(p -> equivs[j])
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 -> VAR2 [ VAR3 ] )
  ORIGINAL[2]: p -> equivs[j]
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2 [ VAR3 ]
  ORIGINAL[3]: for (j = 0;j < p -> nequivs;++j)
  TYPE[3]: CONTROL_STRUCTURE
  TOKENIZED[3]: for ( VAR1 = 0 ; VAR1 < VAR2 -> VAR3 ; ++j )
  ORIGINAL[4]: j
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

CENTER_NODE: 47244640679
FRAGMENT_COUNT: 0

CENTER_NODE: 30064773089
FRAGMENT_COUNT: 9
  ORIGINAL[0]: END - d -> nregexps
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 - VAR2 -> VAR3
  ORIGINAL[1]: d -> nregexps
  TYPE[1]: CALL
  TOKENIZED[1]: VAR1 -> VAR2
  ORIGINAL[2]: d -> nregexps
  TYPE[2]: CALL
  TOKENIZED[2]: VAR1 -> VAR2
  ORIGINAL[3]: nregexps
  TYPE[3]: FIELD_IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: d
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: END
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1
  ORIGINAL[6]: d
  TYPE[6]: IDENTIFIER
  TOKENIZED[6]: VAR1
  ORIGINAL[7]: d
  TYPE[7]: IDENTIFIER
  TOKENIZED[7]: VAR1
  ORIGINAL[8]: d
  TYPE[8]: IDENTIFIER
  TOKENIZED[8]: VAR1

CENTER_NODE: 30064775739
FRAGMENT_COUNT: 3
  ORIGINAL[0]: new == ((void *)0)
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 == ( ( void * ) 0 )
  ORIGINAL[1]: (void *)0
  TYPE[1]: CALL
  TOKENIZED[1]: ( void * ) 0
  ORIGINAL[2]: new
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1

CENTER_NODE: 30064775758
FRAGMENT_COUNT: 6
  ORIGINAL[0]: ( *cp) != '\\0'
  TYPE[0]: CALL
  TOKENIZED[0]: ( *cp ) != '\\0'
  ORIGINAL[1]: strncmp(cp,lookfor,len) == 0
  TYPE[1]: CALL
  TOKENIZED[1]: FUN1 ( VAR1 , VAR2 , VAR3 ) == 0
  ORIGINAL[2]: strncmp(cp,lookfor,len)
  TYPE[2]: CALL
  TOKENIZED[2]: FUN1 ( VAR1 , VAR2 , VAR3 )
  ORIGINAL[3]: cp
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: VAR1
  ORIGINAL[4]: lookfor
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1
  ORIGINAL[5]: len
  TYPE[5]: IDENTIFIER
  TOKENIZED[5]: VAR1

CENTER_NODE: 47244640441
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640349
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640976
FRAGMENT_COUNT: 0

CENTER_NODE: 47244640811
FRAGMENT_COUNT: 0

CENTER_NODE: 68719476961
FRAGMENT_COUNT: 5
  ORIGINAL[0]: prednames[i]
  TYPE[0]: CALL
  TOKENIZED[0]: VAR1 [ VAR2 ]
  ORIGINAL[1]: i
  TYPE[1]: IDENTIFIER
  TOKENIZED[1]: VAR1
  ORIGINAL[2]: i
  TYPE[2]: IDENTIFIER
  TOKENIZED[2]: VAR1
  ORIGINAL[3]: <global> prednames
  TYPE[3]: IDENTIFIER
  TOKENIZED[3]: <global> VAR1
  ORIGINAL[4]: i
  TYPE[4]: IDENTIFIER
  TOKENIZED[4]: VAR1

