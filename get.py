import requests
import os
import zipfile
import json
from io import BytesIO
# Thay Ä‘á»•i biáº¿n nÃ y Ä‘á»ƒ láº¥y dá»¯ liá»‡u cho ngÃ´n ngá»¯ khÃ¡c
LANGUAGE = "c" 

# CÃ¡c folder
zip_dir = f"data_{LANGUAGE}/zips"
unzip_dir = f"data_{LANGUAGE}/unzips"
json_dir = f"data_{LANGUAGE}/json"
summary_file = f"data_{LANGUAGE}/summary.json"

# Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
os.makedirs(zip_dir, exist_ok=True)
os.makedirs(unzip_dir, exist_ok=True)
os.makedirs(json_dir, exist_ok=True)

url = "https://samate.nist.gov/SARD/api/test-cases/search"

# Target
total_target = 4000
good_target = total_target // 2  # 2000 good
bad_target = total_target // 2   # 2000 bad

good_list = []
bad_list = []
summary = []  # nÆ¡i lÆ°u thÃ´ng tin summary

page = 1
limit_per_page = 100  # láº¥y má»—i láº§n nhiá»u testcase hÆ¡n

# ======== Giai Ä‘oáº¡n 1: Search + GET json =========
while len(good_list) < good_target:
    params = {
        "language[]": LANGUAGE,
        "state[]": ["good"],  # ğŸ¯ ban Ä‘áº§u chá»‰ láº¥y good vÃ  bad
        "page": page,
        "limit": limit_per_page
    }
    response = requests.get(url, params=params)
    data = response.json()

    testcases = data.get('testCases', [])
    if not testcases:
        print(f"âš ï¸ KhÃ´ng cÃ²n testcases good á»Ÿ page {page}, dá»«ng láº¡i.")
        break

    print(f"âœ… Page {page} â€” tÃ¬m Ä‘Æ°á»£c {len(testcases)} testcases.")

    # Save JSON page
    json_path = os.path.join(json_dir, f"data-good-{page}.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    for test_case in testcases:
        download_url = test_case.get('download')
        identifier = test_case.get('identifier')

        if not download_url or not identifier:
            continue

        # Láº¥y state tá»« properties
        try:
            sarif = test_case.get('sarif', {})
            runs = sarif.get('runs', [])
            if runs:
                properties = runs[0].get('properties', {})
                state = properties.get('state')
            else:
                state = None
        except Exception as e:
            state = None

        if state == 'good' and len(good_list) < good_target:
            good_list.append((identifier, download_url, state))
        if len(good_list) >= good_target:
            break
    page += 1
page = 1
print(f"\nğŸ“Š Sau bÆ°á»›c 1: GOOD={len(good_list)}, BAD={len(bad_list)}")
# ======== Giai Ä‘oáº¡n 2: Search + GET json BAD=========
while len(bad_list) < bad_target:
    params = {
        "language[]": LANGUAGE,
        "state[]": ["bad"],  # ğŸ¯ ban Ä‘áº§u chá»‰ láº¥y good vÃ  bad
        "page": page,
        "limit": limit_per_page
    }
    response = requests.get(url, params=params)
    data = response.json()

    testcases = data.get('testCases', [])
    if not testcases:
        print(f"âš ï¸ KhÃ´ng cÃ²n testcases bad á»Ÿ page {page}, dá»«ng láº¡i.")
        break

    print(f"âœ… Page {page} â€” tÃ¬m Ä‘Æ°á»£c {len(testcases)} testcases.")

    # Save JSON page
    json_path = os.path.join(json_dir, f"data-bad-{page}.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    for test_case in testcases:
        download_url = test_case.get('download')
        identifier = test_case.get('identifier')

        if not download_url or not identifier:
            continue

        # Láº¥y state tá»« properties
        try:
            sarif = test_case.get('sarif', {})
            runs = sarif.get('runs', [])
            if runs:
                properties = runs[0].get('properties', {})
                state = properties.get('state')
            else:
                state = None
        except Exception as e:
            state = None

        if state == 'bad' and len(bad_list) < bad_target:
            bad_list.append((identifier, download_url, state))
        if len(bad_list) >= bad_target:
            break
    page += 1

print(f"\nğŸ“Š Sau bÆ°á»›c 2: GOOD={len(good_list)}, BAD={len(bad_list)}")

# ======= Giai Ä‘oáº¡n 3: Náº¿u thiáº¿u thÃ¬ láº¥y thÃªm mixed =========
if len(good_list) < good_target or len(bad_list) < bad_target:
    print("\nğŸ”„ KhÃ´ng Ä‘á»§, tiáº¿p tá»¥c search 'mixed' Ä‘á»ƒ bÃ¹...")
    page_mixed = 1
    while (len(good_list) + len(bad_list)) < total_target:
        print(len(good_list) + len(bad_list))
        params = {
            "language[]": LANGUAGE,
            "state[]": ["mixed"], 
            "page": page_mixed,
            "limit": limit_per_page
        }
        response = requests.get(url, params=params)
        data = response.json()

        testcases = data.get('testCases', [])
        if not testcases:
            print(f"âš ï¸ KhÃ´ng cÃ²n testcase mixed á»Ÿ page {page_mixed}, dá»«ng láº¡i.")
            break

        print(f"âœ… [MIXED] Page {page_mixed} â€” tÃ¬m Ä‘Æ°á»£c {len(testcases)} testcases.")

        json_path = os.path.join(json_dir, f"data-mixed-{page_mixed}.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        for test_case in testcases:
            download_url = test_case.get('download')
            identifier = test_case.get('identifier')

            if not download_url or not identifier:
                continue

            # DÃ¡n state="mixed"
            state = "mixed"

            if len(good_list) < good_target:
                good_list.append((identifier, download_url, state))
            elif len(bad_list) < bad_target:
                bad_list.append((identifier, download_url, state))

            # ğŸ¯ Check tá»•ng sá»‘ lÆ°á»£ng Ä‘Ã£ Ä‘á»§ chÆ°a
            if (len(good_list) + len(bad_list)) >= total_target:
                break  # Ä‘á»§ rá»“i thÃ¬ thoÃ¡t for loop luÃ´n
        page_mixed += 1

print(f"\nâœ… ÄÃ£ collect Ä‘á»§: GOOD={len(good_list)}, BAD={len(bad_list)} (bao gá»“m má»™t pháº§n mixed náº¿u cáº§n)")
# ======== Giai Ä‘oáº¡n 3: Download + Unzip =========

total_downloaded = 0
print("\nğŸš› Báº¯t Ä‘áº§u táº£i file zip...")

for group_name, case_list in [('good', good_list), ('bad', bad_list)]:
    for identifier, download_url, state in case_list:
        try:
            zip_filename = download_url.split("/")[-1]
            zip_path = os.path.join(zip_dir, zip_filename)
            unzip_path = os.path.join(unzip_dir, identifier)

            # Download file zip
            zip_response = requests.get(download_url)
            zip_response.raise_for_status()

            # LÆ°u file zip
            with open(zip_path, 'wb') as f:
                f.write(zip_response.content)

            # Giáº£i nÃ©n
            os.makedirs(unzip_path, exist_ok=True)
            with zipfile.ZipFile(BytesIO(zip_response.content)) as zip_ref:
                zip_ref.extractall(unzip_path)

            total_downloaded += 1

            # Ghi thÃ´ng tin vÃ o summary
            summary.append({
                "id": identifier,
                "state": state,
                "path": os.path.abspath(unzip_path)
            })

            if total_downloaded % 50 == 0:
                print(f"âœ… ÄÃ£ táº£i {total_downloaded} testcase")

        except Exception as e:
            print(f"âŒ Lá»—i vá»›i {identifier}: {e}")

# ======== Giai Ä‘oáº¡n 3: Save Summary =========

with open(summary_file, "w", encoding="utf-8") as f:
    json.dump(summary, f, ensure_ascii=False, indent=2)

print(f"\nğŸ“ ÄÃ£ ghi metadata vÃ o {summary_file}")
print(f"\nğŸ”š HoÃ n thÃ nh! Tá»•ng sá»‘ testcases Ä‘Ã£ táº£i: {total_downloaded}")
